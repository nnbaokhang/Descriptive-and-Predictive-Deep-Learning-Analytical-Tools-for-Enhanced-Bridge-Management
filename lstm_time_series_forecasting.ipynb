{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the Python version being used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.6\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check that the available gpu is being utilized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available\")\n",
    "print(len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in clustering dataset, note that this one is still missing the aggregated weather data, but this can easily be added in later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "\n",
    "df = read_csv('Time_Series_For_Clustering_El_Paso_Final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bridge_ID</th>\n",
       "      <th>time_0</th>\n",
       "      <th>time_1</th>\n",
       "      <th>time_2</th>\n",
       "      <th>time_3</th>\n",
       "      <th>time_4</th>\n",
       "      <th>time_5</th>\n",
       "      <th>time_6</th>\n",
       "      <th>time_7</th>\n",
       "      <th>time_8</th>\n",
       "      <th>...</th>\n",
       "      <th>time_12</th>\n",
       "      <th>time_13</th>\n",
       "      <th>time_14</th>\n",
       "      <th>time_15</th>\n",
       "      <th>time_16</th>\n",
       "      <th>time_17</th>\n",
       "      <th>time_18</th>\n",
       "      <th>time_19</th>\n",
       "      <th>time_20</th>\n",
       "      <th>time_21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.12E+13</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CALHAN-8TH ST.</td>\n",
       "      <td>[36.0, 97.0, 428, 1949, 2, 10.9, 7.3]</td>\n",
       "      <td>[36.0, 96.9, 955, 1949, 2, 10.9, 7.3]</td>\n",
       "      <td>[36.0, 96.9, 955, 1949, 2, 10.9, 7.3]</td>\n",
       "      <td>[36.0, 96.9, 955, 1949, 2, 10.9, 7.3]</td>\n",
       "      <td>[36.0, 96.9, 955, 1949, 2, 10.9, 7.3]</td>\n",
       "      <td>[36.3, 97.0, 955, 1949, 2, 11.0, 7.0]</td>\n",
       "      <td>[36.3, 96.9, 955, 1949, 2, 11.0, 7.3]</td>\n",
       "      <td>[36.3, 96.9, 983, 1949, 2, 11.0, 7.3]</td>\n",
       "      <td>[36.3, 96.9, 983, 1949, 2, 11.0, 7.3]</td>\n",
       "      <td>...</td>\n",
       "      <td>[36.3, 97.0, 422, 1949, 2, 11.0, 7.3]</td>\n",
       "      <td>[36.3, 97.0, 422, 1949, 2, 11.0, 7.3]</td>\n",
       "      <td>[36.3, 97.0, 422, 1949, 2, 11.0, 7.3]</td>\n",
       "      <td>[36.3, 97.0, 422, 1949, 2, 9.7, 7.3]</td>\n",
       "      <td>[36.3, 97.0, 369, 1949, 2, 9.7, 7.3]</td>\n",
       "      <td>[36.3, 86.0, 369, 1949, 2, 9.7, 7.3]</td>\n",
       "      <td>[36.3, 86.0, 369, 1949, 2, 9.7, 7.3]</td>\n",
       "      <td>[36.3, 86.0, 369, 1949, 2, 9.7, 7.3]</td>\n",
       "      <td>[36.3, 86.0, 369, 1949, 2, 9.7, 7.3]</td>\n",
       "      <td>[36.3, 86.0, 522, 1949, 2, 9.7, 7.3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CSG-C.80-07.65</td>\n",
       "      <td>[36.0, 83.9, 417, 1970, 2, 6.6, 6.4]</td>\n",
       "      <td>[36.0, 70.9, 351, 1970, 2, 6.6, 3.0]</td>\n",
       "      <td>[36.0, 70.9, 351, 1970, 2, 6.6, 3.0]</td>\n",
       "      <td>[36.0, 70.9, 351, 1970, 2, 6.6, 3.0]</td>\n",
       "      <td>[36.0, 70.9, 351, 1970, 2, 6.6, 3.0]</td>\n",
       "      <td>[36.3, 76.0, 351, 1970, 2, 6.6, 3.0]</td>\n",
       "      <td>[36.3, 69.0, 351, 1970, 2, 6.6, 3.0]</td>\n",
       "      <td>[36.3, 66.9, 478, 1970, 2, 6.6, 2.9]</td>\n",
       "      <td>[36.3, 66.9, 478, 1970, 2, 6.6, 2.9]</td>\n",
       "      <td>...</td>\n",
       "      <td>[36.3, 62.9, 478, 1970, 2, 6.6, 2.9]</td>\n",
       "      <td>[36.3, 62.9, 777, 1970, 2, 6.6, 2.9]</td>\n",
       "      <td>[36.3, 62.9, 777, 1970, 2, 6.6, 2.9]</td>\n",
       "      <td>[36.3, 62.9, 777, 1970, 2, 6.6, 2.9]</td>\n",
       "      <td>[36.3, 62.9, 623, 1970, 2, 6.6, 2.9]</td>\n",
       "      <td>[36.3, 62.9, 623, 1970, 2, 6.6, 2.9]</td>\n",
       "      <td>[36.3, 62.9, 623, 1970, 2, 6.6, 2.9]</td>\n",
       "      <td>[32.7, 55.7, 623, 1970, 2, 6.6, 2.9]</td>\n",
       "      <td>[32.7, 55.7, 623, 1970, 2, 6.6, 2.9]</td>\n",
       "      <td>[32.7, 55.7, 717, 1970, 2, 6.6, 2.9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CSG-D.04-10.42</td>\n",
       "      <td>[36.0, 82.0, 1836, 1955, 2, 7.6, 4.0]</td>\n",
       "      <td>[36.0, 84.3, 1459, 1955, 2, 7.7, 4.0]</td>\n",
       "      <td>[36.0, 84.3, 1459, 1955, 2, 7.7, 4.0]</td>\n",
       "      <td>[36.0, 84.3, 1459, 1955, 2, 7.7, 4.0]</td>\n",
       "      <td>[36.0, 84.3, 1459, 1955, 2, 7.7, 3.4]</td>\n",
       "      <td>[36.3, 83.4, 1459, 1955, 2, 7.7, 3.0]</td>\n",
       "      <td>[36.3, 84.3, 1459, 1955, 2, 7.7, 3.4]</td>\n",
       "      <td>[36.3, 84.4, 1295, 1955, 2, 7.7, 3.4]</td>\n",
       "      <td>[36.3, 84.4, 1295, 1955, 2, 7.7, 3.4]</td>\n",
       "      <td>...</td>\n",
       "      <td>[36.3, 72.3, 1295, 1955, 2, 7.7, 3.4]</td>\n",
       "      <td>[36.3, 72.3, 1329, 1955, 2, 7.7, 3.4]</td>\n",
       "      <td>[36.3, 72.3, 1329, 1955, 2, 7.7, 3.4]</td>\n",
       "      <td>[36.3, 72.3, 1329, 1955, 2, 7.7, 3.4]</td>\n",
       "      <td>[36.3, 72.3, 1446, 1955, 2, 7.7, 3.4]</td>\n",
       "      <td>[36.3, 72.3, 1446, 1955, 2, 7.7, 3.4]</td>\n",
       "      <td>[36.3, 72.3, 1446, 1955, 2, 7.7, 3.4]</td>\n",
       "      <td>[27.2, 50.2, 1446, 1955, 2, 7.7, 3.4]</td>\n",
       "      <td>[27.2, 50.2, 1446, 1955, 2, 7.7, 3.4]</td>\n",
       "      <td>[27.2, 50.2, 2696, 1955, 2, 7.7, 3.4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CSG-D.37-15.67</td>\n",
       "      <td>[36.0, 97.0, 87, 1984, 2, 12.8, 3.0]</td>\n",
       "      <td>[36.0, 97.0, 305, 1984, 2, 12.8, 3.0]</td>\n",
       "      <td>[36.0, 97.0, 305, 1984, 2, 12.8, 3.0]</td>\n",
       "      <td>[36.0, 97.0, 305, 1984, 2, 12.8, 3.0]</td>\n",
       "      <td>[36.0, 97.0, 305, 1984, 2, 12.8, 3.0]</td>\n",
       "      <td>[36.3, 97.0, 305, 1984, 2, 12.8, 3.0]</td>\n",
       "      <td>[36.3, 97.0, 305, 1984, 2, 12.8, 3.0]</td>\n",
       "      <td>[36.3, 97.0, 397, 1984, 2, 12.8, 3.0]</td>\n",
       "      <td>[36.3, 97.0, 397, 1984, 2, 12.8, 3.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>[36.3, 98.0, 397, 1984, 2, 13.3, 3.0]</td>\n",
       "      <td>[36.3, 98.0, 287, 1984, 2, 13.3, 3.0]</td>\n",
       "      <td>[36.3, 98.0, 287, 1984, 2, 13.3, 3.0]</td>\n",
       "      <td>[36.3, 99.0, 287, 1984, 2, 12.8, 3.0]</td>\n",
       "      <td>[36.3, 99.0, 302, 1984, 2, 12.8, 3.0]</td>\n",
       "      <td>[36.3, 100.0, 302, 1984, 2, 12.8, 3.0]</td>\n",
       "      <td>[36.3, 100.0, 302, 1984, 2, 12.8, 3.0]</td>\n",
       "      <td>[36.3, 100.0, 302, 1984, 2, 12.8, 3.0]</td>\n",
       "      <td>[36.3, 100.0, 302, 1984, 2, 12.8, 3.0]</td>\n",
       "      <td>[36.3, 100.0, 268, 1984, 2, 12.8, 3.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>I-17-G</td>\n",
       "      <td>[87.3, 82.0, 13500, 1942, 0, 10.9, 14.0]</td>\n",
       "      <td>[87.3, 82.0, 13500, 1942, 0, 10.9, 14.0]</td>\n",
       "      <td>[87.3, 82.0, 13500, 1942, 0, 10.9, 14.0]</td>\n",
       "      <td>[87.3, 82.0, 13500, 1942, 0, 10.9, 14.0]</td>\n",
       "      <td>[87.3, 82.0, 13500, 1942, 0, 10.9, 14.0]</td>\n",
       "      <td>[87.3, 82.0, 13500, 1942, 0, 10.9, 14.0]</td>\n",
       "      <td>[87.3, 82.0, 13500, 1942, 0, 10.9, 14.0]</td>\n",
       "      <td>[87.3, 82.0, 13500, 1942, 0, 10.9, 14.0]</td>\n",
       "      <td>[87.3, 82.0, 39228, 1972, 0, 24.1, 26.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>[87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]</td>\n",
       "      <td>[87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]</td>\n",
       "      <td>[87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]</td>\n",
       "      <td>[87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]</td>\n",
       "      <td>[87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]</td>\n",
       "      <td>[87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]</td>\n",
       "      <td>[87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]</td>\n",
       "      <td>[87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]</td>\n",
       "      <td>[87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]</td>\n",
       "      <td>[87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>I-17-HK</td>\n",
       "      <td>[87.3, 82.0, 38400, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>...</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>I-17-JH</td>\n",
       "      <td>[87.3, 82.0, 10500, 1995, 0, 12.9, 20.7]</td>\n",
       "      <td>[87.3, 82.0, 32904, 1995, 0, 12.9, 20.7]</td>\n",
       "      <td>[87.3, 82.0, 32904, 1995, 0, 12.9, 20.7]</td>\n",
       "      <td>[87.3, 82.0, 32904, 1995, 0, 12.9, 20.7]</td>\n",
       "      <td>[87.3, 82.0, 36024, 1995, 0, 12.1, 20.7]</td>\n",
       "      <td>[87.3, 82.0, 36024, 1995, 0, 12.2, 21.0]</td>\n",
       "      <td>[87.3, 82.0, 36024, 1995, 0, 12.2, 21.0]</td>\n",
       "      <td>[87.3, 82.0, 39072, 1995, 0, 12.2, 21.0]</td>\n",
       "      <td>[87.3, 82.0, 39072, 1995, 0, 12.2, 21.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>[87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]</td>\n",
       "      <td>[87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]</td>\n",
       "      <td>[87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]</td>\n",
       "      <td>[87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]</td>\n",
       "      <td>[87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]</td>\n",
       "      <td>[87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]</td>\n",
       "      <td>[87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]</td>\n",
       "      <td>[87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]</td>\n",
       "      <td>[87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]</td>\n",
       "      <td>[87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>J-18-BK</td>\n",
       "      <td>[87.3, 82.0, 21800, 1976, 0, 11.5, 28.0]</td>\n",
       "      <td>[87.3, 82.0, 25600, 1976, 0, 11.5, 28.0]</td>\n",
       "      <td>[87.3, 82.0, 25600, 1976, 0, 11.5, 28.0]</td>\n",
       "      <td>[87.3, 82.0, 25600, 1976, 0, 11.5, 28.0]</td>\n",
       "      <td>[87.3, 82.0, 21055, 1976, 0, 11.5, 28.0]</td>\n",
       "      <td>[87.3, 82.0, 21055, 1976, 0, 11.6, 28.0]</td>\n",
       "      <td>[87.3, 82.0, 21055, 1976, 0, 11.6, 28.0]</td>\n",
       "      <td>[87.3, 82.0, 26371, 1976, 0, 11.6, 28.0]</td>\n",
       "      <td>[87.3, 82.0, 26371, 1976, 0, 11.6, 28.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>[87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]</td>\n",
       "      <td>[87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]</td>\n",
       "      <td>[87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]</td>\n",
       "      <td>[87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]</td>\n",
       "      <td>[87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]</td>\n",
       "      <td>[87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]</td>\n",
       "      <td>[87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]</td>\n",
       "      <td>[87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]</td>\n",
       "      <td>[87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]</td>\n",
       "      <td>[87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>TELL-8-TUN</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.7, 4.9]</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.7, 4.9]</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.7, 4.9]</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.7, 4.9]</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.7, 4.9]</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.8, 5.0]</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.8, 4.9]</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.8, 4.9]</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.8, 74.1]</td>\n",
       "      <td>...</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.8, 74.1]</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.8, 74.1]</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.8, 74.1]</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.8, 74.1]</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.8, 74.1]</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.8, 74.1]</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.8, 74.1]</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.8, 74.1]</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.8, 74.1]</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.8, 74.1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>524 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Bridge_ID                                    time_0  \\\n",
       "0           2.12E+13       [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]   \n",
       "1    CALHAN-8TH ST.      [36.0, 97.0, 428, 1949, 2, 10.9, 7.3]   \n",
       "2    CSG-C.80-07.65       [36.0, 83.9, 417, 1970, 2, 6.6, 6.4]   \n",
       "3    CSG-D.04-10.42      [36.0, 82.0, 1836, 1955, 2, 7.6, 4.0]   \n",
       "4    CSG-D.37-15.67       [36.0, 97.0, 87, 1984, 2, 12.8, 3.0]   \n",
       "..               ...                                       ...   \n",
       "519  I-17-G           [87.3, 82.0, 13500, 1942, 0, 10.9, 14.0]   \n",
       "520  I-17-HK          [87.3, 82.0, 38400, 1972, 0, 22.5, 35.1]   \n",
       "521  I-17-JH          [87.3, 82.0, 10500, 1995, 0, 12.9, 20.7]   \n",
       "522  J-18-BK          [87.3, 82.0, 21800, 1976, 0, 11.5, 28.0]   \n",
       "523  TELL-8-TUN            [87.3, 82.0, 28, 1900, 0, 4.7, 4.9]   \n",
       "\n",
       "                                       time_1  \\\n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]   \n",
       "1       [36.0, 96.9, 955, 1949, 2, 10.9, 7.3]   \n",
       "2        [36.0, 70.9, 351, 1970, 2, 6.6, 3.0]   \n",
       "3       [36.0, 84.3, 1459, 1955, 2, 7.7, 4.0]   \n",
       "4       [36.0, 97.0, 305, 1984, 2, 12.8, 3.0]   \n",
       "..                                        ...   \n",
       "519  [87.3, 82.0, 13500, 1942, 0, 10.9, 14.0]   \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]   \n",
       "521  [87.3, 82.0, 32904, 1995, 0, 12.9, 20.7]   \n",
       "522  [87.3, 82.0, 25600, 1976, 0, 11.5, 28.0]   \n",
       "523       [87.3, 82.0, 28, 1900, 0, 4.7, 4.9]   \n",
       "\n",
       "                                       time_2  \\\n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]   \n",
       "1       [36.0, 96.9, 955, 1949, 2, 10.9, 7.3]   \n",
       "2        [36.0, 70.9, 351, 1970, 2, 6.6, 3.0]   \n",
       "3       [36.0, 84.3, 1459, 1955, 2, 7.7, 4.0]   \n",
       "4       [36.0, 97.0, 305, 1984, 2, 12.8, 3.0]   \n",
       "..                                        ...   \n",
       "519  [87.3, 82.0, 13500, 1942, 0, 10.9, 14.0]   \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]   \n",
       "521  [87.3, 82.0, 32904, 1995, 0, 12.9, 20.7]   \n",
       "522  [87.3, 82.0, 25600, 1976, 0, 11.5, 28.0]   \n",
       "523       [87.3, 82.0, 28, 1900, 0, 4.7, 4.9]   \n",
       "\n",
       "                                       time_3  \\\n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]   \n",
       "1       [36.0, 96.9, 955, 1949, 2, 10.9, 7.3]   \n",
       "2        [36.0, 70.9, 351, 1970, 2, 6.6, 3.0]   \n",
       "3       [36.0, 84.3, 1459, 1955, 2, 7.7, 4.0]   \n",
       "4       [36.0, 97.0, 305, 1984, 2, 12.8, 3.0]   \n",
       "..                                        ...   \n",
       "519  [87.3, 82.0, 13500, 1942, 0, 10.9, 14.0]   \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]   \n",
       "521  [87.3, 82.0, 32904, 1995, 0, 12.9, 20.7]   \n",
       "522  [87.3, 82.0, 25600, 1976, 0, 11.5, 28.0]   \n",
       "523       [87.3, 82.0, 28, 1900, 0, 4.7, 4.9]   \n",
       "\n",
       "                                       time_4  \\\n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]   \n",
       "1       [36.0, 96.9, 955, 1949, 2, 10.9, 7.3]   \n",
       "2        [36.0, 70.9, 351, 1970, 2, 6.6, 3.0]   \n",
       "3       [36.0, 84.3, 1459, 1955, 2, 7.7, 3.4]   \n",
       "4       [36.0, 97.0, 305, 1984, 2, 12.8, 3.0]   \n",
       "..                                        ...   \n",
       "519  [87.3, 82.0, 13500, 1942, 0, 10.9, 14.0]   \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]   \n",
       "521  [87.3, 82.0, 36024, 1995, 0, 12.1, 20.7]   \n",
       "522  [87.3, 82.0, 21055, 1976, 0, 11.5, 28.0]   \n",
       "523       [87.3, 82.0, 28, 1900, 0, 4.7, 4.9]   \n",
       "\n",
       "                                       time_5  \\\n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]   \n",
       "1       [36.3, 97.0, 955, 1949, 2, 11.0, 7.0]   \n",
       "2        [36.3, 76.0, 351, 1970, 2, 6.6, 3.0]   \n",
       "3       [36.3, 83.4, 1459, 1955, 2, 7.7, 3.0]   \n",
       "4       [36.3, 97.0, 305, 1984, 2, 12.8, 3.0]   \n",
       "..                                        ...   \n",
       "519  [87.3, 82.0, 13500, 1942, 0, 10.9, 14.0]   \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]   \n",
       "521  [87.3, 82.0, 36024, 1995, 0, 12.2, 21.0]   \n",
       "522  [87.3, 82.0, 21055, 1976, 0, 11.6, 28.0]   \n",
       "523       [87.3, 82.0, 28, 1900, 0, 4.8, 5.0]   \n",
       "\n",
       "                                       time_6  \\\n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]   \n",
       "1       [36.3, 96.9, 955, 1949, 2, 11.0, 7.3]   \n",
       "2        [36.3, 69.0, 351, 1970, 2, 6.6, 3.0]   \n",
       "3       [36.3, 84.3, 1459, 1955, 2, 7.7, 3.4]   \n",
       "4       [36.3, 97.0, 305, 1984, 2, 12.8, 3.0]   \n",
       "..                                        ...   \n",
       "519  [87.3, 82.0, 13500, 1942, 0, 10.9, 14.0]   \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]   \n",
       "521  [87.3, 82.0, 36024, 1995, 0, 12.2, 21.0]   \n",
       "522  [87.3, 82.0, 21055, 1976, 0, 11.6, 28.0]   \n",
       "523       [87.3, 82.0, 28, 1900, 0, 4.8, 4.9]   \n",
       "\n",
       "                                       time_7  \\\n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]   \n",
       "1       [36.3, 96.9, 983, 1949, 2, 11.0, 7.3]   \n",
       "2        [36.3, 66.9, 478, 1970, 2, 6.6, 2.9]   \n",
       "3       [36.3, 84.4, 1295, 1955, 2, 7.7, 3.4]   \n",
       "4       [36.3, 97.0, 397, 1984, 2, 12.8, 3.0]   \n",
       "..                                        ...   \n",
       "519  [87.3, 82.0, 13500, 1942, 0, 10.9, 14.0]   \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]   \n",
       "521  [87.3, 82.0, 39072, 1995, 0, 12.2, 21.0]   \n",
       "522  [87.3, 82.0, 26371, 1976, 0, 11.6, 28.0]   \n",
       "523       [87.3, 82.0, 28, 1900, 0, 4.8, 4.9]   \n",
       "\n",
       "                                       time_8  ...  \\\n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]  ...   \n",
       "1       [36.3, 96.9, 983, 1949, 2, 11.0, 7.3]  ...   \n",
       "2        [36.3, 66.9, 478, 1970, 2, 6.6, 2.9]  ...   \n",
       "3       [36.3, 84.4, 1295, 1955, 2, 7.7, 3.4]  ...   \n",
       "4       [36.3, 97.0, 397, 1984, 2, 12.8, 3.0]  ...   \n",
       "..                                        ...  ...   \n",
       "519  [87.3, 82.0, 39228, 1972, 0, 24.1, 26.0]  ...   \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]  ...   \n",
       "521  [87.3, 82.0, 39072, 1995, 0, 12.2, 21.0]  ...   \n",
       "522  [87.3, 82.0, 26371, 1976, 0, 11.6, 28.0]  ...   \n",
       "523      [87.3, 82.0, 28, 1900, 0, 4.8, 74.1]  ...   \n",
       "\n",
       "                                      time_12  \\\n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]   \n",
       "1       [36.3, 97.0, 422, 1949, 2, 11.0, 7.3]   \n",
       "2        [36.3, 62.9, 478, 1970, 2, 6.6, 2.9]   \n",
       "3       [36.3, 72.3, 1295, 1955, 2, 7.7, 3.4]   \n",
       "4       [36.3, 98.0, 397, 1984, 2, 13.3, 3.0]   \n",
       "..                                        ...   \n",
       "519  [87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]   \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]   \n",
       "521  [87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]   \n",
       "522  [87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]   \n",
       "523      [87.3, 82.0, 28, 1900, 0, 4.8, 74.1]   \n",
       "\n",
       "                                      time_13  \\\n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]   \n",
       "1       [36.3, 97.0, 422, 1949, 2, 11.0, 7.3]   \n",
       "2        [36.3, 62.9, 777, 1970, 2, 6.6, 2.9]   \n",
       "3       [36.3, 72.3, 1329, 1955, 2, 7.7, 3.4]   \n",
       "4       [36.3, 98.0, 287, 1984, 2, 13.3, 3.0]   \n",
       "..                                        ...   \n",
       "519  [87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]   \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]   \n",
       "521  [87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]   \n",
       "522  [87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]   \n",
       "523      [87.3, 82.0, 28, 1900, 0, 4.8, 74.1]   \n",
       "\n",
       "                                      time_14  \\\n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]   \n",
       "1       [36.3, 97.0, 422, 1949, 2, 11.0, 7.3]   \n",
       "2        [36.3, 62.9, 777, 1970, 2, 6.6, 2.9]   \n",
       "3       [36.3, 72.3, 1329, 1955, 2, 7.7, 3.4]   \n",
       "4       [36.3, 98.0, 287, 1984, 2, 13.3, 3.0]   \n",
       "..                                        ...   \n",
       "519  [87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]   \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]   \n",
       "521  [87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]   \n",
       "522  [87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]   \n",
       "523      [87.3, 82.0, 28, 1900, 0, 4.8, 74.1]   \n",
       "\n",
       "                                      time_15  \\\n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]   \n",
       "1        [36.3, 97.0, 422, 1949, 2, 9.7, 7.3]   \n",
       "2        [36.3, 62.9, 777, 1970, 2, 6.6, 2.9]   \n",
       "3       [36.3, 72.3, 1329, 1955, 2, 7.7, 3.4]   \n",
       "4       [36.3, 99.0, 287, 1984, 2, 12.8, 3.0]   \n",
       "..                                        ...   \n",
       "519  [87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]   \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]   \n",
       "521  [87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]   \n",
       "522  [87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]   \n",
       "523      [87.3, 82.0, 28, 1900, 0, 4.8, 74.1]   \n",
       "\n",
       "                                      time_16  \\\n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]   \n",
       "1        [36.3, 97.0, 369, 1949, 2, 9.7, 7.3]   \n",
       "2        [36.3, 62.9, 623, 1970, 2, 6.6, 2.9]   \n",
       "3       [36.3, 72.3, 1446, 1955, 2, 7.7, 3.4]   \n",
       "4       [36.3, 99.0, 302, 1984, 2, 12.8, 3.0]   \n",
       "..                                        ...   \n",
       "519  [87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]   \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]   \n",
       "521  [87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]   \n",
       "522  [87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]   \n",
       "523      [87.3, 82.0, 28, 1900, 0, 4.8, 74.1]   \n",
       "\n",
       "                                      time_17  \\\n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]   \n",
       "1        [36.3, 86.0, 369, 1949, 2, 9.7, 7.3]   \n",
       "2        [36.3, 62.9, 623, 1970, 2, 6.6, 2.9]   \n",
       "3       [36.3, 72.3, 1446, 1955, 2, 7.7, 3.4]   \n",
       "4      [36.3, 100.0, 302, 1984, 2, 12.8, 3.0]   \n",
       "..                                        ...   \n",
       "519  [87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]   \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]   \n",
       "521  [87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]   \n",
       "522  [87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]   \n",
       "523      [87.3, 82.0, 28, 1900, 0, 4.8, 74.1]   \n",
       "\n",
       "                                      time_18  \\\n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]   \n",
       "1        [36.3, 86.0, 369, 1949, 2, 9.7, 7.3]   \n",
       "2        [36.3, 62.9, 623, 1970, 2, 6.6, 2.9]   \n",
       "3       [36.3, 72.3, 1446, 1955, 2, 7.7, 3.4]   \n",
       "4      [36.3, 100.0, 302, 1984, 2, 12.8, 3.0]   \n",
       "..                                        ...   \n",
       "519  [87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]   \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]   \n",
       "521  [87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]   \n",
       "522  [87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]   \n",
       "523      [87.3, 82.0, 28, 1900, 0, 4.8, 74.1]   \n",
       "\n",
       "                                      time_19  \\\n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]   \n",
       "1        [36.3, 86.0, 369, 1949, 2, 9.7, 7.3]   \n",
       "2        [32.7, 55.7, 623, 1970, 2, 6.6, 2.9]   \n",
       "3       [27.2, 50.2, 1446, 1955, 2, 7.7, 3.4]   \n",
       "4      [36.3, 100.0, 302, 1984, 2, 12.8, 3.0]   \n",
       "..                                        ...   \n",
       "519  [87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]   \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]   \n",
       "521  [87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]   \n",
       "522  [87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]   \n",
       "523      [87.3, 82.0, 28, 1900, 0, 4.8, 74.1]   \n",
       "\n",
       "                                      time_20  \\\n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]   \n",
       "1        [36.3, 86.0, 369, 1949, 2, 9.7, 7.3]   \n",
       "2        [32.7, 55.7, 623, 1970, 2, 6.6, 2.9]   \n",
       "3       [27.2, 50.2, 1446, 1955, 2, 7.7, 3.4]   \n",
       "4      [36.3, 100.0, 302, 1984, 2, 12.8, 3.0]   \n",
       "..                                        ...   \n",
       "519  [87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]   \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]   \n",
       "521  [87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]   \n",
       "522  [87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]   \n",
       "523      [87.3, 82.0, 28, 1900, 0, 4.8, 74.1]   \n",
       "\n",
       "                                      time_21  \n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]  \n",
       "1        [36.3, 86.0, 522, 1949, 2, 9.7, 7.3]  \n",
       "2        [32.7, 55.7, 717, 1970, 2, 6.6, 2.9]  \n",
       "3       [27.2, 50.2, 2696, 1955, 2, 7.7, 3.4]  \n",
       "4      [36.3, 100.0, 268, 1984, 2, 12.8, 3.0]  \n",
       "..                                        ...  \n",
       "519  [87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]  \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]  \n",
       "521  [87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]  \n",
       "522  [87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]  \n",
       "523      [87.3, 82.0, 28, 1900, 0, 4.8, 74.1]  \n",
       "\n",
       "[524 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For the first row of the dataset, plot the sufficiency rating over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_row = df.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_row = first_row.iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time_0     [36.0, 97.0, 428, 1949, 2, 10.9, 7.3]\n",
       "time_1     [36.0, 96.9, 955, 1949, 2, 10.9, 7.3]\n",
       "time_2     [36.0, 96.9, 955, 1949, 2, 10.9, 7.3]\n",
       "time_3     [36.0, 96.9, 955, 1949, 2, 10.9, 7.3]\n",
       "time_4     [36.0, 96.9, 955, 1949, 2, 10.9, 7.3]\n",
       "time_5     [36.3, 97.0, 955, 1949, 2, 11.0, 7.0]\n",
       "time_6     [36.3, 96.9, 955, 1949, 2, 11.0, 7.3]\n",
       "time_7     [36.3, 96.9, 983, 1949, 2, 11.0, 7.3]\n",
       "time_8     [36.3, 96.9, 983, 1949, 2, 11.0, 7.3]\n",
       "time_9     [36.3, 96.9, 983, 1949, 2, 11.0, 7.3]\n",
       "time_10    [36.3, 96.9, 983, 1949, 2, 11.0, 7.3]\n",
       "time_11    [36.3, 97.0, 422, 1949, 2, 11.0, 7.3]\n",
       "time_12    [36.3, 97.0, 422, 1949, 2, 11.0, 7.3]\n",
       "time_13    [36.3, 97.0, 422, 1949, 2, 11.0, 7.3]\n",
       "time_14    [36.3, 97.0, 422, 1949, 2, 11.0, 7.3]\n",
       "time_15     [36.3, 97.0, 422, 1949, 2, 9.7, 7.3]\n",
       "time_16     [36.3, 97.0, 369, 1949, 2, 9.7, 7.3]\n",
       "time_17     [36.3, 86.0, 369, 1949, 2, 9.7, 7.3]\n",
       "time_18     [36.3, 86.0, 369, 1949, 2, 9.7, 7.3]\n",
       "time_19     [36.3, 86.0, 369, 1949, 2, 9.7, 7.3]\n",
       "time_20     [36.3, 86.0, 369, 1949, 2, 9.7, 7.3]\n",
       "time_21     [36.3, 86.0, 522, 1949, 2, 9.7, 7.3]\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "non_decimal = re.compile(r'[^\\d.]+')\n",
    "\n",
    "list_of_row_components = []\n",
    "\n",
    "for i, row in first_row.iteritems():\n",
    "    current_row_components = row.split(', ')\n",
    "    current_row_components_replaced = []\n",
    "    \n",
    "#     print(current_row_components)\n",
    "    for idx, component in enumerate(current_row_components):\n",
    "    #     print(first_row_components[idx])\n",
    "        result = non_decimal.sub('', current_row_components[idx])\n",
    "        current_row_components_replaced.append(float(result))\n",
    "        \n",
    "#     print(current_row_components_replaced)\n",
    "    list_of_row_components.append(current_row_components_replaced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_row = df.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[36.0, 97.0, 428.0, 1949.0, 2.0, 10.9, 7.3],\n",
       " [36.0, 96.9, 955.0, 1949.0, 2.0, 10.9, 7.3],\n",
       " [36.0, 96.9, 955.0, 1949.0, 2.0, 10.9, 7.3],\n",
       " [36.0, 96.9, 955.0, 1949.0, 2.0, 10.9, 7.3],\n",
       " [36.0, 96.9, 955.0, 1949.0, 2.0, 10.9, 7.3],\n",
       " [36.3, 97.0, 955.0, 1949.0, 2.0, 11.0, 7.0],\n",
       " [36.3, 96.9, 955.0, 1949.0, 2.0, 11.0, 7.3],\n",
       " [36.3, 96.9, 983.0, 1949.0, 2.0, 11.0, 7.3],\n",
       " [36.3, 96.9, 983.0, 1949.0, 2.0, 11.0, 7.3],\n",
       " [36.3, 96.9, 983.0, 1949.0, 2.0, 11.0, 7.3],\n",
       " [36.3, 96.9, 983.0, 1949.0, 2.0, 11.0, 7.3],\n",
       " [36.3, 97.0, 422.0, 1949.0, 2.0, 11.0, 7.3],\n",
       " [36.3, 97.0, 422.0, 1949.0, 2.0, 11.0, 7.3],\n",
       " [36.3, 97.0, 422.0, 1949.0, 2.0, 11.0, 7.3],\n",
       " [36.3, 97.0, 422.0, 1949.0, 2.0, 11.0, 7.3],\n",
       " [36.3, 97.0, 422.0, 1949.0, 2.0, 9.7, 7.3],\n",
       " [36.3, 97.0, 369.0, 1949.0, 2.0, 9.7, 7.3],\n",
       " [36.3, 86.0, 369.0, 1949.0, 2.0, 9.7, 7.3],\n",
       " [36.3, 86.0, 369.0, 1949.0, 2.0, 9.7, 7.3],\n",
       " [36.3, 86.0, 369.0, 1949.0, 2.0, 9.7, 7.3],\n",
       " [36.3, 86.0, 369.0, 1949.0, 2.0, 9.7, 7.3],\n",
       " [36.3, 86.0, 522.0, 1949.0, 2.0, 9.7, 7.3]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_row_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_row = first_row.iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sufficiency_rating_list = []\n",
    "\n",
    "for row_component in list_of_row_components:\n",
    "    sufficiency_rating_list.append(row_component[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[97.0,\n",
       " 96.9,\n",
       " 96.9,\n",
       " 96.9,\n",
       " 96.9,\n",
       " 97.0,\n",
       " 96.9,\n",
       " 96.9,\n",
       " 96.9,\n",
       " 96.9,\n",
       " 96.9,\n",
       " 97.0,\n",
       " 97.0,\n",
       " 97.0,\n",
       " 97.0,\n",
       " 97.0,\n",
       " 97.0,\n",
       " 86.0,\n",
       " 86.0,\n",
       " 86.0,\n",
       " 86.0,\n",
       " 86.0]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sufficiency_rating_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(sufficiency_rating_list)\n",
    "plt.ylabel('Sufficiency Rating')\n",
    "plt.xlabel('Years')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of first training example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "var1 = []\n",
    "var2 = []\n",
    "var3 = []\n",
    "var4 = []\n",
    "var5 = []\n",
    "var6 = []\n",
    "varout = []\n",
    "\n",
    "for element in list_of_row_components:\n",
    "#     print(element)\n",
    "    var1.append(element[0])\n",
    "    var2.append(element[2])\n",
    "    var3.append(element[3])\n",
    "    var4.append(element[4])\n",
    "    var5.append(element[5])\n",
    "    var6.append(element[6])\n",
    "    varout.append(element[1])\n",
    "    \n",
    "dict_temp = {'var1': var1, 'var2': var2, 'var3': var3, 'var4': var4, 'var5': var5, 'var6': var6, 'varout': varout}\n",
    "\n",
    "df_temp = pd.DataFrame(dict_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>var3</th>\n",
       "      <th>var4</th>\n",
       "      <th>var5</th>\n",
       "      <th>var6</th>\n",
       "      <th>varout</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36.0</td>\n",
       "      <td>428.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>7.3</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36.0</td>\n",
       "      <td>955.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>7.3</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.0</td>\n",
       "      <td>955.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>7.3</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.0</td>\n",
       "      <td>955.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>7.3</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.0</td>\n",
       "      <td>955.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>7.3</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36.3</td>\n",
       "      <td>955.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>36.3</td>\n",
       "      <td>955.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>36.3</td>\n",
       "      <td>983.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>36.3</td>\n",
       "      <td>983.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>36.3</td>\n",
       "      <td>983.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>36.3</td>\n",
       "      <td>983.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>36.3</td>\n",
       "      <td>422.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>36.3</td>\n",
       "      <td>422.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>36.3</td>\n",
       "      <td>422.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>36.3</td>\n",
       "      <td>422.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>36.3</td>\n",
       "      <td>422.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>7.3</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>36.3</td>\n",
       "      <td>369.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>7.3</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>36.3</td>\n",
       "      <td>369.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>7.3</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>36.3</td>\n",
       "      <td>369.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>7.3</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>36.3</td>\n",
       "      <td>369.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>7.3</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>36.3</td>\n",
       "      <td>369.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>7.3</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>36.3</td>\n",
       "      <td>522.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>7.3</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    var1   var2    var3  var4  var5  var6  varout\n",
       "0   36.0  428.0  1949.0   2.0  10.9   7.3    97.0\n",
       "1   36.0  955.0  1949.0   2.0  10.9   7.3    96.9\n",
       "2   36.0  955.0  1949.0   2.0  10.9   7.3    96.9\n",
       "3   36.0  955.0  1949.0   2.0  10.9   7.3    96.9\n",
       "4   36.0  955.0  1949.0   2.0  10.9   7.3    96.9\n",
       "5   36.3  955.0  1949.0   2.0  11.0   7.0    97.0\n",
       "6   36.3  955.0  1949.0   2.0  11.0   7.3    96.9\n",
       "7   36.3  983.0  1949.0   2.0  11.0   7.3    96.9\n",
       "8   36.3  983.0  1949.0   2.0  11.0   7.3    96.9\n",
       "9   36.3  983.0  1949.0   2.0  11.0   7.3    96.9\n",
       "10  36.3  983.0  1949.0   2.0  11.0   7.3    96.9\n",
       "11  36.3  422.0  1949.0   2.0  11.0   7.3    97.0\n",
       "12  36.3  422.0  1949.0   2.0  11.0   7.3    97.0\n",
       "13  36.3  422.0  1949.0   2.0  11.0   7.3    97.0\n",
       "14  36.3  422.0  1949.0   2.0  11.0   7.3    97.0\n",
       "15  36.3  422.0  1949.0   2.0   9.7   7.3    97.0\n",
       "16  36.3  369.0  1949.0   2.0   9.7   7.3    97.0\n",
       "17  36.3  369.0  1949.0   2.0   9.7   7.3    86.0\n",
       "18  36.3  369.0  1949.0   2.0   9.7   7.3    86.0\n",
       "19  36.3  369.0  1949.0   2.0   9.7   7.3    86.0\n",
       "20  36.3  369.0  1949.0   2.0   9.7   7.3    86.0\n",
       "21  36.3  522.0  1949.0   2.0   9.7   7.3    86.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert each rows into it's own dataframe representing an individual time series example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "non_decimal = re.compile(r'[^\\d.]+')\n",
    "\n",
    "list_of_training_df = []\n",
    "\n",
    "for i in range(1, 524):\n",
    "    \n",
    "    list_of_row_components = []\n",
    "    \n",
    "    current_row = df.iloc[i]\n",
    "    current_row = current_row.iloc[1:]\n",
    "    \n",
    "    for j, row in current_row.iteritems():\n",
    "        \n",
    "        current_row_components = row.split(', ')\n",
    "        current_row_components_replaced = []\n",
    "\n",
    "        for idx, component in enumerate(current_row_components):\n",
    "\n",
    "            result = non_decimal.sub('', current_row_components[idx])\n",
    "            current_row_components_replaced.append(float(result))\n",
    "\n",
    "        list_of_row_components.append(current_row_components_replaced)\n",
    "\n",
    "    var1 = []\n",
    "    var2 = []\n",
    "    var3 = []\n",
    "    var4 = []\n",
    "    var5 = []\n",
    "    var6 = []\n",
    "    varout = []\n",
    "\n",
    "    for element in list_of_row_components:\n",
    "\n",
    "        var1.append(element[0])\n",
    "        var2.append(element[2])\n",
    "        var3.append(element[3])\n",
    "        var4.append(element[4])\n",
    "        var5.append(element[5])\n",
    "        var6.append(element[6])\n",
    "        varout.append(element[1])\n",
    "\n",
    "    dict_temp = {'var1': var1, 'var2': var2, 'var3': var3, 'var4': var4, 'var5': var5, 'var6': var6, 'varout': varout}\n",
    "\n",
    "    df_temp = pd.DataFrame(dict_temp)\n",
    "\n",
    "    list_of_training_df.append(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "523"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_of_training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>var3</th>\n",
       "      <th>var4</th>\n",
       "      <th>var5</th>\n",
       "      <th>var6</th>\n",
       "      <th>varout</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>2.4</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36.0</td>\n",
       "      <td>950.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.0</td>\n",
       "      <td>950.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.0</td>\n",
       "      <td>950.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.0</td>\n",
       "      <td>950.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36.3</td>\n",
       "      <td>950.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>36.3</td>\n",
       "      <td>950.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>36.3</td>\n",
       "      <td>700.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>36.3</td>\n",
       "      <td>700.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>36.3</td>\n",
       "      <td>700.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>85.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>36.3</td>\n",
       "      <td>700.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>85.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>36.3</td>\n",
       "      <td>700.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>85.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>36.3</td>\n",
       "      <td>700.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>85.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>36.3</td>\n",
       "      <td>780.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>85.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>36.3</td>\n",
       "      <td>780.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>85.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>36.3</td>\n",
       "      <td>780.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>87.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>36.3</td>\n",
       "      <td>771.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>87.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>36.3</td>\n",
       "      <td>771.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>87.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>36.3</td>\n",
       "      <td>771.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>87.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>27.2</td>\n",
       "      <td>771.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>65.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>27.2</td>\n",
       "      <td>771.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>65.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>27.2</td>\n",
       "      <td>391.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>65.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    var1   var2    var3  var4  var5  var6  varout\n",
       "0   36.0  660.0  1970.0   2.0  11.2   2.4    96.9\n",
       "1   36.0  950.0  1970.0   2.0  11.1   2.4    96.9\n",
       "2   36.0  950.0  1970.0   2.0  11.1   2.4    96.9\n",
       "3   36.0  950.0  1970.0   2.0  11.1   2.4    96.9\n",
       "4   36.0  950.0  1970.0   2.0  11.1   2.4    96.9\n",
       "5   36.3  950.0  1970.0   2.0  11.1   2.0    97.0\n",
       "6   36.3  950.0  1970.0   2.0  11.1   2.4    96.9\n",
       "7   36.3  700.0  1970.0   2.0  11.1   2.0    96.9\n",
       "8   36.3  700.0  1970.0   2.0  11.1   2.0    96.9\n",
       "9   36.3  700.0  1970.0   2.0  11.1   2.6    85.9\n",
       "10  36.3  700.0  1970.0   2.0  11.1   2.6    85.9\n",
       "11  36.3  700.0  1970.0   2.0  11.1   2.6    85.9\n",
       "12  36.3  700.0  1970.0   2.0  11.1   2.6    85.9\n",
       "13  36.3  780.0  1970.0   2.0  11.1   2.6    85.9\n",
       "14  36.3  780.0  1970.0   2.0  11.1   2.6    85.9\n",
       "15  36.3  780.0  1970.0   2.0  11.1   2.6    87.9\n",
       "16  36.3  771.0  1970.0   2.0  11.1   2.6    87.9\n",
       "17  36.3  771.0  1970.0   2.0  11.1   2.6    87.9\n",
       "18  36.3  771.0  1970.0   2.0  11.1   2.6    87.9\n",
       "19  27.2  771.0  1970.0   2.0  11.1   2.6    65.9\n",
       "20  27.2  771.0  1970.0   2.0  11.1   2.6    65.9\n",
       "21  27.2  391.0  1970.0   2.0  11.1   2.6    65.9"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_training_df[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "list_of_scaled_training_df = []\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "for training_df in list_of_training_df:\n",
    "    temp_df = scaler.fit_transform(training_df)\n",
    "    list_of_scaled_training_df.append(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.00194932, 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.00194932, 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.00194932, 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.00194932, 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "        0.00194932, 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "        0.00194932, 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_scaled_training_df[500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single example of a time series example for a single bridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = list_of_training_df[7].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n"
     ]
    }
   ],
   "source": [
    "n_train_hours = 21\n",
    "train = values[:n_train_hours, :]\n",
    "test = values[n_train_hours:, :]\n",
    "\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confirm gpu is being used before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/device:GPU:0']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = tf.keras.models.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "    tf.keras.layers.LSTM(50, return_sequences=True),\n",
    "#     tf.keras.layers.LSTM(30, return_sequences=True),\n",
    "#     tf.keras.layers.LSTM(100, return_sequences=True),\n",
    "#     tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "#     tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "#     tf.keras.layers.Dense(units=16, activation='relu'),\n",
    "#     tf.keras.layers.Dense(units=8, activation='relu'),\n",
    "#     tf.keras.layers.Dense(units=4, activation='relu'),\n",
    "#     tf.keras.layers.Dense(units=2, activation='relu'),\n",
    "#     Shape => [batch, time, features]\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Because we have individual time series for each bridge, we define an epoch number and for each epoch we train the model an a random bridge time series\n",
    "\n",
    "# At the end, we plot the loss and validation loss over time\n",
    "\n",
    "# This experiment is run with min max scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2365 - val_loss: 1.6432e-04\n",
      "EPOCH: 2 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.7741 - val_loss: 4.9046e-04\n",
      "EPOCH: 3 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.4184 - val_loss: 0.0017\n",
      "EPOCH: 4 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2816 - val_loss: 0.9190\n",
      "EPOCH: 5 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1.2534e-04 - val_loss: 4.0015e-05\n",
      "EPOCH: 6 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.7856 - val_loss: 0.9105\n",
      "EPOCH: 7 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2361 - val_loss: 0.0018\n",
      "EPOCH: 8 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.4222 - val_loss: 0.4296\n",
      "EPOCH: 9 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0455 - val_loss: 3.4760e-08\n",
      "EPOCH: 10 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3376 - val_loss: 0.6596\n",
      "EPOCH: 11 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3449 - val_loss: 0.3694\n",
      "EPOCH: 12 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3418 - val_loss: 0.8463\n",
      "EPOCH: 13 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1690 - val_loss: 0.0047\n",
      "EPOCH: 14 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.7172 - val_loss: 0.8011\n",
      "EPOCH: 15 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3880 - val_loss: 0.8324\n",
      "EPOCH: 16 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.5663 - val_loss: 0.7076\n",
      "EPOCH: 17 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3423 - val_loss: 0.3515\n",
      "EPOCH: 18 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.5028 - val_loss: 0.6913\n",
      "EPOCH: 19 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.6746 - val_loss: 0.7692\n",
      "EPOCH: 20 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.6305 - val_loss: 0.7935\n",
      "EPOCH: 21 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0785 - val_loss: 0.7025\n",
      "EPOCH: 22 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2752 - val_loss: 0.3762\n",
      "EPOCH: 23 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0925 - val_loss: 0.0904\n",
      "EPOCH: 24 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0043 - val_loss: 0.0047\n",
      "EPOCH: 25 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1954 - val_loss: 0.4860\n",
      "EPOCH: 26 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0150 - val_loss: 0.0255\n",
      "EPOCH: 27 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1178 - val_loss: 0.0753\n",
      "EPOCH: 28 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0563 - val_loss: 0.0120\n",
      "EPOCH: 29 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0060 - val_loss: 0.0063\n",
      "EPOCH: 30 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1741 - val_loss: 0.4370\n",
      "EPOCH: 31 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1817 - val_loss: 0.5971\n",
      "EPOCH: 32 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3586 - val_loss: 0.0551\n",
      "EPOCH: 33 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0135 - val_loss: 0.0099\n",
      "EPOCH: 34 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1941 - val_loss: 0.0081\n",
      "EPOCH: 35 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0208 - val_loss: 0.0129\n",
      "EPOCH: 36 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1443 - val_loss: 0.0296\n",
      "EPOCH: 37 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1249 - val_loss: 0.1776\n",
      "EPOCH: 38 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.4060 - val_loss: 0.5463\n",
      "EPOCH: 39 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2903 - val_loss: 0.5811\n",
      "EPOCH: 40 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2152 - val_loss: 0.5341\n",
      "EPOCH: 41 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2462 - val_loss: 0.2399\n",
      "EPOCH: 42 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0150 - val_loss: 0.0159\n",
      "EPOCH: 43 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2364 - val_loss: 0.1550\n",
      "EPOCH: 44 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.7651 - val_loss: 0.7982\n",
      "EPOCH: 45 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0687 - val_loss: 0.0520\n",
      "EPOCH: 46 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1166 - val_loss: 0.4686\n",
      "EPOCH: 47 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0122 - val_loss: 0.0125\n",
      "EPOCH: 48 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2646 - val_loss: 0.0419\n",
      "EPOCH: 49 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0359 - val_loss: 0.4191\n",
      "EPOCH: 50 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2107 - val_loss: 0.0833\n",
      "EPOCH: 51 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2304 - val_loss: 0.4662\n",
      "EPOCH: 52 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.4968 - val_loss: 0.7634\n",
      "EPOCH: 53 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.4432 - val_loss: 0.4930\n",
      "EPOCH: 54 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2529 - val_loss: 0.0826\n",
      "EPOCH: 55 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3549 - val_loss: 0.5495\n",
      "EPOCH: 56 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.4276 - val_loss: 0.5354\n",
      "EPOCH: 57 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2442 - val_loss: 0.0201\n",
      "EPOCH: 58 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2146 - val_loss: 0.1357\n",
      "EPOCH: 59 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1949 - val_loss: 0.4009\n",
      "EPOCH: 60 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2794 - val_loss: 0.0312\n",
      "EPOCH: 61 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2640 - val_loss: 0.4562\n",
      "EPOCH: 62 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0866 - val_loss: 0.2025\n",
      "EPOCH: 63 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0342 - val_loss: 0.0358\n",
      "EPOCH: 64 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0953 - val_loss: 0.1270\n",
      "EPOCH: 65 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1429 - val_loss: 0.1116\n",
      "EPOCH: 66 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1663 - val_loss: 0.3324\n",
      "EPOCH: 67 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1792 - val_loss: 0.3228\n",
      "EPOCH: 68 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1558 - val_loss: 0.1915\n",
      "EPOCH: 69 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1574 - val_loss: 0.0061\n",
      "EPOCH: 70 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1530 - val_loss: 0.1225\n",
      "EPOCH: 71 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2161 - val_loss: 0.1284\n",
      "EPOCH: 72 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0725 - val_loss: 0.0408\n",
      "EPOCH: 73 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3546 - val_loss: 0.2820\n",
      "EPOCH: 74 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3272 - val_loss: 0.1231\n",
      "EPOCH: 75 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2429 - val_loss: 0.2267\n",
      "EPOCH: 76 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1642 - val_loss: 0.0658\n",
      "EPOCH: 77 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1672 - val_loss: 0.2332\n",
      "EPOCH: 78 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2278 - val_loss: 0.2239\n",
      "EPOCH: 79 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1988 - val_loss: 0.1933\n",
      "EPOCH: 80 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0918 - val_loss: 0.0488\n",
      "EPOCH: 81 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1500 - val_loss: 0.4021\n",
      "EPOCH: 82 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2692 - val_loss: 0.1180\n",
      "EPOCH: 83 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1032 - val_loss: 0.0881\n",
      "EPOCH: 84 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1124 - val_loss: 0.0877\n",
      "EPOCH: 85 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0318 - val_loss: 0.0321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 86 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.4321 - val_loss: 0.6224\n",
      "EPOCH: 87 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1229 - val_loss: 0.0014\n",
      "EPOCH: 88 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1854 - val_loss: 0.2298\n",
      "EPOCH: 89 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0780 - val_loss: 0.0610\n",
      "EPOCH: 90 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2353 - val_loss: 0.0414\n",
      "EPOCH: 91 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0845 - val_loss: 0.0010\n",
      "EPOCH: 92 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1179 - val_loss: 0.2400\n",
      "EPOCH: 93 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2271 - val_loss: 0.2441\n",
      "EPOCH: 94 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2013 - val_loss: 0.2495\n",
      "EPOCH: 95 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3051 - val_loss: 0.3780\n",
      "EPOCH: 96 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0869 - val_loss: 0.1798\n",
      "EPOCH: 97 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2455 - val_loss: 0.2495\n",
      "EPOCH: 98 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0385 - val_loss: 0.0376\n",
      "EPOCH: 99 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1642 - val_loss: 0.1504\n",
      "EPOCH: 100 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2903 - val_loss: 0.1312\n",
      "EPOCH: 101 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2303 - val_loss: 0.1591\n",
      "EPOCH: 102 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2082 - val_loss: 0.0084\n",
      "EPOCH: 103 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0384 - val_loss: 0.0385\n",
      "EPOCH: 104 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0755 - val_loss: 0.1972\n",
      "EPOCH: 105 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0769 - val_loss: 0.0643\n",
      "EPOCH: 106 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1534 - val_loss: 0.1621\n",
      "EPOCH: 107 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2254 - val_loss: 0.3123\n",
      "EPOCH: 108 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2382 - val_loss: 0.0890\n",
      "EPOCH: 109 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1557 - val_loss: 0.2147\n",
      "EPOCH: 110 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0651 - val_loss: 0.0665\n",
      "EPOCH: 111 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1618 - val_loss: 0.1715\n",
      "EPOCH: 112 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2843 - val_loss: 0.4264\n",
      "EPOCH: 113 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0880 - val_loss: 0.1872\n",
      "EPOCH: 114 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0982 - val_loss: 0.0028\n",
      "EPOCH: 115 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3074 - val_loss: 0.1857\n",
      "EPOCH: 116 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1750 - val_loss: 0.1865\n",
      "EPOCH: 117 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0984 - val_loss: 0.0030\n",
      "EPOCH: 118 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0952 - val_loss: 0.0676\n",
      "EPOCH: 119 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2056 - val_loss: 0.0062\n",
      "EPOCH: 120 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1902 - val_loss: 0.1686\n",
      "EPOCH: 121 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0818 - val_loss: 1.6471e-06\n",
      "EPOCH: 122 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2070 - val_loss: 0.3108\n",
      "EPOCH: 123 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0416 - val_loss: 0.0404\n",
      "EPOCH: 124 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2657 - val_loss: 0.3320\n",
      "EPOCH: 125 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0405 - val_loss: 0.0405\n",
      "EPOCH: 126 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1668 - val_loss: 0.0280\n",
      "EPOCH: 127 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2764 - val_loss: 0.3004\n",
      "EPOCH: 128 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2091 - val_loss: 0.2075\n",
      "EPOCH: 129 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1752 - val_loss: 0.2938\n",
      "EPOCH: 130 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2157 - val_loss: 0.2679\n",
      "EPOCH: 131 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1284 - val_loss: 0.1599\n",
      "EPOCH: 132 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1156 - val_loss: 0.0491\n",
      "EPOCH: 133 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0394 - val_loss: 0.0635\n",
      "EPOCH: 134 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0606 - val_loss: 0.0942\n",
      "EPOCH: 135 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2062 - val_loss: 0.3115\n",
      "EPOCH: 136 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3433 - val_loss: 0.2788\n",
      "EPOCH: 137 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0968 - val_loss: 0.0707\n",
      "EPOCH: 138 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0406 - val_loss: 0.0667\n",
      "EPOCH: 139 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0990 - val_loss: 0.1286\n",
      "EPOCH: 140 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2729 - val_loss: 0.2417\n",
      "EPOCH: 141 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.4433 - val_loss: 0.4599\n",
      "EPOCH: 142 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0832 - val_loss: 0.0768\n",
      "EPOCH: 143 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0726 - val_loss: 0.1670\n",
      "EPOCH: 144 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1788 - val_loss: 0.1554\n",
      "EPOCH: 145 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2946 - val_loss: 0.3963\n",
      "EPOCH: 146 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2951 - val_loss: 0.2780\n",
      "EPOCH: 147 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1500 - val_loss: 0.2446\n",
      "EPOCH: 148 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2016 - val_loss: 0.3017\n",
      "EPOCH: 149 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2547 - val_loss: 0.2691\n",
      "EPOCH: 150 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1386 - val_loss: 8.3016e-04\n",
      "EPOCH: 151 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1178 - val_loss: 0.0763\n",
      "EPOCH: 152 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1848 - val_loss: 0.1786\n",
      "EPOCH: 153 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.4467 - val_loss: 0.2476\n",
      "EPOCH: 154 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2566 - val_loss: 0.0729\n",
      "EPOCH: 155 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1909 - val_loss: 0.1205\n",
      "EPOCH: 156 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1792 - val_loss: 0.2859\n",
      "EPOCH: 157 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1655 - val_loss: 0.1553\n",
      "EPOCH: 158 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1022 - val_loss: 0.2096\n",
      "EPOCH: 159 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1209 - val_loss: 0.1006\n",
      "EPOCH: 160 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2658 - val_loss: 0.3755\n",
      "EPOCH: 161 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2783 - val_loss: 0.3102\n",
      "EPOCH: 162 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1612 - val_loss: 0.1665\n",
      "EPOCH: 163 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0593 - val_loss: 0.0267\n",
      "EPOCH: 164 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0513 - val_loss: 0.0512\n",
      "EPOCH: 165 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1564 - val_loss: 0.1570\n",
      "EPOCH: 166 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0986 - val_loss: 0.1295\n",
      "EPOCH: 167 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2079 - val_loss: 0.2062\n",
      "EPOCH: 168 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1558 - val_loss: 0.1660\n",
      "EPOCH: 169 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0747 - val_loss: 0.0710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 170 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1782 - val_loss: 0.2100\n",
      "EPOCH: 171 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1092 - val_loss: 0.0564\n",
      "EPOCH: 172 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2708 - val_loss: 0.2598\n",
      "EPOCH: 173 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1339 - val_loss: 0.2671\n",
      "EPOCH: 174 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1649 - val_loss: 0.1664\n",
      "EPOCH: 175 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1703 - val_loss: 0.0586\n",
      "EPOCH: 176 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0500 - val_loss: 0.0497\n",
      "EPOCH: 177 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1463 - val_loss: 0.2726\n",
      "EPOCH: 178 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1154 - val_loss: 0.2588\n",
      "EPOCH: 179 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0723 - val_loss: 0.1126\n",
      "EPOCH: 180 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1283 - val_loss: 0.2496\n",
      "EPOCH: 181 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0493 - val_loss: 0.0208\n",
      "EPOCH: 182 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1764 - val_loss: 0.3496\n",
      "EPOCH: 183 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0682 - val_loss: 3.2991e-04\n",
      "EPOCH: 184 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1069 - val_loss: 0.1185\n",
      "EPOCH: 185 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2367 - val_loss: 0.2464\n",
      "EPOCH: 186 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1318 - val_loss: 0.0996\n",
      "EPOCH: 187 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1200 - val_loss: 0.1103\n",
      "EPOCH: 188 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1933 - val_loss: 0.1661\n",
      "EPOCH: 189 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0716 - val_loss: 0.1198\n",
      "EPOCH: 190 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2090 - val_loss: 0.3040\n",
      "EPOCH: 191 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3576 - val_loss: 0.4417\n",
      "EPOCH: 192 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1870 - val_loss: 0.0157\n",
      "EPOCH: 193 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1427 - val_loss: 0.0047\n",
      "EPOCH: 194 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0664 - val_loss: 0.1319\n",
      "EPOCH: 195 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2448 - val_loss: 0.3372\n",
      "EPOCH: 196 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.4756 - val_loss: 0.5747\n",
      "EPOCH: 197 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2269 - val_loss: 0.2326\n",
      "EPOCH: 198 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1296 - val_loss: 0.2619\n",
      "EPOCH: 199 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1371 - val_loss: 0.1533\n",
      "EPOCH: 200 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0400 - val_loss: 5.0230e-05\n",
      "EPOCH: 201 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1405 - val_loss: 0.1415\n",
      "EPOCH: 202 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1424 - val_loss: 0.0528\n",
      "EPOCH: 203 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0495 - val_loss: 0.0498\n",
      "EPOCH: 204 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1080 - val_loss: 0.2534\n",
      "EPOCH: 205 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2769 - val_loss: 0.2363\n",
      "EPOCH: 206 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1201 - val_loss: 0.1563\n",
      "EPOCH: 207 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0332 - val_loss: 0.0075\n",
      "EPOCH: 208 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0508 - val_loss: 0.0509\n",
      "EPOCH: 209 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2637 - val_loss: 0.1786\n",
      "EPOCH: 210 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2413 - val_loss: 0.2692\n",
      "EPOCH: 211 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2291 - val_loss: 0.0558\n",
      "EPOCH: 212 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1604 - val_loss: 0.2277\n",
      "EPOCH: 213 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0831 - val_loss: 0.0974\n",
      "EPOCH: 214 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2873 - val_loss: 0.2127\n",
      "EPOCH: 215 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1273 - val_loss: 0.0867\n",
      "EPOCH: 216 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0502 - val_loss: 0.0500\n",
      "EPOCH: 217 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1670 - val_loss: 0.1001\n",
      "EPOCH: 218 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1232 - val_loss: 0.0099\n",
      "EPOCH: 219 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0384 - val_loss: 0.0560\n",
      "EPOCH: 220 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3365 - val_loss: 0.0500\n",
      "EPOCH: 221 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1174 - val_loss: 0.1539\n",
      "EPOCH: 222 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0757 - val_loss: 0.0040\n",
      "EPOCH: 223 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1283 - val_loss: 0.1508\n",
      "EPOCH: 224 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1183 - val_loss: 0.2235\n",
      "EPOCH: 225 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1230 - val_loss: 0.0997\n",
      "EPOCH: 226 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0672 - val_loss: 0.1399\n",
      "EPOCH: 227 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1605 - val_loss: 0.2738\n",
      "EPOCH: 228 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1419 - val_loss: 0.1451\n",
      "EPOCH: 229 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2513 - val_loss: 0.2755\n",
      "EPOCH: 230 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1026 - val_loss: 0.0580\n",
      "EPOCH: 231 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1816 - val_loss: 0.2802\n",
      "EPOCH: 232 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1153 - val_loss: 0.1987\n",
      "EPOCH: 233 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1273 - val_loss: 0.3298\n",
      "EPOCH: 234 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1136 - val_loss: 0.1399\n",
      "EPOCH: 235 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1615 - val_loss: 0.1721\n",
      "EPOCH: 236 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1070 - val_loss: 0.2328\n",
      "EPOCH: 237 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1593 - val_loss: 0.1436\n",
      "EPOCH: 238 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0377 - val_loss: 1.7233e-06\n",
      "EPOCH: 239 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2561 - val_loss: 0.4997\n",
      "EPOCH: 240 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0517 - val_loss: 0.0517\n",
      "EPOCH: 241 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0836 - val_loss: 0.1025\n",
      "EPOCH: 242 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0767 - val_loss: 0.0777\n",
      "EPOCH: 243 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0817 - val_loss: 0.0984\n",
      "EPOCH: 244 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0526 - val_loss: 0.0527\n",
      "EPOCH: 245 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1543 - val_loss: 0.2038\n",
      "EPOCH: 246 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0555 - val_loss: 0.0553\n",
      "EPOCH: 247 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3599 - val_loss: 0.3399\n",
      "EPOCH: 248 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2376 - val_loss: 0.2473\n",
      "EPOCH: 249 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0549 - val_loss: 0.0543\n",
      "EPOCH: 250 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0518 - val_loss: 0.0513\n",
      "EPOCH: 251 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1550 - val_loss: 0.2043\n",
      "EPOCH: 252 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1620 - val_loss: 0.1513\n",
      "EPOCH: 253 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0516 - val_loss: 0.0503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 254 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0898 - val_loss: 0.0949\n",
      "EPOCH: 255 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2554 - val_loss: 0.3307\n",
      "EPOCH: 256 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0869 - val_loss: 0.1404\n",
      "EPOCH: 257 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0475 - val_loss: 0.0467\n",
      "EPOCH: 258 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2255 - val_loss: 0.2209\n",
      "EPOCH: 259 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2142 - val_loss: 0.2232\n",
      "EPOCH: 260 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1868 - val_loss: 0.2979\n",
      "EPOCH: 261 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1038 - val_loss: 0.0016\n",
      "EPOCH: 262 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1723 - val_loss: 0.1583\n",
      "EPOCH: 263 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2019 - val_loss: 0.0030\n",
      "EPOCH: 264 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0430 - val_loss: 0.0426\n",
      "EPOCH: 265 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0718 - val_loss: 0.2375\n",
      "EPOCH: 266 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1087 - val_loss: 8.9923e-05\n",
      "EPOCH: 267 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2038 - val_loss: 0.2142\n",
      "EPOCH: 268 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0418 - val_loss: 0.0414\n",
      "EPOCH: 269 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1552 - val_loss: 9.2537e-06\n",
      "EPOCH: 270 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1827 - val_loss: 0.1814\n",
      "EPOCH: 271 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1834 - val_loss: 0.0149\n",
      "EPOCH: 272 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1042 - val_loss: 0.0870\n",
      "EPOCH: 273 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2436 - val_loss: 0.3019\n",
      "EPOCH: 274 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1707 - val_loss: 0.2365\n",
      "EPOCH: 275 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0388 - val_loss: 0.0386\n",
      "EPOCH: 276 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1338 - val_loss: 0.0578\n",
      "EPOCH: 277 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2305 - val_loss: 0.3128\n",
      "EPOCH: 278 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2174 - val_loss: 0.0161\n",
      "EPOCH: 279 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0346 - val_loss: 6.1746e-04\n",
      "EPOCH: 280 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1336 - val_loss: 0.0561\n",
      "EPOCH: 281 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1129 - val_loss: 0.1408\n",
      "EPOCH: 282 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0389 - val_loss: 0.0390\n",
      "EPOCH: 283 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0658 - val_loss: 0.0390\n",
      "EPOCH: 284 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1532 - val_loss: 0.1152\n",
      "EPOCH: 285 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.4263 - val_loss: 0.2277\n",
      "EPOCH: 286 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0707 - val_loss: 0.0262\n",
      "EPOCH: 287 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1496 - val_loss: 0.2317\n",
      "EPOCH: 288 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2292 - val_loss: 0.4323\n",
      "EPOCH: 289 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0588 - val_loss: 0.0297\n",
      "EPOCH: 290 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0982 - val_loss: 0.0120\n",
      "EPOCH: 291 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2746 - val_loss: 0.2940\n",
      "EPOCH: 292 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0998 - val_loss: 0.0133\n",
      "EPOCH: 293 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0588 - val_loss: 0.0299\n",
      "EPOCH: 294 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1330 - val_loss: 0.1548\n",
      "EPOCH: 295 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2593 - val_loss: 0.2519\n",
      "EPOCH: 296 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1235 - val_loss: 0.1124\n",
      "EPOCH: 297 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1706 - val_loss: 0.1541\n",
      "EPOCH: 298 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0988 - val_loss: 0.0900\n",
      "EPOCH: 299 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1470 - val_loss: 0.0029\n",
      "EPOCH: 300 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2109 - val_loss: 0.2057\n",
      "EPOCH: 301 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0960 - val_loss: 0.0881\n",
      "EPOCH: 302 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1513 - val_loss: 0.1484\n",
      "EPOCH: 303 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2277 - val_loss: 0.3089\n",
      "EPOCH: 304 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2738 - val_loss: 0.0688\n",
      "EPOCH: 305 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3096 - val_loss: 0.1312\n",
      "EPOCH: 306 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1622 - val_loss: 0.2037\n",
      "EPOCH: 307 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.4171 - val_loss: 0.3624\n",
      "EPOCH: 308 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.4751 - val_loss: 0.1873\n",
      "EPOCH: 309 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2467 - val_loss: 0.0950\n",
      "EPOCH: 310 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0951 - val_loss: 0.0362\n",
      "EPOCH: 311 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1722 - val_loss: 0.1160\n",
      "EPOCH: 312 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1493 - val_loss: 0.0683\n",
      "EPOCH: 313 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0931 - val_loss: 0.0451\n",
      "EPOCH: 314 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3721 - val_loss: 0.3207\n",
      "EPOCH: 315 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3099 - val_loss: 0.4950\n",
      "EPOCH: 316 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1318 - val_loss: 0.0652\n",
      "EPOCH: 317 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1638 - val_loss: 0.3167\n",
      "EPOCH: 318 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1350 - val_loss: 0.0075\n",
      "EPOCH: 319 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2081 - val_loss: 0.0781\n",
      "EPOCH: 320 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1539 - val_loss: 0.0808\n",
      "EPOCH: 321 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0675 - val_loss: 0.0721\n",
      "EPOCH: 322 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0588 - val_loss: 0.0594\n",
      "EPOCH: 323 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1871 - val_loss: 0.0827\n",
      "EPOCH: 324 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1837 - val_loss: 0.1628\n",
      "EPOCH: 325 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.5009 - val_loss: 0.5701\n",
      "EPOCH: 326 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2322 - val_loss: 0.2077\n",
      "EPOCH: 327 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0923 - val_loss: 0.2088\n",
      "EPOCH: 328 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1796 - val_loss: 0.1778\n",
      "EPOCH: 329 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0518 - val_loss: 0.0502\n",
      "EPOCH: 330 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2327 - val_loss: 0.2653\n",
      "EPOCH: 331 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1278 - val_loss: 0.1071\n",
      "EPOCH: 332 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1846 - val_loss: 0.4704\n",
      "EPOCH: 333 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1262 - val_loss: 0.0982\n",
      "EPOCH: 334 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0979 - val_loss: 0.1338\n",
      "EPOCH: 335 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0615 - val_loss: 0.0456\n",
      "EPOCH: 336 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1353 - val_loss: 0.0871\n",
      "EPOCH: 337 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 0.0474 - val_loss: 0.0670\n",
      "EPOCH: 338 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2228 - val_loss: 0.1178\n",
      "EPOCH: 339 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0705 - val_loss: 0.0288\n",
      "EPOCH: 340 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2052 - val_loss: 0.2401\n",
      "EPOCH: 341 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1520 - val_loss: 0.1448\n",
      "EPOCH: 342 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2616 - val_loss: 0.2989\n",
      "EPOCH: 343 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0997 - val_loss: 0.1331\n",
      "EPOCH: 344 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1993 - val_loss: 0.2068\n",
      "EPOCH: 345 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1251 - val_loss: 0.1632\n",
      "EPOCH: 346 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0521 - val_loss: 0.0513\n",
      "EPOCH: 347 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1767 - val_loss: 0.0645\n",
      "EPOCH: 348 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.4813 - val_loss: 0.2889\n",
      "EPOCH: 349 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0832 - val_loss: 1.8314e-05\n",
      "EPOCH: 350 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1933 - val_loss: 0.2203\n",
      "EPOCH: 351 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1532 - val_loss: 0.0065\n",
      "EPOCH: 352 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1298 - val_loss: 0.3233\n",
      "EPOCH: 353 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1439 - val_loss: 0.0068\n",
      "EPOCH: 354 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.4515 - val_loss: 0.3462\n",
      "EPOCH: 355 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0752 - val_loss: 0.0950\n",
      "EPOCH: 356 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1076 - val_loss: 0.2210\n",
      "EPOCH: 357 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1104 - val_loss: 0.1620\n",
      "EPOCH: 358 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1266 - val_loss: 0.1482\n",
      "EPOCH: 359 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2612 - val_loss: 0.3365\n",
      "EPOCH: 360 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1079 - val_loss: 0.1960\n",
      "EPOCH: 361 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3744 - val_loss: 0.3282\n",
      "EPOCH: 362 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2236 - val_loss: 0.1375\n",
      "EPOCH: 363 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1089 - val_loss: 0.0159\n",
      "EPOCH: 364 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2328 - val_loss: 0.2628\n",
      "EPOCH: 365 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2320 - val_loss: 0.2385\n",
      "EPOCH: 366 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1466 - val_loss: 0.1846\n",
      "EPOCH: 367 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1575 - val_loss: 0.1765\n",
      "EPOCH: 368 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1197 - val_loss: 0.1374\n",
      "EPOCH: 369 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0399 - val_loss: 0.0461\n",
      "EPOCH: 370 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2186 - val_loss: 0.1574\n",
      "EPOCH: 371 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3664 - val_loss: 0.5259\n",
      "EPOCH: 372 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1673 - val_loss: 0.0642\n",
      "EPOCH: 373 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1674 - val_loss: 0.1046\n",
      "EPOCH: 374 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2184 - val_loss: 0.2626\n",
      "EPOCH: 375 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1766 - val_loss: 0.1460\n",
      "EPOCH: 376 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2028 - val_loss: 0.2497\n",
      "EPOCH: 377 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1089 - val_loss: 0.0811\n",
      "EPOCH: 378 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0550 - val_loss: 0.0549\n",
      "EPOCH: 379 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2758 - val_loss: 0.4247\n",
      "EPOCH: 380 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3337 - val_loss: 0.2925\n",
      "EPOCH: 381 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0936 - val_loss: 0.1261\n",
      "EPOCH: 382 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1601 - val_loss: 0.1405\n",
      "EPOCH: 383 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0547 - val_loss: 0.0239\n",
      "EPOCH: 384 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1404 - val_loss: 0.1179\n",
      "EPOCH: 385 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1932 - val_loss: 0.0411\n",
      "EPOCH: 386 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1302 - val_loss: 0.1870\n",
      "EPOCH: 387 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2540 - val_loss: 0.2814\n",
      "EPOCH: 388 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1100 - val_loss: 0.2391\n",
      "EPOCH: 389 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2953 - val_loss: 0.2931\n",
      "EPOCH: 390 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0518 - val_loss: 0.0637\n",
      "EPOCH: 391 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1039 - val_loss: 4.5892e-06\n",
      "EPOCH: 392 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0295 - val_loss: 0.0105\n",
      "EPOCH: 393 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3139 - val_loss: 0.2996\n",
      "EPOCH: 394 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1108 - val_loss: 0.2404\n",
      "EPOCH: 395 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1555 - val_loss: 0.1378\n",
      "EPOCH: 396 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1137 - val_loss: 0.2230\n",
      "EPOCH: 397 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1160 - val_loss: 0.1869\n",
      "EPOCH: 398 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1145 - val_loss: 0.1894\n",
      "EPOCH: 399 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1006 - val_loss: 0.2756\n",
      "EPOCH: 400 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1697 - val_loss: 0.1022\n",
      "EPOCH: 401 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1940 - val_loss: 0.0296\n",
      "EPOCH: 402 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1689 - val_loss: 0.0052\n",
      "EPOCH: 403 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1229 - val_loss: 0.0125\n",
      "EPOCH: 404 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1859 - val_loss: 0.1421\n",
      "EPOCH: 405 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0776 - val_loss: 0.0558\n",
      "EPOCH: 406 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0782 - val_loss: 0.0784\n",
      "EPOCH: 407 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3735 - val_loss: 0.1688\n",
      "EPOCH: 408 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0511 - val_loss: 0.1662\n",
      "EPOCH: 409 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1264 - val_loss: 0.0849\n",
      "EPOCH: 410 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1196 - val_loss: 0.0998\n",
      "EPOCH: 411 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1633 - val_loss: 0.0339\n",
      "EPOCH: 412 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1994 - val_loss: 0.1112\n",
      "EPOCH: 413 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1591 - val_loss: 0.4810\n",
      "EPOCH: 414 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0681 - val_loss: 0.0596\n",
      "EPOCH: 415 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1790 - val_loss: 0.1146\n",
      "EPOCH: 416 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0375 - val_loss: 1.2692e-04\n",
      "EPOCH: 417 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1544 - val_loss: 0.0871\n",
      "EPOCH: 418 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1312 - val_loss: 0.3935\n",
      "EPOCH: 419 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0970 - val_loss: 0.0909\n",
      "EPOCH: 420 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0826 - val_loss: 0.0839\n",
      "EPOCH: 421 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 0.2927 - val_loss: 0.3439\n",
      "EPOCH: 422 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1415 - val_loss: 0.1481\n",
      "EPOCH: 423 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0859 - val_loss: 0.0247\n",
      "EPOCH: 424 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1281 - val_loss: 0.3971\n",
      "EPOCH: 425 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1003 - val_loss: 0.1309\n",
      "EPOCH: 426 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1748 - val_loss: 0.0695\n",
      "EPOCH: 427 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1327 - val_loss: 0.0710\n",
      "EPOCH: 428 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2020 - val_loss: 0.1888\n",
      "EPOCH: 429 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0989 - val_loss: 0.0871\n",
      "EPOCH: 430 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1541 - val_loss: 0.1383\n",
      "EPOCH: 431 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1244 - val_loss: 0.1812\n",
      "EPOCH: 432 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1341 - val_loss: 5.2427e-05\n",
      "EPOCH: 433 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0780 - val_loss: 0.0773\n",
      "EPOCH: 434 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1242 - val_loss: 0.1252\n",
      "EPOCH: 435 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0754 - val_loss: 0.0521\n",
      "EPOCH: 436 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2027 - val_loss: 0.1575\n",
      "EPOCH: 437 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0875 - val_loss: 0.0462\n",
      "EPOCH: 438 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3517 - val_loss: 0.4419\n",
      "EPOCH: 439 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2985 - val_loss: 0.2991\n",
      "EPOCH: 440 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2800 - val_loss: 0.2657\n",
      "EPOCH: 441 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1167 - val_loss: 0.2316\n",
      "EPOCH: 442 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0566 - val_loss: 0.0448\n",
      "EPOCH: 443 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0574 - val_loss: 0.0888\n",
      "EPOCH: 444 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0305 - val_loss: 0.0201\n",
      "EPOCH: 445 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1347 - val_loss: 0.0022\n",
      "EPOCH: 446 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2755 - val_loss: 0.3826\n",
      "EPOCH: 447 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1958 - val_loss: 0.1044\n",
      "EPOCH: 448 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2156 - val_loss: 0.1714\n",
      "EPOCH: 449 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1539 - val_loss: 0.0470\n",
      "EPOCH: 450 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1902 - val_loss: 0.1377\n",
      "EPOCH: 451 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0554 - val_loss: 0.0419\n",
      "EPOCH: 452 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1333 - val_loss: 0.0032\n",
      "EPOCH: 453 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2074 - val_loss: 0.1595\n",
      "EPOCH: 454 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1416 - val_loss: 0.0065\n",
      "EPOCH: 455 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1245 - val_loss: 0.3591\n",
      "EPOCH: 456 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1230 - val_loss: 0.0798\n",
      "EPOCH: 457 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2754 - val_loss: 0.2115\n",
      "EPOCH: 458 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1646 - val_loss: 0.0380\n",
      "EPOCH: 459 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0802 - val_loss: 0.1422\n",
      "EPOCH: 460 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1990 - val_loss: 0.1641\n",
      "EPOCH: 461 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0462 - val_loss: 0.1551\n",
      "EPOCH: 462 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1003 - val_loss: 0.1059\n",
      "EPOCH: 463 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1116 - val_loss: 0.1137\n",
      "EPOCH: 464 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1877 - val_loss: 0.1685\n",
      "EPOCH: 465 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0767 - val_loss: 0.0865\n",
      "EPOCH: 466 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0695 - val_loss: 0.0696\n",
      "EPOCH: 467 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0586 - val_loss: 0.2119\n",
      "EPOCH: 468 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1501 - val_loss: 0.1567\n",
      "EPOCH: 469 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0284 - val_loss: 0.1173\n",
      "EPOCH: 470 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2613 - val_loss: 0.2208\n",
      "EPOCH: 471 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0900 - val_loss: 0.0264\n",
      "EPOCH: 472 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0699 - val_loss: 0.0697\n",
      "EPOCH: 473 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1899 - val_loss: 0.0897\n",
      "EPOCH: 474 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2568 - val_loss: 0.1304\n",
      "EPOCH: 475 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2070 - val_loss: 0.1466\n",
      "EPOCH: 476 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2056 - val_loss: 0.1833\n",
      "EPOCH: 477 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1532 - val_loss: 0.1367\n",
      "EPOCH: 478 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1972 - val_loss: 0.1536\n",
      "EPOCH: 479 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1788 - val_loss: 0.0726\n",
      "EPOCH: 480 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1440 - val_loss: 0.1362\n",
      "EPOCH: 481 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3707 - val_loss: 0.4473\n",
      "EPOCH: 482 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1277 - val_loss: 0.0031\n",
      "EPOCH: 483 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3179 - val_loss: 0.4714\n",
      "EPOCH: 484 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0731 - val_loss: 0.0730\n",
      "EPOCH: 485 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3798 - val_loss: 0.4281\n",
      "EPOCH: 486 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0528 - val_loss: 0.0281\n",
      "EPOCH: 487 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0975 - val_loss: 0.1367\n",
      "EPOCH: 488 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0998 - val_loss: 0.1817\n",
      "EPOCH: 489 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.4344 - val_loss: 0.2421\n",
      "EPOCH: 490 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0719 - val_loss: 0.1535\n",
      "EPOCH: 491 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2973 - val_loss: 0.2074\n",
      "EPOCH: 492 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2092 - val_loss: 0.2861\n",
      "EPOCH: 493 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1792 - val_loss: 0.3377\n",
      "EPOCH: 494 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1920 - val_loss: 0.3034\n",
      "EPOCH: 495 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1191 - val_loss: 0.0132\n",
      "EPOCH: 496 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0586 - val_loss: 0.1069\n",
      "EPOCH: 497 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3012 - val_loss: 0.3676\n",
      "EPOCH: 498 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0800 - val_loss: 9.4819e-04\n",
      "EPOCH: 499 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1031 - val_loss: 0.0106\n",
      "EPOCH: 500 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2762 - val_loss: 0.2683\n",
      "EPOCH: 501 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2277 - val_loss: 0.3904\n",
      "EPOCH: 502 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3748 - val_loss: 0.1026\n",
      "EPOCH: 503 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2647 - val_loss: 0.3027\n",
      "EPOCH: 504 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1854 - val_loss: 0.0515\n",
      "EPOCH: 505 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 0.2175 - val_loss: 0.1112\n",
      "EPOCH: 506 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0921 - val_loss: 0.0806\n",
      "EPOCH: 507 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1113 - val_loss: 0.0462\n",
      "EPOCH: 508 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1190 - val_loss: 0.1097\n",
      "EPOCH: 509 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3443 - val_loss: 0.3548\n",
      "EPOCH: 510 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0985 - val_loss: 0.0042\n",
      "EPOCH: 511 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2741 - val_loss: 0.1936\n",
      "EPOCH: 512 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0906 - val_loss: 0.0629\n",
      "EPOCH: 513 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0417 - val_loss: 8.2728e-06\n",
      "EPOCH: 514 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.4235 - val_loss: 0.4041\n",
      "EPOCH: 515 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0964 - val_loss: 0.0109\n",
      "EPOCH: 516 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1713 - val_loss: 0.1814\n",
      "EPOCH: 517 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3311 - val_loss: 0.3484\n",
      "EPOCH: 518 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0897 - val_loss: 0.0701\n",
      "EPOCH: 519 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0573 - val_loss: 0.0550\n",
      "EPOCH: 520 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1195 - val_loss: 0.0018\n",
      "EPOCH: 521 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1671 - val_loss: 0.0692\n",
      "EPOCH: 522 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2491 - val_loss: 0.3116\n",
      "EPOCH: 523 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0636 - val_loss: 0.1291\n",
      "EPOCH: 524 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1182 - val_loss: 0.1540\n",
      "EPOCH: 525 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1967 - val_loss: 0.3932\n",
      "EPOCH: 526 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2360 - val_loss: 0.1407\n",
      "EPOCH: 527 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1668 - val_loss: 0.3432\n",
      "EPOCH: 528 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1167 - val_loss: 0.2042\n",
      "EPOCH: 529 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2283 - val_loss: 0.0738\n",
      "EPOCH: 530 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1995 - val_loss: 0.0600\n",
      "EPOCH: 531 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1702 - val_loss: 0.2567\n",
      "EPOCH: 532 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0776 - val_loss: 0.0312\n",
      "EPOCH: 533 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3902 - val_loss: 0.3262\n",
      "EPOCH: 534 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0939 - val_loss: 0.0045\n",
      "EPOCH: 535 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0774 - val_loss: 0.1840\n",
      "EPOCH: 536 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1276 - val_loss: 0.0117\n",
      "EPOCH: 537 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0426 - val_loss: 0.0460\n",
      "EPOCH: 538 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1210 - val_loss: 0.1264\n",
      "EPOCH: 539 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3206 - val_loss: 0.2649\n",
      "EPOCH: 540 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1930 - val_loss: 0.1905\n",
      "EPOCH: 541 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1992 - val_loss: 0.3599\n",
      "EPOCH: 542 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1280 - val_loss: 0.1452\n",
      "EPOCH: 543 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1274 - val_loss: 0.1426\n",
      "EPOCH: 544 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1851 - val_loss: 0.1862\n",
      "EPOCH: 545 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1939 - val_loss: 0.0406\n",
      "EPOCH: 546 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1062 - val_loss: 0.2851\n",
      "EPOCH: 547 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0867 - val_loss: 0.0684\n",
      "EPOCH: 548 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0874 - val_loss: 0.0687\n",
      "EPOCH: 549 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0219 - val_loss: 0.0952\n",
      "EPOCH: 550 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2123 - val_loss: 0.4270\n",
      "EPOCH: 551 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1287 - val_loss: 0.1588\n",
      "EPOCH: 552 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1325 - val_loss: 0.1957\n",
      "EPOCH: 553 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2115 - val_loss: 0.1973\n",
      "EPOCH: 554 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0761 - val_loss: 0.0529\n",
      "EPOCH: 555 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1604 - val_loss: 0.3228\n",
      "EPOCH: 556 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2458 - val_loss: 0.1592\n",
      "EPOCH: 557 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1929 - val_loss: 0.1703\n",
      "EPOCH: 558 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2270 - val_loss: 0.5163\n",
      "EPOCH: 559 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0300 - val_loss: 0.0479\n",
      "EPOCH: 560 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1571 - val_loss: 0.4716\n",
      "EPOCH: 561 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2279 - val_loss: 0.0699\n",
      "EPOCH: 562 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2219 - val_loss: 0.2663\n",
      "EPOCH: 563 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2365 - val_loss: 0.0555\n",
      "EPOCH: 564 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0682 - val_loss: 0.0443\n",
      "EPOCH: 565 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0466 - val_loss: 0.2136\n",
      "EPOCH: 566 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.4308 - val_loss: 0.4472\n",
      "EPOCH: 567 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0858 - val_loss: 0.0246\n",
      "EPOCH: 568 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0854 - val_loss: 0.0841\n",
      "EPOCH: 569 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2892 - val_loss: 0.5785\n",
      "EPOCH: 570 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2660 - val_loss: 0.0746\n",
      "EPOCH: 571 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0856 - val_loss: 0.0837\n",
      "EPOCH: 572 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2063 - val_loss: 0.0895\n",
      "EPOCH: 573 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2266 - val_loss: 0.1504\n",
      "EPOCH: 574 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.4265 - val_loss: 0.4417\n",
      "EPOCH: 575 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1049 - val_loss: 0.0828\n",
      "EPOCH: 576 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0528 - val_loss: 3.8076e-04\n",
      "EPOCH: 577 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1135 - val_loss: 0.1134\n",
      "EPOCH: 578 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1289 - val_loss: 0.1643\n",
      "EPOCH: 579 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1833 - val_loss: 0.1657\n",
      "EPOCH: 580 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0649 - val_loss: 0.0394\n",
      "EPOCH: 581 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1366 - val_loss: 0.0249\n",
      "EPOCH: 582 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1177 - val_loss: 0.1352\n",
      "EPOCH: 583 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0999 - val_loss: 0.0653\n",
      "EPOCH: 584 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1376 - val_loss: 0.1473\n",
      "EPOCH: 585 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0989 - val_loss: 0.1005\n",
      "EPOCH: 586 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1979 - val_loss: 0.0368\n",
      "EPOCH: 587 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2955 - val_loss: 0.3050\n",
      "EPOCH: 588 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2440 - val_loss: 0.3521\n",
      "EPOCH: 589 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0708 - val_loss: 0.0409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 590 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1144 - val_loss: 0.1144\n",
      "EPOCH: 591 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0862 - val_loss: 0.0599\n",
      "EPOCH: 592 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1004 - val_loss: 0.0243\n",
      "EPOCH: 593 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3002 - val_loss: 0.3275\n",
      "EPOCH: 594 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2332 - val_loss: 0.6198\n",
      "EPOCH: 595 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1723 - val_loss: 0.1073\n",
      "EPOCH: 596 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1807 - val_loss: 0.1477\n",
      "EPOCH: 597 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2768 - val_loss: 0.4490\n",
      "EPOCH: 598 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2937 - val_loss: 0.3405\n",
      "EPOCH: 599 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2949 - val_loss: 0.2193\n",
      "EPOCH: 600 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2188 - val_loss: 0.3144\n",
      "EPOCH: 601 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1771 - val_loss: 0.1232\n",
      "EPOCH: 602 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1228 - val_loss: 0.1058\n",
      "EPOCH: 603 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0344 - val_loss: 5.2869e-04\n",
      "EPOCH: 604 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0468 - val_loss: 0.0470\n",
      "EPOCH: 605 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1483 - val_loss: 0.0531\n",
      "EPOCH: 606 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1346 - val_loss: 0.1262\n",
      "EPOCH: 607 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1367 - val_loss: 0.0191\n",
      "EPOCH: 608 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1090 - val_loss: 0.1086\n",
      "EPOCH: 609 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1086 - val_loss: 0.1079\n",
      "EPOCH: 610 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0668 - val_loss: 0.0417\n",
      "EPOCH: 611 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0833 - val_loss: 0.0636\n",
      "EPOCH: 612 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1843 - val_loss: 0.1343\n",
      "EPOCH: 613 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1182 - val_loss: 0.0613\n",
      "EPOCH: 614 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3376 - val_loss: 0.0649\n",
      "EPOCH: 615 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0768 - val_loss: 0.0037\n",
      "EPOCH: 616 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2640 - val_loss: 0.0436\n",
      "EPOCH: 617 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1137 - val_loss: 0.0882\n",
      "EPOCH: 618 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0890 - val_loss: 0.1238\n",
      "EPOCH: 619 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2961 - val_loss: 0.3552\n",
      "EPOCH: 620 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2010 - val_loss: 0.3039\n",
      "EPOCH: 621 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1150 - val_loss: 0.0457\n",
      "EPOCH: 622 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2330 - val_loss: 0.4113\n",
      "EPOCH: 623 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1214 - val_loss: 0.1410\n",
      "EPOCH: 624 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1232 - val_loss: 0.0842\n",
      "EPOCH: 625 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2992 - val_loss: 0.2432\n",
      "EPOCH: 626 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1543 - val_loss: 0.0487\n",
      "EPOCH: 627 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1667 - val_loss: 0.1642\n",
      "EPOCH: 628 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0565 - val_loss: 0.0533\n",
      "EPOCH: 629 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1575 - val_loss: 0.3366\n",
      "EPOCH: 630 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2378 - val_loss: 0.0760\n",
      "EPOCH: 631 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1718 - val_loss: 0.2294\n",
      "EPOCH: 632 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0781 - val_loss: 0.0985\n",
      "EPOCH: 633 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0688 - val_loss: 0.0362\n",
      "EPOCH: 634 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1760 - val_loss: 0.1726\n",
      "EPOCH: 635 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2427 - val_loss: 0.1387\n",
      "EPOCH: 636 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0566 - val_loss: 0.1081\n",
      "EPOCH: 637 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0983 - val_loss: 0.0809\n",
      "EPOCH: 638 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1020 - val_loss: 0.0419\n",
      "EPOCH: 639 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0539 - val_loss: 0.1468\n",
      "EPOCH: 640 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0924 - val_loss: 0.0888\n",
      "EPOCH: 641 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1053 - val_loss: 0.2524\n",
      "EPOCH: 642 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1188 - val_loss: 0.0645\n",
      "EPOCH: 643 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3668 - val_loss: 0.3003\n",
      "EPOCH: 644 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0615 - val_loss: 0.0098\n",
      "EPOCH: 645 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1339 - val_loss: 0.2217\n",
      "EPOCH: 646 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1026 - val_loss: 0.0038\n",
      "EPOCH: 647 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.4605 - val_loss: 0.4794\n",
      "EPOCH: 648 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1488 - val_loss: 0.1460\n",
      "EPOCH: 649 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1180 - val_loss: 0.0596\n",
      "EPOCH: 650 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2447 - val_loss: 0.2533\n",
      "EPOCH: 651 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0952 - val_loss: 0.0947\n",
      "EPOCH: 652 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1140 - val_loss: 0.1070\n",
      "EPOCH: 653 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0939 - val_loss: 0.0929\n",
      "EPOCH: 654 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3509 - val_loss: 0.3147\n",
      "EPOCH: 655 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0489 - val_loss: 0.1006\n",
      "EPOCH: 656 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3272 - val_loss: 0.2411\n",
      "EPOCH: 657 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0868 - val_loss: 0.0116\n",
      "EPOCH: 658 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0560 - val_loss: 0.0374\n",
      "EPOCH: 659 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2130 - val_loss: 0.3543\n",
      "EPOCH: 660 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1589 - val_loss: 0.3327\n",
      "EPOCH: 661 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1240 - val_loss: 0.2093\n",
      "EPOCH: 662 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2727 - val_loss: 0.2283\n",
      "EPOCH: 663 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1349 - val_loss: 0.1584\n",
      "EPOCH: 664 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0498 - val_loss: 0.0178\n",
      "EPOCH: 665 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2990 - val_loss: 0.4336\n",
      "EPOCH: 666 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2152 - val_loss: 0.3621\n",
      "EPOCH: 667 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1594 - val_loss: 0.1649\n",
      "EPOCH: 668 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0858 - val_loss: 0.0887\n",
      "EPOCH: 669 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2312 - val_loss: 0.1586\n",
      "EPOCH: 670 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0706 - val_loss: 0.1232\n",
      "EPOCH: 671 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1651 - val_loss: 0.1017\n",
      "EPOCH: 672 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0364 - val_loss: 0.0341\n",
      "EPOCH: 673 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 0.2127 - val_loss: 0.0526\n",
      "EPOCH: 674 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0956 - val_loss: 0.0907\n",
      "EPOCH: 675 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0630 - val_loss: 0.1151\n",
      "EPOCH: 676 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0435 - val_loss: 0.0353\n",
      "EPOCH: 677 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.5607 - val_loss: 0.5645\n",
      "EPOCH: 678 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2024 - val_loss: 0.2893\n",
      "EPOCH: 679 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2062 - val_loss: 0.0847\n",
      "EPOCH: 680 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0478 - val_loss: 0.0104\n",
      "EPOCH: 681 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0959 - val_loss: 0.0993\n",
      "EPOCH: 682 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1494 - val_loss: 0.1515\n",
      "EPOCH: 683 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2101 - val_loss: 0.1201\n",
      "EPOCH: 684 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2412 - val_loss: 0.0014\n",
      "EPOCH: 685 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0787 - val_loss: 0.0138\n",
      "EPOCH: 686 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1853 - val_loss: 0.2340\n",
      "EPOCH: 687 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2325 - val_loss: 0.2252\n",
      "EPOCH: 688 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3732 - val_loss: 0.3013\n",
      "EPOCH: 689 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1204 - val_loss: 0.1100\n",
      "EPOCH: 690 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1166 - val_loss: 0.0049\n",
      "EPOCH: 691 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1497 - val_loss: 0.0403\n",
      "EPOCH: 692 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0850 - val_loss: 0.0400\n",
      "EPOCH: 693 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1385 - val_loss: 0.1746\n",
      "EPOCH: 694 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0419 - val_loss: 1.9427e-05\n",
      "EPOCH: 695 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.4101 - val_loss: 0.2620\n",
      "EPOCH: 696 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2362 - val_loss: 0.0723\n",
      "EPOCH: 697 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0879 - val_loss: 0.0852\n",
      "EPOCH: 698 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1876 - val_loss: 0.1879\n",
      "EPOCH: 699 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0643 - val_loss: 0.1267\n",
      "EPOCH: 700 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0926 - val_loss: 0.2349\n",
      "EPOCH: 701 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1304 - val_loss: 0.1271\n",
      "EPOCH: 702 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0696 - val_loss: 0.0458\n",
      "EPOCH: 703 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1460 - val_loss: 0.3877\n",
      "EPOCH: 704 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2344 - val_loss: 0.1075\n",
      "EPOCH: 705 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1455 - val_loss: 0.1078\n",
      "EPOCH: 706 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1059 - val_loss: 0.1313\n",
      "EPOCH: 707 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0826 - val_loss: 0.0731\n",
      "EPOCH: 708 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0427 - val_loss: 0.0731\n",
      "EPOCH: 709 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3355 - val_loss: 0.5817\n",
      "EPOCH: 710 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2960 - val_loss: 0.3644\n",
      "EPOCH: 711 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1842 - val_loss: 0.2825\n",
      "EPOCH: 712 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1638 - val_loss: 0.2815\n",
      "EPOCH: 713 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1284 - val_loss: 0.0894\n",
      "EPOCH: 714 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1029 - val_loss: 0.1474\n",
      "EPOCH: 715 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2340 - val_loss: 0.4563\n",
      "EPOCH: 716 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1661 - val_loss: 0.2821\n",
      "EPOCH: 717 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1158 - val_loss: 0.0023\n",
      "EPOCH: 718 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0631 - val_loss: 0.0566\n",
      "EPOCH: 719 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3707 - val_loss: 0.0838\n",
      "EPOCH: 720 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1107 - val_loss: 0.0405\n",
      "EPOCH: 721 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1525 - val_loss: 0.1011\n",
      "EPOCH: 722 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1162 - val_loss: 0.5086\n",
      "EPOCH: 723 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0790 - val_loss: 0.0642\n",
      "EPOCH: 724 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2198 - val_loss: 0.3165\n",
      "EPOCH: 725 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0847 - val_loss: 0.0069\n",
      "EPOCH: 726 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2059 - val_loss: 0.2002\n",
      "EPOCH: 727 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1123 - val_loss: 0.1114\n",
      "EPOCH: 728 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2770 - val_loss: 0.2319\n",
      "EPOCH: 729 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2175 - val_loss: 0.2484\n",
      "EPOCH: 730 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1092 - val_loss: 0.1077\n",
      "EPOCH: 731 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1848 - val_loss: 0.0842\n",
      "EPOCH: 732 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1104 - val_loss: 0.0687\n",
      "EPOCH: 733 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2121 - val_loss: 0.0782\n",
      "EPOCH: 734 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1053 - val_loss: 0.1044\n",
      "EPOCH: 735 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1017 - val_loss: 0.0774\n",
      "EPOCH: 736 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1331 - val_loss: 0.0794\n",
      "EPOCH: 737 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1600 - val_loss: 0.0353\n",
      "EPOCH: 738 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0767 - val_loss: 0.0447\n",
      "EPOCH: 739 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1030 - val_loss: 0.1024\n",
      "EPOCH: 740 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0997 - val_loss: 0.1016\n",
      "EPOCH: 741 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1632 - val_loss: 0.1449\n",
      "EPOCH: 742 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3377 - val_loss: 0.2610\n",
      "EPOCH: 743 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3137 - val_loss: 0.3516\n",
      "EPOCH: 744 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3185 - val_loss: 0.2126\n",
      "EPOCH: 745 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.4422 - val_loss: 0.3247\n",
      "EPOCH: 746 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1024 - val_loss: 0.0786\n",
      "EPOCH: 747 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2270 - val_loss: 0.4511\n",
      "EPOCH: 748 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3531 - val_loss: 0.1600\n",
      "EPOCH: 749 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0523 - val_loss: 0.0495\n",
      "EPOCH: 750 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0780 - val_loss: 0.0102\n",
      "EPOCH: 751 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1148 - val_loss: 0.0337\n",
      "EPOCH: 752 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1597 - val_loss: 0.0844\n",
      "EPOCH: 753 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2321 - val_loss: 0.2876\n",
      "EPOCH: 754 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0489 - val_loss: 0.0474\n",
      "EPOCH: 755 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2041 - val_loss: 0.2036\n",
      "EPOCH: 756 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2553 - val_loss: 0.2624\n",
      "EPOCH: 757 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 0.1052 - val_loss: 0.1043\n",
      "EPOCH: 758 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1095 - val_loss: 0.1847\n",
      "EPOCH: 759 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0448 - val_loss: 0.0642\n",
      "EPOCH: 760 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0951 - val_loss: 0.0911\n",
      "EPOCH: 761 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0441 - val_loss: 0.1754\n",
      "EPOCH: 762 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0739 - val_loss: 0.0019\n",
      "EPOCH: 763 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1054 - val_loss: 0.2433\n",
      "EPOCH: 764 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0810 - val_loss: 0.0014\n",
      "EPOCH: 765 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2516 - val_loss: 5.0997e-04\n",
      "EPOCH: 766 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0723 - val_loss: 0.1352\n",
      "EPOCH: 767 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1103 - val_loss: 0.0061\n",
      "EPOCH: 768 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1210 - val_loss: 0.0896\n",
      "EPOCH: 769 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1274 - val_loss: 0.0062\n",
      "EPOCH: 770 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2112 - val_loss: 0.0601\n",
      "EPOCH: 771 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.4533 - val_loss: 0.2916\n",
      "EPOCH: 772 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0483 - val_loss: 0.0114\n",
      "EPOCH: 773 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1103 - val_loss: 0.1016\n",
      "EPOCH: 774 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2419 - val_loss: 0.2159\n",
      "EPOCH: 775 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1766 - val_loss: 0.2186\n",
      "EPOCH: 776 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0419 - val_loss: 0.0386\n",
      "EPOCH: 777 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1457 - val_loss: 0.1312\n",
      "EPOCH: 778 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0798 - val_loss: 0.0746\n",
      "EPOCH: 779 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1121 - val_loss: 0.1272\n",
      "EPOCH: 780 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0871 - val_loss: 0.0712\n",
      "EPOCH: 781 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1644 - val_loss: 0.3012\n",
      "EPOCH: 782 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0569 - val_loss: 0.0356\n",
      "EPOCH: 783 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0799 - val_loss: 0.0318\n",
      "EPOCH: 784 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3893 - val_loss: 0.2606\n",
      "EPOCH: 785 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1179 - val_loss: 0.1815\n",
      "EPOCH: 786 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1054 - val_loss: 0.0407\n",
      "EPOCH: 787 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1311 - val_loss: 0.1041\n",
      "EPOCH: 788 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0698 - val_loss: 0.0620\n",
      "EPOCH: 789 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0985 - val_loss: 0.0986\n",
      "EPOCH: 790 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2569 - val_loss: 0.3837\n",
      "EPOCH: 791 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0510 - val_loss: 0.0831\n",
      "EPOCH: 792 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2378 - val_loss: 0.3244\n",
      "EPOCH: 793 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0804 - val_loss: 0.0778\n",
      "EPOCH: 794 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0881 - val_loss: 0.0198\n",
      "EPOCH: 795 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0463 - val_loss: 0.0447\n",
      "EPOCH: 796 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0581 - val_loss: 0.0377\n",
      "EPOCH: 797 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1011 - val_loss: 0.1008\n",
      "EPOCH: 798 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1830 - val_loss: 0.1404\n",
      "EPOCH: 799 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1010 - val_loss: 0.1008\n",
      "EPOCH: 800 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1412 - val_loss: 0.1585\n",
      "EPOCH: 801 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0408 - val_loss: 0.0378\n",
      "EPOCH: 802 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2132 - val_loss: 0.2376\n",
      "EPOCH: 803 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0719 - val_loss: 0.0029\n",
      "EPOCH: 804 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0997 - val_loss: 0.0990\n",
      "EPOCH: 805 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1296 - val_loss: 0.1220\n",
      "EPOCH: 806 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0984 - val_loss: 0.0975\n",
      "EPOCH: 807 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1597 - val_loss: 0.4201\n",
      "EPOCH: 808 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1703 - val_loss: 0.1801\n",
      "EPOCH: 809 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0831 - val_loss: 0.0147\n",
      "EPOCH: 810 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0572 - val_loss: 0.0355\n",
      "EPOCH: 811 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1629 - val_loss: 0.0244\n",
      "EPOCH: 812 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2119 - val_loss: 0.2602\n",
      "EPOCH: 813 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2386 - val_loss: 0.2254\n",
      "EPOCH: 814 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0957 - val_loss: 0.0949\n",
      "EPOCH: 815 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0975 - val_loss: 0.0154\n",
      "EPOCH: 816 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1174 - val_loss: 0.2337\n",
      "EPOCH: 817 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3596 - val_loss: 0.3644\n",
      "EPOCH: 818 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0447 - val_loss: 0.0380\n",
      "EPOCH: 819 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2638 - val_loss: 0.2291\n",
      "EPOCH: 820 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2093 - val_loss: 0.1242\n",
      "EPOCH: 821 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2185 - val_loss: 0.0843\n",
      "EPOCH: 822 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0581 - val_loss: 0.1502\n",
      "EPOCH: 823 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2439 - val_loss: 0.3135\n",
      "EPOCH: 824 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2465 - val_loss: 0.3747\n",
      "EPOCH: 825 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0580 - val_loss: 0.1511\n",
      "EPOCH: 826 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0853 - val_loss: 0.0414\n",
      "EPOCH: 827 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1261 - val_loss: 0.1111\n",
      "EPOCH: 828 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2987 - val_loss: 0.3150\n",
      "EPOCH: 829 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0800 - val_loss: 0.0286\n",
      "EPOCH: 830 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3151 - val_loss: 0.4115\n",
      "EPOCH: 831 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1174 - val_loss: 0.0534\n",
      "EPOCH: 832 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0495 - val_loss: 0.1684\n",
      "EPOCH: 833 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0278 - val_loss: 0.0557\n",
      "EPOCH: 834 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2528 - val_loss: 0.2021\n",
      "EPOCH: 835 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1961 - val_loss: 0.3310\n",
      "EPOCH: 836 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1537 - val_loss: 0.1487\n",
      "EPOCH: 837 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0885 - val_loss: 0.0837\n",
      "EPOCH: 838 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3523 - val_loss: 0.2708\n",
      "EPOCH: 839 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1019 - val_loss: 0.0638\n",
      "EPOCH: 840 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0367 - val_loss: 0.0182\n",
      "EPOCH: 841 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2526 - val_loss: 0.1374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 842 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0865 - val_loss: 0.1152\n",
      "EPOCH: 843 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1830 - val_loss: 0.1978\n",
      "EPOCH: 844 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1016 - val_loss: 0.1014\n",
      "EPOCH: 845 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0557 - val_loss: 0.0348\n",
      "EPOCH: 846 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0234 - val_loss: 0.0072\n",
      "EPOCH: 847 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2087 - val_loss: 0.3017\n",
      "EPOCH: 848 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1492 - val_loss: 0.0166\n",
      "EPOCH: 849 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0968 - val_loss: 0.0991\n",
      "EPOCH: 850 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1200 - val_loss: 0.0570\n",
      "EPOCH: 851 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1406 - val_loss: 0.0871\n",
      "EPOCH: 852 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1962 - val_loss: 0.2044\n",
      "EPOCH: 853 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2754 - val_loss: 0.0863\n",
      "EPOCH: 854 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1094 - val_loss: 0.2090\n",
      "EPOCH: 855 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1364 - val_loss: 0.0109\n",
      "EPOCH: 856 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0336 - val_loss: 0.0264\n",
      "EPOCH: 857 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0573 - val_loss: 0.0717\n",
      "EPOCH: 858 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3131 - val_loss: 0.0908\n",
      "EPOCH: 859 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0981 - val_loss: 0.0945\n",
      "EPOCH: 860 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0395 - val_loss: 0.2102\n",
      "EPOCH: 861 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.4345 - val_loss: 0.3183\n",
      "EPOCH: 862 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1620 - val_loss: 0.0095\n",
      "EPOCH: 863 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1127 - val_loss: 0.0084\n",
      "EPOCH: 864 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1125 - val_loss: 0.0083\n",
      "EPOCH: 865 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0623 - val_loss: 0.0580\n",
      "EPOCH: 866 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1451 - val_loss: 0.0862\n",
      "EPOCH: 867 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1069 - val_loss: 0.1609\n",
      "EPOCH: 868 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3280 - val_loss: 0.3976\n",
      "EPOCH: 869 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1166 - val_loss: 0.0531\n",
      "EPOCH: 870 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1453 - val_loss: 0.1345\n",
      "EPOCH: 871 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2903 - val_loss: 0.1683\n",
      "EPOCH: 872 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0797 - val_loss: 0.0163\n",
      "EPOCH: 873 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0498 - val_loss: 0.0290\n",
      "EPOCH: 874 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1585 - val_loss: 0.1514\n",
      "EPOCH: 875 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2202 - val_loss: 0.0159\n",
      "EPOCH: 876 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3084 - val_loss: 0.2040\n",
      "EPOCH: 877 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2727 - val_loss: 0.2254\n",
      "EPOCH: 878 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2579 - val_loss: 0.3263\n",
      "EPOCH: 879 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0499 - val_loss: 0.0024\n",
      "EPOCH: 880 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1619 - val_loss: 0.2937\n",
      "EPOCH: 881 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1026 - val_loss: 0.0497\n",
      "EPOCH: 882 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1482 - val_loss: 0.0472\n",
      "EPOCH: 883 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3040 - val_loss: 0.3666\n",
      "EPOCH: 884 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2494 - val_loss: 0.3131\n",
      "EPOCH: 885 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1403 - val_loss: 0.1785\n",
      "EPOCH: 886 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3637 - val_loss: 0.2880\n",
      "EPOCH: 887 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.4326 - val_loss: 0.4491\n",
      "EPOCH: 888 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2562 - val_loss: 0.2978\n",
      "EPOCH: 889 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2914 - val_loss: 0.1524\n",
      "EPOCH: 890 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2946 - val_loss: 0.2759\n",
      "EPOCH: 891 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1098 - val_loss: 0.1142\n",
      "EPOCH: 892 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2104 - val_loss: 0.1148\n",
      "EPOCH: 893 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1234 - val_loss: 0.0629\n",
      "EPOCH: 894 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1234 - val_loss: 5.2794e-06\n",
      "EPOCH: 895 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3318 - val_loss: 0.3596\n",
      "EPOCH: 896 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0456 - val_loss: 0.0084\n",
      "EPOCH: 897 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1142 - val_loss: 0.0451\n",
      "EPOCH: 898 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1402 - val_loss: 0.2122\n",
      "EPOCH: 899 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0724 - val_loss: 0.0893\n",
      "EPOCH: 900 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1617 - val_loss: 0.1232\n",
      "EPOCH: 901 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.4230 - val_loss: 0.2946\n",
      "EPOCH: 902 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.4097 - val_loss: 0.3227\n",
      "EPOCH: 903 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1181 - val_loss: 0.0014\n",
      "EPOCH: 904 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0683 - val_loss: 0.0517\n",
      "EPOCH: 905 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1013 - val_loss: 0.1822\n",
      "EPOCH: 906 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2113 - val_loss: 0.3453\n",
      "EPOCH: 907 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1002 - val_loss: 0.1591\n",
      "EPOCH: 908 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1343 - val_loss: 0.1344\n",
      "EPOCH: 909 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1148 - val_loss: 0.1958\n",
      "EPOCH: 910 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2561 - val_loss: 0.2135\n",
      "EPOCH: 911 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1830 - val_loss: 0.1790\n",
      "EPOCH: 912 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1307 - val_loss: 0.1351\n",
      "EPOCH: 913 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1117 - val_loss: 0.0109\n",
      "EPOCH: 914 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2217 - val_loss: 0.2209\n",
      "EPOCH: 915 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1451 - val_loss: 0.3992\n",
      "EPOCH: 916 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1080 - val_loss: 0.1862\n",
      "EPOCH: 917 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1564 - val_loss: 0.0618\n",
      "EPOCH: 918 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1128 - val_loss: 0.1670\n",
      "EPOCH: 919 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3399 - val_loss: 0.3817\n",
      "EPOCH: 920 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1606 - val_loss: 0.1560\n",
      "EPOCH: 921 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0491 - val_loss: 0.0171\n",
      "EPOCH: 922 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0872 - val_loss: 0.0694\n",
      "EPOCH: 923 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1409 - val_loss: 0.1404\n",
      "EPOCH: 924 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1301 - val_loss: 0.1242\n",
      "EPOCH: 925 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1462 - val_loss: 0.1617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 926 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1562 - val_loss: 0.0421\n",
      "EPOCH: 927 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0761 - val_loss: 0.1239\n",
      "EPOCH: 928 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0849 - val_loss: 0.0698\n",
      "EPOCH: 929 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0715 - val_loss: 3.8936e-06\n",
      "EPOCH: 930 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0831 - val_loss: 0.0629\n",
      "EPOCH: 931 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1599 - val_loss: 0.4106\n",
      "EPOCH: 932 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0343 - val_loss: 0.0660\n",
      "EPOCH: 933 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2494 - val_loss: 0.6292\n",
      "EPOCH: 934 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1700 - val_loss: 0.1028\n",
      "EPOCH: 935 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2785 - val_loss: 0.0622\n",
      "EPOCH: 936 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1061 - val_loss: 0.2337\n",
      "EPOCH: 937 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2580 - val_loss: 0.3177\n",
      "EPOCH: 938 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0862 - val_loss: 0.0703\n",
      "EPOCH: 939 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1986 - val_loss: 0.0929\n",
      "EPOCH: 940 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0929 - val_loss: 0.1072\n",
      "EPOCH: 941 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2499 - val_loss: 0.2954\n",
      "EPOCH: 942 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2948 - val_loss: 0.4315\n",
      "EPOCH: 943 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1087 - val_loss: 0.1450\n",
      "EPOCH: 944 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2448 - val_loss: 0.3713\n",
      "EPOCH: 945 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1168 - val_loss: 0.0699\n",
      "EPOCH: 946 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1526 - val_loss: 0.1118\n",
      "EPOCH: 947 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1185 - val_loss: 0.3217\n",
      "EPOCH: 948 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0813 - val_loss: 2.7269e-04\n",
      "EPOCH: 949 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2596 - val_loss: 0.2552\n",
      "EPOCH: 950 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2420 - val_loss: 0.2646\n",
      "EPOCH: 951 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0806 - val_loss: 0.0692\n",
      "EPOCH: 952 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0725 - val_loss: 0.0108\n",
      "EPOCH: 953 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1819 - val_loss: 0.0891\n",
      "EPOCH: 954 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1230 - val_loss: 0.1288\n",
      "EPOCH: 955 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3132 - val_loss: 0.3709\n",
      "EPOCH: 956 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1143 - val_loss: 0.1887\n",
      "EPOCH: 957 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1021 - val_loss: 0.0723\n",
      "EPOCH: 958 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1932 - val_loss: 0.3293\n",
      "EPOCH: 959 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1325 - val_loss: 0.1309\n",
      "EPOCH: 960 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3515 - val_loss: 0.3502\n",
      "EPOCH: 961 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2331 - val_loss: 0.4887\n",
      "EPOCH: 962 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2147 - val_loss: 0.1262\n",
      "EPOCH: 963 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1740 - val_loss: 0.1437\n",
      "EPOCH: 964 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0662 - val_loss: 0.0460\n",
      "EPOCH: 965 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1152 - val_loss: 0.0010\n",
      "EPOCH: 966 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1896 - val_loss: 0.1874\n",
      "EPOCH: 967 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1080 - val_loss: 0.2650\n",
      "EPOCH: 968 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1303 - val_loss: 0.0826\n",
      "EPOCH: 969 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1196 - val_loss: 0.1181\n",
      "EPOCH: 970 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1495 - val_loss: 0.1607\n",
      "EPOCH: 971 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1601 - val_loss: 0.2099\n",
      "EPOCH: 972 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0990 - val_loss: 0.0438\n",
      "EPOCH: 973 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2069 - val_loss: 0.1708\n",
      "EPOCH: 974 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1013 - val_loss: 0.0877\n",
      "EPOCH: 975 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2715 - val_loss: 0.1857\n",
      "EPOCH: 976 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1011 - val_loss: 0.1036\n",
      "EPOCH: 977 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1219 - val_loss: 0.0256\n",
      "EPOCH: 978 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1132 - val_loss: 0.1124\n",
      "EPOCH: 979 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1221 - val_loss: 0.1031\n",
      "EPOCH: 980 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0651 - val_loss: 0.1036\n",
      "EPOCH: 981 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1515 - val_loss: 0.2500\n",
      "EPOCH: 982 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2371 - val_loss: 0.2264\n",
      "EPOCH: 983 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2239 - val_loss: 0.1001\n",
      "EPOCH: 984 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0972 - val_loss: 0.0374\n",
      "EPOCH: 985 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0379 - val_loss: 0.0340\n",
      "EPOCH: 986 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2147 - val_loss: 0.0919\n",
      "EPOCH: 987 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2172 - val_loss: 0.1731\n",
      "EPOCH: 988 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0379 - val_loss: 0.0329\n",
      "EPOCH: 989 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1113 - val_loss: 0.1839\n",
      "EPOCH: 990 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0591 - val_loss: 0.0288\n",
      "EPOCH: 991 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0657 - val_loss: 3.3876e-04\n",
      "EPOCH: 992 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1147 - val_loss: 0.0678\n",
      "EPOCH: 993 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2961 - val_loss: 0.2779\n",
      "EPOCH: 994 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1963 - val_loss: 0.1562\n",
      "EPOCH: 995 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0540 - val_loss: 0.0946\n",
      "EPOCH: 996 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0562 - val_loss: 0.1848\n",
      "EPOCH: 997 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1343 - val_loss: 0.0709\n",
      "EPOCH: 998 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1639 - val_loss: 0.1022\n",
      "EPOCH: 999 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1385 - val_loss: 0.1680\n",
      "EPOCH: 1000 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2871 - val_loss: 0.2995\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAABRuUlEQVR4nO2deZwUxfn/P8/M7MFyX3KqoKICHoh4a+KJeAQ1GqOGxF9iJGqMmqgJmEi88o23xjteMWqUeIuKt+ARRVjAg1NuWc5lgYVlz5mu3x/dPdNHdXf1MTvTQ71fL17sVFdXV1+fevqpp6qIMQaJRCKRxJ9EoSsgkUgkkmiQgi6RSCQlghR0iUQiKRGkoEskEkmJIAVdIpFISoRUoQ7cq1cvNmjQoEIdXiKRSGLJ7NmzNzHGevO2FUzQBw0ahOrq6kIdXiKRSGIJEa1y2iZdLhKJRFIiSEGXSCSSEkEKukQikZQIBfOhSyQSSRDa2tpQU1OD5ubmQlclr1RWVmLgwIEoKysT3kcKukQiiRU1NTXo3LkzBg0aBCIqdHXyAmMMdXV1qKmpweDBg4X3ky4XiUQSK5qbm9GzZ8+SFXMAICL07NnT91eIFHSJRBI7SlnMdYKcYzwFfetqYMn7ha6FRCKRFBXxFPSHjwL+c06hayGRSHZCtm7dioceesj3fqeeeiq2bt0afYUMxFPQW+rV/9fMLmw9JBLJToeToKfTadf9pk6dim7duuWpVirxFHSdx44vdA0kEslOxoQJE7Bs2TKMGDEChxxyCI455hiMHTsWw4YNAwCceeaZOPjggzF8+HA8+uij2f0GDRqETZs2YeXKlRg6dCguvvhiDB8+HKNHj0ZTU1MkdZNhixKJJLbc+MZ8LFi7LdIyh/Xvgr/+aLjj9ltvvRXz5s3DV199henTp+O0007DvHnzsuGFTz75JHr06IGmpiYccsghOPvss9GzZ09TGUuWLMHzzz+Pxx57DOeeey5efvlljBs3LnTdpaBLJBJJCA499FBTrPh9992HV199FQCwevVqLFmyxCbogwcPxogRIwAABx98MFauXBlJXaSgSySS2OJmSbcXHTt2zP49ffp0fPDBB/jiiy9QVVWFY489lhtLXlFRkf07mUxG5nKJtw9dIpFI2pnOnTtj+/bt3G319fXo3r07qqqqsGjRIsyYMaNd6yYtdIlEIvFBz549cdRRR2G//fZDhw4d0KdPn+y2MWPG4JFHHsHQoUOxzz774PDDD2/XuklBl0gkEp8899xz3PSKigq8/fbb3G26n7xXr16YN29eNv2aa66JrF7S5SKRSCQlghR0iUQiKRGkoEskEkmJIAVdIpFISgQp6BKJRFIiSEGXSCSSEiH+gn7/wcCqzwtdC4lEspMQdPpcALj33nvR2NgYcY1yxF/Q65YC7/2l0LWQSCQ7CcUs6HJgkUQikfjAOH3uSSedhF122QUvvPACWlpacNZZZ+HGG2/Ejh07cO6556KmpgaZTAbXX389NmzYgLVr1+K4445Dr169MG3atMjrVhqCvmY2sHERsMu+ha6JRCJpT96eAKz/Ntoy++4PnHKr42bj9LnvvfceXnrpJcycOROMMYwdOxaffPIJamtr0b9/f7z11lsA1DleunbtirvvvhvTpk1Dr169oq2zRvxdLjpfPlLoGkgkkp2M9957D++99x4OOuggjBw5EosWLcKSJUuw//774/3338ef/vQnfPrpp+jatWu71Kc0LHQASFUWugYSiaS9cbGk2wPGGCZOnIjf/OY3tm1z5szB1KlT8Ze//AUnnHACJk2alPf6lI6FXiYFXSKR5B/j9Lknn3wynnzySTQ0NAAA1qxZg40bN2Lt2rWoqqrCuHHjcO2112LOnDm2ffNBCVnoHQpdA4lEshNgnD73lFNOwQUXXIAjjjgCANCpUyc8++yzWLp0Ka699lokEgmUlZXh4YcfBgCMHz8eY8aMQf/+/fPSKUqMMe9MRGMA/ANAEsDjjLFbLdt3A/BvAN20PBMYY1Pdyhw1ahSrrq4OVusbOP6ok24CjroyWHkSiSQ2LFy4EEOHDi10NdoF3rkS0WzG2Chefk+XCxElATwI4BQAwwCcT0TDLNn+AuAFxthBAM4DECxIMwzSQpdIJDs5Ij70QwEsZYwtZ4y1ApgM4AxLHgagi/Z3VwBro6uiIKly520tDcCcpwGBrxGJRCKJKyKCPgDAasPvGi3NyA0AxhFRDYCpAH7HK4iIxhNRNRFV19bWBqiuCxsXAiv/x9/29h+BKb+TUwRIJCWCiKs47gQ5x6iiXM4H8BRjbCCAUwE8Q0S2shljjzLGRjHGRvXu3TuiQ2t8+Qjw1Kn8bdvXq/+35W/IrUQiaR8qKytRV1dX0qLOGENdXR0qK/1F74lEuawBsKvh90AtzchFAMZoFfmCiCoB9AKw0VdtJBKJxIOBAweipqYGkX/lFxmVlZUYOHCgr31EBH0WgCFENBiqkJ8H4AJLnu8BnADgKSIaCqASQGlfbYlEUhDKysowePDgQlejKPF0uTDG0gAuB/AugIVQo1nmE9FNRDRWy3Y1gIuJ6GsAzwP4f6yUv4ckEomkCBEaWKTFlE+1pE0y/L0AwFHRVo3P16u34sD2OJBEIpHEjNgN/d+wrdn3Por8VpBIJDsBsRP0ICzfpM6zsKy2QR1lOuWKAtdIIpFIoid2gk5EvvdpbM0AABpa0mrCnH9HWSWJRCIpCmIn6BKJRCLhs5MJun/rXiKRSOJC7AQ9jCRLOZdIJKVM7ATdE0UpdA0kEomkIJSeoLNMoWsgkUgkBSF2gu4Z5KKk26UeEolEUmzETtA9kYIukUh2UqSgSyQSSYkQO0H3drnwfOhy7L9EIil9YifonkgLXSKR7KRIQZdIJJISIXaCTl7DgzJtbjtLJBJJyRI7QfeEyYFFEolk56T0BF0ikUh2UuIn6F5uE7nynUQi2UmJn6B74izo0oUukUhKmdITdGmhSySSnZTYCbqnle3aKSptdIlEUrrET9A9h4pyLHTmsk0ikUhKhNgJuicclwtJIZdIJDsBsRN0b6eJFG+JRLJzEjtB98SlU1Ra6hKJpJQpQUF36xSVgi6RSEqX2Am6Z5+oWxy6DGmUSCQlTOwE3RNX0ZaCLpFISpfSE3Q30ZYTd0kkkhImdoLuOX2ua6eoRCKR+CCTBpq3FboWwsRO0D2RUS4SiSQqXr8MuHXXQtdCmNITdI5oBxoounom8L/7oqiQROJOutV9YRZJ4fjmv4WugS9iJ+jeI/8j6hR94iTg/evF80skQbmlN3Dv/oWuhaQEiJ2ge8Mb+u+8TSIpCravK3QNJCWAkKAT0RgiWkxES4logkOec4loARHNJ6Lnoq2mDzgWOnPZJpFIJJ7ERDtSXhmIKAngQQAnAagBMIuIpjDGFhjyDAEwEcBRjLEtRLRLviocZi4X2SkqkUhKGREL/VAASxljyxljrQAmAzjDkudiAA8yxrYAAGNsY7TV9AFT1Na09rtskhRyiUQSiphY6CKCPgDAasPvGi3NyN4A9iai/xHRDCIawyuIiMYTUTURVdfW1garsReMATMfBR48RI1UMR5fCrtEIglEPLQjqk7RFIAhAI4FcD6Ax4iomzUTY+xRxtgoxtio3r17R3Ro21GAmlnqn5tX2LdJJBJJiSIi6GsAGCPrB2ppRmoATGGMtTHGVgD4DqrAR46nJDOW+zyihH2bRCKR+CUm2iEi6LMADCGiwURUDuA8AFMseV6Dap2DiHpBdcEsj66afmC5OVuIgDeuwv4tcwtTFYkEUAcN1S0rdC3EmPwz9Z/EQokIOmMsDeByAO8CWAjgBcbYfCK6iYjGatneBVBHRAsATANwLWOsLh8V9mwomWIW9Nn/ym6KpQ99yftA4+ZC10IShveuB+4fCdRbP2yLkEVvqv8kscQzbBEAGGNTAUy1pE0y/M0A/EH7l1eYlygzhmxranO5xGy2xcbNwH/OAXY/GvjlW4WujZ0N89X/+wwvbD2KnZWfqv83bQa6WuMJJLGghFwuMcPgcrFErcfOQk+3qP/XLS1sPZx4+Ej1n6T4aWsG6msKXYsYEw/tiJ2ge7tcDJ2iStrnzsVG3OorKVZaJ/8CuEd+SZU68RN0kRy6cLc1+d67qMhG68iZ3CXhKF/2rvpH7IyaIiEm1y12gu4JQ87lkm42bZKyKCkIRSQGTMkUugoxpXjuoRuxE3Tm9XIwBdmL72ahT/t7lNWSSGKB5/sj4ROT6xY/QRfJoVvomRbLJsPeH98aYa3yhV5f+W0Ra4rAZaYwtQ4sbpFeEl/ETtA9Yc5RLnH5bJJIokZ/8pkiBT0Y8dCO+Am699j/2HweeSI7RSURwSAt9FDERFNiJ+i+BhZx9o4nUtAl0SB96KVN7ATdE+vQfwMUu4c5bvUV5L8/B549p9C12KnIWegyyiUY8XgXhYb+FxPemuzmQ48ZpepyWWid202Sb3I+9HgIU9ERE2Mwdha6r5GiFmI39F9GucSXKb8D3sz71EbC6BZ6XIRJEozYCbo3zNGyjZ3/MG71leSY8zRQ/USha2FAd7n4fKaatgIt26OvTuyIx7sYO0EXWuDCIVfsLPRsX0BhqyGJP1mXi18f+m27A7cNjrw+sSMmxlX8BF1kpKiTDz0mNyULC+hyqVsGNNdHXh1JQIrouQvkQ1faoq+IJC/ETtC9MXaKWjfFLQY3oBDcPxJ48pRoq6KzfT2wY1N+ypbkjWyUC+L2DhQLxdMouxG/KBfPDAYfuk3AA9wUxgoXZeIQfinExvnR1kXnrn3U/2+QXwDCFEGUUrZTVI4UDUYRfWW5ETsL3fO6fj8jN4eLVdBjclOylEr4paTg5HzoUtAj5869gS//WehaAIihoHsy6zFg3dfaD4uABxH0QjYCcWuADNRsacTqzY3RFbhlZXyjLYroPsYu0isONGwA3v5joWsBIJaC7uOBtD28QayTQgq6Wl9WBJ/sfjn6tmk45vZp0RX4jwOBJ0ZHV14p8c5E4NHjXLPkXC5S0AMRk4YwdoLu67rG3OXS1KYuobelsbXANQEGTXgLf319XmErsXFBtOW1NakLcecTRcm/D33GQ8DaOa5ZZKdoWBy0o8j6JGIn6L6wCHiPtdNDl9GeNLWo4WINzWmPnO3Dv79Yxd8w5Yp4xio/fiJwe57r/dndRWVIyOlzI6bI5sYpvSgXU2bzw9ttw4xI65Jv9A4sVuydonP+XegaBGNDO3xx1MzK/zEEyA39l4IeCKdGuciuZ+ws9FAul2BHDL7rzMeAb18KfmTN31loOZcdaSEpgj6QrMtFWugBcXK5FJeFHjtB94eHEN3QFVj1ef4OP/Ua4OWLAu9OKA4LPSM70mJPNmxR1Id+x17ABzeGOub3dY2oa2jxzhhnpIUeDs8FLkyZBS72LI8JlAoatqgLemFpzQR/aE+4azruef+7CGsTM1xm/7RRvyZ/1cha6IJ12VGr+v/daNwMPHAosHERd/MP7piGo277yE8180dDLbDyf8H3d3S5SAs9FNG7XDzn4/VxQGe27GjFPn95G7NW+oiqKBJXR1s6eD2W1e7APz5cEmFtImJDxBEzTiyfJj5q955heatG9g5GaVEu/QDYtBj49E7HLM1tRWLBPnky8NSpIQrwcLlQcUhpcdQiX4gIYjuJ5uxVW9CSVvDw9GViO3zzIrq+fQmAwrtcwljo7cL6eepovYZa8X1WfJy/+hjJGEJOp1yhTqtbSCJ83h/7dHlkZeWdzYLvnV+CTqCXJ2In6GGiXAKVGNEL4Ltf7JVfI7WtRt87kjoEpa3YBf3z+9TReks/EN/HcF/rGlqwZUc7xPqvnaMufNFemDpAo18ket6a4pnPpyWdwYpNO7wzBn2fvVwu0kIPhq+IiyKy0HOHKw43ChfGgOd+Ciz90JTcmi5yQddfpoBidfAtH+Cgm9+PsEJFwOYVwE3dgW9eBGDwoeejE68InunrXpmH4+6cjvpGj6l+A58/Axa/DSyxGA1hJtDLA7ETdH9E8aA5lLH+W+C794RLCXO/22vo/0ffrgK+eweYfIEpXbfQk4k81GNHXfgyAgl67r6ek4zI/ZJuBd65Tl3lp9BsXKj+P+9lAPkJW8y5Agsv6J8vU6d0bmj1GIQXpkF7/jzgP2eb06QPvR3Jp8vlkaOB537iu0rFzG+fm639ZRbu1nwJ+rxXgDv2AFbPDFcOhRs0c2eZ80x5dQ0t2PvPb2P2KoHO7G9fAGY8CHwYLtwvEhLamEFtcYpc2GKURPg8NNcD6eAhjsI10Z6RuoYWnPfoF9iwrVlwP+lyyQuRR7m0t8ulnfYJQvalsHwRtGXUGqSiFvSVn6n/Z2fHDEj2ZYr+Ss1csRmtGQWPfbLCO7OSNv9fSBJJ9f+MLuj65FzFFWaX5dbd1EiUPMO0e/PS7BrMWL4Zj30i2rHrNVJUulwC4S8OXSRv+4QtUtaH6X/f9opyya25aj5eWrPQE1G7frKWddhrHMBCLwK/LwDxevgNs0yWqf9bBDwvfThRlbl2Lj9901Jh15zX+ekupz5dKgEAG7aHHPgUR5cLEY0hosVEtJSIJrjkO5uIGBGNiq6KISgmCz2EFvraNcT5ZAXdItx5GygalWWd9aHHTKRF8377EvDwEcDCN8TLTeiCrn8t2Bu9jMIwaMJb+McHwcYJtNvVfuBg4P6DXLOQoLGhZNTr0b1jOQC4u1zqa3J/e83lEhdBJ6IkgAcBnAJgGIDzicg2AoKIOgO4EsCXUVfSiJ93ZfOOgK3vBsNAkIhFIpjLpb0sdPtfQM7qid66i2jCqJA+dNeilVbcmnoUXdIiMe5B7pPANdWnDXYYkckl60NPm45ivId6Z/eD05eKl1soIlr0XLFYJ64huVu/N/zwEvRw9YoKkWblUABLGWPLGWOtACYDOIOT72YAtwEQ7GUIhh9NqW8UEHRrgdvWAQ8facwgfkAXwtxvf7H3EVjoFvJuoXvV2bq9tdE8iCiQdSR2Un3WTcN5qek4f9P9kZetZhXJG+Dp0X3oWUF3afSK5MMmCpiiAKu+cNyu6NeDd90/vUuNXuMWXDojRQcAWG34XaOlZSGikQB2ZYy95VYQEY0nomoiqq6t9TGqLyBOAuVK89bI64Ebumb/zH8cevQuF1/9Fr4OKGhZG6/ZoreAf40B7tzLWJBYOSHICuKGBWqMN49AfQx5urZZQff2oSuhn8nCtwj6pe8852H1+VjGn0NG96FzT/nDm4BHjvF34FLrFCWiBIC7AVztlZcx9ihjbBRjbFTv3r0DHc/Po0NCM8tZS7TcmMhGirbTDQ9R3wQcHs6C+9AN2ydfYI+KidKH3tYMPH2m2e1m5OEjgPtGYMWmHfjd83PDD7ryF7blv3yLy4XX6DFAPW+fYwL8ugLfmbcei9fnd13Yss3aRHDb1nK3s+z1sFzL7H1wusalE7a4BsCuht8DtTSdzgD2AzCdiFYCOBzAlHx1jPqxcIUet3bqSAsn5+3TGCSyFro5XXe55O1K+bHQeRgt/UxabFkwpzJrZqkTak21LPpryf6nl7/BG1+vxZzvt3DK9j58Lq9AXYMYA/r5WVwuxpGiehbGGPDv09UxAXnkkmdn4+R7PwFqZqvL/+WBnD7wr5niZKH7dftlC4yfoM8CMISIBhNROYDzAEzRNzLG6hljvRhjgxhjgwDMADCWMVadlxr7IBHIQudsz7RFFr+b//YjjIXOfxny73IJGTpqtPRv7gk8PTZ4nWxDuf2IaRG5XHQUfSi8/Vrr95UB7bay0i7YAjx+PPD65ZGWK9rm6YKuWG0XY8P62m/FD6xfz7gM/WeMpQFcDuBdAAsBvMAYm09ENxFRiDcnGP5cLgK5RRT25l6WjtKQVP8L2LJSOLuvT9tQLYZ72GKYoldvbsTarRarTMDl0pLOoCXtMVDHOvR/5afBKmkoozHElMH+jhd1B2o2s/qfZojkLHQ1XVGYwUL3UWzIenWmRvWPdV95Z960xNn15QB5CaxTp6hR0L96lrNjPFwuQmuKMsamAphqSZvkkPfY8NVyq4x4VrFOUUse64Og3/haHyFjLqRYK/DmVUDnfsDV0ZRpJg8WunYNmtNpIBms7GNunwYAWHnraYZU787M4ZPeRecyBXPd2rQAYYsZReGfilbG7FVb4bN7LCB5inKxuVz09AxWb27EMbdPw81n7ue/XOMh8u0KfMC/1zZ3Nfl1y2Qylnz6jj7cfg0bgU67qB302QFfMbHQ44zQyXmNLIt4+tys+6Jhg/C+7RWHnnCw0LMyH7W/SKAzM60wNLZ4zKAXIMrlW97Ur2tmA8/+WC1K8JqHt27Ddao+/cVKp4LV/6zTEDCGRVrH5Jtf8zsO84nQdW3aqoam+oCy5XJuyMI3c8fP+tBdLHQvpl6j/j/5AmDaLVoFikNKi6MWPvDjzxWLcvE4XkQapj9wXJ+dVx38HMhQ4ea2DNbVi3U+McYco1ySLfV4rOwu9MZWPzXxJqqh/wFmW2xLc/pEPs0tueYlPKat29f7FqDcgcJFuUx63cEloWfldIrqYYpF4va1c9vuYA8eGl15//1Z9k+mZIDGzZxZJ33cB15/mhT0YPh5/lfVCUx4b7iRPGs8sg5B5mAZRE6u/Mufm4Mj/i62piNjzi94v2Uv4KTkbFyS8jH0XATBsEVP1xnP0q9fo8b/f/1f8foY9ldAQKYNCUVf+MJcB9Ovu/axdMRGHIpoHILut1zdIs1+xeSjY96PkSWWl+pXe2cKwo5a4PbB2Gu+OlCMgoyF4FEkjWPsBN0PG0WsU+1G3TBlPgZPnAon/3FYElBbdQo07DLY0/LBwo0AxM6BwfBFY3W5aLuLRQ35Qexl8hKBTLZzz1BOrTYf+DeTuft4x9UQ8MAoHDjzGve66ZeqZpZ/k3f9PGDRVPc8674Gvn5OqLjG1jSW1zaoDdkHN2iploaIZWxpQWAt23FCco5axfogg8P9P9M1Wxrx5Gcr+KVlP/bcO0WpYT0AoO/a98z5uc+geB2ZtNCD4S/KRSQeWc3z1OcrAdjXz4zMos4+MC7lLftIfRnrzOsfho1yyQg0IqrLxSmGV01PBBCCAahFZzi4IwRdLl5n/+VKNRZ82cYG+8aA908BmSKRRjZ+BjRtiap4lUeOAl67xD2PcVSqx8Eueqoax9+lLdahR/ro8/AYwhajeKTZlCvx46Q6/TE3Ft+7BN97XPjkTNz05gLUhpghkVncJcQU9SvG011nqC+nsdjRWhzTEsdP0B2egz2a7aFGfmyAyjL1UjRZbowSoNNq845W3PymebpTlu2ccinvmxfU/1db5jfzN92iLSUj8AYrzKVTlAUX9P9VXok3yv/M3xjRbIuNreo1bWo1dp6GiwlnvFdjxsPZP6sUF3delD6NZLlw1i+W80Z6mgWdKUo0TsQ69wm9nAyhMB3825qd52HJ9U3ZUiwVUEzZHqn7lTqgiltfQ5rHPS2WZXdjJ+hO8C63mACpeTqWqxGcjW3WuS/81+WmN+bjCeunoWYZBJlfxmmPHS1pNLTYoxh0fp58H3MqxosNnIRzpyiyqcGkYFBiA3qBN1teNC4XSqiPseJjeTXrGfZDHbAiF7+ucK9BLu3c7U8LlBqOpRsbsHKrZfHq+jViI2F1bNc2Ggu92fCe8M7a6RhBnyFT2bxyNSOEeXyVWztDeysb1S8vPxY6l+JwosdO0J06KX933BBbmpDPd8cmYMtKdKzQBN366ST69G9fn11Cy+q2AQyfeoHeJv7Dst8N72K/v77ruNfNZf9CD2pARkAATNVy8KGHeRmrKy9Ff2wyJ2oW+haPaY69jpsIIOjWF3RqxUSgdbthK+eaG65LOVrt2yPmxLs/xp+nGMYqbF4O3DMM+Owul72s4XjMlKpa6OFFdXktx73lXAsOeRZABx967j20bfBTuL1cH3vnk/gJutOV49xAoUdmwzzgHweiqlwdZtJoWWRWWH/v2gd44RfO++gjyiK89bbjzHgYmP2ULV+meTtwQ7fsgsFOZXkNLAricjFyZNIcYqeX9vLs7+2ZDXjdR13Q+Svai9W5O5kFimehr9uWa3jcS43uHrcxw9g/Pdpl2XTH/E6Nn3FB59yw9+Ci6tXIes/g6P8azWo72zN0lnn0F21vVhviTTssDXLYKBdpoUcMV9DFW90uZdqQb4uF7vUJZ7rR371jS8oSYrV1Yb/jOxOA93L+aoVp+239HgADPrzZ5RgGl4vtWuqC7u+h7wKzSFoXY85o5+U1Y6Gny4U4FnrIIGueoK8wWKWHNX+OlZUXINVsWDxaP2bztlDHNpL2OTTX3uhaGmlFiaSj3+vqeh7CwwfvxD4J93DGpdo9Wrh+O7BmjmnqagBoaFIb5XRGMTcOfhogzrPVXoP/vIidoDsa6Jw0PxZlH6Z2KGVsUS5eFeJNR8rZSVusN/rQP2d0UVIEFi12tdC1/xPkcTEsF2ty+d9cs+vhhimvch3n0dAaGt3lkoku0sDL5dJFUfsEls3jLNC12HVZgBD1cA/JU3O7u1yi+nowHofX4ArNsd601fdxGfjvejlrwyBah4Zm9T2rb2oDFrzGKSD3/s2qvIybzqXFMO3vgtfVUcW2mhWe2Am6Hx+0H59vOakPgtXfzP+Mt9THUif1pyVNL9et/hFHBija7WXZya045TMGpFuhmMIW+dUyXc/VM7k1NTIsscq1fhlFPa+k4fTmranHDktHr+PZZwU9qf3krcYT7EXjX3N72pSv13DyhWDbOssRHe4Zh37YjNEJ6ySnnCiXIJfEOgd9JAIW9N5YfjOG3zY+gOkVV6Oj0qDlIf6ITi3N9qx7vedPnGT+vfht8+5FMuw2foLuAO96+rHQU9qVsAu6pYxta82fcUwBvp9hynLUtqn4v9Tj5v2YKlKexqiaSySTJxnorggXy3X2U8AtvTX/LMcCTLeitZbzeVz9pD3Np1LoLpdkQt2vuS2D0+//DJf+Z44pn3PDbLbQzREMHtfQo648l8thqx+3pYXtV7Dx6LGmn36MklcrJuGh8vvMibnWWE/IfkH60iBDyKapOAfCr4LEh9fQPjNjFQ5TvgIAVOorYDIgzfli0xv9KrIMhvIdnmythxT0QDi7XHg+dB+CrrlCrJEStufSYple/PRMdckrAxduugsXpKaZ99MeGIJ/t0DQR0W30JW0S0TG/FfUY2xezne5vHElDqqdoqVG29GVdblo++nRQXNWbTHlczyufk11l4uvl9JL0O2vRpLZXVeRu9C0kYw6fp7hvrTFnpiNu87N5RKF1laVu0uHvylqxDPzBP3DhRuzz26234iAZz5fbt9fM246WZc+Drt8YXF4XGIo6D4unJ+XoUwzndMZyz72pU1Mvz75zrI2qsPq5Lsu4c2xLEbQZ0XRY3OdfMtL3gdWfJI9Sq5T1JDHsDaj2RrlNDO6+0lwMRC9uyKRyJW1G22whQR6u1x4Fno2k1Bd0sz8KuijIL0gl19RYLzmvBXqh9FKfwUyBqYouCr1Ejpl/HTeWs+UOWxRsVnoC9/AYbTQlwvJCYUxYP5rwNzcO6WXmxV8IodjqdewI5q46cJYQ3tFP3fSrcDyj22utaiInaA7Ed7lolvo1oFF7jfaZqG99CtuvkFLn9YLFK5Ttg4hfejZTtEtK4GHj8pl+M85uWM4doq6d35Za4qXfgnc1EOofhnNmkoRA2MMc5evxycVv8ffcb8pn7fLRfOhh4hyCeo6yXcnt7Ejeu7qrbbtUyuuc91fF9bc0H8FfTb+D1elXsH/q38weMW8pp22Jvx3HP5bcbPDk2zILTLvEAPw4oXA6+rKQkQcQWf8e9qkTcWctPo+fb+X/MABJzIKwzMzVqF1+yZ1IrfFHnP4BCR2gu4UchU2yiWp5U1b4liNcz8s2bDdduNtx1j6gceR2jPKhRP9sWEeN68aPaCdy9ZVOR858yHojAHzXxWun74oUIKA9z6vxr7/PRoA8ENYfehOxzO7XFhbkEmi9DoEE/Rknu+nVzSJN3bhooxqnZax/A2OYgpwbGIuhpK5Y5x44m18pzwMKAbi+uet96G2oZV7bz5etN6WppecT16sXo3rX5uH575coSYkAq4U40H8BN1HXvLxkuqhczYfeiY3P8hJ93yCxevNn6l+Lbu92r7zlV/FLGnz1tRj8kz3wTiAMbJBIGwRlpdtztOGLbxaOJWi8liZ22hGFWPYYteFz6MPbQVgfzmdfegWQWgTn5M8qsU6TBa6j+OLEnaofMJmuSrZc48qMqMX1QPvTFQX6NZgYHiq/A68XTHRlJcr6MY0AXcd79bp56mX/+78DdxxKI7va1gfusfbsV2bh2bdFvUZWb4pP4tkCy1BFwd4z6afl6GnUosfJNYgnTnIlG51uayvb8I+AY9xcmIm/lR/r3D+bB0sD8vp93P8u5ynPNux5zsOPVeeKvQqngO1DHU4KWmN07WjjydKENCzKdeBVUbWl9rrJdRe5jTnJXEU7mgE3XRn3vpDJGWay4+mnjnpZNBHLfM6fkUx1mtU4jtgxnfA4B8C+6gBAk4DNs2CyrPQ3QWdMeLeUsoKem7yrSTn2jm6yML60D0EPTvmrFX9KtrQ0IY9/B1RiPhZ6A4PCnEU3Y9/81frbsbT5bfZ5wOxdChaP/f8vHD7UJCFCrRqKAyfLdnknGH2v+z7ZF0uXku4qS86z3pxHFXIte78iY8+rW+CgCF10ywbc3V2flWYqY7JjNHl0j5hZFEJrhN8izLIMXMjRUnRBV38s7+usRV1DYY5dzxmJ3R2jXLcK0Yx9bDQGQDewD39XTd+efHe/07kYBmHDlt0J8HSuCz5GlK60SFdLipOj3Jzm/1BCPJK2+PQzWJonSvCT6PRgVwmoVo9E9jEd8cwAP/8ZBnGPfElpi3eaM+w/GPgzd/bkrMWWFpA0BmQoNy5bG+xTybmeT39xqHrQsxzjd3cKzt4Q9TlUs7s1/fzZbwpZaMj352iXtEkohjnQ9f7cXiLMrQyvtB8tHAjznroc269YEjVcbLQTefAc7l4WOim3QAMmvAWpi+utblcAPPzrHNJ6k1bmlpoWAs9R0NLGtuaze/c0LWv4I9lL+Dkzc9qu0tBd6XOOtkOgr1siuVJJIvAW2eT9vOSdYBdcF6buwbHTnxcHYm2dg5nL5WVm9T5tzvOfx6nJcwDmczLn+XQ5/RmAha69f1cv021do0uJ8+wRZ+Wo944Ogr2kvfct1tcLhWcGRDzbacHjY4RnU8lqoFLOelUsvMK8Vwubsf7frOxj8C9Xk4zOprddv47RV+ouBmM01eRgL1x8NVhHXKUsdHlMvKm93HADe+Ztqe0r8fKjDaSNZEf6Y2doOcrykVHyaRdf1tjnf0coxx2Yf1w1teYXnG1OdHS+hsbgkO/mYQHraMBHcgO/c94RzMw8tsAcs5b5AXYviH7Z1mzaj0nHN06av29XS7qrw7M4HIxXMN8ruN6fHJuoP3EVyKMuO6KYvChJ9EFO5A0DHYTfZ6592RrLqLFeT50A7xVvAQmsaMWe/y83lAYwxd9vf9+Z+qcZp6nqDzTBDx+ErBxIXf6bGgCTtq1T0iXSxACCLrVh2cZHWj3oYf75N6zZZE90XKMvZVlqMj47xVX9E9qAQvdtGIR1Fkn562pN4lhJCNF78p1Ke+58CH3crOCLuZyqeR8AQE58bxhynwMmqBPnBWNUIoOQLKSFpx903hPwvjrcyswsayoEBi+qbwYt6Ry0zgIh2/yFPvtPwKNmx03A8DFKcPEZbywRcPYCOdD83zoHJdLO1ro3VtqgJqZwAc3crfrM4ImdJeSdLm4k+B2ivp/Aawhfsw6+6LVJeOjbF7eLkxstF73tg0YRP5Gl+WG/guswcjs1+v0+z8zPdRCI0VFDmTBMbxUUND1KY65LhdiWfHU140dNOEtbG8ScEPlEZF1XgGPZ9iXS0DD0CmqGyMijZLo4DalRXUNOs3lMjb5haFQjoXu4nbUsS1CAyBF5k5Rvxb6Zc/yorICNKAelrc+9QflyUKPXdiin6CLKFwuRgu9DGlbGGPYTjH+Umd2frfs1/hDhb+BILqgb2nwjo9mzPy1cWBiOe5IPQLzQx2Bhc7BMSZcF3TnkUWm/yodVhHiiWeYhYajQFTQ3axy9sGNAfoIcp2ifqJcOlETepqWEeTXa11DGg9M+xYzV9ThQ6G6wHdn+v/7VzVmVfK3GZ9hP+//uq2NQIW1egGeZ+PDOu8VoPsgYMBIu4UufegqfpbPCvSJanG5JLflJtS/NDnFVqKfh+Z864RdALiWLmcl+CCj+nSXS8LqcuE8qIwzvdlPUp+YspquJ7dPNGJ/r9ci0pYoCSeXC0888+dVFyOIhV6h98Ho5z3LPvujE8aBRfozrvhYpPvU5EzMrrw0+9vp3SpPJfHmzEVYVuuyiHa2UhwLPSTG6+WnU5R/PkEE3dBIvvRL4LHjtHT1+uuCLqNcPIiuU9Qs6JXLc0P5u9N2WxRM0CHjOvmNY3YYKaoJQsZw+82LRJsyW0qLHsevHO0l8Ixy0f5PcWayZIz4gp7HjlIRrFNMOJPLt19iJQBgW3MbBk14y9c56IJe39SK9+atFd7PCad71mHxa/i28tfYn3IDxV6a7TD+IutDjzL0M+dL99O/xT2fIM+IkyvFKuiyU1QlX7MtZsu3iF9bTc6nl0aSM1lXMQu6hrWj955hwLcvmWcY5PjQ1XQfnXJL3g9YwXBRLm7VUn3oPAu9sIJuNQyc4N2ThevV1XPEG4Ucr86pybqmdJdcBXmPJLaSdIgXL1upfoUO1xofALjmReviGCptmQyw8A3gtkE+j+583sZoFz8WemQDuDix/UCuUzR73aSgq/TqZHV0qfAufRCxvGjVH02/WxtzfsMMErZws7Bxwu0h6GR9+bavA9640tTRpcBhxSKHTlFuw+owdbAXjtdQ+yz1jkPnvbiGc+MJX4F9LmleaBsH3rl31qZ+Ff1iWlbbkL3XBIZry14AIN7RySPpNK+/D2u7uSXtGBXihlutc9Eu/t5N7pd2kC8Hjislo7CshZ6E2njKsEWNsw8eyE13m7AnDL0pF4WiIIEdlhFgYTtFg+6/G23wzJN9YbnDqc2vxZINDfhb2ROcMox7MG56LkNQgQgZ5cLdnEvkWrIFdrlkBNc/5T3D2aX9BC/3CXd9nH0WTGGQISbncnpumeBc+AC8l3f0eWwg18FOji5Eh/24xozvqnEtb3XKBGunqBR0V9zmd4iKNBLY1GDueAvrVw5qoV+TUq2sc5Ife2cWGE5ds7UZvYgXQungcuEI4pcrN3vXhYPjp7Gwy8VZsAks60PvjEbsTuu1PQvtQ/cfh24jQKNkapQpeJBbFBZ60M8kt2uSm6SLcSZ5cysz+OIo5grYn9YN21pACb1B1ad8loLuSnsYXBmWRFNrxBZ6QCtFf3DvLPund14HQTd+cm/lTJ2g7ivuQ3/j62CrsDheA08LXZuTxGOUn26hv1o+CR9XqDMiCupp3sgIulycRcXvA5+z0BcouwMA0iEiLXgd0Gq17Od1Xeo/wnlFcAtEMLpcOsPHdMq8xEBhi/Zr+vhny1HfpLlasp2iMmzRFd6lj9pCzyCBxlbrivTeNz27ziGHoBb6j5IzvDPpflPeZ3DrdnSgnIjv4AzWAMzeaaMlzYuwCOqTdbT2BF0uvKMuXKv68/ektaqF3rQFeyVy0R1BOhSjxGnh7u+6Hmn67WSN+l1Yo9Uwb46+ODcFENSPFqmuPkdB55zXeOPoUAOMMe6yet54d4oCzJeg/znFWyIymiiX179ai+nfqdNcpLI+9PwMARISdCIaQ0SLiWgpEU3gbP8DES0gom+I6EMi2j36qrrjNhw4KjJIornNuviCyH78y/zJt8vwsy0PRVAzPtkFDARcLk7uVKMlmTTMXrd6sz3OOF+C7ozmQ+fc55kr1BeoF21TBf35C0zbrbNqtje8FekB+xwvTo2ZX0E3dopmyxZ4Lqz86qlqbGpowRrswj+Oj0ZCUTLYsM3/KlPG9/rYxFxMSD1nrAEA9Ty7kLigD02sticGsdCrn8SVyZdtyW3a85a9b4VyuZAaAf8ggFMADANwPhENs2SbC2AUY+wAAC8BuD3qinrhNul9VGRgX3hW5CvAaTToD14eGUm9nNg7sxQAcOC6FwOXUWWY8td4rrNX2f3lQa92ijmEzXnEoX9fp85ct26rfZ6bDxbmOo3TigKs/9a0vaHFf6helDi1J9ZORSejJAEl0PNtFvRgjVprWkGr0yBzP4LOlEDjAYzP4VPld5imxDW6XLr4sND5BHuif19mF3TGdJeXPrCocC6XQwEsZYwtZ4y1ApgM4AxjBsbYNMaYfvVmAOCHouQRbpRLyEE/VjJIoB+Z59cW+QoIszJMeyEiDl5WYdDzTHi6XPj8/IkvsXTjdqyqs38tGM/nlTlrgGSZJUeho1wcGhSLIDrNcxN8UevcdxQ5NaQCOD4LfqJcMsHOYZhlnVIjxk7R0O9/hB1zuts1qd3fRLJwnaIDABi/R2q0NCcuAvA2bwMRjSeiaiKqrq2tFa+lALzP7qgt9K60A1emXjWlibxYTi6XYsJpoIgpj4egB73a5LBE3qINqlA73UcCw/r6Fu6RjY3AE5+t4Ah6YXFy+djm48+DyyVrxYYYoenYke3TQg8S6vqQy/TRRkEPT3T6ob9dug8dhfShi0JE4wCMAnAHbztj7FHG2CjG2KjevXtHeeh2cbnoAzosR/bcLw4Wuj7gwT0PZ3ECU0owH3pbGz/C5uW5aiem030cnahGgvjbzWkMmRAhevnAOsVEFtvkb84uFz+Ck/vkZ9lrEzRogMEtbNFPnYK5jdwwulxCE8pCNz9/ejutv0OFtNDXANjV8HuglmaCiE4E8GcAYxnjrAWWZ/hRLtE+LGnO7HSvl1/vuV8cLPSEkIWeyxPlvC5e1qbTsa4rex6d675x2J679wkw1NTnwk27oAHd0OC7nlGxYtMOx8m59E7F1rR5wQYrSSjOs1TyyjX8lbViBRYP56EozoN2OtTNU8sWePda2zKO0+wGRo98isTdGryMXyXfyf7dBY0YQWp/lh4bX8iwxVkAhhDRYCIqB3AegCnGDER0EIB/QhVzzqKX+Yf3YEQf5WK/XCnOuoUi+0VB2MU1TGUJCHqZSdCju7ZlDtYeb9ECK8PeH8dtEIwin4Biaoy/qRyPC1NB550Jz3F3TseSDQ7z4GuumAemqQLgbKEz8Kc84GMcKaqLcVALPaMw57BFDZEG//eT5/qIxxcjUpdLiMZmUtkz2b8fKLsPP099YNpesKH/jLE0gMsBvAtgIYAXGGPziegmIhqrZbsDQCcALxLRV0Q0xaG4/NEOLpeghJkzww2/flRXBKy1MoNbhndtgzagTp/vIoKeTO9AD/CWJDNb6G1FNvX/+nqHCAzNQt+ohfM5nXvCp4WuQ4ansVcmWD9WhnkPqxdpLJxCN8Mg8syIoC41GY1+HJhYZkujPPnQhUpljE0FMNWSNsnw94kR18s3+RxY9JWyJ0YklgV+SPJloUcp6CKf3+Ues/IFrY+TtUdQUIZ0bh5wBzIcV1gHw2IXBMZ1lxUS5zU7NFeLR8jmg+X/8NUBqZditNCHpRcI728sKaMwZx+6D/JhcOUsdDMfZUbg+ORXwuUoioJkRO6grpx4+ESygIIeB3jxrFEJni4GQS3QnhwLMgqiHAmbEAhhM1vo0dWn3KFDNgGG58pvwSGJ71z357mefpbMfeJemHw3O5d4MfDjxCcgNpa/UQ9r0y6wk+gdkvjO15dfNsqFWCghTWQFPbyFng9B1497W9ljpvTvGX8glBMKU5DM4xd+mInR3Cj+3jpB8mmh6xZ2UEH3M0mQH9rb5eIkvDpBr3fK4fokwDzFHAD3xSszfE1cV/Z8oHrli7vLH0G3FodFJrIWuvpTZCIqEYy+5XCCrmDlph0Cgu59jHxa6KGZ+wywIcgXjBiJVHleyi0hC92elopI8BRtIYiLUtzw+oIRpYUu1imaE0neCx20gSlzaCiSAh3OAPDT1HRbmkhDUEiSTksKZi108+x8Ybg4mRtJaYxDD0ISCi79zxwsrPCKTPI+RhllMDjhPQ20H6J6J8qm/iGScpygPAl6yVjo/CiXqCz0fC2+Fo7Tkl9GVlbCZ6coz4ca9Ho7CXqUUTxFh9P11p7jRNaHHp4/lz2XLWcUfYcetD1wWbpQe/nQRRqNLhBYd9QnXtE3xQLlaaBbyQh6fl0u4TrUHkw7+EtD8hfuDHHBIObe8QiYQzR5Xz9BLT+nlzDqsFM3Ps9YpyfKL7vWV3PTFabg5jdzn/pRNWq6EB+ZXIDOxBsgJ4b+Feb9NRZ+KokgOHewF0fEmw4lpYXuTh5dLmGjVDp07hFJPaxEdX4AkMw4uAAcj223MN1e0HXM+Ro4WegDKdrpIdy4P3NWux0LAI7f+DQ3PQGGJz5bgWW16sCnqL4NoyonqY1QTXoM3BFpjJ3uexicxjQAwO9bL438eEEJs7iIGyUj6FyXS0STc4UV9P49ukRSDytRhI7p/LKZLzDOx+ZZ6M6C/lj6NMdt5Q6domcmP/dVpzC0sOCfwG7z3fuhLVGRFcLVm9VQt6jn9A8LgXmGker5vLiv/MEoqmTC6Z0nOM96Wgia0vm5ryUj6Pkk7FwsqfI89WgLdhrm5dicxmSPxHrH/MX0MvFoQXBBf0c5JJI6pJMdsi6WrXUbcEvqCVQKiKcI0QyFVxtyEUEvtsii/t0qcege0c4fFYbde1blpdySEfR8LkGXDivoZRUR1cSbjzIj2uU4vAiUc5KfOOb3EzP9q9Zr0MAqA9UrKGEGHkU1+VomWZW10P+YmoxxqQ9xZvKzSMqOyoecAEMF/LnnioE9e3dEWYp/j7ex/IirG5Vlck1RVyKf5MdYdtjLlKdhvjzaayIwN//nx5kDbGl+7o4CaneL3o+gWwUgqrpmUh3Qi+qxsvICnJicC6B9O4ZFSEBBBUXz1dCeqC4X/rtxbdtv2rcyeaRkBN3psc9E4N/0I5K8vCxPPdp82kcI3TpA2zji6G8+G/KZPzyigv5I+kdohvl+du8UjYWXKeuInlpI4S60FUB+IkHCIOpyKTYI5KgFxe4O9EPpCLqDokdhsfopQ+H1Xrejhd5eD6dbvG+aM17N7zD19p5DPs3EBJ2BYzxEdH9bOvSxpVVSNO6NwxKLIiknASUyv367QoDiMNw+rEbUVbT7Am2OlJCg8xU9bAw5kBspKpSXJ+jtuFpOewm6m+UYdiIsdWLY4rTQFRAqUuZ7HNXiGS1V/WxpxeavTpBSdHUSgcCwpawvd1vYZ40VkYwWT03yRBSCHtpCb0eXS3sJoZsPPazLRdGWQG5PRAWdgVBh6dCKqt+itaNd0CuLTDyH0Bp0oHZfvyY0BODgw37I3Rb2a7AtorDVKCiduVwc0qN42fzccJZIwuqNoERwCz3NEr7CE1N5WgnFiquFznFfjB7eFxCcXmX/gd2gbGhnl4sPC926DqZC4b/Adhx0Mdoq7DMCOsXoF4ony+8sdBUCkUwQjtqrF3dbWEGPop8uKkrGQneKcklTBC4XP9Ylx0JnAVwua1hPAP7dF/27d/R9rCA4zZAI8C30/Qd2Ey77kEE9Io3WmaXs7ZnHj4VufRoyETxjbQdcAMrTHNkSoF9X5zDYsM9aj04dQu0fJSUj6E6dolF0rvkpgyfo1ol4lp062bOcv7X9DICY0CxXDL5BKryFzpu8vzwpXq9+3arQv3vnQPXi0ca8hVL0pWYcCz0KQe/SoSJvix7kg2VKv3Z1JYbFLQ7/wiMHhyo7macFn4NQOoLukB6FD91PJDDjRDxQyizoJLCeoN6IiAj6RnTPHb9AUS6NLDd4qrLCPJDqlczRKHcY1MGDKBFpR7J1+TluaKngdWOMbIsTKBE8Y4lEAol2jIYKS2vpeGtRVhbyXPK0PmgQSkfQ8xnl4uMycS2BhNmSSQi06Hopvj8H28lC7031pt9Vho4yZrFYt7JOjqP0eFACQIh+BytNMDcwO2CPGxcVdNX9ZrXQoxA3QsLHNeKxo7KvbdDTfGV33+XM7nEqGvZ2n6xMbSSLx3cchtALNjvs3yYYChslJSTo/PQofLHnHbqbcN6kYo9KaGgzP/hJoQdI3cevy4jlaWkrPxCnUfG35FYCiND9sJWZ+xXqOUO9hS10bqdoBC8uUfiFgzlrjN6X9j+L5DZ0RtvAI1zztMei2/enz8z7MQCE/jLiPe9A+PDdIJSMoP/9x/tz060v23VtFwH7nu6r7A7l4tZiiiPo6xrMAzHIh4XuP3yv8Lc0tMARRWqhW7/S+IIuBi/KJYqvQIBC+9B5MzMGEl6lDSmPZ7RDZQfg1+/7L9sH06Kcl8hlapBE2MgwJwu9AG6pwr/9EbFrD/7wa+7L5nveF3FRTVgWiti3+V84dA9DuNSIcUgICB4LbKEX/pYyywM+Zr++8HMNo/ahW+/2dnQEOvW15BGtH4GlzFENog3Y0s6HuhSbQDIVvYXuV1RqWRd8UzESSY9O7H37dQH6HYg38ANf5fuhvfz0Ii5QAEBlN25y0x5juOm8aC8AaOi5n9jxAlD4tz/P8AXd5/wYPtwFCYuFvujWH+OAAd1yCWc+KPQA3XKW+sXh20LPh8ul7wHALuIr+lgtzf5dO/iqF4OghX7E5cLlXdH6W7ycORoAsP/g/sA1i0155lx/slBZGSSQ6Wgeop82xKG7uQm2l7tM30rhLXRiiq3xuupkb/G4rPWK7N+HtDyC6vJD+eMZjrk6+2dCe4dalPy5+KL58tFxNuKG9u8mVsQlnwLn/Mucdn0d0nvz5/rnNabntEzCktHPiB0vACUv6ArPYhVYENmERYyW9h+L1/e6mZs1qagW+qWtV+Lw5vu5+4u8uH26qFbgLl28Y1xH7W6IcsmHhX7Jp0BfvkuLRwXjjSQUf/EzDGI+9L35lpEVBsIU5Sh8lBkJAOhUZb+mXavEQvDakEJFN/OITmOUy13pn7js7X4NQgs6x+UisrhK327mPoaWtIIUz0I/YRJw2l3q35qgtynxlxChOPKeewHddgP2+7E5PZlCz85870CHCnvsezXbF1SVnxXMgJ1B0C2tPAMAxUXQ+4+0p1lEcsW+F+OMH53tetwFbHesR0/u/h0rxd0JZQLWfCqRADrpVmO+LCZ7uR9WnMDN2VXZaklhtkZt3jEPOR4po0DMQhdsvBiA7lVluekKUpz56QW/ICadcSBSp/zdlGaOQ3cpx+0YREiGdDN9euAddteRwOryPzrA7H5qSSvZRaptpHSRUi1eo0uwjomNHXgpI+amiXTqYDc3q+E5Wn7A722bT2i5A7h4mvP+Dp2qXR0ailQif181JS/o3EEfbi4X7oNsTitLpjzFZCPr5rh/x0qDoFzyP2zYjffJpu3DOU7DiIvt2a/8Gpi4pt3CFgHghImvcNO7lHtfQ4UpmHPgjVhVaXflKCAxH7rguSpI4OrR+6CMNEEPMyAmWQZ0NA8hF/Whu34FUELcl+vAul5H2AU94X2u1pDflrYMoDjM1aMLuvYOlRtW4xLthzANhHNh8vjDTL9v7PZ/tjzKru7RODnEBL2u5yjb5tVsF6DS5UvHKUqG85yVpxLYa5dOzmWFpOQFnTvow03Qh51hT2trNP0sSzkL+vqe6kPYBMPnVraR4Ih03/3Q4Ue32QsiZ0HPHHWVPX9ZB6CiU/alml12MBaf9S6+P+s11HbYk1vXKNg85mHU7XK4KW3vcXd57scUYORZV2H3i5+1bcswZF+SbcMucC7ER+NVliSU6xZ6GEuY8+VgjUNv/u03+IJG2PIN7uX2Igta6Ps7u3RGcKZXqOK4l6woFq1rTStAxmGKXF3Qta/c00bsmt20jPX3PBYAnDZSbGRm5/Lc/X0zczjmJfexZ+rNmdbh+OvtaeUu195w3Xfrbr9eTp2bWZzCkDnPyqKbxuRttSJgZxB0y0tPgLugH3kFMOF7c1rTVtPPsvKU4+fzJ3tPxB7NFpHS66DfeP231oJ36b0rcIN5oI6bhd65Yyc0HvhLfv21/A27Hod9Djwcux14HHr/aQ62ja9Gc5XYC+eHHodfgJ6XvQsc/5dsWkXn3kB3y0ur1Wth5Qg8nz4OG/vxZ74DNIHRXrIuHVyW7zNemx9OcMw2pG9XnDFiAMr1ebyTAksCXrucn86xujpVWXyo3Qbi2uQfcVqL2aJ0ilfWNjpb6LsfDRzwU+BPq4Cz/ulYxP4Du6JblVlEkgLLHxIAHHIxto1R+3z6d+sAKE6CrpWnNbhVVar/XekyALMPf8DzWAAwfCB/kiwbhi+HBlaJzc32d44bu99jD3va0ZorhefKM7jg+nS2b/ecHtfYEPcwGE+cPpFEHt0twM4g6JZTbGFlzoJ+zDWqUFd2Nae37jD97NGp0tE63LNPFyhIYEC3DjhjhC6gFnHW/3ezGlws9ER5B/PkWIbGRR9iX2F5lrr0H4LKoy5xPp4X+jHOfJi//QfX2s8vt3N2/y69B2Ji+mLsO8D5pU4bfegW68cU9aMfp98I4LiJ+DSjRnRkLFEHR48YjsqyZM5CF/Aro2NPYDDH18t5Sc8+fG/goHF4O6MuFk0EtFAF5rNB2HiZYYpJDz990lov/TkccT7w40eBDt3M1+PY62xl2I4gYPWP2LUrcNqd6HL4L/Dozw/GAxcc5GyhN21R/+86QP2/TG3MEkNG47JTnRfLZhUGl8VQwXEg/UeYnqX6Fvt7qwt6i3G+njJOJ2Vnzc3Dux7GBl7vX3N7N62kDF/jl3wKXPCi+L4RU1KCrnCmsbS6XIYP6msS9E3M8KCdwPlUA4BMC9ac9Ej25179+zgK+sG7dcec60/C/yYcj3+cd5CaqL/IVmvC9aFxFnQky1FunFLXYMkM1UIkD9m9m30/TsdQpqK7PR+PI68Auu4KDBntnEf3JbsI14CulVh562m5cQN6nQxWlSnKhZJqhIF+CFPZ2r7aNcqGuZUbXuiT/y8b3pjtFBWx0I11M8Kx8MorOwFnPIhL21QrMEGU29X4slvldsQ4oIMW8ZBpU115RnY9jFMGgL1PUaNNjv2TvX5pc4RRVQfv5fGShmqNHt4X3arKc4J+zDXmzHq008gLLXVz8VH/8h2Q/tyMfQDoYvhSPP0e/j5nP6E2XqffC0C9ctuaOH59TaDbjFMYl7ksMM4T9BRH0Hd1GTNgxfhel3cEqnqK7xsxJSXo3EmXLIJ49uH7mKJcGn47n1tWU8IgtukWDDjq/Nzvcpcpalsa0KOjxdLKWq6a4Og+ebdyrPua0sgxUkefViDJfcHsacmBB3nXAQD6DAN+P8/WIWhil31djkUO6cyyHejZqSLn2kgkgYvez1o9pslr9WugnXP/HmqURaLM4Afd/9xs41CuL24cplNUf3n3PD6XVmb2uyaIcNr+qkWYjWiihL2hO/NBoJM2B3qmFZUVFrHRz89SPi6YDBzya379LP09iVQZcOnnwHXrHE+JK8YZbTyF9VrtMhT461Zgz+PM292iknY/Ahh9C7DXibn9dAY6WPV7naj+r32lbEZnMF49NYE2NVw8C13Hw+WSNfYMHd1fTTrJuTzA/cvr6sXAUVe67x8hJS/o28gcSqWUVeXi0C/6AIN24fded/hBbrCF1epBqoIvtD+cAPThDeTQLXRtn+6DgI69gZNv4R7buItjx59TFIL+cPHcSlyL02BdHPBT5/qI8PPXgJ+9zAkLNIQtWuugC4LBatu3X9fc1wslgKoe6uc3kCunomvuPmov35B+3dSfRgE0XIfDT79I/cPa8X3e8/zzcQt1O+3u3N8WCzpBwKQfDcfc609CR12kdz0c3JDGXYaq/yfL7V9w+vnxwixFYQzoM9z81SKC7kPnxcYbBUwRbCS79APGvQx0tay/6TXIb9gZwNj7kTzhz3j1sqM4dVHfj4TROLI2gEa4LhdD3fVrbrgX3QTHKGTR3VHDzlBdPYeFcHX6pLQEnRM+1qP3ANNvJVUFDDhY/dHR7dPI8DKnm82byD6fBwDguIk50bbmB3KtfnlH4NqlOStEp5exF1/fx6H1dxR0/fhiFrrJYvnxo+7WjRcdewFDTvTOZ6T77sBZjwI/+bchkQDd56qYRRsg4LezgCvmGKyphJaF53fPnfOhh/9A7Xw2fUkA2PdUh8pxrldWgAzbNMG9cexwdCxPgoiQTBC6dyxXBeTij4AL/pu7N8dcDVyzRP37jAfVr4+ee5qsQtO5B5k8qryzpb4u8BqujKBQ68ZO0Mghp/pl7y0BI3+B8ccNxX4DutrztWxX/+9kGIXrVmdePU0NlPZehZmBsXNfYMJqQI9G8+OPD0lJCTpv3pMRQ4eYfmfKqoDRfwN+8ym/N1zH+JBnWjkZAvRWez0kF39oyKu9xE4PvJegi1ro3QeZf3cQ9Kl7YT2W7gff/Uh73gN/am5cKZGL+23TOqT1hpJIDVXr2Mvmcsl2IrY1Gerhc5oHt3NQE+3bNAv9wiMHYf5NnNGrAw5Wz0cXjqpeOVdLeUdgb82/bBTu8R9zP/+FOf95YMjJjvOPeKILutcAL1Hht3Lp58DvFzjfH6cG4pTb1X86ujXe0SDoer8ED6/z0V1Ah453z+eF8X6LuFYjQkjQiWgMES0moqVEZIsPI6IKIvqvtv1LIhoUeU0F4E1XmegxGHN+8iXe2fN6KIzQufcgNcqh3wEepblY6NbtXtisTAeMn+5dtC+L7Q6+zyoHX7aboPPqfNKN5t9Haq4mQxhiJPQfAVw1z9n3a4QSyDaYNlEzNKRZl4t2zvqLbIxK8jMRm20MAs9C56QJN4IeRoDeMFV0Ua+XtcESYbAWDjr4GOBnL5i/GFMOrgjeObm5XIzofSpdB7jns9JnuLqPfuy++wNj7weuWwtc8j+gwmHU6WG/ycXiV3YF+midtHoHsl6niWuAK7+x7+/UUHTWXH6d+6pfcXs4h9X6ph0XwPD8liOiJIAHAZwEoAbALCKawhhbYMh2EYAtjLG9iOg8ALcBCOmQ9c8OVKE7tucS+h4A7HkcRlZ0BobvC+AaCK/+Z3zI05qFfuKNwNbv+fndEP6MMwxA6qYN2DCGj+1+NLB5mfr36FuAlm3AvJctbhkHXzXAb4OsD/hhv1H/EQEfOfj4KSEwBbHhYLtpA4/0c/KiS7/cNdNf2GwMv1HQzS4XVHEE3Y91dObDwILX+dsGHAysmW1vKLvtJu6fztbdqZHR+1q0c9WvgZshcPls4IGDc7/HvWzv89G5Yg7w7x8BdUstGwRcLrwpMQBg1K/UBm34j/nb/7DIserqobXrmaoERv5C/buvx4Riujvu4F8C+5+juqv6jQDWfaU2gkRARSf1nxX9ed/3dGDRm7n0yz63jTfxhNdgFBgR59yhAJYyxpYDABFNBnAGAKOgnwHgBu3vlwA8QETEnJYRCkP1k/a0ceoQ9LafvYJpH/8Hux1zPnr07o/uPQQHMPA+/YzumJ7aYIGjr8ql+fE16y+Fm4sHyL3wnXZR/bKn3K66KB5RZwnEL9/K5a3oBJzxkBoXPPpvuXTdyuc1Hr2G2NOc6gCon+xr59rz/HWLdzllmpD+/FVzRIgIlV1VoUgkgVFaR6Yu2sYxAnqa/uLuprlz9j0VWPwWcNyf1dhtJ6p6AQeeZyhPu2Z6x/aZDwH3aVFAQ0argt5NW+ykxx7A0X8ADhrn77wA5047/drrHYdj/g68cZX7xGi99gKGnwUMHav+TpY5W6Fd+qvC+8ntauP12qVqOu9Z2eNYYO4zqlBet87Zj59IqqKarc8+wCZtJsvx09XG2Q19II4fF0cyBUzanIscGqA1Nuc+zc8//Kzc3xXaPTjmamDRW8g2Zh26+3c3dve/GlTeYYy5/gNwDoDHDb9/DuABS555AAYafi8D0ItT1ngA1QCqd9ttNxaIJR+w9Evj2dJ7T2Vtr13BWO13wcrxQlEYW/k5Y0s/Yqxxs3ve6qcY+/5L9zwL3mBsR533cWf/m7HNK8xp37zI2PKPvfdljLGWHYy9+xfGWhv529fMZWzJ+4y9+Cv1f8YYWzWDse9nipUvyuaVjH18u3odRVn+CWOzn3be/sVDjG1amvudyTD24c2MNWzKpW3f6O+YVha/a75PtUsY+/RutczaJcHLZYyx1ibGPr2HsXSbc565zzG2bX2447jR1pK7142bGXv/r871adrqv/yWBsa+ep6xZdMDVzFSWhsZy6Rzv+vXMvbhLer93LaOsY2Lnfdd/A5j81+3p381mbH1881pGxYwtmGhc1kL34rsHQNQzRz0mpiHEU1E5wAYwxj7tfb75wAOY4xdbsgzT8tTo/1epuXZ5FTuqFGjWHV1tf8WSCKRSHZiiGg2Y8w+ixjEOkXXADA6Pwdqadw8RJQC0BVAnf+qSiQSiSQoIoI+C8AQIhpMROUAzgMwxZJnCgBtLDDOAfAR8zL9JRKJRBIpnp2ijLE0EV0O4F0ASQBPMsbmE9FNUH05UwA8AeAZIloKYDNU0ZdIJBJJOyI0BI0xNhXAVEvaJMPfzQDc1t6SSCQSSZ4pqZGiEolEsjMjBV0ikUhKBCnoEolEUiJIQZdIJJISwXNgUd4OTFQLYFXA3XsBcBy0VKLIc945kOe8cxDmnHdnjPXmbSiYoIeBiKqdRkqVKvKcdw7kOe8c5OucpctFIpFISgQp6BKJRFIixFXQHy10BQqAPOedA3nOOwd5OedY+tAlEolEYieuFrpEIpFILEhBl0gkkhIhdoLutWB1XCGiXYloGhEtIKL5RHSllt6DiN4noiXa/921dCKi+7Tr8A0ROSz6WNwQUZKI5hLRm9rvwdpC40u1hcfLtfSiWIg8LETUjYheIqJFRLSQiI7YCe7x77Vneh4RPU9ElaV4n4noSSLaqC34o6f5vrdEdKGWfwkRXcg7lhOxEnTDgtWnABgG4HwiGlbYWkVGGsDVjLFhAA4H8Fvt3CYA+JAxNgTAh9pvQL0GQ7R/4wE83P5VjoQrASw0/L4NwD2Msb0AbIG6ADlgWIgcwD1avjjyDwDvMMb2BXAg1HMv2XtMRAMAXAFgFGNsP6hTcOsLyZfafX4KwBhLmq97S0Q9APwVwGFQ13P+q94ICOG0Nl0x/gNwBIB3Db8nAphY6Hrl6VxfB3ASgMUA+mlp/QAs1v7+J4DzDfmz+eLyD+rqVx8COB7Am1CXvd8EIGW931Dn4z9C+zul5aNCn4PP8+0KYIW13iV+jwcAWA2gh3bf3gRwcqneZwCDAMwLem8BnA/gn4Z0Uz6vf7Gy0JF7OHRqtLSSQvvMPAjAlwD6MMbWaZvWA+ij/V0K1+JeAH8EoGi/ewLYyhhLa7+N55Q9X217vZY/TgwGUAvgX5qb6XEi6ogSvseMsTUA7gTwPYB1UO/bbJT2fTbi996GuudxE/SSh4g6AXgZwFWMsW3GbUxtsksizpSITgewkTE2u9B1aUdSAEYCeJgxdhCAHch9ggMorXsMAJq74AyojVl/AB1hd0vsFLTHvY2boIssWB1biKgMqpj/hzH2ipa8gYj6adv7Adiopcf9WhwFYCwRrQQwGarb5R8AumkLjQPmcyqFhchrANQwxr7Ufr8EVeBL9R4DwIkAVjDGahljbQBegXrvS/k+G/F7b0Pd87gJusiC1bGEiAjq2qwLGWN3GzYZF+C+EKpvXU//hdZbfjiAesOnXdHDGJvIGBvIGBsE9T5+xBj7GYBpUBcaB+znG+uFyBlj6wGsJqJ9tKQTACxAid5jje8BHE5EVdozrp9zyd5nC37v7bsARhNRd+3rZrSWJkahOxECdDqcCuA7AMsA/LnQ9YnwvI6G+jn2DYCvtH+nQvUffghgCYAPAPTQ8hPUiJ9lAL6FGkVQ8PMIeO7HAnhT+3sPADMBLAXwIoAKLb1S+71U275Hoesd8FxHAKjW7vNrALqX+j0GcCOARQDmAXgGQEUp3mcAz0PtJ2iD+jV2UZB7C+BX2vkvBfBLP3WQQ/8lEomkRIiby0UikUgkDkhBl0gkkhJBCrpEIpGUCFLQJRKJpESQgi6RSCQlghR0iUQiKRGkoEskEkmJ8P8B26kaFYxhncsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "import random\n",
    "\n",
    "EPOCHS = 1000\n",
    "\n",
    "losses = []\n",
    "val_losses = []\n",
    "\n",
    "for a in range(EPOCHS):\n",
    "    \n",
    "    print('EPOCH: ' + str(a+1) +  ' OUT OF ' + str(EPOCHS))\n",
    "\n",
    "    rand_int = random.randint(0, 522)\n",
    "\n",
    "    values = list_of_scaled_training_df[rand_int]\n",
    "\n",
    "    n_train_hours = 21\n",
    "    train = values[:n_train_hours, :]\n",
    "    test = values[n_train_hours:, :]\n",
    "\n",
    "    train_X, train_y = train[:, :-1], train[:, -1]\n",
    "    test_X, test_y = test[:, :-1], test[:, -1]\n",
    "\n",
    "    train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "    test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "    print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "\n",
    "    # fit network\n",
    "    lstm_model.reset_states()\n",
    "    history = lstm_model.fit(train_X, train_y, epochs=1, batch_size=21, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "\n",
    "    for idx, h in enumerate(history.history['loss']):\n",
    "        losses.append(h)\n",
    "        val_losses.append(history.history['val_loss'])\n",
    "        \n",
    "# plot history\n",
    "pyplot.plot(losses, label='train')\n",
    "pyplot.plot(val_losses, label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Based on the num_predictions we choose, we predict on that many random time series and derive a resulting root mean square error\n",
    "\n",
    "# The resulting prediction is sufficiency rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import concatenate\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "num_predictions = 500\n",
    "\n",
    "summation = 0\n",
    "\n",
    "actual = []\n",
    "predicted = []\n",
    "\n",
    "for a in range(num_predictions):\n",
    "    \n",
    "    rand_int = random.randint(0, 522)\n",
    "\n",
    "    values = list_of_training_df[rand_int].values\n",
    "\n",
    "    n_train_hours = 21\n",
    "    train = values[:n_train_hours, :]\n",
    "    test = values[n_train_hours:, :]\n",
    "\n",
    "    train_X, train_y = train[:, :-1], train[:, -1]\n",
    "    test_X, test_y = test[:, :-1], test[:, -1]\n",
    "\n",
    "    train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "    test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "#     print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "\n",
    "    yhat = lstm_model.predict(test_X)\n",
    "    \n",
    "    actual.append(test_y[0])\n",
    "    predicted.append(yhat[0][0][0])\n",
    "    \n",
    "#     print(yhat[0][0][0])\n",
    "#     print(test_y[0])\n",
    "    \n",
    "#     difference = test_y[0] - yhat[0][0][0]\n",
    "#     squared_difference = difference**2\n",
    "#     summation = summation + squared_difference\n",
    "    \n",
    "mse = mean_squared_error(actual, predicted)\n",
    "rmse = math.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.71721062815779"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Because we have individual time series for each bridge, we define an epoch number and for each epoch we train the model an a random bridge time series\n",
    "\n",
    "# At the end, we plot the loss and validation loss over time\n",
    "\n",
    "# This experiment is run without min max scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8197.9453 - val_loss: 8109.1431\n",
      "EPOCH: 2 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8511.2080 - val_loss: 8787.5850\n",
      "EPOCH: 3 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5886.8491 - val_loss: 6622.9907\n",
      "EPOCH: 4 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7238.7246 - val_loss: 7366.7891\n",
      "EPOCH: 5 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8968.0811 - val_loss: 8956.3193\n",
      "EPOCH: 6 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9659.4463 - val_loss: 9676.1123\n",
      "EPOCH: 7 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5237.1753 - val_loss: 5226.1201\n",
      "EPOCH: 8 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7529.3506 - val_loss: 4045.0676\n",
      "EPOCH: 9 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6320.1846 - val_loss: 6308.9639\n",
      "EPOCH: 10 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7988.9927 - val_loss: 7703.3740\n",
      "EPOCH: 11 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6752.3765 - val_loss: 6748.4448\n",
      "EPOCH: 12 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1155.4861 - val_loss: 1144.4398\n",
      "EPOCH: 13 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8062.1235 - val_loss: 8008.3110\n",
      "EPOCH: 14 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9423.1514 - val_loss: 9446.0107\n",
      "EPOCH: 15 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9411.7920 - val_loss: 9394.1289\n",
      "EPOCH: 16 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7838.0215 - val_loss: 7778.0000\n",
      "EPOCH: 17 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4219.1665 - val_loss: 4255.7329\n",
      "EPOCH: 18 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7945.7314 - val_loss: 2574.6472\n",
      "EPOCH: 19 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9316.9170 - val_loss: 9339.8428\n",
      "EPOCH: 20 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8687.6582 - val_loss: 9174.1426\n",
      "EPOCH: 21 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1646.8776 - val_loss: 1645.3727\n",
      "EPOCH: 22 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7131.0229 - val_loss: 7164.5107\n",
      "EPOCH: 23 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1573.7521 - val_loss: 1601.9265\n",
      "EPOCH: 24 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3437.6831 - val_loss: 3600.5337\n",
      "EPOCH: 25 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8122.1777 - val_loss: 8360.4561\n",
      "EPOCH: 26 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8507.9307 - val_loss: 8458.0195\n",
      "EPOCH: 27 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9152.5303 - val_loss: 9261.1758\n",
      "EPOCH: 28 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9607.7637 - val_loss: 9313.3633\n",
      "EPOCH: 29 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4792.5386 - val_loss: 4790.7324\n",
      "EPOCH: 30 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6693.7134 - val_loss: 6690.6611\n",
      "EPOCH: 31 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8827.4805 - val_loss: 9222.7920\n",
      "EPOCH: 32 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6592.9614 - val_loss: 6442.0903\n",
      "EPOCH: 33 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6960.6992 - val_loss: 9613.4512\n",
      "EPOCH: 34 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3345.6792 - val_loss: 3028.5366\n",
      "EPOCH: 35 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6260.1519 - val_loss: 6628.4409\n",
      "EPOCH: 36 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8531.2100 - val_loss: 7203.4614\n",
      "EPOCH: 37 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6247.8384 - val_loss: 6191.0972\n",
      "EPOCH: 38 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9294.5977 - val_loss: 9670.6260\n",
      "EPOCH: 39 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6435.1084 - val_loss: 6473.9893\n",
      "EPOCH: 40 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5715.4375 - val_loss: 5645.1182\n",
      "EPOCH: 41 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3093.7349 - val_loss: 467.4681\n",
      "EPOCH: 42 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4578.3877 - val_loss: 4844.8979\n",
      "EPOCH: 43 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5866.0923 - val_loss: 5851.7783\n",
      "EPOCH: 44 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5480.7783 - val_loss: 2355.8442\n",
      "EPOCH: 45 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7450.7446 - val_loss: 7510.2656\n",
      "EPOCH: 46 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1612.6842 - val_loss: 1608.6821\n",
      "EPOCH: 47 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6825.8154 - val_loss: 5025.5454\n",
      "EPOCH: 48 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6821.7666 - val_loss: 6818.2998\n",
      "EPOCH: 49 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5017.2686 - val_loss: 5012.5430\n",
      "EPOCH: 50 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8929.3867 - val_loss: 8918.5898\n",
      "EPOCH: 51 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8067.7256 - val_loss: 8103.5200\n",
      "EPOCH: 52 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8045.2842 - val_loss: 8172.1797\n",
      "EPOCH: 53 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6753.2446 - val_loss: 6143.4648\n",
      "EPOCH: 54 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8217.0850 - val_loss: 7754.5361\n",
      "EPOCH: 55 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5511.4194 - val_loss: 5827.7017\n",
      "EPOCH: 56 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3307.1536 - val_loss: 3378.0725\n",
      "EPOCH: 57 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5947.6772 - val_loss: 5942.6675\n",
      "EPOCH: 58 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7994.7173 - val_loss: 6568.9746\n",
      "EPOCH: 59 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3580.7004 - val_loss: 2067.5942\n",
      "EPOCH: 60 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6443.4023 - val_loss: 6440.7178\n",
      "EPOCH: 61 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1569.2571 - val_loss: 1563.2463\n",
      "EPOCH: 62 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8014.2305 - val_loss: 8030.3462\n",
      "EPOCH: 63 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8927.7998 - val_loss: 9198.0850\n",
      "EPOCH: 64 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6594.5200 - val_loss: 6591.8052\n",
      "EPOCH: 65 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4455.7583 - val_loss: 4450.3555\n",
      "EPOCH: 66 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5134.8867 - val_loss: 5259.5205\n",
      "EPOCH: 67 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6196.1748 - val_loss: 6409.3579\n",
      "EPOCH: 68 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3029.8535 - val_loss: 3028.1790\n",
      "EPOCH: 69 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8037.7993 - val_loss: 8484.7793\n",
      "EPOCH: 70 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4135.3535 - val_loss: 2915.6482\n",
      "EPOCH: 71 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1201.7705 - val_loss: 1199.9856\n",
      "EPOCH: 72 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8309.7168 - val_loss: 7807.0947\n",
      "EPOCH: 73 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9291.8008 - val_loss: 9135.6260\n",
      "EPOCH: 74 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9401.9561 - val_loss: 9425.1562\n",
      "EPOCH: 75 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3092.9973 - val_loss: 651.5944\n",
      "EPOCH: 76 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8491.8145 - val_loss: 8340.6035\n",
      "EPOCH: 77 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6566.3540 - val_loss: 6598.3926\n",
      "EPOCH: 78 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8351.0938 - val_loss: 8771.9717\n",
      "EPOCH: 79 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8904.2041 - val_loss: 8895.1689\n",
      "EPOCH: 80 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7881.7388 - val_loss: 3405.9551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 81 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8940.7080 - val_loss: 9225.2510\n",
      "EPOCH: 82 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3316.1213 - val_loss: 3028.7224\n",
      "EPOCH: 83 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9090.6299 - val_loss: 8879.5557\n",
      "EPOCH: 84 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9532.0889 - val_loss: 9664.1660\n",
      "EPOCH: 85 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8936.8457 - val_loss: 9563.2256\n",
      "EPOCH: 86 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8925.2529 - val_loss: 9054.0400\n",
      "EPOCH: 87 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6816.1460 - val_loss: 6866.1084\n",
      "EPOCH: 88 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3499.3928 - val_loss: 3541.7617\n",
      "EPOCH: 89 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2334.1172 - val_loss: 2330.9558\n",
      "EPOCH: 90 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6244.3882 - val_loss: 9181.8525\n",
      "EPOCH: 91 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7670.5039 - val_loss: 7923.5303\n",
      "EPOCH: 92 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3208.1379 - val_loss: 3365.1594\n",
      "EPOCH: 93 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9596.1494 - val_loss: 9640.1846\n",
      "EPOCH: 94 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8947.8701 - val_loss: 9345.2539\n",
      "EPOCH: 95 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6042.2710 - val_loss: 6147.5352\n",
      "EPOCH: 96 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3801.0413 - val_loss: 3254.0774\n",
      "EPOCH: 97 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7992.2529 - val_loss: 7997.8325\n",
      "EPOCH: 98 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6549.8281 - val_loss: 6644.9092\n",
      "EPOCH: 99 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8586.0713 - val_loss: 8229.3018\n",
      "EPOCH: 100 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7961.5742 - val_loss: 8406.7070\n",
      "EPOCH: 101 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8772.7480 - val_loss: 8766.7725\n",
      "EPOCH: 102 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3316.9099 - val_loss: 3487.1926\n",
      "EPOCH: 103 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3352.8379 - val_loss: 3550.4243\n",
      "EPOCH: 104 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8734.7910 - val_loss: 8824.2295\n",
      "EPOCH: 105 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6393.6743 - val_loss: 6433.5679\n",
      "EPOCH: 106 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5951.6099 - val_loss: 6005.3809\n",
      "EPOCH: 107 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6446.7241 - val_loss: 6428.6426\n",
      "EPOCH: 108 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9191.1602 - val_loss: 8675.0605\n",
      "EPOCH: 109 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8108.1606 - val_loss: 8509.5498\n",
      "EPOCH: 110 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9242.5176 - val_loss: 9473.2061\n",
      "EPOCH: 111 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6836.8867 - val_loss: 7125.6011\n",
      "EPOCH: 112 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8790.7451 - val_loss: 8619.1699\n",
      "EPOCH: 113 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7392.9702 - val_loss: 7347.9146\n",
      "EPOCH: 114 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6478.1260 - val_loss: 6181.9482\n",
      "EPOCH: 115 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8396.2324 - val_loss: 9015.6426\n",
      "EPOCH: 116 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4298.0679 - val_loss: 4347.4600\n",
      "EPOCH: 117 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6584.5698 - val_loss: 4819.0610\n",
      "EPOCH: 118 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7707.5142 - val_loss: 7725.0020\n",
      "EPOCH: 119 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9354.0449 - val_loss: 9484.5967\n",
      "EPOCH: 120 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5251.7866 - val_loss: 5142.7432\n",
      "EPOCH: 121 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6597.8794 - val_loss: 6635.4868\n",
      "EPOCH: 122 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2420.2954 - val_loss: 2514.3691\n",
      "EPOCH: 123 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8937.7236 - val_loss: 9395.0020\n",
      "EPOCH: 124 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3291.2612 - val_loss: 3287.8271\n",
      "EPOCH: 125 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2511.6562 - val_loss: 3984.0259\n",
      "EPOCH: 126 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6798.6919 - val_loss: 7087.0073\n",
      "EPOCH: 127 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6772.7910 - val_loss: 3465.5762\n",
      "EPOCH: 128 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2486.7026 - val_loss: 3941.3052\n",
      "EPOCH: 129 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7576.1504 - val_loss: 7554.5093\n",
      "EPOCH: 130 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8050.6987 - val_loss: 8450.9736\n",
      "EPOCH: 131 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9027.8887 - val_loss: 9046.7832\n",
      "EPOCH: 132 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6812.1816 - val_loss: 6938.8208\n",
      "EPOCH: 133 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7895.2212 - val_loss: 7467.7212\n",
      "EPOCH: 134 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2230.9653 - val_loss: 2291.6245\n",
      "EPOCH: 135 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6478.4941 - val_loss: 6475.7441\n",
      "EPOCH: 136 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5368.1133 - val_loss: 5366.5137\n",
      "EPOCH: 137 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8817.7930 - val_loss: 8769.7959\n",
      "EPOCH: 138 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4266.4531 - val_loss: 3339.9553\n",
      "EPOCH: 139 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5028.0117 - val_loss: 3808.2322\n",
      "EPOCH: 140 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8951.1787 - val_loss: 8967.1201\n",
      "EPOCH: 141 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8462.5586 - val_loss: 8577.4561\n",
      "EPOCH: 142 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5465.6943 - val_loss: 5648.9917\n",
      "EPOCH: 143 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3233.5938 - val_loss: 720.7223\n",
      "EPOCH: 144 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7890.4897 - val_loss: 8106.0654\n",
      "EPOCH: 145 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2216.5854 - val_loss: 2277.0808\n",
      "EPOCH: 146 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5998.7251 - val_loss: 8263.7031\n",
      "EPOCH: 147 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8221.5840 - val_loss: 8152.3779\n",
      "EPOCH: 148 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5146.8438 - val_loss: 5038.3579\n",
      "EPOCH: 149 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4258.2031 - val_loss: 4311.6216\n",
      "EPOCH: 150 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8215.9004 - val_loss: 8175.1030\n",
      "EPOCH: 151 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4435.5366 - val_loss: 4665.9370\n",
      "EPOCH: 152 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3617.8005 - val_loss: 3081.8528\n",
      "EPOCH: 153 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6238.3208 - val_loss: 6272.5913\n",
      "EPOCH: 154 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8413.5957 - val_loss: 8341.8184\n",
      "EPOCH: 155 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4782.1499 - val_loss: 4739.4116\n",
      "EPOCH: 156 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4776.7686 - val_loss: 3582.8716\n",
      "EPOCH: 157 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8495.5449 - val_loss: 8483.1475\n",
      "EPOCH: 158 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8509.0293 - val_loss: 8502.9570\n",
      "EPOCH: 159 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5404.3008 - val_loss: 5894.8037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 160 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9062.1426 - val_loss: 9074.5117\n",
      "EPOCH: 161 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7282.7085 - val_loss: 8486.3115\n",
      "EPOCH: 162 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3138.3721 - val_loss: 3134.7961\n",
      "EPOCH: 163 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8591.8018 - val_loss: 9208.6465\n",
      "EPOCH: 164 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4274.4712 - val_loss: 3562.5176\n",
      "EPOCH: 165 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4093.5796 - val_loss: 2208.6013\n",
      "EPOCH: 166 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5089.8999 - val_loss: 4965.2588\n",
      "EPOCH: 167 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1729.5033 - val_loss: 40.3136\n",
      "EPOCH: 168 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7133.2632 - val_loss: 7127.3906\n",
      "EPOCH: 169 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6294.7417 - val_loss: 6293.0713\n",
      "EPOCH: 170 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5990.4697 - val_loss: 3088.0159\n",
      "EPOCH: 171 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8567.7559 - val_loss: 8508.3340\n",
      "EPOCH: 172 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5062.6226 - val_loss: 2557.4941\n",
      "EPOCH: 173 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6072.1875 - val_loss: 6160.2666\n",
      "EPOCH: 174 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8453.2256 - val_loss: 7891.1948\n",
      "EPOCH: 175 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6121.0635 - val_loss: 6370.4238\n",
      "EPOCH: 176 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8406.2422 - val_loss: 8400.5020\n",
      "EPOCH: 177 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8148.7915 - val_loss: 8273.5840\n",
      "EPOCH: 178 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8389.6104 - val_loss: 8388.5586\n",
      "EPOCH: 179 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2410.4998 - val_loss: 2373.8721\n",
      "EPOCH: 180 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4311.2334 - val_loss: 4265.7178\n",
      "EPOCH: 181 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5421.1055 - val_loss: 5505.8945\n",
      "EPOCH: 182 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7969.4761 - val_loss: 7912.3721\n",
      "EPOCH: 183 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5833.5293 - val_loss: 5259.4058\n",
      "EPOCH: 184 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4723.2847 - val_loss: 4660.6558\n",
      "EPOCH: 185 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7200.3994 - val_loss: 8350.7344\n",
      "EPOCH: 186 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8463.4336 - val_loss: 8575.0830\n",
      "EPOCH: 187 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8297.9453 - val_loss: 8245.9648\n",
      "EPOCH: 188 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1044.9933 - val_loss: 1043.1392\n",
      "EPOCH: 189 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8002.8623 - val_loss: 8806.1426\n",
      "EPOCH: 190 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 929.3300 - val_loss: 114.9805\n",
      "EPOCH: 191 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8170.4390 - val_loss: 8190.0498\n",
      "EPOCH: 192 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7823.6992 - val_loss: 7185.1621\n",
      "EPOCH: 193 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9230.4629 - val_loss: 9234.1143\n",
      "EPOCH: 194 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8556.5830 - val_loss: 8405.4502\n",
      "EPOCH: 195 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7797.0381 - val_loss: 5474.4634\n",
      "EPOCH: 196 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7709.7827 - val_loss: 6408.6187\n",
      "EPOCH: 197 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8013.9180 - val_loss: 7942.6074\n",
      "EPOCH: 198 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8290.2500 - val_loss: 8284.6729\n",
      "EPOCH: 199 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2563.1042 - val_loss: 2561.8027\n",
      "EPOCH: 200 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6019.7388 - val_loss: 6020.2217\n",
      "EPOCH: 201 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2109.6216 - val_loss: 2077.1362\n",
      "EPOCH: 202 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6419.0542 - val_loss: 3227.8140\n",
      "EPOCH: 203 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5362.1226 - val_loss: 3939.3335\n",
      "EPOCH: 204 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5615.7002 - val_loss: 5336.1445\n",
      "EPOCH: 205 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6229.9507 - val_loss: 6231.1133\n",
      "EPOCH: 206 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4832.1621 - val_loss: 4804.3359\n",
      "EPOCH: 207 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4827.5181 - val_loss: 4800.5278\n",
      "EPOCH: 208 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1011.1412 - val_loss: 1009.5947\n",
      "EPOCH: 209 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7562.9956 - val_loss: 7463.7222\n",
      "EPOCH: 210 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7911.5425 - val_loss: 7870.4546\n",
      "EPOCH: 211 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7937.3867 - val_loss: 7435.0781\n",
      "EPOCH: 212 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6109.9854 - val_loss: 8437.8379\n",
      "EPOCH: 213 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6993.8037 - val_loss: 7560.3882\n",
      "EPOCH: 214 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5800.3892 - val_loss: 9012.5918\n",
      "EPOCH: 215 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5990.3115 - val_loss: 5988.1313\n",
      "EPOCH: 216 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6978.6064 - val_loss: 7043.6060\n",
      "EPOCH: 217 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6301.4072 - val_loss: 4110.7612\n",
      "EPOCH: 218 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4193.8579 - val_loss: 4367.3350\n",
      "EPOCH: 219 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3619.8616 - val_loss: 3644.9490\n",
      "EPOCH: 220 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6414.1226 - val_loss: 6425.7217\n",
      "EPOCH: 221 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6903.5669 - val_loss: 6861.0039\n",
      "EPOCH: 222 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6583.6367 - val_loss: 8323.9590\n",
      "EPOCH: 223 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7792.9771 - val_loss: 8169.5825\n",
      "EPOCH: 224 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6572.3823 - val_loss: 6693.0542\n",
      "EPOCH: 225 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8348.2988 - val_loss: 7823.0903\n",
      "EPOCH: 226 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7965.8633 - val_loss: 7990.8555\n",
      "EPOCH: 227 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6504.6729 - val_loss: 6213.8828\n",
      "EPOCH: 228 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4243.5991 - val_loss: 4198.3604\n",
      "EPOCH: 229 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3925.6143 - val_loss: 4062.3379\n",
      "EPOCH: 230 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5131.7183 - val_loss: 5180.2246\n",
      "EPOCH: 231 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2971.5769 - val_loss: 2968.8040\n",
      "EPOCH: 232 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7175.6265 - val_loss: 8128.5649\n",
      "EPOCH: 233 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8884.4727 - val_loss: 8976.4648\n",
      "EPOCH: 234 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6538.1587 - val_loss: 6592.0928\n",
      "EPOCH: 235 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7664.8945 - val_loss: 8016.2202\n",
      "EPOCH: 236 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6461.7827 - val_loss: 6366.7378\n",
      "EPOCH: 237 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7977.3740 - val_loss: 8922.0576\n",
      "EPOCH: 238 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7985.3833 - val_loss: 7981.1904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 239 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4187.4858 - val_loss: 4183.6348\n",
      "EPOCH: 240 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8071.8867 - val_loss: 8057.6016\n",
      "EPOCH: 241 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8057.6167 - val_loss: 8051.0205\n",
      "EPOCH: 242 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5948.7319 - val_loss: 5983.4932\n",
      "EPOCH: 243 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1328.3440 - val_loss: 1040.7904\n",
      "EPOCH: 244 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6366.6929 - val_loss: 5666.7017\n",
      "EPOCH: 245 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6167.6128 - val_loss: 6166.0371\n",
      "EPOCH: 246 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6264.4585 - val_loss: 5702.3193\n",
      "EPOCH: 247 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7997.0254 - val_loss: 8021.2583\n",
      "EPOCH: 248 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5846.3462 - val_loss: 3689.1860\n",
      "EPOCH: 249 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7820.6919 - val_loss: 7992.6729\n",
      "EPOCH: 250 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1277.8229 - val_loss: 1303.7173\n",
      "EPOCH: 251 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 786.9944 - val_loss: 778.1139\n",
      "EPOCH: 252 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3843.8489 - val_loss: 3093.5422\n",
      "EPOCH: 253 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3103.3345 - val_loss: 1959.3047\n",
      "EPOCH: 254 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7767.3491 - val_loss: 6947.6128\n",
      "EPOCH: 255 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1907.4691 - val_loss: 1905.3306\n",
      "EPOCH: 256 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2840.5107 - val_loss: 525.1199\n",
      "EPOCH: 257 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7981.0415 - val_loss: 7642.7832\n",
      "EPOCH: 258 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7329.8765 - val_loss: 7180.9761\n",
      "EPOCH: 259 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3754.8638 - val_loss: 2894.3196\n",
      "EPOCH: 260 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6822.1362 - val_loss: 7054.2798\n",
      "EPOCH: 261 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3440.8857 - val_loss: 2936.5134\n",
      "EPOCH: 262 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7625.9116 - val_loss: 7527.2080\n",
      "EPOCH: 263 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4036.4851 - val_loss: 4373.2412\n",
      "EPOCH: 264 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8620.9170 - val_loss: 8641.0859\n",
      "EPOCH: 265 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8276.6250 - val_loss: 8317.6055\n",
      "EPOCH: 266 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4622.3770 - val_loss: 1626.8767\n",
      "EPOCH: 267 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3975.1526 - val_loss: 4148.4746\n",
      "EPOCH: 268 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8061.7900 - val_loss: 8084.0117\n",
      "EPOCH: 269 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6408.3677 - val_loss: 6462.0747\n",
      "EPOCH: 270 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7724.5054 - val_loss: 8052.3979\n",
      "EPOCH: 271 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7296.6069 - val_loss: 7402.1978\n",
      "EPOCH: 272 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5793.8867 - val_loss: 5791.6279\n",
      "EPOCH: 273 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6229.8442 - val_loss: 6217.3462\n",
      "EPOCH: 274 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2910.7688 - val_loss: 2891.6301\n",
      "EPOCH: 275 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7734.9404 - val_loss: 7840.7651\n",
      "EPOCH: 276 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8214.7266 - val_loss: 8277.6035\n",
      "EPOCH: 277 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7817.4194 - val_loss: 7700.7827\n",
      "EPOCH: 278 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4536.8218 - val_loss: 4520.5688\n",
      "EPOCH: 279 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5760.6304 - val_loss: 7426.7046\n",
      "EPOCH: 280 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8035.4092 - val_loss: 8057.5757\n",
      "EPOCH: 281 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5998.5742 - val_loss: 6029.6899\n",
      "EPOCH: 282 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5432.2290 - val_loss: 3968.4775\n",
      "EPOCH: 283 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4460.4507 - val_loss: 2212.8525\n",
      "EPOCH: 284 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3702.3091 - val_loss: 3808.7859\n",
      "EPOCH: 285 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4897.6479 - val_loss: 4985.0718\n",
      "EPOCH: 286 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8181.9077 - val_loss: 8176.2231\n",
      "EPOCH: 287 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6535.8652 - val_loss: 4515.0029\n",
      "EPOCH: 288 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2478.1536 - val_loss: 50.1461\n",
      "EPOCH: 289 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1308.0409 - val_loss: 1307.2543\n",
      "EPOCH: 290 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7759.5806 - val_loss: 7754.9409\n",
      "EPOCH: 291 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7485.9507 - val_loss: 7044.7891\n",
      "EPOCH: 292 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5564.8628 - val_loss: 4575.5493\n",
      "EPOCH: 293 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2804.8269 - val_loss: 507.7454\n",
      "EPOCH: 294 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8596.4395 - val_loss: 8573.4189\n",
      "EPOCH: 295 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6182.1055 - val_loss: 5626.9878\n",
      "EPOCH: 296 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7229.8081 - val_loss: 7423.0034\n",
      "EPOCH: 297 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6053.3960 - val_loss: 6082.8574\n",
      "EPOCH: 298 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8513.5322 - val_loss: 8921.6768\n",
      "EPOCH: 299 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5645.3369 - val_loss: 8825.1943\n",
      "EPOCH: 300 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6109.2476 - val_loss: 5569.6772\n",
      "EPOCH: 301 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 773.9537 - val_loss: 772.8074\n",
      "EPOCH: 302 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4203.6401 - val_loss: 4822.2500\n",
      "EPOCH: 303 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5054.4927 - val_loss: 5528.6699\n",
      "EPOCH: 304 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7700.9448 - val_loss: 7696.3540\n",
      "EPOCH: 305 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7061.6323 - val_loss: 5462.7114\n",
      "EPOCH: 306 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1960.1381 - val_loss: 1776.4875\n",
      "EPOCH: 307 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2787.0073 - val_loss: 2825.4458\n",
      "EPOCH: 308 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7674.1733 - val_loss: 8096.6797\n",
      "EPOCH: 309 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3675.8977 - val_loss: 2826.3008\n",
      "EPOCH: 310 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8362.9658 - val_loss: 8466.2607\n",
      "EPOCH: 311 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7060.2202 - val_loss: 5424.5386\n",
      "EPOCH: 312 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8212.3340 - val_loss: 8559.1211\n",
      "EPOCH: 313 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5033.3237 - val_loss: 5538.7632\n",
      "EPOCH: 314 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4956.7031 - val_loss: 7656.7319\n",
      "EPOCH: 315 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7849.4062 - val_loss: 7757.1299\n",
      "EPOCH: 316 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8551.5215 - val_loss: 8565.7568\n",
      "EPOCH: 317 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4643.1040 - val_loss: 4547.7578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 318 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6411.4204 - val_loss: 6369.9194\n",
      "EPOCH: 319 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5513.5913 - val_loss: 7522.1294\n",
      "EPOCH: 320 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7603.1978 - val_loss: 7630.9805\n",
      "EPOCH: 321 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4034.6533 - val_loss: 4179.7964\n",
      "EPOCH: 322 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3152.1606 - val_loss: 2959.0862\n",
      "EPOCH: 323 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8160.7666 - val_loss: 8333.4795\n",
      "EPOCH: 324 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7051.7666 - val_loss: 6727.1523\n",
      "EPOCH: 325 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8516.0371 - val_loss: 8487.0381\n",
      "EPOCH: 326 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6709.1772 - val_loss: 7602.5010\n",
      "EPOCH: 327 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7336.2031 - val_loss: 6899.4424\n",
      "EPOCH: 328 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4654.2700 - val_loss: 4642.0303\n",
      "EPOCH: 329 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7706.5239 - val_loss: 8156.3726\n",
      "EPOCH: 330 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7587.0728 - val_loss: 7581.7148\n",
      "EPOCH: 331 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 756.1367 - val_loss: 1.9269\n",
      "EPOCH: 332 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 786.5212 - val_loss: 785.0131\n",
      "EPOCH: 333 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3023.5847 - val_loss: 2313.3044\n",
      "EPOCH: 334 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7719.5537 - val_loss: 8673.8760\n",
      "EPOCH: 335 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7952.6772 - val_loss: 7942.0049\n",
      "EPOCH: 336 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1603.7426 - val_loss: 1332.7053\n",
      "EPOCH: 337 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6043.5815 - val_loss: 6130.6338\n",
      "EPOCH: 338 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7790.5806 - val_loss: 7671.8457\n",
      "EPOCH: 339 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7384.9478 - val_loss: 7559.9185\n",
      "EPOCH: 340 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5315.6968 - val_loss: 5370.8774\n",
      "EPOCH: 341 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3897.4937 - val_loss: 2975.2788\n",
      "EPOCH: 342 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7691.7646 - val_loss: 7914.7734\n",
      "EPOCH: 343 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3912.6514 - val_loss: 3911.4607\n",
      "EPOCH: 344 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7413.5923 - val_loss: 7521.8062\n",
      "EPOCH: 345 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5717.2114 - val_loss: 5991.0234\n",
      "EPOCH: 346 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 697.0501 - val_loss: 695.7040\n",
      "EPOCH: 347 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6004.4258 - val_loss: 5553.1025\n",
      "EPOCH: 348 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7342.0850 - val_loss: 7429.6846\n",
      "EPOCH: 349 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2697.7673 - val_loss: 4017.3718\n",
      "EPOCH: 350 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5031.7939 - val_loss: 3656.7803\n",
      "EPOCH: 351 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6931.4819 - val_loss: 6784.8726\n",
      "EPOCH: 352 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3763.1604 - val_loss: 3759.8242\n",
      "EPOCH: 353 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3716.9758 - val_loss: 4081.8706\n",
      "EPOCH: 354 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4690.8140 - val_loss: 4686.8496\n",
      "EPOCH: 355 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1330.5372 - val_loss: 1291.1426\n",
      "EPOCH: 356 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4976.5244 - val_loss: 4918.0259\n",
      "EPOCH: 357 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2846.3499 - val_loss: 3024.5112\n",
      "EPOCH: 358 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6107.2422 - val_loss: 6148.4336\n",
      "EPOCH: 359 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4855.9429 - val_loss: 5319.5884\n",
      "EPOCH: 360 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3695.0789 - val_loss: 4059.0068\n",
      "EPOCH: 361 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1116.4709 - val_loss: 1238.0391\n",
      "EPOCH: 362 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2559.4036 - val_loss: 2556.3975\n",
      "EPOCH: 363 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5978.6924 - val_loss: 5986.5093\n",
      "EPOCH: 364 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6975.8242 - val_loss: 6404.8301\n",
      "EPOCH: 365 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8309.4102 - val_loss: 8485.2139\n",
      "EPOCH: 366 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2925.6343 - val_loss: 2221.0767\n",
      "EPOCH: 367 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3690.2478 - val_loss: 3687.3420\n",
      "EPOCH: 368 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7230.4448 - val_loss: 7248.5674\n",
      "EPOCH: 369 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7441.0352 - val_loss: 8477.1270\n",
      "EPOCH: 370 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7258.6079 - val_loss: 7335.8394\n",
      "EPOCH: 371 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6217.1499 - val_loss: 6328.3813\n",
      "EPOCH: 372 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 661.9896 - val_loss: 660.6363\n",
      "EPOCH: 373 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1578.1279 - val_loss: 18.3924\n",
      "EPOCH: 374 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5635.6431 - val_loss: 5592.1089\n",
      "EPOCH: 375 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5972.2607 - val_loss: 5970.9355\n",
      "EPOCH: 376 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4449.7529 - val_loss: 4212.0015\n",
      "EPOCH: 377 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7290.0366 - val_loss: 7354.1958\n",
      "EPOCH: 378 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5219.7461 - val_loss: 3338.0054\n",
      "EPOCH: 379 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5659.5186 - val_loss: 6983.5239\n",
      "EPOCH: 380 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7623.1416 - val_loss: 7509.2671\n",
      "EPOCH: 381 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5910.1846 - val_loss: 5836.7388\n",
      "EPOCH: 382 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5629.9639 - val_loss: 6977.7783\n",
      "EPOCH: 383 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7426.2979 - val_loss: 7321.4336\n",
      "EPOCH: 384 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2829.9023 - val_loss: 2818.6309\n",
      "EPOCH: 385 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4253.5796 - val_loss: 4248.6411\n",
      "EPOCH: 386 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6840.8916 - val_loss: 6836.9526\n",
      "EPOCH: 387 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4727.5625 - val_loss: 7337.8203\n",
      "EPOCH: 388 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8032.5430 - val_loss: 7827.5703\n",
      "EPOCH: 389 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7017.8682 - val_loss: 7009.3223\n",
      "EPOCH: 390 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2003.1982 - val_loss: 1948.0813\n",
      "EPOCH: 391 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7334.1294 - val_loss: 8268.6631\n",
      "EPOCH: 392 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4819.3477 - val_loss: 3271.6887\n",
      "EPOCH: 393 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7125.0552 - val_loss: 7087.2627\n",
      "EPOCH: 394 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3916.9863 - val_loss: 3969.1106\n",
      "EPOCH: 395 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4217.9463 - val_loss: 4249.3447\n",
      "EPOCH: 396 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7171.8179 - val_loss: 7160.8701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 397 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1254.9578 - val_loss: 1218.9603\n",
      "EPOCH: 398 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6539.1431 - val_loss: 7168.9287\n",
      "EPOCH: 399 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5223.0303 - val_loss: 5276.9331\n",
      "EPOCH: 400 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2745.7590 - val_loss: 2616.0654\n",
      "EPOCH: 401 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3618.3474 - val_loss: 3615.6514\n",
      "EPOCH: 402 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6941.1929 - val_loss: 7134.2803\n",
      "EPOCH: 403 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5551.4634 - val_loss: 8262.4756\n",
      "EPOCH: 404 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6301.7275 - val_loss: 6282.8955\n",
      "EPOCH: 405 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5102.0229 - val_loss: 5184.4922\n",
      "EPOCH: 406 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7513.3125 - val_loss: 7730.6343\n",
      "EPOCH: 407 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7509.8525 - val_loss: 7727.1104\n",
      "EPOCH: 408 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1147.4729 - val_loss: 916.5369\n",
      "EPOCH: 409 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7004.6836 - val_loss: 7127.9482\n",
      "EPOCH: 410 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7250.4590 - val_loss: 7245.8955\n",
      "EPOCH: 411 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3532.0847 - val_loss: 3662.9739\n",
      "EPOCH: 412 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3240.4133 - val_loss: 2657.2832\n",
      "EPOCH: 413 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3223.1228 - val_loss: 3258.9832\n",
      "EPOCH: 414 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5651.2944 - val_loss: 2638.0327\n",
      "EPOCH: 415 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4773.7285 - val_loss: 5309.4434\n",
      "EPOCH: 416 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6080.0918 - val_loss: 6132.5396\n",
      "EPOCH: 417 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6998.7354 - val_loss: 7465.7896\n",
      "EPOCH: 418 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4415.4336 - val_loss: 4354.8125\n",
      "EPOCH: 419 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6471.3198 - val_loss: 6989.6562\n",
      "EPOCH: 420 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 620.6185 - val_loss: 619.5343\n",
      "EPOCH: 421 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7206.3867 - val_loss: 7202.2959\n",
      "EPOCH: 422 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 669.0677 - val_loss: 667.8737\n",
      "EPOCH: 423 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1859.2103 - val_loss: 1823.9551\n",
      "EPOCH: 424 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1709.8129 - val_loss: 1542.3342\n",
      "EPOCH: 425 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3549.2935 - val_loss: 3766.7510\n",
      "EPOCH: 426 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4984.1816 - val_loss: 5117.7939\n",
      "EPOCH: 427 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5092.1616 - val_loss: 7052.3936\n",
      "EPOCH: 428 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6304.0527 - val_loss: 4906.0869\n",
      "EPOCH: 429 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4465.0371 - val_loss: 4415.8071\n",
      "EPOCH: 430 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6734.4785 - val_loss: 7013.6460\n",
      "EPOCH: 431 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4317.6646 - val_loss: 4305.8115\n",
      "EPOCH: 432 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3899.3840 - val_loss: 3351.8740\n",
      "EPOCH: 433 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5299.7227 - val_loss: 8307.8135\n",
      "EPOCH: 434 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3978.3657 - val_loss: 3952.4512\n",
      "EPOCH: 435 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2035.8643 - val_loss: 2033.7236\n",
      "EPOCH: 436 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7550.3306 - val_loss: 6969.4165\n",
      "EPOCH: 437 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7139.3618 - val_loss: 7046.0830\n",
      "EPOCH: 438 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8294.2734 - val_loss: 8558.9668\n",
      "EPOCH: 439 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3315.3118 - val_loss: 3312.4062\n",
      "EPOCH: 440 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3894.5442 - val_loss: 3946.3049\n",
      "EPOCH: 441 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3955.6255 - val_loss: 2932.9482\n",
      "EPOCH: 442 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5758.6660 - val_loss: 5894.1406\n",
      "EPOCH: 443 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6441.1396 - val_loss: 6482.6948\n",
      "EPOCH: 444 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7325.5664 - val_loss: 7605.2817\n",
      "EPOCH: 445 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6412.7959 - val_loss: 6479.0068\n",
      "EPOCH: 446 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1866.3864 - val_loss: 1287.2275\n",
      "EPOCH: 447 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6843.9360 - val_loss: 7886.9570\n",
      "EPOCH: 448 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7731.1948 - val_loss: 7987.3833\n",
      "EPOCH: 449 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3704.9597 - val_loss: 3751.1074\n",
      "EPOCH: 450 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5244.4561 - val_loss: 8307.7598\n",
      "EPOCH: 451 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6585.2163 - val_loss: 6969.1528\n",
      "EPOCH: 452 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5358.5034 - val_loss: 2481.7581\n",
      "EPOCH: 453 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5856.5249 - val_loss: 5868.9170\n",
      "EPOCH: 454 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6987.6821 - val_loss: 6986.7788\n",
      "EPOCH: 455 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2305.8306 - val_loss: 2303.8777\n",
      "EPOCH: 456 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1757.6890 - val_loss: 1711.5984\n",
      "EPOCH: 457 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7031.5640 - val_loss: 6950.4619\n",
      "EPOCH: 458 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7314.5581 - val_loss: 7751.3013\n",
      "EPOCH: 459 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7287.8110 - val_loss: 7561.2202\n",
      "EPOCH: 460 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5372.9219 - val_loss: 6627.4160\n",
      "EPOCH: 461 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1597.1439 - val_loss: 1297.2990\n",
      "EPOCH: 462 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5452.9541 - val_loss: 5372.5977\n",
      "EPOCH: 463 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1873.3508 - val_loss: 1513.5592\n",
      "EPOCH: 464 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7654.1104 - val_loss: 7651.7539\n",
      "EPOCH: 465 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4859.0571 - val_loss: 4991.6157\n",
      "EPOCH: 466 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5973.1865 - val_loss: 6125.4565\n",
      "EPOCH: 467 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3510.3486 - val_loss: 3593.9600\n",
      "EPOCH: 468 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7929.7686 - val_loss: 8354.3691\n",
      "EPOCH: 469 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1649.9814 - val_loss: 867.8215\n",
      "EPOCH: 470 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5095.8374 - val_loss: 5374.8545\n",
      "EPOCH: 471 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4493.6753 - val_loss: 4834.4302\n",
      "EPOCH: 472 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6743.4741 - val_loss: 6398.7036\n",
      "EPOCH: 473 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8112.0615 - val_loss: 8041.4326\n",
      "EPOCH: 474 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7837.8677 - val_loss: 7860.5854\n",
      "EPOCH: 475 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5742.4868 - val_loss: 3884.1504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 476 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3018.3889 - val_loss: 3729.1748\n",
      "EPOCH: 477 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1379.0483 - val_loss: 0.2698\n",
      "EPOCH: 478 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 925.5982 - val_loss: 1056.2133\n",
      "EPOCH: 479 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7189.5981 - val_loss: 7088.7300\n",
      "EPOCH: 480 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5397.6577 - val_loss: 4995.9019\n",
      "EPOCH: 481 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5807.7305 - val_loss: 5924.1440\n",
      "EPOCH: 482 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7148.9561 - val_loss: 6732.1655\n",
      "EPOCH: 483 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2812.1042 - val_loss: 2750.0886\n",
      "EPOCH: 484 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2444.1514 - val_loss: 2433.2632\n",
      "EPOCH: 485 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4195.1167 - val_loss: 4192.5811\n",
      "EPOCH: 486 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7392.1963 - val_loss: 7444.8569\n",
      "EPOCH: 487 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2895.6028 - val_loss: 2936.4104\n",
      "EPOCH: 488 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7267.9883 - val_loss: 7305.9858\n",
      "EPOCH: 489 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4277.1304 - val_loss: 2963.6624\n",
      "EPOCH: 490 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3040.6228 - val_loss: 3063.4458\n",
      "EPOCH: 491 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5373.9429 - val_loss: 2500.0684\n",
      "EPOCH: 492 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2789.3755 - val_loss: 2733.5701\n",
      "EPOCH: 493 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1787.8828 - val_loss: 1893.1003\n",
      "EPOCH: 494 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6821.8169 - val_loss: 6818.3770\n",
      "EPOCH: 495 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5708.5469 - val_loss: 5712.9424\n",
      "EPOCH: 496 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7539.4678 - val_loss: 7608.4932\n",
      "EPOCH: 497 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3520.3955 - val_loss: 3752.4832\n",
      "EPOCH: 498 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2426.0151 - val_loss: 2415.1902\n",
      "EPOCH: 499 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6887.4365 - val_loss: 7723.4062\n",
      "EPOCH: 500 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6305.9175 - val_loss: 4763.4810\n",
      "EPOCH: 501 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3765.8955 - val_loss: 3758.2478\n",
      "EPOCH: 502 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6475.5664 - val_loss: 6462.0957\n",
      "EPOCH: 503 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3013.8496 - val_loss: 2258.5171\n",
      "EPOCH: 504 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6483.3271 - val_loss: 4261.2144\n",
      "EPOCH: 505 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6252.6777 - val_loss: 6185.8193\n",
      "EPOCH: 506 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5178.5654 - val_loss: 6518.5615\n",
      "EPOCH: 507 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4011.1152 - val_loss: 1269.0859\n",
      "EPOCH: 508 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3147.5732 - val_loss: 3144.9529\n",
      "EPOCH: 509 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7462.2173 - val_loss: 7708.4253\n",
      "EPOCH: 510 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5723.6357 - val_loss: 5988.2651\n",
      "EPOCH: 511 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7756.3892 - val_loss: 7650.9438\n",
      "EPOCH: 512 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4123.5117 - val_loss: 4120.6445\n",
      "EPOCH: 513 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4494.2808 - val_loss: 5335.1060\n",
      "EPOCH: 514 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4550.6494 - val_loss: 4627.7900\n",
      "EPOCH: 515 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5583.8882 - val_loss: 5627.0669\n",
      "EPOCH: 516 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5925.3745 - val_loss: 4542.6943\n",
      "EPOCH: 517 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7849.3022 - val_loss: 7982.6274\n",
      "EPOCH: 518 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 973.2789 - val_loss: 977.8766\n",
      "EPOCH: 519 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3274.2322 - val_loss: 3504.9395\n",
      "EPOCH: 520 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6954.8281 - val_loss: 7211.5669\n",
      "EPOCH: 521 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5890.8618 - val_loss: 6727.2646\n",
      "EPOCH: 522 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6706.1929 - val_loss: 6707.1943\n",
      "EPOCH: 523 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6528.6533 - val_loss: 6459.8389\n",
      "EPOCH: 524 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5517.6157 - val_loss: 6016.4067\n",
      "EPOCH: 525 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5071.4609 - val_loss: 3277.2297\n",
      "EPOCH: 526 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4387.3789 - val_loss: 2005.0905\n",
      "EPOCH: 527 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6530.7983 - val_loss: 5417.0215\n",
      "EPOCH: 528 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1029.1128 - val_loss: 982.5627\n",
      "EPOCH: 529 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1314.4656 - val_loss: 641.2071\n",
      "EPOCH: 530 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6306.4858 - val_loss: 4772.2510\n",
      "EPOCH: 531 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6269.3823 - val_loss: 6204.6992\n",
      "EPOCH: 532 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5678.9702 - val_loss: 7230.5391\n",
      "EPOCH: 533 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5532.2500 - val_loss: 5493.4097\n",
      "EPOCH: 534 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7381.2866 - val_loss: 7535.0059\n",
      "EPOCH: 535 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6217.6079 - val_loss: 6170.3809\n",
      "EPOCH: 536 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5956.1807 - val_loss: 5932.5137\n",
      "EPOCH: 537 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4396.9902 - val_loss: 4176.1187\n",
      "EPOCH: 538 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6422.8931 - val_loss: 7816.9805\n",
      "EPOCH: 539 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6269.0000 - val_loss: 4739.1826\n",
      "EPOCH: 540 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6395.3179 - val_loss: 6937.4341\n",
      "EPOCH: 541 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2353.3047 - val_loss: 1746.8990\n",
      "EPOCH: 542 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4097.6372 - val_loss: 4039.7966\n",
      "EPOCH: 543 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4498.5884 - val_loss: 4575.4409\n",
      "EPOCH: 544 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5352.2998 - val_loss: 5338.0361\n",
      "EPOCH: 545 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6139.7788 - val_loss: 6143.8462\n",
      "EPOCH: 546 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7022.7114 - val_loss: 7217.7944\n",
      "EPOCH: 547 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6806.8125 - val_loss: 6692.6250\n",
      "EPOCH: 548 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5831.6104 - val_loss: 4530.4365\n",
      "EPOCH: 549 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5932.2744 - val_loss: 2215.4966\n",
      "EPOCH: 550 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2318.1272 - val_loss: 157.5109\n",
      "EPOCH: 551 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4001.1646 - val_loss: 3997.8171\n",
      "EPOCH: 552 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7712.6836 - val_loss: 7929.4844\n",
      "EPOCH: 553 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6106.7197 - val_loss: 6110.7480\n",
      "EPOCH: 554 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6521.5381 - val_loss: 6702.1704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 555 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7618.4834 - val_loss: 7921.6152\n",
      "EPOCH: 556 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5177.2246 - val_loss: 5254.5464\n",
      "EPOCH: 557 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5012.5522 - val_loss: 2206.8054\n",
      "EPOCH: 558 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4325.0269 - val_loss: 5149.2495\n",
      "EPOCH: 559 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1295.0564 - val_loss: 1.5768\n",
      "EPOCH: 560 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5947.1680 - val_loss: 6546.0557\n",
      "EPOCH: 561 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5139.4053 - val_loss: 5143.1895\n",
      "EPOCH: 562 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6402.6587 - val_loss: 5989.4492\n",
      "EPOCH: 563 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7173.9712 - val_loss: 7171.8501\n",
      "EPOCH: 564 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5600.6763 - val_loss: 4252.5210\n",
      "EPOCH: 565 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5136.8467 - val_loss: 5134.6904\n",
      "EPOCH: 566 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3723.5881 - val_loss: 1107.5624\n",
      "EPOCH: 567 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2348.6387 - val_loss: 1222.5483\n",
      "EPOCH: 568 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5887.7319 - val_loss: 5286.0283\n",
      "EPOCH: 569 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1785.0154 - val_loss: 1431.4941\n",
      "EPOCH: 570 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4777.5117 - val_loss: 4897.9492\n",
      "EPOCH: 571 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5033.6074 - val_loss: 6131.7744\n",
      "EPOCH: 572 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6586.2915 - val_loss: 6618.5073\n",
      "EPOCH: 573 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3480.3799 - val_loss: 3300.4478\n",
      "EPOCH: 574 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7518.2842 - val_loss: 7719.5112\n",
      "EPOCH: 575 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6177.4814 - val_loss: 6513.3589\n",
      "EPOCH: 576 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4886.5654 - val_loss: 4988.6968\n",
      "EPOCH: 577 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3674.9587 - val_loss: 3635.8750\n",
      "EPOCH: 578 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6388.8008 - val_loss: 4378.5352\n",
      "EPOCH: 579 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5976.4570 - val_loss: 6024.2266\n",
      "EPOCH: 580 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7435.1421 - val_loss: 7663.7622\n",
      "EPOCH: 581 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3553.1045 - val_loss: 3617.0723\n",
      "EPOCH: 582 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5817.9419 - val_loss: 5654.1191\n",
      "EPOCH: 583 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2954.0149 - val_loss: 2244.1882\n",
      "EPOCH: 584 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5411.2783 - val_loss: 5403.0947\n",
      "EPOCH: 585 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5311.7212 - val_loss: 1199.2172\n",
      "EPOCH: 586 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6172.2852 - val_loss: 6654.6455\n",
      "EPOCH: 587 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5977.2070 - val_loss: 6072.9028\n",
      "EPOCH: 588 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6351.0098 - val_loss: 6745.9131\n",
      "EPOCH: 589 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5648.9116 - val_loss: 6042.8193\n",
      "EPOCH: 590 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6460.4507 - val_loss: 6456.0244\n",
      "EPOCH: 591 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6328.9731 - val_loss: 6436.5840\n",
      "EPOCH: 592 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3532.5085 - val_loss: 3525.0020\n",
      "EPOCH: 593 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6157.6758 - val_loss: 5907.0361\n",
      "EPOCH: 594 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3032.5603 - val_loss: 3029.7292\n",
      "EPOCH: 595 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2460.8059 - val_loss: 339.6513\n",
      "EPOCH: 596 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4714.1270 - val_loss: 6275.1729\n",
      "EPOCH: 597 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7035.9233 - val_loss: 7328.7822\n",
      "EPOCH: 598 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6427.7842 - val_loss: 6423.8799\n",
      "EPOCH: 599 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5982.5840 - val_loss: 5949.8311\n",
      "EPOCH: 600 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6008.2529 - val_loss: 6272.1934\n",
      "EPOCH: 601 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2838.1663 - val_loss: 2115.4448\n",
      "EPOCH: 602 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3210.1335 - val_loss: 3252.7314\n",
      "EPOCH: 603 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6633.2427 - val_loss: 6596.4976\n",
      "EPOCH: 604 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6404.0254 - val_loss: 6400.0903\n",
      "EPOCH: 605 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5007.3862 - val_loss: 5053.8960\n",
      "EPOCH: 606 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6816.6191 - val_loss: 6850.8940\n",
      "EPOCH: 607 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3520.0469 - val_loss: 3547.1956\n",
      "EPOCH: 608 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2577.6272 - val_loss: 2599.6721\n",
      "EPOCH: 609 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3149.7566 - val_loss: 3241.6470\n",
      "EPOCH: 610 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4642.6738 - val_loss: 7502.1592\n",
      "EPOCH: 611 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4765.0386 - val_loss: 6774.6821\n",
      "EPOCH: 612 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 410.9952 - val_loss: 389.2449\n",
      "EPOCH: 613 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2248.1956 - val_loss: 1130.1481\n",
      "EPOCH: 614 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5947.9136 - val_loss: 6051.5396\n",
      "EPOCH: 615 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 539.0093 - val_loss: 25.5149\n",
      "EPOCH: 616 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5079.5762 - val_loss: 5023.8433\n",
      "EPOCH: 617 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3138.1194 - val_loss: 1920.5016\n",
      "EPOCH: 618 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7205.4502 - val_loss: 7125.0913\n",
      "EPOCH: 619 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1764.8615 - val_loss: 1763.7758\n",
      "EPOCH: 620 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4372.0542 - val_loss: 4374.3994\n",
      "EPOCH: 621 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 949.9132 - val_loss: 706.0703\n",
      "EPOCH: 622 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5133.9893 - val_loss: 5132.4468\n",
      "EPOCH: 623 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2981.2410 - val_loss: 3199.6089\n",
      "EPOCH: 624 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3197.2104 - val_loss: 3243.7388\n",
      "EPOCH: 625 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7059.2300 - val_loss: 7094.7100\n",
      "EPOCH: 626 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4454.4414 - val_loss: 6924.8931\n",
      "EPOCH: 627 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4206.9688 - val_loss: 2344.2769\n",
      "EPOCH: 628 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5121.9038 - val_loss: 5245.7515\n",
      "EPOCH: 629 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4469.3066 - val_loss: 4331.6807\n",
      "EPOCH: 630 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6327.3569 - val_loss: 6324.5254\n",
      "EPOCH: 631 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5805.6997 - val_loss: 5853.3379\n",
      "EPOCH: 632 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5007.9629 - val_loss: 5006.1064\n",
      "EPOCH: 633 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4736.1084 - val_loss: 7227.5591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 634 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2639.3152 - val_loss: 2636.8508\n",
      "EPOCH: 635 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5739.2344 - val_loss: 5362.5317\n",
      "EPOCH: 636 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1367.9103 - val_loss: 667.4418\n",
      "EPOCH: 637 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6287.0400 - val_loss: 6243.1821\n",
      "EPOCH: 638 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5044.5791 - val_loss: 3498.4387\n",
      "EPOCH: 639 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6030.4546 - val_loss: 4569.0215\n",
      "EPOCH: 640 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4335.3862 - val_loss: 4333.1353\n",
      "EPOCH: 641 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5911.4443 - val_loss: 4538.6670\n",
      "EPOCH: 642 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1737.5443 - val_loss: 1788.2222\n",
      "EPOCH: 643 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5094.8789 - val_loss: 5219.3550\n",
      "EPOCH: 644 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6092.0352 - val_loss: 6029.1235\n",
      "EPOCH: 645 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1109.0763 - val_loss: 1319.6473\n",
      "EPOCH: 646 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6490.4976 - val_loss: 6358.3335\n",
      "EPOCH: 647 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5618.7930 - val_loss: 6117.7588\n",
      "EPOCH: 648 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4071.7939 - val_loss: 4845.8208\n",
      "EPOCH: 649 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3112.2546 - val_loss: 2301.1013\n",
      "EPOCH: 650 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4843.9546 - val_loss: 4842.0542\n",
      "EPOCH: 651 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5173.1182 - val_loss: 5170.0317\n",
      "EPOCH: 652 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4302.9443 - val_loss: 4419.6548\n",
      "EPOCH: 653 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2914.5657 - val_loss: 3081.9614\n",
      "EPOCH: 654 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7331.8931 - val_loss: 7332.5176\n",
      "EPOCH: 655 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2039.4639 - val_loss: 2013.3350\n",
      "EPOCH: 656 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1381.1946 - val_loss: 1332.5149\n",
      "EPOCH: 657 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5153.4116 - val_loss: 3412.0137\n",
      "EPOCH: 658 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2966.2002 - val_loss: 2862.4966\n",
      "EPOCH: 659 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4818.0884 - val_loss: 4937.0898\n",
      "EPOCH: 660 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3388.6436 - val_loss: 3381.5159\n",
      "EPOCH: 661 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6123.7397 - val_loss: 6653.9238\n",
      "EPOCH: 662 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3072.8711 - val_loss: 2256.8176\n",
      "EPOCH: 663 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4899.4502 - val_loss: 4982.2002\n",
      "EPOCH: 664 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2851.0044 - val_loss: 3161.1089\n",
      "EPOCH: 665 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2573.3811 - val_loss: 2570.5242\n",
      "EPOCH: 666 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1424.1494 - val_loss: 922.7884\n",
      "EPOCH: 667 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4068.5662 - val_loss: 2868.8923\n",
      "EPOCH: 668 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 390.2789 - val_loss: 389.4602\n",
      "EPOCH: 669 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1151.0088 - val_loss: 161.6595\n",
      "EPOCH: 670 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6532.0181 - val_loss: 6882.6221\n",
      "EPOCH: 671 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3753.5364 - val_loss: 3698.3384\n",
      "EPOCH: 672 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5886.7388 - val_loss: 5881.5952\n",
      "EPOCH: 673 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 883.9485 - val_loss: 757.7489\n",
      "EPOCH: 674 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5706.8818 - val_loss: 5414.2412\n",
      "EPOCH: 675 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3225.3806 - val_loss: 1397.5619\n",
      "EPOCH: 676 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5044.4414 - val_loss: 5091.8848\n",
      "EPOCH: 677 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3736.0503 - val_loss: 3682.7686\n",
      "EPOCH: 678 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1428.0812 - val_loss: 1390.9604\n",
      "EPOCH: 679 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6143.2852 - val_loss: 6285.8916\n",
      "EPOCH: 680 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5857.8179 - val_loss: 6165.6201\n",
      "EPOCH: 681 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2973.8550 - val_loss: 3079.7615\n",
      "EPOCH: 682 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1667.1776 - val_loss: 1716.4923\n",
      "EPOCH: 683 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3009.4233 - val_loss: 1817.1761\n",
      "EPOCH: 684 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2057.3223 - val_loss: 186.6275\n",
      "EPOCH: 685 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3476.9482 - val_loss: 2464.4678\n",
      "EPOCH: 686 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5549.1353 - val_loss: 6122.8096\n",
      "EPOCH: 687 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2054.6812 - val_loss: 185.6714\n",
      "EPOCH: 688 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6355.3257 - val_loss: 6394.3237\n",
      "EPOCH: 689 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5055.5884 - val_loss: 3333.1963\n",
      "EPOCH: 690 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1262.6536 - val_loss: 1261.1466\n",
      "EPOCH: 691 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2981.4766 - val_loss: 3022.6401\n",
      "EPOCH: 692 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6220.6792 - val_loss: 6587.9517\n",
      "EPOCH: 693 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6000.8853 - val_loss: 6565.4775\n",
      "EPOCH: 694 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6447.5132 - val_loss: 5355.8530\n",
      "EPOCH: 695 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6041.1040 - val_loss: 6026.5552\n",
      "EPOCH: 696 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5704.4111 - val_loss: 5648.5435\n",
      "EPOCH: 697 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2625.0488 - val_loss: 2616.9456\n",
      "EPOCH: 698 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2973.3296 - val_loss: 2410.2180\n",
      "EPOCH: 699 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5784.4263 - val_loss: 6095.0645\n",
      "EPOCH: 700 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6929.4487 - val_loss: 7327.2188\n",
      "EPOCH: 701 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4291.9507 - val_loss: 4278.9907\n",
      "EPOCH: 702 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5743.3335 - val_loss: 5501.0586\n",
      "EPOCH: 703 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5536.4258 - val_loss: 6151.9746\n",
      "EPOCH: 704 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5962.5381 - val_loss: 6015.1475\n",
      "EPOCH: 705 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7028.1992 - val_loss: 7348.3423\n",
      "EPOCH: 706 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7157.9829 - val_loss: 7158.1914\n",
      "EPOCH: 707 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5191.9351 - val_loss: 6066.4053\n",
      "EPOCH: 708 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5958.9902 - val_loss: 5907.8081\n",
      "EPOCH: 709 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4557.9702 - val_loss: 6998.5225\n",
      "EPOCH: 710 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6373.5454 - val_loss: 6780.6274\n",
      "EPOCH: 711 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6035.1079 - val_loss: 6035.6182\n",
      "EPOCH: 712 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2938.7097 - val_loss: 2377.9258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 713 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3245.9189 - val_loss: 3587.1448\n",
      "EPOCH: 714 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6020.4785 - val_loss: 5636.5210\n",
      "EPOCH: 715 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4448.4595 - val_loss: 5830.9697\n",
      "EPOCH: 716 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1485.8890 - val_loss: 1152.0756\n",
      "EPOCH: 717 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4328.8960 - val_loss: 4628.1201\n",
      "EPOCH: 718 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4820.2275 - val_loss: 4818.4224\n",
      "EPOCH: 719 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5486.3301 - val_loss: 5316.1089\n",
      "EPOCH: 720 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6023.5679 - val_loss: 6020.0049\n",
      "EPOCH: 721 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4540.0054 - val_loss: 4067.3643\n",
      "EPOCH: 722 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5275.8848 - val_loss: 4037.5649\n",
      "EPOCH: 723 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5428.3779 - val_loss: 5993.3799\n",
      "EPOCH: 724 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5690.8892 - val_loss: 5449.6279\n",
      "EPOCH: 725 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5889.5479 - val_loss: 5996.0723\n",
      "EPOCH: 726 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4849.1943 - val_loss: 4757.6577\n",
      "EPOCH: 727 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5913.8555 - val_loss: 5850.0723\n",
      "EPOCH: 728 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1653.0294 - val_loss: 1822.7502\n",
      "EPOCH: 729 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7096.6445 - val_loss: 7096.9863\n",
      "EPOCH: 730 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5986.0703 - val_loss: 5982.1665\n",
      "EPOCH: 731 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6159.8452 - val_loss: 6117.1133\n",
      "EPOCH: 732 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3656.6997 - val_loss: 2400.5903\n",
      "EPOCH: 733 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3815.8948 - val_loss: 2648.0452\n",
      "EPOCH: 734 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2524.4941 - val_loss: 1774.1326\n",
      "EPOCH: 735 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4253.5928 - val_loss: 4408.5713\n",
      "EPOCH: 736 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3319.2605 - val_loss: 3264.5278\n",
      "EPOCH: 737 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1790.7596 - val_loss: 1821.8442\n",
      "EPOCH: 738 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5560.0288 - val_loss: 5499.7222\n",
      "EPOCH: 739 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6801.3022 - val_loss: 7117.5391\n",
      "EPOCH: 740 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7131.7656 - val_loss: 7148.5532\n",
      "EPOCH: 741 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4285.1284 - val_loss: 4282.6118\n",
      "EPOCH: 742 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 815.5038 - val_loss: 601.3979\n",
      "EPOCH: 743 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2690.7097 - val_loss: 2688.4976\n",
      "EPOCH: 744 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5936.8135 - val_loss: 5933.2974\n",
      "EPOCH: 745 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1237.8007 - val_loss: 1201.8771\n",
      "EPOCH: 746 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 324.2232 - val_loss: 323.4892\n",
      "EPOCH: 747 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 927.3926 - val_loss: 947.7516\n",
      "EPOCH: 748 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5600.4194 - val_loss: 5920.6377\n",
      "EPOCH: 749 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4043.2812 - val_loss: 3981.6660\n",
      "EPOCH: 750 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5917.4292 - val_loss: 5913.9868\n",
      "EPOCH: 751 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2026.3717 - val_loss: 1527.2632\n",
      "EPOCH: 752 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5515.0352 - val_loss: 5440.0605\n",
      "EPOCH: 753 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4853.1147 - val_loss: 3171.3740\n",
      "EPOCH: 754 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5718.2759 - val_loss: 5722.8164\n",
      "EPOCH: 755 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2850.0315 - val_loss: 613.5210\n",
      "EPOCH: 756 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6686.2476 - val_loss: 7042.5493\n",
      "EPOCH: 757 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3741.5632 - val_loss: 2613.9705\n",
      "EPOCH: 758 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4584.7007 - val_loss: 4588.2227\n",
      "EPOCH: 759 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4354.5254 - val_loss: 6736.2715\n",
      "EPOCH: 760 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4221.7573 - val_loss: 6094.4902\n",
      "EPOCH: 761 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5049.2168 - val_loss: 3925.2168\n",
      "EPOCH: 762 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1364.9088 - val_loss: 1434.9277\n",
      "EPOCH: 763 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6149.7568 - val_loss: 6129.4678\n",
      "EPOCH: 764 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1264.7632 - val_loss: 794.6142\n",
      "EPOCH: 765 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5865.8594 - val_loss: 5862.4673\n",
      "EPOCH: 766 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5983.5674 - val_loss: 6021.3750\n",
      "EPOCH: 767 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2526.0859 - val_loss: 2778.5701\n",
      "EPOCH: 768 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5696.9512 - val_loss: 4277.1772\n",
      "EPOCH: 769 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3202.6912 - val_loss: 3200.1658\n",
      "EPOCH: 770 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5840.0225 - val_loss: 5845.0547\n",
      "EPOCH: 771 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4466.2949 - val_loss: 2703.6636\n",
      "EPOCH: 772 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1853.6584 - val_loss: 1995.6654\n",
      "EPOCH: 773 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4678.1274 - val_loss: 4687.7515\n",
      "EPOCH: 774 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5223.8867 - val_loss: 1866.4290\n",
      "EPOCH: 775 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1247.4728 - val_loss: 780.7711\n",
      "EPOCH: 776 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5828.1436 - val_loss: 5824.6665\n",
      "EPOCH: 777 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4097.0400 - val_loss: 4094.0500\n",
      "EPOCH: 778 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3269.2529 - val_loss: 2989.8357\n",
      "EPOCH: 779 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5648.0039 - val_loss: 5723.1201\n",
      "EPOCH: 780 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5814.2612 - val_loss: 5810.5166\n",
      "EPOCH: 781 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5362.1562 - val_loss: 5358.4248\n",
      "EPOCH: 782 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 983.2631 - val_loss: 1003.5565\n",
      "EPOCH: 783 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 500.3943 - val_loss: 497.0747\n",
      "EPOCH: 784 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4421.9521 - val_loss: 4360.0835\n",
      "EPOCH: 785 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2781.0046 - val_loss: 581.3928\n",
      "EPOCH: 786 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1361.2052 - val_loss: 1427.3324\n",
      "EPOCH: 787 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5701.0010 - val_loss: 5709.6797\n",
      "EPOCH: 788 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3204.0071 - val_loss: 3287.7517\n",
      "EPOCH: 789 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2257.4753 - val_loss: 2244.4370\n",
      "EPOCH: 790 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5411.4917 - val_loss: 5625.2769\n",
      "EPOCH: 791 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4590.0781 - val_loss: 3115.0198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 792 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5588.0884 - val_loss: 5527.3970\n",
      "EPOCH: 793 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5278.1167 - val_loss: 4996.1577\n",
      "EPOCH: 794 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5494.6357 - val_loss: 5461.0874\n",
      "EPOCH: 795 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1831.8789 - val_loss: 1636.5414\n",
      "EPOCH: 796 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2946.5020 - val_loss: 2770.9490\n",
      "EPOCH: 797 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3832.0754 - val_loss: 3275.5310\n",
      "EPOCH: 798 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4489.2729 - val_loss: 4530.7500\n",
      "EPOCH: 799 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2777.8113 - val_loss: 2012.6709\n",
      "EPOCH: 800 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3836.5127 - val_loss: 6239.9282\n",
      "EPOCH: 801 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3084.6436 - val_loss: 2141.5503\n",
      "EPOCH: 802 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5344.7915 - val_loss: 5319.1064\n",
      "EPOCH: 803 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5003.0640 - val_loss: 3807.1863\n",
      "EPOCH: 804 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2529.9956 - val_loss: 2817.4275\n",
      "EPOCH: 805 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2273.3293 - val_loss: 2271.1501\n",
      "EPOCH: 806 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4503.3921 - val_loss: 4466.6396\n",
      "EPOCH: 807 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5720.3398 - val_loss: 5716.5967\n",
      "EPOCH: 808 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2627.5461 - val_loss: 2711.1394\n",
      "EPOCH: 809 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 892.6857 - val_loss: 851.0397\n",
      "EPOCH: 810 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4490.7905 - val_loss: 4454.1772\n",
      "EPOCH: 811 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5637.4048 - val_loss: 5612.3340\n",
      "EPOCH: 812 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2531.6514 - val_loss: 2529.2354\n",
      "EPOCH: 813 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 253.6485 - val_loss: 236.2105\n",
      "EPOCH: 814 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1591.7748 - val_loss: 2548.1567\n",
      "EPOCH: 815 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4902.9214 - val_loss: 4917.5586\n",
      "EPOCH: 816 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4654.6929 - val_loss: 4651.5122\n",
      "EPOCH: 817 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4096.8569 - val_loss: 4083.4287\n",
      "EPOCH: 818 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4482.1221 - val_loss: 3073.1941\n",
      "EPOCH: 819 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5670.1592 - val_loss: 5675.2837\n",
      "EPOCH: 820 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5643.8105 - val_loss: 5656.5840\n",
      "EPOCH: 821 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6414.0708 - val_loss: 6438.6543\n",
      "EPOCH: 822 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2293.8049 - val_loss: 2377.8257\n",
      "EPOCH: 823 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2233.7869 - val_loss: 2231.5784\n",
      "EPOCH: 824 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4303.3916 - val_loss: 4349.4907\n",
      "EPOCH: 825 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5563.8135 - val_loss: 5525.2983\n",
      "EPOCH: 826 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2227.2200 - val_loss: 2225.0137\n",
      "EPOCH: 827 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2067.9446 - val_loss: 2102.2224\n",
      "EPOCH: 828 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3176.7373 - val_loss: 3400.6929\n",
      "EPOCH: 829 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5635.3345 - val_loss: 5640.4419\n",
      "EPOCH: 830 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4007.8691 - val_loss: 6643.0669\n",
      "EPOCH: 831 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2590.9490 - val_loss: 2678.2734\n",
      "EPOCH: 832 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1932.1381 - val_loss: 1775.6274\n",
      "EPOCH: 833 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4114.9766 - val_loss: 4305.4951\n",
      "EPOCH: 834 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2843.7612 - val_loss: 1142.0514\n",
      "EPOCH: 835 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6391.5928 - val_loss: 6467.1479\n",
      "EPOCH: 836 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5361.3877 - val_loss: 5508.2754\n",
      "EPOCH: 837 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2944.4697 - val_loss: 2945.7629\n",
      "EPOCH: 838 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6155.2168 - val_loss: 6153.9722\n",
      "EPOCH: 839 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4210.1538 - val_loss: 4208.1240\n",
      "EPOCH: 840 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4946.2734 - val_loss: 4381.0640\n",
      "EPOCH: 841 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2654.4087 - val_loss: 523.8298\n",
      "EPOCH: 842 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3668.7322 - val_loss: 3666.3486\n",
      "EPOCH: 843 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2726.7983 - val_loss: 2725.7056\n",
      "EPOCH: 844 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6386.7993 - val_loss: 6543.5967\n",
      "EPOCH: 845 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5264.5771 - val_loss: 5757.2285\n",
      "EPOCH: 846 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4563.2749 - val_loss: 4560.3071\n",
      "EPOCH: 847 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3967.4048 - val_loss: 3921.5862\n",
      "EPOCH: 848 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3670.9810 - val_loss: 3652.4165\n",
      "EPOCH: 849 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5384.0269 - val_loss: 4983.2847\n",
      "EPOCH: 850 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4187.6597 - val_loss: 4185.5518\n",
      "EPOCH: 851 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5835.5972 - val_loss: 5923.1235\n",
      "EPOCH: 852 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5123.0640 - val_loss: 5461.8022\n",
      "EPOCH: 853 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4547.5596 - val_loss: 2930.6455\n",
      "EPOCH: 854 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2270.3149 - val_loss: 1408.5140\n",
      "EPOCH: 855 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1484.5743 - val_loss: 1483.3782\n",
      "EPOCH: 856 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2556.2473 - val_loss: 2640.1445\n",
      "EPOCH: 857 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1029.3690 - val_loss: 1068.3038\n",
      "EPOCH: 858 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3667.1797 - val_loss: 3122.5750\n",
      "EPOCH: 859 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4211.3057 - val_loss: 1716.4060\n",
      "EPOCH: 860 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 899.9604 - val_loss: 71.2458\n",
      "EPOCH: 861 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5521.8135 - val_loss: 5851.3887\n",
      "EPOCH: 862 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6356.7744 - val_loss: 6547.9980\n",
      "EPOCH: 863 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 541.4247 - val_loss: 379.5125\n",
      "EPOCH: 864 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4154.9492 - val_loss: 4262.1367\n",
      "EPOCH: 865 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4100.1177 - val_loss: 4054.5710\n",
      "EPOCH: 866 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4907.0645 - val_loss: 5838.0210\n",
      "EPOCH: 867 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4145.1719 - val_loss: 4152.6812\n",
      "EPOCH: 868 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2652.7026 - val_loss: 2880.6086\n",
      "EPOCH: 869 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3640.8318 - val_loss: 3423.6555\n",
      "EPOCH: 870 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5272.5884 - val_loss: 5085.0405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 871 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5381.8760 - val_loss: 5434.4990\n",
      "EPOCH: 872 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2477.0435 - val_loss: 1396.3489\n",
      "EPOCH: 873 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2504.5754 - val_loss: 2545.4302\n",
      "EPOCH: 874 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5436.8223 - val_loss: 5412.8223\n",
      "EPOCH: 875 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5318.2876 - val_loss: 5468.8403\n",
      "EPOCH: 876 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4127.9585 - val_loss: 4160.8442\n",
      "EPOCH: 877 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3311.1145 - val_loss: 3685.5688\n",
      "EPOCH: 878 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2129.0984 - val_loss: 1322.9852\n",
      "EPOCH: 879 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3207.6558 - val_loss: 3173.1653\n",
      "EPOCH: 880 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4366.9043 - val_loss: 4365.1836\n",
      "EPOCH: 881 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3956.7332 - val_loss: 2286.3140\n",
      "EPOCH: 882 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2711.3167 - val_loss: 2920.6978\n",
      "EPOCH: 883 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3856.5789 - val_loss: 3868.3547\n",
      "EPOCH: 884 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2378.5193 - val_loss: 2531.3269\n",
      "EPOCH: 885 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2169.4822 - val_loss: 2251.6431\n",
      "EPOCH: 886 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1198.3829 - val_loss: 1195.9280\n",
      "EPOCH: 887 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3170.2515 - val_loss: 3207.8674\n",
      "EPOCH: 888 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2651.4468 - val_loss: 2654.3218\n",
      "EPOCH: 889 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5198.5479 - val_loss: 5166.5923\n",
      "EPOCH: 890 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4597.6602 - val_loss: 4693.4302\n",
      "EPOCH: 891 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6024.7998 - val_loss: 5914.4878\n",
      "EPOCH: 892 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5002.4565 - val_loss: 4884.3179\n",
      "EPOCH: 893 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2113.0190 - val_loss: 2710.7554\n",
      "EPOCH: 894 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2345.5327 - val_loss: 2619.5901\n",
      "EPOCH: 895 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 407.7394 - val_loss: 422.0143\n",
      "EPOCH: 896 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5203.0586 - val_loss: 5014.4834\n",
      "EPOCH: 897 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5434.0596 - val_loss: 5435.2417\n",
      "EPOCH: 898 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4144.5088 - val_loss: 4146.8306\n",
      "EPOCH: 899 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5400.8574 - val_loss: 5429.0742\n",
      "EPOCH: 900 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5444.0552 - val_loss: 5920.1304\n",
      "EPOCH: 901 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2052.1218 - val_loss: 2074.4373\n",
      "EPOCH: 902 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2651.6938 - val_loss: 2675.9602\n",
      "EPOCH: 903 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2293.0950 - val_loss: 2501.6169\n",
      "EPOCH: 904 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3325.9136 - val_loss: 3385.0190\n",
      "EPOCH: 905 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2860.1042 - val_loss: 2619.5688\n",
      "EPOCH: 906 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6151.6323 - val_loss: 6314.7158\n",
      "EPOCH: 907 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2405.2678 - val_loss: 2403.3535\n",
      "EPOCH: 908 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5930.4648 - val_loss: 5933.9438\n",
      "EPOCH: 909 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5167.3911 - val_loss: 6155.3477\n",
      "EPOCH: 910 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4216.6040 - val_loss: 4181.2998\n",
      "EPOCH: 911 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4272.3188 - val_loss: 4269.4526\n",
      "EPOCH: 912 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6023.5767 - val_loss: 6125.0078\n",
      "EPOCH: 913 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5346.8545 - val_loss: 4941.5068\n",
      "EPOCH: 914 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5282.2627 - val_loss: 5709.8228\n",
      "EPOCH: 915 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3252.8354 - val_loss: 3272.7849\n",
      "EPOCH: 916 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5729.9434 - val_loss: 5638.5073\n",
      "EPOCH: 917 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5619.4272 - val_loss: 5647.1685\n",
      "EPOCH: 918 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3982.5269 - val_loss: 4026.2827\n",
      "EPOCH: 919 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5569.9604 - val_loss: 5703.1353\n",
      "EPOCH: 920 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2415.9558 - val_loss: 1981.6807\n",
      "EPOCH: 921 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5878.1528 - val_loss: 6240.6108\n",
      "EPOCH: 922 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4878.4219 - val_loss: 5003.4897\n",
      "EPOCH: 923 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4938.0898 - val_loss: 5340.1929\n",
      "EPOCH: 924 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3533.9617 - val_loss: 3799.7275\n",
      "EPOCH: 925 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2261.4844 - val_loss: 2433.6892\n",
      "EPOCH: 926 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 854.9245 - val_loss: 853.4701\n",
      "EPOCH: 927 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5319.3491 - val_loss: 5269.9766\n",
      "EPOCH: 928 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3944.1558 - val_loss: 3840.5703\n",
      "EPOCH: 929 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3058.3840 - val_loss: 3499.3396\n",
      "EPOCH: 930 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2084.7534 - val_loss: 2165.1218\n",
      "EPOCH: 931 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 517.4293 - val_loss: 119.2466\n",
      "EPOCH: 932 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5322.3501 - val_loss: 5327.6743\n",
      "EPOCH: 933 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 822.1232 - val_loss: 48.5974\n",
      "EPOCH: 934 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5599.6709 - val_loss: 5591.3931\n",
      "EPOCH: 935 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5317.7280 - val_loss: 5318.8115\n",
      "EPOCH: 936 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3486.2466 - val_loss: 1945.4011\n",
      "EPOCH: 937 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3241.7747 - val_loss: 3367.1143\n",
      "EPOCH: 938 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3998.3301 - val_loss: 3939.7009\n",
      "EPOCH: 939 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5038.7227 - val_loss: 4677.7056\n",
      "EPOCH: 940 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5562.0762 - val_loss: 4445.7739\n",
      "EPOCH: 941 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4834.8540 - val_loss: 4962.2349\n",
      "EPOCH: 942 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4916.1167 - val_loss: 5010.0327\n",
      "EPOCH: 943 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3197.8330 - val_loss: 3217.6799\n",
      "EPOCH: 944 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5294.0435 - val_loss: 5290.7676\n",
      "EPOCH: 945 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3462.5847 - val_loss: 2620.3665\n",
      "EPOCH: 946 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 584.5077 - val_loss: 397.7001\n",
      "EPOCH: 947 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5284.6016 - val_loss: 5281.4497\n",
      "EPOCH: 948 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5281.4497 - val_loss: 5278.1436\n",
      "EPOCH: 949 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1799.5889 - val_loss: 1430.5483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 950 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1384.3975 - val_loss: 1513.8323\n",
      "EPOCH: 951 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3443.0767 - val_loss: 2914.5254\n",
      "EPOCH: 952 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5252.9907 - val_loss: 5318.8774\n",
      "EPOCH: 953 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5265.5952 - val_loss: 5262.2651\n",
      "EPOCH: 954 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 926.1655 - val_loss: 1001.1754\n",
      "EPOCH: 955 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5478.6978 - val_loss: 6134.7910\n",
      "EPOCH: 956 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4147.1235 - val_loss: 4144.2290\n",
      "EPOCH: 957 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3482.0269 - val_loss: 3797.7954\n",
      "EPOCH: 958 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3768.9438 - val_loss: 3766.9014\n",
      "EPOCH: 959 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4776.0322 - val_loss: 1502.1991\n",
      "EPOCH: 960 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2215.1416 - val_loss: 2478.9678\n",
      "EPOCH: 961 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5093.3750 - val_loss: 5840.7695\n",
      "EPOCH: 962 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4124.1045 - val_loss: 4122.3477\n",
      "EPOCH: 963 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5223.1475 - val_loss: 5288.8711\n",
      "EPOCH: 964 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4334.9795 - val_loss: 706.6979\n",
      "EPOCH: 965 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2667.6184 - val_loss: 564.4342\n",
      "EPOCH: 966 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4119.7373 - val_loss: 4117.0249\n",
      "EPOCH: 967 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5222.0933 - val_loss: 5218.8809\n",
      "EPOCH: 968 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3748.3613 - val_loss: 3746.2642\n",
      "EPOCH: 969 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5164.3550 - val_loss: 5154.8833\n",
      "EPOCH: 970 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6139.0103 - val_loss: 6173.4785\n",
      "EPOCH: 971 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4673.9917 - val_loss: 4644.6548\n",
      "EPOCH: 972 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3895.0168 - val_loss: 3923.2246\n",
      "EPOCH: 973 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3750.3423 - val_loss: 3932.0254\n",
      "EPOCH: 974 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1621.0430 - val_loss: 1175.3428\n",
      "EPOCH: 975 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3945.8096 - val_loss: 3954.3440\n",
      "EPOCH: 976 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4852.5059 - val_loss: 4347.8506\n",
      "EPOCH: 977 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3372.3308 - val_loss: 3370.0654\n",
      "EPOCH: 978 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2221.0105 - val_loss: 2221.4426\n",
      "EPOCH: 979 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4040.4204 - val_loss: 4097.9609\n",
      "EPOCH: 980 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5822.6445 - val_loss: 6114.9341\n",
      "EPOCH: 981 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3826.5291 - val_loss: 4703.3232\n",
      "EPOCH: 982 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4785.6714 - val_loss: 5236.3350\n",
      "EPOCH: 983 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3893.6365 - val_loss: 2534.7136\n",
      "EPOCH: 984 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4446.9458 - val_loss: 3567.4929\n",
      "EPOCH: 985 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5716.8682 - val_loss: 5762.4341\n",
      "EPOCH: 986 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5107.7666 - val_loss: 5131.8589\n",
      "EPOCH: 987 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4665.2861 - val_loss: 4886.1201\n",
      "EPOCH: 988 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4500.6807 - val_loss: 4937.5410\n",
      "EPOCH: 989 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1369.2291 - val_loss: 1165.4874\n",
      "EPOCH: 990 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1934.0583 - val_loss: 1937.9744\n",
      "EPOCH: 991 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3561.3125 - val_loss: 5945.2852\n",
      "EPOCH: 992 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2841.7656 - val_loss: 3054.1763\n",
      "EPOCH: 993 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1243.5244 - val_loss: 1404.4012\n",
      "EPOCH: 994 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 356.4973 - val_loss: 422.5778\n",
      "EPOCH: 995 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3521.2615 - val_loss: 5966.5679\n",
      "EPOCH: 996 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2317.3442 - val_loss: 2316.3853\n",
      "EPOCH: 997 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3482.0320 - val_loss: 3306.4570\n",
      "EPOCH: 998 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3388.3005 - val_loss: 3648.0376\n",
      "EPOCH: 999 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3903.6021 - val_loss: 4055.6235\n",
      "EPOCH: 1000 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5093.6880 - val_loss: 5135.7925\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "import random\n",
    "\n",
    "EPOCHS = 1000\n",
    "\n",
    "losses = []\n",
    "val_losses = []\n",
    "\n",
    "for a in range(EPOCHS):\n",
    "    \n",
    "    print('EPOCH: ' + str(a+1) +  ' OUT OF ' + str(EPOCHS))\n",
    "\n",
    "    rand_int = random.randint(0, 522)\n",
    "\n",
    "    values = list_of_training_df[rand_int].values\n",
    "\n",
    "    n_train_hours = 21\n",
    "    train = values[:n_train_hours, :]\n",
    "    test = values[n_train_hours:, :]\n",
    "\n",
    "    train_X, train_y = train[:, :-1], train[:, -1]\n",
    "    test_X, test_y = test[:, :-1], test[:, -1]\n",
    "\n",
    "    train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "    test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "    print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "\n",
    "    # fit network\n",
    "    history = lstm_model.fit(train_X, train_y, epochs=1, batch_size=21, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "\n",
    "    for idx, h in enumerate(history.history['loss']):\n",
    "        losses.append(h)\n",
    "        val_losses.append(history.history['val_loss'])\n",
    "        \n",
    "# plot history\n",
    "pyplot.plot(losses, label='train')\n",
    "pyplot.plot(val_losses, label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Based on the num_predictions we choose, we predict on that many random time series and derive a resulting root mean square error\n",
    "\n",
    "# The resulting prediction is sufficiency rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import concatenate\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "num_predictions = 500\n",
    "\n",
    "summation = 0\n",
    "\n",
    "actual = []\n",
    "predicted = []\n",
    "\n",
    "for a in range(num_predictions):\n",
    "    \n",
    "    rand_int = random.randint(0, 522)\n",
    "\n",
    "    values = list_of_training_df[rand_int].values\n",
    "\n",
    "    n_train_hours = 21\n",
    "    train = values[:n_train_hours, :]\n",
    "    test = values[n_train_hours:, :]\n",
    "\n",
    "    train_X, train_y = train[:, :-1], train[:, -1]\n",
    "    test_X, test_y = test[:, :-1], test[:, -1]\n",
    "\n",
    "    train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "    test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "#     print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "\n",
    "    yhat = lstm_model.predict(test_X)\n",
    "    \n",
    "    actual.append(test_y[0])\n",
    "    predicted.append(yhat[0][0][0])\n",
    "    \n",
    "#     print(yhat[0][0][0])\n",
    "#     print(test_y[0])\n",
    "    \n",
    "#     difference = test_y[0] - yhat[0][0][0]\n",
    "#     squared_difference = difference**2\n",
    "#     summation = summation + squared_difference\n",
    "    \n",
    "mse = mean_squared_error(actual, predicted)\n",
    "rmse = math.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.81395543331846"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21.331879,\n",
       " 21.331879,\n",
       " 28.135601,\n",
       " 22.39915,\n",
       " 24.369858,\n",
       " 24.369858,\n",
       " 28.13556,\n",
       " 22.398853,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 24.369858,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 28.45451,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 24.369858,\n",
       " 28.45451,\n",
       " 28.454514,\n",
       " 23.301289,\n",
       " 24.369858,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 25.309406,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 25.309387,\n",
       " 22.399147,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 28.13556,\n",
       " 23.354588,\n",
       " 28.13556,\n",
       " 21.331879,\n",
       " 28.13556,\n",
       " 21.331879,\n",
       " 22.399162,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 24.369858,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 19.276615,\n",
       " 21.331879,\n",
       " 28.13556,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 24.369858,\n",
       " 28.454514,\n",
       " 25.309422,\n",
       " 25.309422,\n",
       " 28.45451,\n",
       " 28.454514,\n",
       " 19.276615,\n",
       " 28.13556,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 28.13556,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 24.369858,\n",
       " 21.331879,\n",
       " 26.52538,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 25.659252,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 24.369858,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 23.354584,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 19.276615,\n",
       " 19.276615,\n",
       " 24.369858,\n",
       " 23.354584,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 25.309422,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 24.369858,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 22.398853,\n",
       " 24.369858,\n",
       " 24.369858,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 24.369858,\n",
       " 21.331879,\n",
       " 28.13556,\n",
       " 22.39915,\n",
       " 21.331879,\n",
       " 28.13556,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 24.369858,\n",
       " 24.369858,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 24.369858,\n",
       " 28.454514,\n",
       " 24.369858,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 25.309422,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 23.354588,\n",
       " 28.454514,\n",
       " 24.369858,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 24.369858,\n",
       " 24.369858,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 28.13556,\n",
       " 25.309422,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 24.369858,\n",
       " 21.332687,\n",
       " 28.13556,\n",
       " 28.454514,\n",
       " 28.13556,\n",
       " 28.13556,\n",
       " 24.369858,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 28.45451,\n",
       " 28.13556,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 24.369858,\n",
       " 28.454514,\n",
       " 28.13556,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 19.276615,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 28.13556,\n",
       " 28.454514,\n",
       " 28.13556,\n",
       " 21.331879,\n",
       " 28.13556,\n",
       " 28.454506,\n",
       " 28.13556,\n",
       " 22.398853,\n",
       " 28.454514,\n",
       " 21.333923,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 21.332687,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 24.758244,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 24.369858,\n",
       " 24.369858,\n",
       " 21.331879,\n",
       " 28.13556,\n",
       " 28.454514,\n",
       " 28.13556,\n",
       " 28.45451,\n",
       " 24.369858,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 24.614788,\n",
       " 21.331879,\n",
       " 28.397789,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 24.369858,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 28.13556,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 24.369858,\n",
       " 28.13556,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 25.659378,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 22.39915,\n",
       " 28.454514,\n",
       " 28.13556,\n",
       " 24.369858,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 28.13556,\n",
       " 23.354584,\n",
       " 21.331879,\n",
       " 28.13556,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 24.369858,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 25.309422,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 25.309406,\n",
       " 24.369858,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 23.35463,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 28.13556,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 24.369858,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 22.39915,\n",
       " 28.454514,\n",
       " 24.369858,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 24.614788,\n",
       " 19.276615,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 28.13556,\n",
       " 25.309422,\n",
       " 24.369858,\n",
       " 21.331879,\n",
       " 24.369858,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 24.369858,\n",
       " 23.354584,\n",
       " 21.331879,\n",
       " 24.739986,\n",
       " 21.331879,\n",
       " 28.13556,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 22.39915,\n",
       " 19.276615,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 24.369858,\n",
       " 19.276615,\n",
       " 28.454514,\n",
       " 28.13556,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 23.354584,\n",
       " 28.454514,\n",
       " 25.309422,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 28.13556,\n",
       " 21.331879,\n",
       " 28.13556,\n",
       " 24.739986,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 24.369858,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 25.309406,\n",
       " 21.331879,\n",
       " 21.33191,\n",
       " 28.454514,\n",
       " 28.397789,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 28.135601,\n",
       " 19.276615,\n",
       " 23.566975,\n",
       " 25.526234,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 24.369858,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 24.369858,\n",
       " 25.659378,\n",
       " 21.333923,\n",
       " 28.454514,\n",
       " 28.13556,\n",
       " 28.13556,\n",
       " 28.454514,\n",
       " 24.614788,\n",
       " 28.286968,\n",
       " 24.369858,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 25.309387,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 24.369858,\n",
       " 25.309422,\n",
       " 28.13556,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 24.369858,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 24.369858,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 25.526234,\n",
       " 21.331879,\n",
       " 28.13556,\n",
       " 22.399136,\n",
       " 24.369858,\n",
       " 28.454514,\n",
       " 22.399162,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 25.660477,\n",
       " 24.369858,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 25.659172,\n",
       " 21.331879,\n",
       " 28.13556,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 24.369858,\n",
       " 21.331879,\n",
       " 23.35463,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 28.13556,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 21.331879,\n",
       " 28.454514,\n",
       " 21.331879]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "\n",
    "df = read_csv('Time_Series_For_Clustering_El_Paso_Final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "non_decimal = re.compile(r'[^\\d.]+')\n",
    "\n",
    "list_of_training_df = []\n",
    "list_of_row_components = []\n",
    "\n",
    "for i in range(1, 524):\n",
    "    \n",
    "#     list_of_row_components = []\n",
    "    \n",
    "    current_row = df.iloc[i]\n",
    "    \n",
    "    bridge_id = current_row.iloc[0]\n",
    "    \n",
    "    current_row = current_row.iloc[1:]\n",
    "    \n",
    "#     print(bridge_id)\n",
    "#     print(current_row)\n",
    "    \n",
    "    for j, row in current_row.iteritems():\n",
    "        \n",
    "        current_row_components = row.split(', ')\n",
    "        current_row_components_replaced = []\n",
    "        \n",
    "#         current_row_components_replaced.append(bridge_id)\n",
    "\n",
    "        for idx, component in enumerate(current_row_components):\n",
    "\n",
    "            result = non_decimal.sub('', current_row_components[idx])\n",
    "#             print(result)\n",
    "            current_row_components_replaced.append(float(result))\n",
    "\n",
    "        list_of_row_components.append(current_row_components_replaced)\n",
    "\n",
    "# bridge_ids = []\n",
    "# var1 = []\n",
    "# var2 = []\n",
    "# var3 = []\n",
    "# var4 = []\n",
    "# var5 = []\n",
    "# var6 = []\n",
    "# varout = []\n",
    "\n",
    "# for element in list_of_row_components:\n",
    "\n",
    "#     bridge_ids.append(element[0])\n",
    "#     var1.append(float(element[1]))\n",
    "#     var2.append(float(element[2]))\n",
    "#     var3.append(float(element[3]))\n",
    "#     var4.append(float(element[5]))\n",
    "#     var5.append(float(element[6]))\n",
    "#     var6.append(float(element[7]))\n",
    "#     varout.append(float(element[2]))\n",
    "\n",
    "# # dict_temp = {'bridge_id':bridge_ids, 'var1': var1, 'var2': var2, 'var3': var3, 'var4': var4, 'var5': var5, 'var6': var6, 'varout': varout}\n",
    "# dict_temp = {'var1': var1, 'var2': var2, 'var3': var3, 'var4': var4, 'var5': var5, 'var6': var6, 'varout': varout}\n",
    "\n",
    "# df_temp = pd.DataFrame(dict_temp)\n",
    "\n",
    "# list_of_training_df.append(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, element in enumerate(list_of_row_components):\n",
    "    for i in range(1, len(element)):\n",
    "        list_of_row_components[idx][i] = float( list_of_row_components[idx][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[36.0, 97.0, 428.0, 1949.0, 2.0, 10.9, 7.3],\n",
       " [36.0, 96.9, 955.0, 1949.0, 2.0, 10.9, 7.3],\n",
       " [36.0, 96.9, 955.0, 1949.0, 2.0, 10.9, 7.3],\n",
       " [36.0, 96.9, 955.0, 1949.0, 2.0, 10.9, 7.3],\n",
       " [36.0, 96.9, 955.0, 1949.0, 2.0, 10.9, 7.3],\n",
       " [36.3, 97.0, 955.0, 1949.0, 2.0, 11.0, 7.0],\n",
       " [36.3, 96.9, 955.0, 1949.0, 2.0, 11.0, 7.3],\n",
       " [36.3, 96.9, 983.0, 1949.0, 2.0, 11.0, 7.3],\n",
       " [36.3, 96.9, 983.0, 1949.0, 2.0, 11.0, 7.3],\n",
       " [36.3, 96.9, 983.0, 1949.0, 2.0, 11.0, 7.3],\n",
       " [36.3, 96.9, 983.0, 1949.0, 2.0, 11.0, 7.3],\n",
       " [36.3, 97.0, 422.0, 1949.0, 2.0, 11.0, 7.3],\n",
       " [36.3, 97.0, 422.0, 1949.0, 2.0, 11.0, 7.3],\n",
       " [36.3, 97.0, 422.0, 1949.0, 2.0, 11.0, 7.3],\n",
       " [36.3, 97.0, 422.0, 1949.0, 2.0, 11.0, 7.3],\n",
       " [36.3, 97.0, 422.0, 1949.0, 2.0, 9.7, 7.3],\n",
       " [36.3, 97.0, 369.0, 1949.0, 2.0, 9.7, 7.3],\n",
       " [36.3, 86.0, 369.0, 1949.0, 2.0, 9.7, 7.3],\n",
       " [36.3, 86.0, 369.0, 1949.0, 2.0, 9.7, 7.3],\n",
       " [36.3, 86.0, 369.0, 1949.0, 2.0, 9.7, 7.3],\n",
       " [36.3, 86.0, 369.0, 1949.0, 2.0, 9.7, 7.3],\n",
       " [36.3, 86.0, 522.0, 1949.0, 2.0, 9.7, 7.3],\n",
       " [36.0, 83.9, 417.0, 1970.0, 2.0, 6.6, 6.4],\n",
       " [36.0, 70.9, 351.0, 1970.0, 2.0, 6.6, 3.0],\n",
       " [36.0, 70.9, 351.0, 1970.0, 2.0, 6.6, 3.0],\n",
       " [36.0, 70.9, 351.0, 1970.0, 2.0, 6.6, 3.0],\n",
       " [36.0, 70.9, 351.0, 1970.0, 2.0, 6.6, 3.0],\n",
       " [36.3, 76.0, 351.0, 1970.0, 2.0, 6.6, 3.0],\n",
       " [36.3, 69.0, 351.0, 1970.0, 2.0, 6.6, 3.0],\n",
       " [36.3, 66.9, 478.0, 1970.0, 2.0, 6.6, 2.9],\n",
       " [36.3, 66.9, 478.0, 1970.0, 2.0, 6.6, 2.9],\n",
       " [36.3, 66.9, 478.0, 1970.0, 2.0, 6.6, 2.9],\n",
       " [36.3, 66.9, 478.0, 1970.0, 2.0, 6.6, 2.9],\n",
       " [36.3, 62.9, 478.0, 1970.0, 2.0, 6.6, 2.9],\n",
       " [36.3, 62.9, 478.0, 1970.0, 2.0, 6.6, 2.9],\n",
       " [36.3, 62.9, 777.0, 1970.0, 2.0, 6.6, 2.9],\n",
       " [36.3, 62.9, 777.0, 1970.0, 2.0, 6.6, 2.9],\n",
       " [36.3, 62.9, 777.0, 1970.0, 2.0, 6.6, 2.9],\n",
       " [36.3, 62.9, 623.0, 1970.0, 2.0, 6.6, 2.9],\n",
       " [36.3, 62.9, 623.0, 1970.0, 2.0, 6.6, 2.9],\n",
       " [36.3, 62.9, 623.0, 1970.0, 2.0, 6.6, 2.9],\n",
       " [32.7, 55.7, 623.0, 1970.0, 2.0, 6.6, 2.9],\n",
       " [32.7, 55.7, 623.0, 1970.0, 2.0, 6.6, 2.9],\n",
       " [32.7, 55.7, 717.0, 1970.0, 2.0, 6.6, 2.9],\n",
       " [36.0, 82.0, 1836.0, 1955.0, 2.0, 7.6, 4.0],\n",
       " [36.0, 84.3, 1459.0, 1955.0, 2.0, 7.7, 4.0],\n",
       " [36.0, 84.3, 1459.0, 1955.0, 2.0, 7.7, 4.0],\n",
       " [36.0, 84.3, 1459.0, 1955.0, 2.0, 7.7, 4.0],\n",
       " [36.0, 84.3, 1459.0, 1955.0, 2.0, 7.7, 3.4],\n",
       " [36.3, 83.4, 1459.0, 1955.0, 2.0, 7.7, 3.0],\n",
       " [36.3, 84.3, 1459.0, 1955.0, 2.0, 7.7, 3.4],\n",
       " [36.3, 84.4, 1295.0, 1955.0, 2.0, 7.7, 3.4],\n",
       " [36.3, 84.4, 1295.0, 1955.0, 2.0, 7.7, 3.4],\n",
       " [36.3, 72.3, 1295.0, 1955.0, 2.0, 7.7, 3.4],\n",
       " [36.3, 72.3, 1295.0, 1955.0, 2.0, 7.7, 3.4],\n",
       " [36.3, 72.3, 1295.0, 1955.0, 2.0, 7.7, 3.4],\n",
       " [36.3, 72.3, 1295.0, 1955.0, 2.0, 7.7, 3.4],\n",
       " [36.3, 72.3, 1329.0, 1955.0, 2.0, 7.7, 3.4],\n",
       " [36.3, 72.3, 1329.0, 1955.0, 2.0, 7.7, 3.4],\n",
       " [36.3, 72.3, 1329.0, 1955.0, 2.0, 7.7, 3.4],\n",
       " [36.3, 72.3, 1446.0, 1955.0, 2.0, 7.7, 3.4],\n",
       " [36.3, 72.3, 1446.0, 1955.0, 2.0, 7.7, 3.4],\n",
       " [36.3, 72.3, 1446.0, 1955.0, 2.0, 7.7, 3.4],\n",
       " [27.2, 50.2, 1446.0, 1955.0, 2.0, 7.7, 3.4],\n",
       " [27.2, 50.2, 1446.0, 1955.0, 2.0, 7.7, 3.4],\n",
       " [27.2, 50.2, 2696.0, 1955.0, 2.0, 7.7, 3.4],\n",
       " [36.0, 97.0, 87.0, 1984.0, 2.0, 12.8, 3.0],\n",
       " [36.0, 97.0, 305.0, 1984.0, 2.0, 12.8, 3.0],\n",
       " [36.0, 97.0, 305.0, 1984.0, 2.0, 12.8, 3.0],\n",
       " [36.0, 97.0, 305.0, 1984.0, 2.0, 12.8, 3.0],\n",
       " [36.0, 97.0, 305.0, 1984.0, 2.0, 12.8, 3.0],\n",
       " [36.3, 97.0, 305.0, 1984.0, 2.0, 12.8, 3.0],\n",
       " [36.3, 97.0, 305.0, 1984.0, 2.0, 12.8, 3.0],\n",
       " [36.3, 97.0, 397.0, 1984.0, 2.0, 12.8, 3.0],\n",
       " [36.3, 97.0, 397.0, 1984.0, 2.0, 12.8, 3.0],\n",
       " [36.3, 97.0, 397.0, 1984.0, 2.0, 12.8, 3.0],\n",
       " [36.3, 97.0, 397.0, 1984.0, 2.0, 12.8, 3.0],\n",
       " [36.3, 98.0, 397.0, 1984.0, 2.0, 13.3, 3.0],\n",
       " [36.3, 98.0, 397.0, 1984.0, 2.0, 13.3, 3.0],\n",
       " [36.3, 98.0, 287.0, 1984.0, 2.0, 13.3, 3.0],\n",
       " [36.3, 98.0, 287.0, 1984.0, 2.0, 13.3, 3.0],\n",
       " [36.3, 99.0, 287.0, 1984.0, 2.0, 12.8, 3.0],\n",
       " [36.3, 99.0, 302.0, 1984.0, 2.0, 12.8, 3.0],\n",
       " [36.3, 100.0, 302.0, 1984.0, 2.0, 12.8, 3.0],\n",
       " [36.3, 100.0, 302.0, 1984.0, 2.0, 12.8, 3.0],\n",
       " [36.3, 100.0, 302.0, 1984.0, 2.0, 12.8, 3.0],\n",
       " [36.3, 100.0, 302.0, 1984.0, 2.0, 12.8, 3.0],\n",
       " [36.3, 100.0, 268.0, 1984.0, 2.0, 12.8, 3.0],\n",
       " [67.5, 80.1, 16737.0, 1960.0, 12.0, 18.5, 7.6],\n",
       " [36.0, 80.5, 13460.0, 1960.0, 12.0, 18.5, 7.6],\n",
       " [36.0, 80.5, 13460.0, 1960.0, 12.0, 18.5, 7.6],\n",
       " [36.0, 80.5, 13460.0, 1960.0, 12.0, 18.5, 7.6],\n",
       " [36.0, 80.5, 13460.0, 1960.0, 12.0, 18.5, 7.6],\n",
       " [36.3, 81.2, 13460.0, 1960.0, 12.0, 18.6, 7.6],\n",
       " [36.3, 80.5, 13460.0, 1960.0, 12.0, 18.6, 7.6],\n",
       " [36.3, 80.3, 15229.0, 1960.0, 12.0, 18.6, 7.6],\n",
       " [36.3, 80.3, 15229.0, 1960.0, 12.0, 18.6, 7.6],\n",
       " [36.3, 68.9, 15229.0, 1960.0, 12.0, 18.6, 7.6],\n",
       " [36.3, 68.9, 15229.0, 1960.0, 12.0, 18.6, 7.6],\n",
       " [36.3, 68.9, 15229.0, 1960.0, 12.0, 18.6, 7.6],\n",
       " [36.3, 68.9, 15229.0, 1960.0, 12.0, 18.6, 7.6],\n",
       " [36.3, 68.8, 16000.0, 1960.0, 12.0, 18.6, 7.6],\n",
       " [36.3, 68.8, 16000.0, 1960.0, 12.0, 18.6, 7.6],\n",
       " [36.3, 68.8, 16000.0, 1960.0, 12.0, 18.6, 7.6],\n",
       " [36.3, 70.9, 664.0, 1960.0, 12.0, 18.6, 7.6],\n",
       " [36.3, 70.9, 664.0, 1960.0, 12.0, 18.6, 7.6],\n",
       " [36.3, 70.9, 664.0, 1960.0, 12.0, 18.6, 7.6],\n",
       " [36.3, 70.9, 664.0, 1960.0, 12.0, 18.6, 7.6],\n",
       " [36.3, 70.9, 664.0, 1960.0, 12.0, 18.6, 7.6],\n",
       " [99.9, 70.9, 14775.0, 1960.0, 12.0, 18.6, 7.6],\n",
       " [36.0, 96.8, 2289.0, 1955.0, 2.0, 12.1, 3.7],\n",
       " [36.0, 85.7, 3236.0, 1955.0, 2.0, 12.1, 3.7],\n",
       " [36.0, 85.7, 3236.0, 1955.0, 2.0, 12.1, 3.7],\n",
       " [36.0, 85.7, 3236.0, 1955.0, 2.0, 12.1, 3.7],\n",
       " [36.0, 85.7, 3236.0, 1955.0, 2.0, 12.1, 2.7],\n",
       " [36.3, 96.9, 3236.0, 1955.0, 2.0, 12.2, 3.0],\n",
       " [36.3, 85.7, 3236.0, 1955.0, 2.0, 12.2, 3.4],\n",
       " [36.3, 69.6, 2810.0, 1955.0, 2.0, 12.2, 3.4],\n",
       " [36.3, 69.6, 2810.0, 1955.0, 2.0, 12.2, 3.4],\n",
       " [36.3, 87.7, 2810.0, 1955.0, 2.0, 12.2, 3.4],\n",
       " [36.3, 87.7, 2810.0, 1955.0, 2.0, 12.2, 3.4],\n",
       " [36.3, 87.7, 2810.0, 1955.0, 2.0, 12.2, 3.4],\n",
       " [36.3, 87.7, 2810.0, 1955.0, 2.0, 12.2, 3.4],\n",
       " [36.3, 71.7, 2355.0, 1955.0, 2.0, 12.2, 3.4],\n",
       " [36.3, 71.7, 2355.0, 1955.0, 2.0, 12.2, 3.4],\n",
       " [36.3, 71.7, 2355.0, 1955.0, 2.0, 12.2, 3.4],\n",
       " [36.3, 71.7, 2019.0, 1955.0, 2.0, 12.2, 3.4],\n",
       " [36.3, 71.7, 2019.0, 1955.0, 2.0, 12.2, 3.4],\n",
       " [36.3, 71.7, 2019.0, 1955.0, 2.0, 12.2, 3.4],\n",
       " [36.3, 71.7, 2019.0, 1955.0, 2.0, 12.2, 3.4],\n",
       " [36.3, 71.7, 2019.0, 1955.0, 2.0, 12.2, 3.4],\n",
       " [39.1, 71.7, 727.0, 1955.0, 2.0, 12.2, 3.4],\n",
       " [36.0, 81.1, 8323.0, 1955.0, 4.0, 20.4, 2.7],\n",
       " [36.0, 96.3, 7809.0, 1955.0, 2.0, 20.4, 2.7],\n",
       " [36.0, 96.3, 7809.0, 1955.0, 2.0, 20.4, 2.7],\n",
       " [36.0, 96.3, 7809.0, 1955.0, 2.0, 20.4, 2.7],\n",
       " [36.0, 96.3, 7809.0, 1955.0, 2.0, 20.4, 2.7],\n",
       " [36.3, 96.6, 7809.0, 1955.0, 2.0, 20.4, 3.0],\n",
       " [36.3, 96.3, 7809.0, 1955.0, 2.0, 20.4, 2.7],\n",
       " [36.3, 95.9, 11303.0, 1955.0, 2.0, 20.4, 2.7],\n",
       " [36.3, 95.9, 11303.0, 1955.0, 2.0, 20.4, 2.7],\n",
       " [36.3, 97.9, 11303.0, 1955.0, 2.0, 20.4, 2.7],\n",
       " [36.3, 97.9, 11303.0, 1955.0, 2.0, 20.4, 2.7],\n",
       " [36.3, 97.9, 11303.0, 1955.0, 2.0, 20.4, 2.7],\n",
       " [36.3, 97.9, 11303.0, 1955.0, 2.0, 20.4, 2.7],\n",
       " [36.3, 98.0, 10629.0, 1955.0, 2.0, 20.4, 2.7],\n",
       " [36.3, 98.0, 10629.0, 1955.0, 2.0, 20.4, 2.7],\n",
       " [36.3, 98.0, 10629.0, 1955.0, 2.0, 20.4, 2.7],\n",
       " [36.3, 98.9, 954.0, 1955.0, 2.0, 20.4, 2.7],\n",
       " [36.3, 98.9, 954.0, 1955.0, 2.0, 20.4, 2.7],\n",
       " [36.3, 98.9, 954.0, 1955.0, 2.0, 20.4, 2.7],\n",
       " [36.3, 98.9, 954.0, 1955.0, 2.0, 20.4, 2.7],\n",
       " [36.3, 98.9, 954.0, 1955.0, 2.0, 20.4, 2.7],\n",
       " [99.9, 98.9, 16371.0, 1955.0, 2.0, 20.4, 2.7],\n",
       " [36.0, 96.9, 660.0, 1970.0, 2.0, 11.2, 2.4],\n",
       " [36.0, 96.9, 950.0, 1970.0, 2.0, 11.1, 2.4],\n",
       " [36.0, 96.9, 950.0, 1970.0, 2.0, 11.1, 2.4],\n",
       " [36.0, 96.9, 950.0, 1970.0, 2.0, 11.1, 2.4],\n",
       " [36.0, 96.9, 950.0, 1970.0, 2.0, 11.1, 2.4],\n",
       " [36.3, 97.0, 950.0, 1970.0, 2.0, 11.1, 2.0],\n",
       " [36.3, 96.9, 950.0, 1970.0, 2.0, 11.1, 2.4],\n",
       " [36.3, 96.9, 700.0, 1970.0, 2.0, 11.1, 2.0],\n",
       " [36.3, 96.9, 700.0, 1970.0, 2.0, 11.1, 2.0],\n",
       " [36.3, 85.9, 700.0, 1970.0, 2.0, 11.1, 2.6],\n",
       " [36.3, 85.9, 700.0, 1970.0, 2.0, 11.1, 2.6],\n",
       " [36.3, 85.9, 700.0, 1970.0, 2.0, 11.1, 2.6],\n",
       " [36.3, 85.9, 700.0, 1970.0, 2.0, 11.1, 2.6],\n",
       " [36.3, 85.9, 780.0, 1970.0, 2.0, 11.1, 2.6],\n",
       " [36.3, 85.9, 780.0, 1970.0, 2.0, 11.1, 2.6],\n",
       " [36.3, 87.9, 780.0, 1970.0, 2.0, 11.1, 2.6],\n",
       " [36.3, 87.9, 771.0, 1970.0, 2.0, 11.1, 2.6],\n",
       " [36.3, 87.9, 771.0, 1970.0, 2.0, 11.1, 2.6],\n",
       " [36.3, 87.9, 771.0, 1970.0, 2.0, 11.1, 2.6],\n",
       " [27.2, 65.9, 771.0, 1970.0, 2.0, 11.1, 2.6],\n",
       " [27.2, 65.9, 771.0, 1970.0, 2.0, 11.1, 2.6],\n",
       " [27.2, 65.9, 391.0, 1970.0, 2.0, 11.1, 2.6],\n",
       " [36.0, 79.6, 3698.0, 1964.0, 2.0, 8.5, 9.4],\n",
       " [36.0, 79.4, 4746.0, 1964.0, 2.0, 8.5, 9.4],\n",
       " [36.0, 79.4, 4746.0, 1964.0, 2.0, 8.5, 9.4],\n",
       " [36.0, 79.4, 4746.0, 1964.0, 2.0, 8.5, 9.4],\n",
       " [36.0, 79.4, 4746.0, 1964.0, 2.0, 8.5, 8.8],\n",
       " [36.3, 79.7, 4746.0, 1964.0, 2.0, 8.5, 9.0],\n",
       " [36.3, 79.4, 4746.0, 1964.0, 2.0, 8.5, 8.8],\n",
       " [36.3, 79.5, 4701.0, 1964.0, 2.0, 8.5, 8.9],\n",
       " [36.3, 79.5, 4701.0, 1964.0, 2.0, 8.5, 8.9],\n",
       " [36.3, 68.3, 4701.0, 1964.0, 2.0, 8.5, 8.9],\n",
       " [36.3, 68.3, 4701.0, 1964.0, 2.0, 8.5, 8.9],\n",
       " [36.3, 68.3, 4701.0, 1964.0, 2.0, 8.5, 8.9],\n",
       " [36.3, 68.3, 4701.0, 1964.0, 2.0, 8.5, 8.9],\n",
       " [36.3, 79.5, 4409.0, 1964.0, 2.0, 8.5, 8.9],\n",
       " [36.3, 79.5, 4409.0, 1964.0, 2.0, 8.5, 8.9],\n",
       " [36.3, 79.5, 4409.0, 1964.0, 2.0, 8.5, 8.9],\n",
       " [36.3, 79.5, 4240.0, 1964.0, 2.0, 8.5, 8.9],\n",
       " [36.3, 79.5, 4240.0, 1964.0, 2.0, 8.5, 8.9],\n",
       " [36.3, 79.5, 4240.0, 1964.0, 2.0, 8.5, 8.9],\n",
       " [36.3, 79.5, 4240.0, 1964.0, 2.0, 8.5, 8.9],\n",
       " [36.3, 79.5, 4240.0, 1964.0, 2.0, 8.5, 8.9],\n",
       " [36.3, 79.5, 4811.0, 1964.0, 2.0, 8.5, 8.9],\n",
       " [36.0, 83.3, 1927.0, 1984.0, 5.0, 18.2, 3.7],\n",
       " [36.0, 98.5, 5329.0, 1984.0, 3.0, 18.2, 3.7],\n",
       " [36.0, 98.5, 5329.0, 1984.0, 3.0, 18.2, 3.7],\n",
       " [36.0, 98.5, 5329.0, 1984.0, 3.0, 18.2, 3.7],\n",
       " [36.0, 95.5, 5329.0, 1984.0, 3.0, 18.2, 3.7],\n",
       " [36.3, 98.8, 5329.0, 1984.0, 3.0, 18.3, 4.0],\n",
       " [36.3, 96.5, 5329.0, 1984.0, 3.0, 18.3, 3.7],\n",
       " [36.3, 98.6, 4606.0, 1984.0, 3.0, 18.3, 4.0],\n",
       " [36.3, 98.6, 4606.0, 1984.0, 3.0, 18.3, 4.0],\n",
       " [36.3, 96.6, 4606.0, 1984.0, 3.0, 18.3, 3.7],\n",
       " [36.3, 96.6, 4606.0, 1984.0, 3.0, 18.3, 3.7],\n",
       " [36.3, 96.6, 4606.0, 1984.0, 3.0, 18.3, 3.7],\n",
       " [36.3, 96.6, 4606.0, 1984.0, 3.0, 18.3, 3.7],\n",
       " [36.3, 96.4, 6021.0, 1984.0, 3.0, 18.3, 3.7],\n",
       " [36.3, 96.4, 6021.0, 1984.0, 3.0, 18.3, 3.7],\n",
       " [36.3, 96.4, 6021.0, 1984.0, 3.0, 18.3, 3.7],\n",
       " [36.3, 96.6, 4478.0, 1984.0, 3.0, 18.3, 3.7],\n",
       " [36.3, 97.6, 4478.0, 1984.0, 3.0, 18.3, 3.7],\n",
       " [36.3, 97.6, 4478.0, 1984.0, 3.0, 18.3, 3.7],\n",
       " [36.3, 97.6, 4478.0, 1984.0, 3.0, 18.3, 3.7],\n",
       " [36.3, 97.6, 4478.0, 1984.0, 3.0, 18.3, 3.7],\n",
       " [36.3, 97.6, 3890.0, 1984.0, 3.0, 18.3, 3.7],\n",
       " [31.5, 49.7, 560.0, 1915.0, 2.0, 5.9, 9.8],\n",
       " [31.5, 48.8, 147.0, 1915.0, 2.0, 5.9, 9.8],\n",
       " [31.5, 48.8, 147.0, 1915.0, 2.0, 5.9, 9.8],\n",
       " [31.5, 48.8, 147.0, 1915.0, 2.0, 5.9, 9.8],\n",
       " [31.5, 48.8, 147.0, 1915.0, 2.0, 5.9, 9.1],\n",
       " [31.7, 47.0, 147.0, 1915.0, 2.0, 5.9, 9.0],\n",
       " [31.8, 49.0, 147.0, 1915.0, 2.0, 5.9, 9.1],\n",
       " [32.3, 49.4, 988.0, 1915.0, 2.0, 5.9, 9.0],\n",
       " [32.3, 49.4, 988.0, 1915.0, 2.0, 5.9, 9.0],\n",
       " [32.3, 51.4, 988.0, 1915.0, 2.0, 5.9, 9.0],\n",
       " [32.3, 51.4, 988.0, 1915.0, 2.0, 5.9, 9.0],\n",
       " [32.3, 51.4, 988.0, 1915.0, 2.0, 5.9, 9.0],\n",
       " [32.3, 51.4, 988.0, 1915.0, 2.0, 5.9, 9.0],\n",
       " [32.3, 51.5, 385.0, 1915.0, 2.0, 5.9, 9.0],\n",
       " [32.3, 51.5, 385.0, 1915.0, 2.0, 5.9, 9.0],\n",
       " [32.3, 51.5, 385.0, 1915.0, 2.0, 5.9, 9.0],\n",
       " [32.3, 51.5, 349.0, 1915.0, 2.0, 5.9, 9.0],\n",
       " [32.3, 51.5, 349.0, 1915.0, 2.0, 5.9, 9.0],\n",
       " [32.3, 51.5, 349.0, 1915.0, 2.0, 5.9, 9.0],\n",
       " [32.3, 49.5, 349.0, 1915.0, 2.0, 5.9, 9.0],\n",
       " [32.3, 49.5, 349.0, 1915.0, 2.0, 5.9, 9.0],\n",
       " [32.3, 49.5, 433.0, 1915.0, 2.0, 5.9, 9.0],\n",
       " [46.8, 77.7, 10205.0, 1984.0, 5.0, 29.4, 3.0],\n",
       " [46.8, 77.0, 15983.0, 1984.0, 5.0, 99.9, 3.0],\n",
       " [46.8, 77.0, 15983.0, 1984.0, 5.0, 99.9, 3.0],\n",
       " [46.8, 77.0, 15983.0, 1984.0, 5.0, 99.9, 3.0],\n",
       " [46.8, 77.0, 15983.0, 1984.0, 5.0, 99.9, 3.0],\n",
       " [47.2, 78.2, 15983.0, 1984.0, 5.0, 30.5, 3.0],\n",
       " [47.2, 77.2, 15983.0, 1984.0, 5.0, 30.5, 3.0],\n",
       " [47.4, 77.8, 13807.0, 1984.0, 5.0, 30.5, 3.0],\n",
       " [47.4, 77.8, 13807.0, 1984.0, 5.0, 30.5, 3.0],\n",
       " [47.4, 77.8, 13807.0, 1984.0, 5.0, 18.0, 3.0],\n",
       " [47.4, 77.8, 13807.0, 1984.0, 5.0, 18.0, 3.0],\n",
       " [47.4, 78.1, 11436.0, 1984.0, 5.0, 18.0, 3.0],\n",
       " [47.4, 78.1, 11436.0, 1984.0, 5.0, 18.0, 3.0],\n",
       " [47.4, 78.1, 11436.0, 1984.0, 5.0, 18.0, 3.0],\n",
       " [47.4, 78.1, 11436.0, 1984.0, 5.0, 18.0, 3.0],\n",
       " [47.4, 78.1, 11436.0, 1984.0, 5.0, 18.0, 3.0],\n",
       " [47.4, 77.6, 15597.0, 1984.0, 5.0, 18.0, 3.0],\n",
       " [47.4, 77.6, 15597.0, 1984.0, 5.0, 18.0, 3.0],\n",
       " [47.4, 77.6, 15597.0, 1984.0, 5.0, 18.0, 3.0],\n",
       " [47.4, 66.2, 15597.0, 1984.0, 5.0, 18.0, 3.0],\n",
       " [47.4, 66.2, 15597.0, 1984.0, 5.0, 18.0, 3.0],\n",
       " [47.4, 66.2, 15009.0, 1984.0, 5.0, 18.0, 3.0],\n",
       " [36.0, 65.5, 567.0, 1925.0, 2.0, 5.9, 4.9],\n",
       " [36.0, 65.5, 691.0, 1925.0, 2.0, 6.0, 4.9],\n",
       " [36.0, 65.5, 691.0, 1925.0, 2.0, 6.0, 4.9],\n",
       " [36.0, 65.5, 691.0, 1925.0, 2.0, 6.0, 4.9],\n",
       " [36.0, 65.5, 691.0, 1925.0, 2.0, 6.0, 4.6],\n",
       " [16.3, 30.2, 691.0, 1925.0, 2.0, 6.0, 5.0],\n",
       " [16.3, 30.0, 691.0, 1925.0, 2.0, 6.0, 4.6],\n",
       " [16.4, 31.8, 574.0, 1925.0, 2.0, 6.0, 4.5],\n",
       " [16.4, 31.8, 574.0, 1925.0, 2.0, 6.0, 4.5],\n",
       " [16.4, 21.4, 574.0, 1925.0, 2.0, 6.0, 4.5],\n",
       " [16.4, 21.4, 574.0, 1925.0, 2.0, 6.0, 4.5],\n",
       " [16.4, 21.4, 574.0, 1925.0, 2.0, 6.0, 4.5],\n",
       " [16.4, 21.4, 574.0, 1925.0, 2.0, 6.0, 4.5],\n",
       " [16.4, 21.2, 710.0, 1925.0, 2.0, 6.0, 4.5],\n",
       " [16.4, 21.2, 710.0, 1925.0, 2.0, 6.0, 4.5],\n",
       " [16.4, 21.2, 710.0, 1925.0, 2.0, 6.0, 4.5],\n",
       " [16.4, 21.1, 830.0, 1925.0, 2.0, 6.0, 4.5],\n",
       " [16.4, 21.1, 830.0, 1925.0, 2.0, 6.0, 4.7],\n",
       " [16.4, 21.1, 830.0, 1925.0, 2.0, 6.0, 4.7],\n",
       " [16.4, 19.9, 830.0, 1925.0, 2.0, 6.0, 4.7],\n",
       " [16.4, 19.9, 830.0, 1925.0, 2.0, 6.0, 4.7],\n",
       " [16.4, 19.9, 830.0, 1925.0, 2.0, 6.0, 4.7],\n",
       " [36.0, 95.2, 7543.0, 1984.0, 2.0, 29.8, 4.0],\n",
       " [36.0, 97.6, 10181.0, 1984.0, 2.0, 10.2, 4.0],\n",
       " [36.0, 97.6, 10181.0, 1984.0, 2.0, 10.2, 4.0],\n",
       " [36.0, 97.6, 10181.0, 1984.0, 2.0, 10.2, 4.0],\n",
       " [36.0, 97.6, 10181.0, 1984.0, 4.0, 10.5, 4.0],\n",
       " [36.3, 96.5, 10181.0, 1984.0, 4.0, 10.5, 4.0],\n",
       " [36.3, 99.1, 10181.0, 1984.0, 4.0, 10.5, 4.0],\n",
       " [36.3, 95.8, 12723.0, 1984.0, 4.0, 10.5, 4.0],\n",
       " [36.3, 95.8, 12723.0, 1984.0, 4.0, 10.5, 4.0],\n",
       " [36.3, 98.8, 12723.0, 1984.0, 4.0, 10.2, 4.1],\n",
       " [36.3, 98.8, 12723.0, 1984.0, 4.0, 10.2, 4.1],\n",
       " [36.3, 98.8, 12723.0, 1984.0, 4.0, 10.2, 4.1],\n",
       " [36.3, 98.8, 12723.0, 1984.0, 4.0, 10.2, 4.1],\n",
       " [36.3, 99.1, 10146.0, 1984.0, 4.0, 10.2, 4.1],\n",
       " [36.3, 99.1, 10146.0, 1984.0, 4.0, 10.2, 4.1],\n",
       " [36.3, 99.1, 10146.0, 1984.0, 4.0, 10.2, 4.1],\n",
       " [36.3, 99.0, 10431.0, 1984.0, 4.0, 10.2, 4.1],\n",
       " [36.3, 99.0, 10431.0, 1984.0, 4.0, 10.2, 4.1],\n",
       " [36.3, 99.0, 10431.0, 1984.0, 4.0, 10.2, 4.1],\n",
       " [36.3, 99.0, 10431.0, 1984.0, 4.0, 10.2, 4.1],\n",
       " [36.3, 99.0, 10431.0, 1984.0, 4.0, 10.2, 4.1],\n",
       " [36.3, 99.0, 9717.0, 1984.0, 4.0, 10.2, 4.1],\n",
       " [31.5, 79.9, 10.0, 1984.0, 2.0, 10.6, 4.6],\n",
       " [31.5, 79.8, 626.0, 1984.0, 2.0, 10.6, 4.6],\n",
       " [31.5, 79.8, 626.0, 1984.0, 2.0, 10.6, 4.6],\n",
       " [31.5, 79.8, 626.0, 1984.0, 2.0, 10.6, 4.6],\n",
       " [31.5, 79.8, 626.0, 1984.0, 2.0, 10.6, 4.6],\n",
       " [31.7, 80.0, 626.0, 1984.0, 2.0, 10.6, 5.0],\n",
       " [31.8, 80.0, 626.0, 1984.0, 2.0, 10.6, 4.6],\n",
       " [32.1, 80.3, 537.0, 1984.0, 2.0, 10.6, 4.5],\n",
       " [32.1, 80.3, 537.0, 1984.0, 2.0, 10.6, 4.5],\n",
       " [32.1, 80.3, 537.0, 1984.0, 2.0, 10.6, 4.5],\n",
       " [32.1, 80.3, 537.0, 1984.0, 2.0, 10.6, 4.5],\n",
       " [32.1, 80.3, 537.0, 1984.0, 2.0, 10.6, 4.5],\n",
       " [32.1, 80.3, 537.0, 1984.0, 2.0, 10.6, 4.5],\n",
       " [32.1, 81.3, 532.0, 1984.0, 2.0, 10.6, 4.5],\n",
       " [32.1, 81.3, 532.0, 1984.0, 2.0, 10.6, 4.5],\n",
       " [32.1, 81.3, 532.0, 1984.0, 2.0, 10.6, 4.5],\n",
       " [32.1, 81.3, 481.0, 1984.0, 2.0, 10.6, 4.5],\n",
       " [32.1, 81.3, 481.0, 1984.0, 2.0, 10.6, 4.5],\n",
       " [32.1, 81.3, 481.0, 1984.0, 2.0, 10.6, 4.5],\n",
       " [32.1, 81.3, 481.0, 1984.0, 2.0, 10.6, 4.5],\n",
       " [32.1, 81.3, 481.0, 1984.0, 2.0, 10.6, 4.5],\n",
       " [32.1, 81.3, 424.0, 1984.0, 2.0, 10.6, 4.5],\n",
       " [37.8, 86.9, 10.0, 1984.0, 2.0, 10.3, 4.6],\n",
       " [37.8, 86.8, 304.0, 1984.0, 2.0, 10.3, 4.3],\n",
       " [37.8, 86.8, 304.0, 1984.0, 2.0, 10.3, 4.3],\n",
       " [37.8, 86.8, 304.0, 1984.0, 2.0, 10.3, 4.3],\n",
       " [37.8, 86.8, 304.0, 1984.0, 2.0, 10.3, 4.3],\n",
       " [38.1, 87.2, 304.0, 1984.0, 2.0, 10.4, 4.0],\n",
       " [38.1, 87.1, 304.0, 1984.0, 2.0, 10.4, 4.3],\n",
       " [38.4, 87.6, 287.0, 1984.0, 2.0, 10.4, 4.3],\n",
       " [38.4, 87.6, 287.0, 1984.0, 2.0, 10.4, 4.3],\n",
       " [38.4, 90.6, 287.0, 1984.0, 2.0, 10.4, 4.3],\n",
       " [38.4, 90.6, 287.0, 1984.0, 2.0, 10.4, 4.3],\n",
       " [38.4, 90.6, 287.0, 1984.0, 2.0, 10.4, 4.3],\n",
       " [38.4, 90.6, 287.0, 1984.0, 2.0, 10.4, 4.3],\n",
       " [38.4, 90.6, 283.0, 1984.0, 2.0, 10.4, 4.3],\n",
       " [38.4, 90.6, 283.0, 1984.0, 2.0, 10.4, 4.3],\n",
       " [38.4, 90.6, 283.0, 1984.0, 2.0, 10.4, 4.3],\n",
       " [38.4, 90.6, 329.0, 1984.0, 2.0, 10.4, 4.3],\n",
       " [38.4, 90.6, 329.0, 1984.0, 2.0, 10.4, 4.3],\n",
       " [38.4, 90.6, 329.0, 1984.0, 2.0, 10.4, 4.3],\n",
       " [38.4, 90.6, 329.0, 1984.0, 2.0, 10.4, 4.3],\n",
       " [38.4, 90.6, 329.0, 1984.0, 2.0, 10.4, 4.3],\n",
       " [38.4, 90.6, 260.0, 1984.0, 2.0, 10.4, 4.3],\n",
       " [36.0, 91.1, 100.0, 1984.0, 2.0, 14.6, 3.7],\n",
       " [36.0, 77.0, 1842.0, 1984.0, 2.0, 14.6, 3.7],\n",
       " [36.0, 77.0, 1842.0, 1984.0, 2.0, 14.6, 3.7],\n",
       " [36.0, 77.0, 1842.0, 1984.0, 2.0, 14.6, 3.7],\n",
       " [36.0, 77.0, 1842.0, 1984.0, 2.0, 14.6, 3.7],\n",
       " [36.3, 87.6, 1842.0, 1984.0, 2.0, 14.6, 4.0],\n",
       " [36.3, 78.3, 1842.0, 1984.0, 2.0, 14.6, 3.7],\n",
       " [36.3, 79.6, 1670.0, 1984.0, 2.0, 14.6, 3.7],\n",
       " [36.3, 79.6, 1670.0, 1984.0, 2.0, 14.6, 3.7],\n",
       " [36.3, 79.6, 1670.0, 1984.0, 2.0, 14.6, 3.7],\n",
       " [36.3, 79.6, 1670.0, 1984.0, 2.0, 14.6, 3.7],\n",
       " [36.3, 79.6, 1670.0, 1984.0, 2.0, 14.6, 3.7],\n",
       " [36.3, 79.6, 1670.0, 1984.0, 2.0, 14.6, 3.7],\n",
       " [36.3, 79.6, 1670.0, 1984.0, 2.0, 14.6, 3.7],\n",
       " [36.3, 79.6, 1670.0, 1984.0, 2.0, 14.6, 3.7],\n",
       " [36.3, 79.6, 1670.0, 1984.0, 2.0, 14.6, 3.7],\n",
       " [36.3, 77.0, 2209.0, 1984.0, 2.0, 14.6, 3.7],\n",
       " [36.3, 77.0, 2209.0, 1984.0, 2.0, 14.6, 3.7],\n",
       " [36.3, 77.0, 2209.0, 1984.0, 2.0, 14.6, 3.7],\n",
       " [32.7, 58.8, 2209.0, 1984.0, 2.0, 14.6, 3.7],\n",
       " [32.7, 58.8, 2209.0, 1984.0, 2.0, 14.6, 3.7],\n",
       " [32.7, 58.8, 411.0, 1984.0, 2.0, 14.6, 3.7],\n",
       " [36.0, 96.9, 582.0, 1984.0, 2.0, 10.3, 3.0],\n",
       " [36.0, 96.9, 741.0, 1984.0, 2.0, 10.3, 3.0],\n",
       " [36.0, 96.9, 741.0, 1984.0, 2.0, 10.3, 3.0],\n",
       " [36.0, 96.9, 741.0, 1984.0, 2.0, 10.3, 3.0],\n",
       " [36.0, 96.9, 741.0, 1984.0, 2.0, 10.3, 3.0],\n",
       " [36.3, 97.0, 741.0, 1984.0, 2.0, 10.4, 3.0],\n",
       " [36.3, 96.9, 741.0, 1984.0, 2.0, 10.4, 3.0],\n",
       " [36.3, 96.9, 710.0, 1984.0, 2.0, 10.4, 3.0],\n",
       " [36.3, 96.9, 710.0, 1984.0, 2.0, 10.4, 3.0],\n",
       " [36.3, 96.9, 710.0, 1984.0, 2.0, 10.4, 3.0],\n",
       " [36.3, 96.9, 710.0, 1984.0, 2.0, 10.4, 3.0],\n",
       " [36.3, 96.9, 710.0, 1984.0, 2.0, 10.4, 3.0],\n",
       " [36.3, 96.9, 710.0, 1984.0, 2.0, 10.4, 3.0],\n",
       " [36.3, 97.9, 775.0, 1984.0, 2.0, 10.4, 3.0],\n",
       " [36.3, 97.9, 775.0, 1984.0, 2.0, 10.4, 3.0],\n",
       " [36.3, 97.9, 775.0, 1984.0, 2.0, 10.4, 3.0],\n",
       " [36.3, 98.0, 501.0, 1984.0, 2.0, 10.4, 3.0],\n",
       " [36.3, 98.0, 501.0, 1984.0, 2.0, 10.4, 3.0],\n",
       " [36.3, 98.0, 501.0, 1984.0, 2.0, 10.4, 3.0],\n",
       " [36.3, 98.0, 501.0, 1984.0, 2.0, 10.4, 3.0],\n",
       " [36.3, 98.0, 501.0, 1984.0, 2.0, 10.4, 3.0],\n",
       " [36.3, 98.0, 467.0, 1984.0, 2.0, 10.4, 3.0],\n",
       " [29.7, 88.0, 7602.0, 1958.0, 2.0, 13.4, 14.3],\n",
       " [29.7, 87.5, 12275.0, 1958.0, 2.0, 13.4, 14.3],\n",
       " [29.7, 87.5, 12275.0, 1958.0, 2.0, 13.4, 14.3],\n",
       " [29.7, 87.5, 12275.0, 1958.0, 2.0, 13.4, 14.3],\n",
       " [29.7, 87.5, 12275.0, 1958.0, 2.0, 13.4, 13.7],\n",
       " [29.9, 88.5, 12275.0, 1958.0, 2.0, 13.4, 14.0],\n",
       " [29.9, 87.9, 12275.0, 1958.0, 2.0, 13.4, 13.7],\n",
       " [30.2, 88.7, 11508.0, 1958.0, 2.0, 13.4, 13.7],\n",
       " [30.2, 88.7, 11508.0, 1958.0, 2.0, 13.4, 13.7],\n",
       " [30.2, 86.7, 11508.0, 1958.0, 2.0, 13.4, 13.7],\n",
       " [30.2, 86.7, 11508.0, 1958.0, 2.0, 13.4, 13.7],\n",
       " [30.2, 86.7, 11508.0, 1958.0, 2.0, 13.4, 13.7],\n",
       " [30.2, 86.7, 11508.0, 1958.0, 2.0, 13.4, 13.7],\n",
       " [30.2, 86.8, 11006.0, 1958.0, 2.0, 13.4, 13.7],\n",
       " [30.2, 86.8, 11006.0, 1958.0, 2.0, 13.4, 13.7],\n",
       " [30.2, 86.8, 11006.0, 1958.0, 2.0, 13.4, 13.7],\n",
       " [30.2, 88.5, 4394.0, 1958.0, 2.0, 13.4, 13.7],\n",
       " [30.2, 88.5, 4394.0, 1958.0, 2.0, 13.4, 13.7],\n",
       " [30.2, 88.5, 4394.0, 1958.0, 2.0, 13.4, 13.7],\n",
       " [30.2, 89.5, 4394.0, 1958.0, 2.0, 13.4, 13.7],\n",
       " [30.2, 89.5, 4394.0, 1958.0, 2.0, 13.4, 13.7],\n",
       " [30.2, 89.5, 11399.0, 1958.0, 2.0, 13.4, 13.7],\n",
       " [36.0, 91.6, 10455.0, 1957.0, 2.0, 12.1, 3.0],\n",
       " [36.0, 91.0, 11690.0, 1957.0, 2.0, 12.1, 3.0],\n",
       " [36.0, 91.0, 11690.0, 1957.0, 2.0, 12.1, 3.0],\n",
       " [36.0, 91.0, 11690.0, 1957.0, 2.0, 12.1, 3.0],\n",
       " [36.0, 91.0, 11690.0, 1957.0, 2.0, 12.1, 3.0],\n",
       " [36.3, 78.7, 11690.0, 1957.0, 3.0, 12.2, 3.0],\n",
       " [36.3, 67.1, 11690.0, 1957.0, 3.0, 12.2, 3.0],\n",
       " [36.3, 68.4, 7594.0, 1957.0, 3.0, 12.2, 3.2],\n",
       " [36.3, 68.4, 7594.0, 1957.0, 3.0, 12.2, 3.2],\n",
       " [36.3, 71.4, 7594.0, 1957.0, 3.0, 12.2, 3.2],\n",
       " [36.3, 71.4, 7594.0, 1957.0, 3.0, 12.2, 3.2],\n",
       " [36.3, 71.4, 7594.0, 1957.0, 3.0, 12.2, 3.2],\n",
       " [36.3, 71.4, 7594.0, 1957.0, 3.0, 12.2, 3.2],\n",
       " [36.3, 81.9, 10811.0, 1957.0, 3.0, 12.2, 3.2],\n",
       " [36.3, 81.9, 10811.0, 1957.0, 3.0, 12.2, 3.2],\n",
       " [36.3, 81.9, 10811.0, 1957.0, 3.0, 12.2, 3.2],\n",
       " [36.3, 81.9, 10838.0, 1957.0, 3.0, 12.2, 3.2],\n",
       " [36.3, 80.9, 10838.0, 1957.0, 3.0, 12.2, 3.2],\n",
       " [36.3, 80.9, 10838.0, 1957.0, 3.0, 12.2, 3.2],\n",
       " [36.3, 95.4, 10838.0, 1957.0, 2.0, 12.2, 3.2],\n",
       " [36.3, 95.4, 10838.0, 1957.0, 2.0, 12.2, 3.2],\n",
       " [36.3, 95.4, 8296.0, 1957.0, 2.0, 12.2, 3.2],\n",
       " [36.0, 95.0, 193.0, 1968.0, 2.0, 9.2, 8.2],\n",
       " [36.0, 97.0, 447.0, 1968.0, 2.0, 9.2, 8.2],\n",
       " [36.0, 97.0, 447.0, 1968.0, 2.0, 9.2, 8.2],\n",
       " [36.0, 97.0, 447.0, 1968.0, 2.0, 9.2, 8.2],\n",
       " [36.0, 96.0, 447.0, 1968.0, 2.0, 9.2, 7.6],\n",
       " [36.3, 95.0, 447.0, 1968.0, 2.0, 9.2, 8.0],\n",
       " [36.3, 83.0, 447.0, 1968.0, 2.0, 9.2, 7.9],\n",
       " [36.3, 83.0, 410.0, 1968.0, 2.0, 9.2, 7.9],\n",
       " [36.3, 83.0, 410.0, 1968.0, 2.0, 9.2, 7.9],\n",
       " [36.3, 86.0, 410.0, 1968.0, 2.0, 9.2, 7.9],\n",
       " [36.3, 86.0, 410.0, 1968.0, 2.0, 9.2, 7.9],\n",
       " [36.3, 85.0, 410.0, 1968.0, 2.0, 9.2, 7.9],\n",
       " [36.3, 85.0, 410.0, 1968.0, 2.0, 9.2, 7.9],\n",
       " [36.3, 85.0, 384.0, 1968.0, 2.0, 9.2, 7.9],\n",
       " [36.3, 85.0, 384.0, 1968.0, 2.0, 9.2, 7.9],\n",
       " [36.3, 85.0, 384.0, 1968.0, 2.0, 9.2, 7.9],\n",
       " [36.3, 85.0, 363.0, 1968.0, 2.0, 9.2, 7.9],\n",
       " [36.3, 86.0, 363.0, 1968.0, 2.0, 9.2, 8.0],\n",
       " [36.3, 86.0, 363.0, 1968.0, 2.0, 9.2, 8.0],\n",
       " [36.3, 84.0, 363.0, 1968.0, 2.0, 9.2, 8.0],\n",
       " [36.3, 84.0, 363.0, 1968.0, 2.0, 9.2, 8.0],\n",
       " [36.3, 84.0, 383.0, 1968.0, 2.0, 9.2, 8.0],\n",
       " [81.9, 99.0, 207.0, 1986.0, 2.0, 12.2, 15.5],\n",
       " [81.9, 99.9, 664.0, 1986.0, 2.0, 12.2, 15.5],\n",
       " [81.9, 99.9, 664.0, 1986.0, 2.0, 12.2, 15.5],\n",
       " [81.9, 99.9, 664.0, 1986.0, 2.0, 12.2, 15.5],\n",
       " [81.9, 99.9, 664.0, 1986.0, 2.0, 12.2, 14.9],\n",
       " [82.5, 99.0, 664.0, 1986.0, 2.0, 12.3, 15.0],\n",
       " [82.6, 99.9, 664.0, 1986.0, 2.0, 12.3, 14.9],\n",
       " [82.6, 99.0, 540.0, 1986.0, 2.0, 12.3, 15.0],\n",
       " [82.6, 99.0, 540.0, 1986.0, 2.0, 12.3, 15.0],\n",
       " [83.2, 100.0, 540.0, 1986.0, 2.0, 12.3, 15.0],\n",
       " [83.2, 100.0, 540.0, 1986.0, 2.0, 12.3, 15.0],\n",
       " [83.2, 100.0, 540.0, 1986.0, 2.0, 12.3, 15.0],\n",
       " [83.2, 100.0, 540.0, 1986.0, 2.0, 12.3, 15.0],\n",
       " [83.2, 100.0, 419.0, 1986.0, 2.0, 12.3, 15.0],\n",
       " [83.2, 100.0, 419.0, 1986.0, 2.0, 12.3, 15.0],\n",
       " [83.2, 100.0, 419.0, 1986.0, 2.0, 12.3, 15.0],\n",
       " [83.2, 100.0, 461.0, 1986.0, 2.0, 12.3, 15.0],\n",
       " [83.2, 100.0, 461.0, 1986.0, 2.0, 12.3, 15.0],\n",
       " [83.2, 100.0, 461.0, 1986.0, 2.0, 12.3, 15.0],\n",
       " [83.2, 100.0, 461.0, 1986.0, 2.0, 12.3, 15.0],\n",
       " [83.2, 100.0, 461.0, 1986.0, 2.0, 12.3, 15.0],\n",
       " [83.2, 100.0, 392.0, 1986.0, 2.0, 12.3, 15.0],\n",
       " [36.0, 97.5, 5102.0, 1970.0, 2.0, 12.1, 3.4],\n",
       " [36.0, 95.1, 9942.0, 1970.0, 3.0, 12.1, 3.4],\n",
       " [36.0, 95.1, 9942.0, 1970.0, 3.0, 12.1, 3.4],\n",
       " [36.0, 95.1, 9942.0, 1970.0, 3.0, 12.1, 3.4],\n",
       " [36.0, 95.1, 9942.0, 1970.0, 3.0, 12.1, 3.4],\n",
       " [36.3, 96.5, 9942.0, 1970.0, 3.0, 12.2, 3.0],\n",
       " [36.3, 95.1, 9942.0, 1970.0, 3.0, 12.2, 3.4],\n",
       " [36.3, 95.1, 9746.0, 1970.0, 3.0, 12.2, 3.2],\n",
       " [36.3, 95.1, 9746.0, 1970.0, 3.0, 12.2, 3.2],\n",
       " [36.3, 96.1, 9746.0, 1970.0, 3.0, 12.2, 3.2],\n",
       " [36.3, 96.1, 9746.0, 1970.0, 3.0, 12.2, 3.2],\n",
       " [36.3, 96.1, 9746.0, 1970.0, 3.0, 12.2, 3.2],\n",
       " [36.3, 96.1, 9746.0, 1970.0, 3.0, 12.2, 3.2],\n",
       " [36.3, 96.1, 9726.0, 1970.0, 3.0, 12.2, 3.2],\n",
       " [36.3, 96.1, 9726.0, 1970.0, 3.0, 12.2, 3.2],\n",
       " [36.3, 79.9, 9726.0, 1970.0, 3.0, 12.2, 3.2],\n",
       " [36.3, 79.9, 9125.0, 1970.0, 3.0, 12.2, 3.2],\n",
       " [36.3, 78.9, 9125.0, 1970.0, 3.0, 12.2, 3.2],\n",
       " [36.3, 78.9, 9125.0, 1970.0, 3.0, 12.2, 3.2],\n",
       " [36.3, 78.9, 9125.0, 1970.0, 3.0, 12.2, 3.2],\n",
       " [36.3, 78.9, 9125.0, 1970.0, 3.0, 12.2, 3.2],\n",
       " [36.3, 78.9, 7680.0, 1970.0, 3.0, 12.2, 3.2],\n",
       " [36.0, 82.5, 5089.0, 1984.0, 4.0, 20.1, 4.6],\n",
       " [36.0, 82.4, 8990.0, 1984.0, 4.0, 25.2, 4.6],\n",
       " [36.0, 82.4, 8990.0, 1984.0, 4.0, 25.2, 4.6],\n",
       " [36.0, 82.4, 8990.0, 1984.0, 4.0, 25.2, 4.6],\n",
       " [36.0, 82.4, 8990.0, 1984.0, 4.0, 25.2, 4.6],\n",
       " [36.3, 82.4, 8990.0, 1984.0, 4.0, 25.3, 5.0],\n",
       " [36.3, 83.5, 8990.0, 1984.0, 4.0, 25.3, 4.6],\n",
       " [36.3, 83.5, 13588.0, 1984.0, 4.0, 10.2, 4.4],\n",
       " [36.3, 83.5, 13588.0, 1984.0, 4.0, 10.2, 4.4],\n",
       " [36.3, 83.5, 13588.0, 1984.0, 4.0, 10.2, 4.4],\n",
       " [36.3, 83.5, 13588.0, 1984.0, 4.0, 10.2, 4.4],\n",
       " [36.3, 83.5, 13588.0, 1984.0, 4.0, 10.2, 4.4],\n",
       " [36.3, 83.5, 13588.0, 1984.0, 4.0, 10.2, 4.4],\n",
       " [36.3, 83.5, 13588.0, 1984.0, 4.0, 10.2, 4.4],\n",
       " [36.3, 83.5, 13588.0, 1984.0, 4.0, 10.2, 4.4],\n",
       " [36.3, 83.5, 13588.0, 1984.0, 4.0, 10.2, 4.4],\n",
       " [36.3, 83.4, 14264.0, 1984.0, 4.0, 10.2, 4.4],\n",
       " [36.3, 83.4, 14264.0, 1984.0, 4.0, 10.2, 4.4],\n",
       " [36.3, 83.4, 14264.0, 1984.0, 4.0, 10.2, 4.4],\n",
       " [36.3, 83.4, 14264.0, 1984.0, 4.0, 10.2, 4.4],\n",
       " [36.3, 83.4, 14264.0, 1984.0, 4.0, 10.2, 4.4],\n",
       " [36.3, 83.4, 14206.0, 1984.0, 4.0, 10.2, 4.4],\n",
       " [36.0, 96.8, 1637.0, 1975.0, 2.0, 16.1, 3.0],\n",
       " [36.0, 96.7, 2243.0, 1975.0, 2.0, 16.1, 3.0],\n",
       " [36.0, 96.7, 2243.0, 1975.0, 2.0, 16.1, 3.0],\n",
       " [36.0, 96.7, 2243.0, 1975.0, 2.0, 16.1, 3.0],\n",
       " [36.0, 96.7, 2243.0, 1975.0, 2.0, 16.1, 3.0],\n",
       " [36.3, 96.9, 2243.0, 1975.0, 2.0, 16.2, 3.0],\n",
       " [36.3, 96.8, 2243.0, 1975.0, 2.0, 16.2, 3.0],\n",
       " [36.3, 96.8, 2076.0, 1975.0, 2.0, 16.2, 3.0],\n",
       " [36.3, 96.8, 2076.0, 1975.0, 2.0, 16.2, 3.0],\n",
       " [36.3, 96.8, 2076.0, 1975.0, 2.0, 16.2, 3.1],\n",
       " [36.3, 96.8, 2076.0, 1975.0, 2.0, 16.2, 3.1],\n",
       " [36.3, 96.9, 1577.0, 1975.0, 2.0, 16.2, 3.1],\n",
       " [36.3, 96.9, 1577.0, 1975.0, 2.0, 16.2, 3.1],\n",
       " [36.3, 96.9, 1577.0, 1975.0, 2.0, 4.0, 3.1],\n",
       " [36.3, 96.9, 1577.0, 1975.0, 2.0, 4.0, 3.1],\n",
       " [36.3, 96.9, 1577.0, 1975.0, 2.0, 4.0, 3.1],\n",
       " [36.3, 96.8, 2128.0, 1975.0, 2.0, 4.0, 3.1],\n",
       " [36.3, 95.8, 2128.0, 1975.0, 2.0, 4.0, 3.1],\n",
       " [36.3, 95.8, 2128.0, 1975.0, 2.0, 4.0, 3.1],\n",
       " [36.3, 95.8, 2128.0, 1975.0, 2.0, 4.0, 3.1],\n",
       " [36.3, 95.8, 2128.0, 1975.0, 2.0, 4.0, 3.1],\n",
       " [36.3, 95.8, 1899.0, 1975.0, 2.0, 4.0, 3.1],\n",
       " [99.9, 82.9, 18848.0, 1986.0, 5.0, 22.8, 13.1],\n",
       " [99.9, 97.2, 30281.0, 1986.0, 7.0, 22.8, 13.1],\n",
       " [99.9, 97.2, 30281.0, 1986.0, 7.0, 22.8, 13.1],\n",
       " [99.9, 97.2, 30281.0, 1986.0, 7.0, 22.8, 13.1],\n",
       " [99.9, 95.2, 30281.0, 1986.0, 7.0, 27.2, 13.1],\n",
       " [89.8, 98.6, 30281.0, 1986.0, 7.0, 27.3, 13.0],\n",
       " [89.8, 95.2, 30281.0, 1986.0, 7.0, 27.3, 13.1],\n",
       " [10.5, 94.2, 40588.0, 1986.0, 7.0, 14.5, 13.0],\n",
       " [10.5, 94.2, 40588.0, 1986.0, 7.0, 14.5, 13.0],\n",
       " [10.5, 96.2, 40588.0, 1986.0, 7.0, 14.5, 13.0],\n",
       " [81.6, 96.2, 40588.0, 1986.0, 7.0, 14.5, 13.0],\n",
       " [81.6, 96.7, 34840.0, 1986.0, 7.0, 14.5, 13.0],\n",
       " [81.6, 96.7, 34840.0, 1986.0, 7.0, 14.5, 13.0],\n",
       " [81.6, 96.7, 34840.0, 1986.0, 7.0, 14.5, 13.0],\n",
       " [81.6, 96.7, 34840.0, 1986.0, 7.0, 14.5, 13.0],\n",
       " [81.6, 96.7, 34840.0, 1986.0, 7.0, 14.5, 13.0],\n",
       " [81.6, 98.0, 21836.0, 1986.0, 7.0, 14.5, 13.0],\n",
       " [81.6, 98.0, 21836.0, 1986.0, 7.0, 14.5, 13.0],\n",
       " [81.6, 98.0, 21836.0, 1986.0, 7.0, 14.5, 13.0],\n",
       " [81.6, 98.0, 21836.0, 1986.0, 7.0, 14.5, 13.0],\n",
       " [81.6, 98.0, 21836.0, 1986.0, 7.0, 14.5, 13.0],\n",
       " [81.6, 98.0, 16382.0, 1986.0, 7.0, 14.5, 13.0],\n",
       " [79.2, 99.9, 726.0, 1984.0, 2.0, 12.1, 12.2],\n",
       " [79.2, 99.8, 1979.0, 1984.0, 2.0, 12.1, 12.2],\n",
       " [79.2, 99.8, 1979.0, 1984.0, 2.0, 12.1, 12.2],\n",
       " [79.2, 99.8, 1979.0, 1984.0, 2.0, 12.1, 12.2],\n",
       " [79.2, 99.8, 1979.0, 1984.0, 2.0, 12.1, 11.9],\n",
       " [79.8, 99.9, 1979.0, 1984.0, 2.0, 12.2, 12.0],\n",
       " [79.8, 99.8, 1979.0, 1984.0, 2.0, 12.2, 11.9],\n",
       " [79.8, 99.9, 1561.0, 1984.0, 2.0, 12.2, 12.0],\n",
       " [79.8, 99.9, 1561.0, 1984.0, 2.0, 12.2, 12.0],\n",
       " [80.5, 99.9, 1561.0, 1984.0, 2.0, 12.2, 11.6],\n",
       " [80.5, 99.9, 1561.0, 1984.0, 2.0, 12.2, 11.6],\n",
       " [80.5, 99.9, 1561.0, 1984.0, 2.0, 12.2, 11.6],\n",
       " [80.5, 99.9, 1561.0, 1984.0, 2.0, 12.2, 11.6],\n",
       " [80.5, 99.9, 929.0, 1984.0, 2.0, 12.2, 11.6],\n",
       " [80.5, 99.9, 929.0, 1984.0, 2.0, 12.2, 11.6],\n",
       " [80.5, 99.9, 929.0, 1984.0, 2.0, 12.2, 11.6],\n",
       " [80.5, 99.9, 1360.0, 1984.0, 2.0, 12.2, 11.6],\n",
       " [80.5, 99.9, 1360.0, 1984.0, 2.0, 12.2, 11.6],\n",
       " [80.5, 99.9, 1360.0, 1984.0, 2.0, 12.2, 11.6],\n",
       " [80.5, 99.9, 1360.0, 1984.0, 2.0, 12.2, 11.6],\n",
       " [80.5, 99.9, 1360.0, 1984.0, 2.0, 12.2, 11.6],\n",
       " [80.5, 99.9, 1048.0, 1984.0, 2.0, 12.2, 11.6],\n",
       " [32.4, 77.3, 24032.0, 1951.0, 4.0, 18.8, 19.5],\n",
       " [32.4, 75.0, 24875.0, 1951.0, 5.0, 18.8, 19.5],\n",
       " [32.4, 75.0, 24875.0, 1951.0, 5.0, 18.8, 19.5],\n",
       " [32.4, 75.0, 24875.0, 1951.0, 5.0, 18.8, 19.5],\n",
       " [32.4, 75.0, 24875.0, 1951.0, 5.0, 18.8, 18.9],\n",
       " [32.7, 75.4, 24875.0, 1951.0, 5.0, 18.8, 19.0],\n",
       " [32.7, 75.4, 24875.0, 1951.0, 5.0, 18.8, 18.9],\n",
       " [33.4, 74.0, 32792.0, 1951.0, 5.0, 18.8, 18.7],\n",
       " [33.4, 74.0, 32792.0, 1951.0, 5.0, 18.8, 18.7],\n",
       " [33.4, 74.0, 32792.0, 1951.0, 5.0, 18.8, 18.7],\n",
       " [33.4, 74.0, 32792.0, 1951.0, 5.0, 18.8, 18.7],\n",
       " [33.4, 74.0, 32792.0, 1951.0, 5.0, 18.8, 18.7],\n",
       " [33.4, 74.0, 32792.0, 1951.0, 5.0, 18.8, 18.7],\n",
       " [33.4, 75.1, 26528.0, 1951.0, 5.0, 18.8, 18.7],\n",
       " [33.4, 75.1, 26528.0, 1951.0, 5.0, 18.8, 18.7],\n",
       " [33.4, 75.1, 26528.0, 1951.0, 5.0, 18.8, 18.7],\n",
       " [33.4, 75.3, 25700.0, 1951.0, 5.0, 18.8, 18.7],\n",
       " [33.4, 75.3, 25700.0, 1951.0, 5.0, 18.8, 18.7],\n",
       " [33.4, 75.3, 25700.0, 1951.0, 5.0, 18.8, 18.7],\n",
       " [33.4, 75.3, 25700.0, 1951.0, 5.0, 18.8, 18.7],\n",
       " [33.4, 75.3, 25700.0, 1951.0, 5.0, 18.8, 18.7],\n",
       " [28.8, 75.3, 26829.0, 1951.0, 5.0, 18.8, 18.7],\n",
       " [36.0, 82.3, 16059.0, 1970.0, 4.0, 24.2, 4.0],\n",
       " [36.0, 81.8, 18642.0, 1970.0, 4.0, 24.2, 4.0],\n",
       " [36.0, 81.8, 18642.0, 1970.0, 4.0, 24.2, 4.0],\n",
       " [36.0, 81.8, 18642.0, 1970.0, 4.0, 24.2, 4.0],\n",
       " [36.0, 81.8, 18642.0, 1970.0, 5.0, 24.2, 6.1],\n",
       " [36.3, 81.8, 18642.0, 1970.0, 5.0, 24.2, 6.0],\n",
       " [36.3, 81.8, 18642.0, 1970.0, 5.0, 24.2, 6.1],\n",
       " [36.3, 81.3, 21731.0, 1970.0, 5.0, 24.2, 6.2],\n",
       " [36.3, 81.3, 21731.0, 1970.0, 5.0, 24.2, 6.2],\n",
       " [36.3, 81.3, 21731.0, 1970.0, 5.0, 24.2, 6.2],\n",
       " [36.3, 81.3, 21731.0, 1970.0, 5.0, 24.2, 6.2],\n",
       " [36.3, 81.3, 21731.0, 1970.0, 5.0, 24.2, 6.2],\n",
       " [36.3, 81.3, 21731.0, 1970.0, 5.0, 24.2, 6.2],\n",
       " [36.3, 82.2, 16509.0, 1970.0, 5.0, 24.2, 6.2],\n",
       " [36.3, 82.2, 16509.0, 1970.0, 5.0, 24.2, 6.2],\n",
       " [36.3, 82.2, 16509.0, 1970.0, 6.0, 24.2, 6.2],\n",
       " [36.3, 82.0, 17336.0, 1970.0, 6.0, 24.2, 6.2],\n",
       " [36.3, 82.0, 17336.0, 1970.0, 6.0, 24.2, 6.2],\n",
       " [36.3, 82.0, 17336.0, 1970.0, 6.0, 24.2, 6.2],\n",
       " [36.3, 82.0, 17336.0, 1970.0, 5.0, 24.2, 6.2],\n",
       " [36.3, 82.0, 17336.0, 1970.0, 5.0, 24.2, 6.2],\n",
       " [36.3, 82.0, 17088.0, 1970.0, 5.0, 24.2, 6.2],\n",
       " [53.1, 73.4, 3314.0, 1973.0, 2.0, 18.2, 2.4],\n",
       " [53.1, 72.7, 8391.0, 1973.0, 3.0, 18.2, 2.4],\n",
       " [53.1, 72.7, 8391.0, 1973.0, 3.0, 18.2, 2.4],\n",
       " [53.1, 72.7, 8391.0, 1973.0, 3.0, 18.2, 2.4],\n",
       " [53.1, 72.7, 8391.0, 1973.0, 3.0, 18.2, 2.4],\n",
       " [53.5, 73.4, 8391.0, 1973.0, 3.0, 18.3, 2.0],\n",
       " [53.5, 72.9, 8391.0, 1973.0, 3.0, 18.3, 2.4],\n",
       " [53.6, 72.9, 8652.0, 1973.0, 3.0, 18.3, 2.4],\n",
       " [53.6, 72.9, 8652.0, 1973.0, 3.0, 18.3, 2.4],\n",
       " [53.6, 72.9, 8652.0, 1973.0, 3.0, 18.3, 2.4],\n",
       " [53.6, 72.9, 8652.0, 1973.0, 3.0, 18.3, 2.4],\n",
       " [53.6, 72.9, 8590.0, 1973.0, 3.0, 18.3, 2.4],\n",
       " [53.6, 72.9, 8590.0, 1973.0, 3.0, 18.3, 2.4],\n",
       " [53.6, 72.9, 8590.0, 1973.0, 3.0, 18.3, 2.4],\n",
       " [53.6, 72.9, 8590.0, 1973.0, 3.0, 18.3, 2.4],\n",
       " [53.6, 72.9, 8590.0, 1973.0, 3.0, 18.3, 2.4],\n",
       " [53.6, 72.9, 8145.0, 1973.0, 3.0, 18.3, 2.4],\n",
       " [53.6, 72.9, 8145.0, 1973.0, 3.0, 18.3, 2.4],\n",
       " [53.6, 72.9, 8145.0, 1973.0, 3.0, 18.3, 2.4],\n",
       " [53.6, 62.7, 8145.0, 1973.0, 3.0, 18.3, 2.4],\n",
       " [53.6, 62.7, 8145.0, 1973.0, 3.0, 18.3, 2.4],\n",
       " [53.6, 62.7, 9149.0, 1973.0, 3.0, 18.3, 2.4],\n",
       " [60.3, 88.2, 850.0, 1995.0, 2.0, 9.1, 10.1],\n",
       " [60.3, 86.0, 2556.0, 1995.0, 2.0, 9.1, 10.1],\n",
       " [60.3, 86.0, 2556.0, 1995.0, 2.0, 9.1, 10.1],\n",
       " [60.3, 86.0, 2556.0, 1995.0, 2.0, 9.1, 10.1],\n",
       " [60.3, 86.0, 2556.0, 1995.0, 2.0, 9.1, 9.8],\n",
       " [60.8, 86.1, 2556.0, 1995.0, 2.0, 9.1, 10.0],\n",
       " [60.8, 86.0, 2556.0, 1995.0, 2.0, 9.1, 9.8],\n",
       " [61.2, 79.6, 3061.0, 1995.0, 2.0, 9.1, 9.8],\n",
       " [61.2, 79.6, 3061.0, 1995.0, 2.0, 9.1, 9.8],\n",
       " [61.2, 79.6, 3061.0, 1995.0, 2.0, 9.1, 9.8],\n",
       " [61.2, 79.6, 3061.0, 1995.0, 2.0, 9.1, 9.8],\n",
       " [61.2, 81.6, 3061.0, 1995.0, 2.0, 9.1, 9.8],\n",
       " [61.2, 81.6, 3061.0, 1995.0, 2.0, 9.1, 9.8],\n",
       " [61.2, 88.0, 2445.0, 1995.0, 2.0, 9.1, 9.8],\n",
       " [61.2, 88.0, 2445.0, 1995.0, 2.0, 9.1, 9.8],\n",
       " [61.2, 88.0, 2445.0, 1995.0, 2.0, 9.1, 9.8],\n",
       " [61.2, 81.7, 2738.0, 1995.0, 2.0, 9.1, 9.8],\n",
       " [61.2, 81.7, 2738.0, 1995.0, 2.0, 9.1, 9.8],\n",
       " [61.2, 81.7, 2738.0, 1995.0, 2.0, 9.1, 9.8],\n",
       " [61.2, 81.7, 2738.0, 1995.0, 2.0, 9.1, 9.8],\n",
       " [61.2, 81.7, 2738.0, 1995.0, 2.0, 9.1, 9.8],\n",
       " [61.2, 81.7, 3198.0, 1995.0, 2.0, 9.1, 9.8],\n",
       " [48.6, 96.5, 3274.0, 1989.0, 2.0, 13.4, 9.1],\n",
       " [48.6, 90.4, 3621.0, 1989.0, 3.0, 13.4, 9.1],\n",
       " [48.6, 90.4, 3621.0, 1989.0, 3.0, 13.4, 9.1],\n",
       " [48.6, 90.4, 3621.0, 1989.0, 3.0, 13.4, 9.1],\n",
       " [48.6, 90.4, 3621.0, 1989.0, 3.0, 13.4, 9.4],\n",
       " [38.1, 83.0, 3621.0, 1989.0, 3.0, 13.5, 9.0],\n",
       " [38.1, 82.8, 3621.0, 1989.0, 3.0, 13.5, 9.5],\n",
       " [38.4, 83.4, 1844.0, 1989.0, 3.0, 13.5, 9.4],\n",
       " [38.4, 83.4, 1844.0, 1989.0, 3.0, 13.5, 9.4],\n",
       " [38.4, 83.4, 1844.0, 1989.0, 3.0, 13.5, 9.4],\n",
       " [38.4, 83.4, 1844.0, 1989.0, 3.0, 13.5, 9.4],\n",
       " [38.4, 83.4, 1844.0, 1989.0, 3.0, 13.5, 9.4],\n",
       " [38.4, 83.4, 1844.0, 1989.0, 3.0, 13.5, 9.4],\n",
       " [38.4, 83.3, 2429.0, 1989.0, 3.0, 13.5, 9.4],\n",
       " [38.4, 83.3, 2429.0, 1989.0, 3.0, 13.5, 9.4],\n",
       " [38.4, 71.3, 2429.0, 1989.0, 3.0, 13.5, 9.4],\n",
       " [38.4, 71.2, 3029.0, 1989.0, 3.0, 13.5, 9.4],\n",
       " [38.4, 71.2, 3029.0, 1989.0, 3.0, 13.5, 9.4],\n",
       " [38.4, 71.2, 3029.0, 1989.0, 3.0, 13.5, 9.4],\n",
       " [38.4, 71.2, 3029.0, 1989.0, 3.0, 13.5, 9.4],\n",
       " [38.4, 71.2, 3029.0, 1989.0, 3.0, 13.5, 9.4],\n",
       " [38.4, 71.2, 2768.0, 1989.0, 3.0, 13.5, 9.4],\n",
       " [55.8, 73.2, 23300.0, 1959.0, 6.0, 24.3, 22.3],\n",
       " [55.8, 78.6, 23504.0, 1959.0, 6.0, 25.6, 22.3],\n",
       " [55.8, 78.6, 23504.0, 1959.0, 6.0, 25.6, 22.3],\n",
       " [55.8, 78.6, 23504.0, 1959.0, 6.0, 25.6, 22.3],\n",
       " [55.8, 78.6, 23504.0, 1959.0, 6.0, 25.6, 21.3],\n",
       " [56.2, 84.7, 23504.0, 1959.0, 5.0, 25.6, 21.0],\n",
       " [56.3, 83.5, 23504.0, 1959.0, 5.0, 25.6, 21.3],\n",
       " [57.0, 84.0, 18994.0, 1959.0, 5.0, 25.6, 21.2],\n",
       " [57.0, 84.0, 18994.0, 1959.0, 5.0, 25.6, 21.2],\n",
       " [57.0, 84.0, 18994.0, 1959.0, 5.0, 25.6, 21.2],\n",
       " [57.0, 84.0, 18994.0, 1959.0, 5.0, 25.6, 21.2],\n",
       " [57.0, 84.0, 18994.0, 1959.0, 5.0, 25.6, 21.2],\n",
       " [57.0, 84.0, 18994.0, 1959.0, 5.0, 25.6, 21.2],\n",
       " [57.0, 95.3, 18326.0, 1959.0, 5.0, 25.6, 21.2],\n",
       " [57.0, 95.3, 18326.0, 1959.0, 5.0, 25.6, 21.2],\n",
       " [57.0, 84.0, 18326.0, 1959.0, 5.0, 25.6, 21.2],\n",
       " [57.0, 84.0, 18933.0, 1959.0, 5.0, 25.6, 21.2],\n",
       " [57.0, 84.0, 18933.0, 1959.0, 5.0, 25.6, 21.2],\n",
       " [57.0, 84.0, 18933.0, 1959.0, 5.0, 25.6, 21.2],\n",
       " [57.0, 84.0, 18933.0, 1959.0, 5.0, 25.6, 21.2],\n",
       " [57.0, 84.0, 18933.0, 1959.0, 5.0, 25.6, 21.2],\n",
       " [57.0, 84.0, 18933.0, 1959.0, 5.0, 25.6, 21.2],\n",
       " [53.1, 99.9, 753.0, 1987.0, 2.0, 11.2, 15.2],\n",
       " [53.1, 98.9, 848.0, 1987.0, 2.0, 11.2, 15.2],\n",
       " [53.1, 98.9, 848.0, 1987.0, 2.0, 11.2, 15.2],\n",
       " [53.1, 98.9, 848.0, 1987.0, 2.0, 11.2, 15.2],\n",
       " [53.1, 98.9, 848.0, 1987.0, 2.0, 11.2, 14.6],\n",
       " [53.5, 100.0, 848.0, 1987.0, 2.0, 11.3, 15.0],\n",
       " [53.5, 99.9, 848.0, 1987.0, 2.0, 11.3, 14.6],\n",
       " [53.7, 99.9, 725.0, 1987.0, 2.0, 11.3, 14.5],\n",
       " [53.7, 99.9, 725.0, 1987.0, 2.0, 11.3, 14.5],\n",
       " [53.7, 99.9, 725.0, 1987.0, 2.0, 11.3, 14.5],\n",
       " [53.7, 99.9, 725.0, 1987.0, 2.0, 11.3, 14.5],\n",
       " [53.7, 98.9, 725.0, 1987.0, 2.0, 11.3, 14.5],\n",
       " [53.7, 98.9, 725.0, 1987.0, 2.0, 11.3, 14.5],\n",
       " [53.7, 98.9, 733.0, 1987.0, 2.0, 11.3, 14.5],\n",
       " [53.7, 98.9, 733.0, 1987.0, 2.0, 11.3, 14.5],\n",
       " [53.7, 98.9, 733.0, 1987.0, 2.0, 11.3, 14.5],\n",
       " [53.7, 99.0, 81.0, 1987.0, 2.0, 11.3, 14.5],\n",
       " [53.7, 99.0, 81.0, 1987.0, 2.0, 11.3, 14.5],\n",
       " [53.7, 99.0, 81.0, 1987.0, 2.0, 11.3, 14.5],\n",
       " [53.7, 99.0, 81.0, 1987.0, 2.0, 11.3, 14.5],\n",
       " [53.7, 99.0, 81.0, 1987.0, 2.0, 11.3, 14.5],\n",
       " [53.7, 99.0, 589.0, 1987.0, 2.0, 11.3, 14.5],\n",
       " [30.6, 40.6, 17972.0, 1935.0, 4.0, 16.1, 35.1],\n",
       " [30.6, 40.6, 17972.0, 1935.0, 4.0, 16.1, 35.1],\n",
       " [30.6, 40.6, 17972.0, 1935.0, 4.0, 16.1, 35.1],\n",
       " [30.6, 40.6, 17972.0, 1935.0, 4.0, 16.1, 35.1],\n",
       " [30.6, 40.6, 17972.0, 1935.0, 4.0, 16.1, 35.1],\n",
       " [30.6, 40.6, 17972.0, 1935.0, 4.0, 16.1, 35.1],\n",
       " [30.6, 40.6, 17972.0, 1935.0, 4.0, 16.1, 35.1],\n",
       " [30.6, 40.6, 17972.0, 1935.0, 4.0, 16.1, 35.1],\n",
       " [30.6, 40.6, 17972.0, 1935.0, 4.0, 16.1, 35.1],\n",
       " [30.6, 40.6, 17972.0, 1935.0, 4.0, 16.1, 35.1],\n",
       " [30.6, 40.6, 17972.0, 1935.0, 4.0, 16.1, 35.1],\n",
       " [30.6, 40.6, 17972.0, 1935.0, 4.0, 16.1, 35.1],\n",
       " [30.6, 40.6, 17972.0, 1935.0, 4.0, 16.1, 35.1],\n",
       " [30.6, 40.6, 17972.0, 1935.0, 4.0, 16.1, 35.1],\n",
       " [30.6, 40.6, 17972.0, 1935.0, 4.0, 16.1, 35.1],\n",
       " [30.6, 40.6, 17972.0, 1935.0, 4.0, 16.1, 35.1],\n",
       " [30.6, 40.6, 17972.0, 1935.0, 4.0, 16.1, 35.1],\n",
       " [30.6, 40.6, 17972.0, 1935.0, 4.0, 16.1, 35.1],\n",
       " [30.6, 40.6, 17972.0, 1935.0, 4.0, 16.1, 35.1],\n",
       " [30.6, 40.6, 17972.0, 1935.0, 4.0, 16.1, 35.1],\n",
       " [30.6, 40.6, 17972.0, 1935.0, 4.0, 16.1, 35.1],\n",
       " [30.6, 40.6, 17972.0, 1935.0, 4.0, 16.1, 35.1],\n",
       " [76.5, 83.6, 1218.0, 1986.0, 2.0, 10.9, 33.5],\n",
       " [76.5, 81.9, 1409.0, 1986.0, 2.0, 10.9, 33.5],\n",
       " [76.5, 81.9, 1409.0, 1986.0, 2.0, 10.9, 33.5],\n",
       " [76.5, 81.9, 1409.0, 1986.0, 2.0, 10.9, 33.5],\n",
       " [76.5, 81.9, 1409.0, 1986.0, 2.0, 10.9, 32.9],\n",
       " [77.1, 99.9, 1409.0, 1986.0, 2.0, 11.0, 33.0],\n",
       " [77.1, 99.9, 1409.0, 1986.0, 2.0, 11.0, 32.9],\n",
       " [77.3, 99.9, 871.0, 1986.0, 2.0, 11.0, 32.5],\n",
       " [77.3, 99.9, 871.0, 1986.0, 2.0, 11.0, 32.5],\n",
       " [77.3, 99.9, 871.0, 1986.0, 2.0, 11.0, 32.5],\n",
       " [77.3, 99.9, 871.0, 1986.0, 2.0, 11.0, 32.5],\n",
       " [77.3, 99.9, 871.0, 1986.0, 2.0, 11.0, 32.5],\n",
       " [77.3, 99.9, 871.0, 1986.0, 2.0, 11.0, 32.5],\n",
       " [77.3, 98.9, 633.0, 1986.0, 2.0, 11.0, 32.5],\n",
       " [77.3, 98.9, 633.0, 1986.0, 2.0, 11.0, 32.5],\n",
       " [77.3, 98.9, 633.0, 1986.0, 2.0, 11.0, 32.5],\n",
       " [77.3, 98.9, 614.0, 1986.0, 2.0, 11.0, 32.5],\n",
       " [77.3, 98.9, 614.0, 1986.0, 2.0, 11.0, 32.5],\n",
       " [77.3, 98.9, 614.0, 1986.0, 2.0, 11.0, 32.5],\n",
       " [77.3, 98.9, 614.0, 1986.0, 2.0, 11.0, 32.5],\n",
       " [77.3, 98.9, 614.0, 1986.0, 2.0, 11.0, 32.5],\n",
       " [77.3, 98.9, 978.0, 1986.0, 2.0, 11.0, 32.5],\n",
       " [36.0, 96.7, 1827.0, 1975.0, 2.0, 12.1, 3.7],\n",
       " [36.0, 96.6, 2586.0, 1975.0, 2.0, 12.1, 3.7],\n",
       " [36.0, 96.6, 2586.0, 1975.0, 2.0, 12.1, 3.7],\n",
       " [36.0, 96.6, 2586.0, 1975.0, 2.0, 12.1, 3.7],\n",
       " [36.0, 96.6, 2586.0, 1975.0, 2.0, 12.1, 3.7],\n",
       " [36.3, 96.9, 2586.0, 1975.0, 2.0, 12.2, 4.0],\n",
       " [36.3, 96.8, 2586.0, 1975.0, 2.0, 12.2, 3.7],\n",
       " [36.3, 96.5, 5180.0, 1975.0, 2.0, 12.2, 4.0],\n",
       " [36.3, 96.5, 5180.0, 1975.0, 2.0, 12.2, 4.0],\n",
       " [36.3, 96.5, 5180.0, 1975.0, 2.0, 12.2, 3.7],\n",
       " [36.3, 96.5, 5180.0, 1975.0, 2.0, 12.2, 3.7],\n",
       " [36.3, 96.5, 5180.0, 1975.0, 2.0, 12.2, 3.7],\n",
       " [36.3, 96.5, 5180.0, 1975.0, 2.0, 12.2, 3.7],\n",
       " [36.3, 97.8, 2657.0, 1975.0, 2.0, 12.2, 3.7],\n",
       " [36.3, 97.8, 2657.0, 1975.0, 2.0, 12.2, 3.7],\n",
       " [36.3, 97.8, 2657.0, 1975.0, 2.0, 12.2, 3.7],\n",
       " [36.3, 97.7, 3620.0, 1975.0, 2.0, 12.2, 3.7],\n",
       " [36.3, 97.7, 3620.0, 1975.0, 2.0, 12.2, 3.7],\n",
       " [36.3, 97.7, 3620.0, 1975.0, 2.0, 12.2, 3.7],\n",
       " [36.3, 97.7, 3620.0, 1975.0, 2.0, 12.2, 3.7],\n",
       " [36.3, 97.7, 3620.0, 1975.0, 2.0, 12.2, 3.7],\n",
       " [36.3, 97.7, 3099.0, 1975.0, 2.0, 12.2, 3.7],\n",
       " [36.0, 85.0, 2092.0, 1940.0, 2.0, 9.1, 23.8],\n",
       " [36.0, 74.0, 2025.0, 1940.0, 2.0, 9.1, 23.8],\n",
       " [36.0, 74.0, 2025.0, 1940.0, 2.0, 9.1, 23.8],\n",
       " [36.0, 74.0, 2025.0, 1940.0, 2.0, 9.1, 23.8],\n",
       " [36.0, 74.0, 2025.0, 1940.0, 2.0, 9.1, 22.6],\n",
       " [36.3, 85.1, 2025.0, 1940.0, 2.0, 9.1, 23.0],\n",
       " [36.3, 85.0, 2025.0, 1940.0, 2.0, 9.1, 22.6],\n",
       " [36.3, 71.9, 2348.0, 1940.0, 2.0, 9.1, 22.6],\n",
       " [36.3, 71.9, 2348.0, 1940.0, 2.0, 9.1, 22.6],\n",
       " [36.3, 74.0, 2348.0, 1940.0, 2.0, 9.1, 22.6],\n",
       " [36.3, 74.0, 2348.0, 1940.0, 2.0, 9.1, 22.6],\n",
       " [36.3, 74.0, 2348.0, 1940.0, 2.0, 9.1, 22.6],\n",
       " [36.3, 74.0, 2348.0, 1940.0, 2.0, 9.1, 22.6],\n",
       " [36.3, 75.0, 1924.0, 1940.0, 2.0, 9.1, 22.6],\n",
       " [36.3, 75.0, 1924.0, 1940.0, 2.0, 9.1, 22.6],\n",
       " [36.3, 73.0, 1924.0, 1940.0, 2.0, 9.1, 22.6],\n",
       " [36.3, 73.0, 1926.0, 1940.0, 2.0, 9.1, 22.6],\n",
       " [36.3, 73.0, 1926.0, 1940.0, 2.0, 9.1, 22.6],\n",
       " [36.3, 73.0, 1926.0, 1940.0, 2.0, 9.1, 22.6],\n",
       " [36.3, 73.0, 1926.0, 1940.0, 2.0, 9.1, 22.6],\n",
       " [36.3, 73.0, 1926.0, 1940.0, 2.0, 9.1, 22.6],\n",
       " [63.8, 73.0, 2651.0, 1940.0, 2.0, 9.1, 22.6],\n",
       " [36.0, 69.3, 26968.0, 1940.0, 4.0, 13.4, 23.5],\n",
       " [36.0, 69.4, 26219.0, 1940.0, 4.0, 13.4, 23.5],\n",
       " [36.0, 69.4, 26219.0, 1940.0, 4.0, 13.4, 23.5],\n",
       " [36.0, 69.4, 26219.0, 1940.0, 4.0, 13.4, 23.5],\n",
       " [36.0, 69.4, 26219.0, 1940.0, 4.0, 13.4, 23.5],\n",
       " [36.0, 69.4, 26219.0, 1940.0, 4.0, 13.4, 23.5],\n",
       " [36.0, 69.4, 26219.0, 1940.0, 4.0, 13.4, 23.5],\n",
       " [36.0, 69.4, 26219.0, 1940.0, 4.0, 13.4, 23.5],\n",
       " [36.0, 69.4, 26219.0, 1940.0, 4.0, 13.4, 23.5],\n",
       " [36.0, 69.4, 26219.0, 1940.0, 4.0, 13.4, 23.5],\n",
       " [36.0, 69.4, 26219.0, 1940.0, 4.0, 13.4, 23.5],\n",
       " [36.0, 69.4, 26219.0, 1940.0, 4.0, 13.4, 23.5],\n",
       " [36.0, 69.4, 26219.0, 1940.0, 4.0, 13.4, 23.5],\n",
       " [36.0, 69.4, 26219.0, 1940.0, 4.0, 13.4, 23.5],\n",
       " [36.0, 69.4, 26219.0, 1940.0, 4.0, 13.4, 23.5],\n",
       " [36.0, 69.4, 26219.0, 1940.0, 4.0, 13.4, 23.5],\n",
       " [36.0, 69.4, 26219.0, 1940.0, 4.0, 13.4, 23.5],\n",
       " [36.0, 69.4, 26219.0, 1940.0, 4.0, 13.4, 23.5],\n",
       " [36.0, 69.4, 26219.0, 1940.0, 4.0, 13.4, 23.5],\n",
       " [36.0, 69.4, 26219.0, 1940.0, 4.0, 13.4, 23.5],\n",
       " [36.0, 69.4, 26219.0, 1940.0, 4.0, 13.4, 23.5],\n",
       " [36.0, 69.4, 26219.0, 1940.0, 4.0, 13.4, 23.5],\n",
       " [36.0, 73.0, 13631.0, 1937.0, 2.0, 9.1, 30.2],\n",
       " [36.0, 61.8, 12655.0, 1937.0, 2.0, 9.1, 30.2],\n",
       " [36.0, 61.8, 12655.0, 1937.0, 2.0, 9.1, 30.2],\n",
       " [36.0, 61.8, 12655.0, 1937.0, 2.0, 9.1, 30.2],\n",
       " [36.0, 59.8, 12655.0, 1937.0, 2.0, 9.1, 27.1],\n",
       " [36.3, 74.2, 12655.0, 1937.0, 2.0, 9.1, 27.0],\n",
       " [36.3, 59.9, 12655.0, 1937.0, 2.0, 9.1, 27.1],\n",
       " [36.3, 60.6, 12924.0, 1937.0, 2.0, 9.1, 27.1],\n",
       " [36.3, 60.6, 12924.0, 1937.0, 2.0, 9.1, 27.1],\n",
       " [36.3, 74.0, 12924.0, 1937.0, 2.0, 9.1, 27.1],\n",
       " [36.3, 74.0, 12924.0, 1937.0, 2.0, 9.1, 27.1],\n",
       " [36.3, 74.0, 12924.0, 1937.0, 2.0, 9.1, 27.1],\n",
       " [36.3, 74.0, 12924.0, 1937.0, 2.0, 9.1, 27.1],\n",
       " [36.3, 74.0, 12924.0, 1937.0, 2.0, 9.1, 27.1],\n",
       " [36.3, 74.0, 12924.0, 1937.0, 2.0, 9.1, 27.1],\n",
       " [36.3, 74.0, 12924.0, 1937.0, 2.0, 9.1, 27.1],\n",
       " [36.3, 74.0, 12924.0, 1937.0, 2.0, 9.1, 27.1],\n",
       " [36.3, 74.0, 12924.0, 1937.0, 2.0, 9.1, 27.1],\n",
       " [36.3, 74.0, 12924.0, 1937.0, 2.0, 9.1, 27.1],\n",
       " [36.3, 74.0, 12924.0, 1937.0, 2.0, 9.1, 27.1],\n",
       " [36.3, 74.0, 12924.0, 1937.0, 2.0, 9.1, 27.1],\n",
       " [36.3, 74.0, 12924.0, 1937.0, 2.0, 9.1, 27.1],\n",
       " [36.0, 75.8, 10051.0, 1958.0, 2.0, 9.1, 29.9],\n",
       " [36.0, 74.5, 12109.0, 1958.0, 3.0, 9.1, 29.9],\n",
       " [36.0, 74.5, 12109.0, 1958.0, 3.0, 9.1, 29.9],\n",
       " [36.0, 74.5, 12109.0, 1958.0, 3.0, 9.1, 29.9],\n",
       " [36.0, 74.5, 12109.0, 1958.0, 3.0, 9.1, 28.0],\n",
       " [36.3, 74.2, 12109.0, 1958.0, 3.0, 9.1, 29.0],\n",
       " [36.3, 74.5, 12109.0, 1958.0, 3.0, 9.1, 28.7],\n",
       " [36.3, 61.9, 13774.0, 1958.0, 3.0, 9.1, 28.7],\n",
       " [36.3, 61.9, 13774.0, 1958.0, 3.0, 9.1, 28.7],\n",
       " [36.3, 61.9, 13774.0, 1958.0, 3.0, 9.1, 28.7],\n",
       " [36.3, 61.9, 13774.0, 1958.0, 3.0, 9.1, 28.7],\n",
       " [36.3, 61.9, 13774.0, 1958.0, 3.0, 9.1, 28.7],\n",
       " [36.3, 61.9, 13774.0, 1958.0, 3.0, 9.1, 28.7],\n",
       " [36.3, 61.9, 13774.0, 1958.0, 3.0, 9.1, 28.7],\n",
       " [36.3, 61.9, 13774.0, 1958.0, 3.0, 9.1, 28.7],\n",
       " [36.3, 61.9, 13774.0, 1958.0, 3.0, 9.1, 28.7],\n",
       " [36.3, 61.9, 13774.0, 1958.0, 3.0, 9.1, 28.7],\n",
       " [36.3, 61.9, 13774.0, 1958.0, 3.0, 9.1, 28.7],\n",
       " [36.3, 61.9, 13774.0, 1958.0, 3.0, 9.1, 28.7],\n",
       " [36.3, 61.9, 13774.0, 1958.0, 3.0, 9.1, 28.7],\n",
       " [36.3, 61.9, 13774.0, 1958.0, 3.0, 9.1, 28.7],\n",
       " [36.3, 61.9, 13774.0, 1958.0, 3.0, 9.1, 28.7],\n",
       " [36.0, 69.7, 190.0, 1929.0, 1.0, 3.6, 7.9],\n",
       " [36.0, 74.3, 59.0, 1929.0, 1.0, 3.6, 7.9],\n",
       " [36.0, 74.3, 59.0, 1929.0, 1.0, 3.6, 7.9],\n",
       " [36.0, 74.3, 59.0, 1929.0, 1.0, 3.6, 7.9],\n",
       " [36.0, 63.2, 59.0, 1929.0, 1.0, 3.6, 7.9],\n",
       " [36.3, 77.9, 59.0, 1929.0, 1.0, 3.7, 7.9],\n",
       " [36.3, 48.1, 59.0, 1929.0, 1.0, 3.7, 7.9],\n",
       " [36.3, 43.5, 215.0, 1929.0, 1.0, 3.7, 7.9],\n",
       " [36.3, 43.5, 215.0, 1929.0, 1.0, 3.7, 7.9],\n",
       " [36.3, 43.5, 215.0, 1929.0, 1.0, 3.7, 7.9],\n",
       " [36.3, 43.5, 215.0, 1929.0, 1.0, 3.7, 7.9],\n",
       " [36.3, 43.5, 215.0, 1929.0, 1.0, 3.7, 7.9],\n",
       " [36.3, 43.5, 215.0, 1929.0, 1.0, 3.7, 7.9],\n",
       " [36.3, 43.5, 215.0, 1929.0, 1.0, 3.7, 7.9],\n",
       " [36.3, 43.5, 215.0, 1929.0, 1.0, 3.7, 7.9],\n",
       " [36.3, 43.5, 215.0, 1929.0, 1.0, 3.7, 7.9],\n",
       " [36.3, 43.5, 215.0, 1929.0, 1.0, 3.7, 7.9],\n",
       " [36.3, 43.5, 215.0, 1929.0, 1.0, 3.7, 7.9],\n",
       " [36.3, 43.5, 215.0, 1929.0, 1.0, 3.7, 7.9],\n",
       " [36.3, 43.5, 215.0, 1929.0, 1.0, 3.7, 7.9],\n",
       " [36.3, 43.5, 215.0, 1929.0, 1.0, 3.7, 7.9],\n",
       " [36.3, 43.5, 215.0, 1929.0, 1.0, 3.7, 7.9],\n",
       " [54.0, 86.3, 860.0, 1984.0, 3.0, 13.4, 4.9],\n",
       " [54.0, 96.6, 1768.0, 1984.0, 3.0, 13.4, 4.9],\n",
       " [54.0, 96.6, 1768.0, 1984.0, 3.0, 13.4, 4.9],\n",
       " [54.0, 96.6, 1768.0, 1984.0, 3.0, 13.4, 4.9],\n",
       " [54.0, 85.5, 1768.0, 1984.0, 3.0, 13.4, 4.9],\n",
       " [54.4, 96.9, 1768.0, 1984.0, 3.0, 13.5, 5.0],\n",
       " [54.4, 86.8, 1768.0, 1984.0, 3.0, 13.5, 4.9],\n",
       " [50.6, 85.8, 2584.0, 1984.0, 3.0, 13.5, 4.8],\n",
       " [50.6, 85.8, 2584.0, 1984.0, 3.0, 13.5, 4.8],\n",
       " [50.6, 98.8, 2584.0, 1984.0, 3.0, 13.5, 4.8],\n",
       " [50.6, 98.8, 2584.0, 1984.0, 3.0, 13.5, 4.8],\n",
       " [50.6, 98.8, 2584.0, 1984.0, 3.0, 13.5, 4.8],\n",
       " [50.6, 98.8, 2584.0, 1984.0, 3.0, 13.5, 4.8],\n",
       " [50.6, 98.9, 1554.0, 1984.0, 3.0, 13.5, 4.8],\n",
       " [50.6, 98.9, 1554.0, 1984.0, 3.0, 13.5, 4.8],\n",
       " [50.6, 98.9, 1554.0, 1984.0, 3.0, 13.5, 4.8],\n",
       " [50.6, 98.9, 1566.0, 1984.0, 3.0, 13.5, 4.8],\n",
       " [50.6, 98.9, 1566.0, 1984.0, 3.0, 13.5, 4.8],\n",
       " [50.6, 98.9, 1566.0, 1984.0, 3.0, 13.5, 4.8],\n",
       " [50.6, 98.9, 1566.0, 1984.0, 3.0, 13.5, 4.8],\n",
       " [50.6, 98.9, 1566.0, 1984.0, 3.0, 13.5, 4.8],\n",
       " [50.6, 98.9, 2281.0, 1984.0, 3.0, 13.5, 4.8],\n",
       " [36.0, 82.6, 2501.0, 1975.0, 3.0, 12.1, 3.7],\n",
       " [36.0, 94.3, 4370.0, 1975.0, 3.0, 12.1, 3.7],\n",
       " [36.0, 94.3, 4370.0, 1975.0, 3.0, 12.1, 3.7],\n",
       " [36.0, 94.3, 4370.0, 1975.0, 3.0, 12.1, 3.7],\n",
       " [36.0, 94.3, 4370.0, 1975.0, 3.0, 12.1, 3.7],\n",
       " [36.3, 95.4, 4370.0, 1975.0, 3.0, 12.2, 4.0],\n",
       " [36.3, 95.4, 4370.0, 1975.0, 3.0, 12.2, 3.7],\n",
       " [36.3, 95.4, 3936.0, 1975.0, 3.0, 12.2, 4.0],\n",
       " [36.3, 95.4, 3936.0, 1975.0, 3.0, 12.2, 4.0],\n",
       " [36.3, 95.4, 3936.0, 1975.0, 3.0, 12.2, 3.7],\n",
       " [36.3, 95.4, 3936.0, 1975.0, 3.0, 12.2, 3.7],\n",
       " [36.3, 95.4, 3936.0, 1975.0, 3.0, 12.2, 3.7],\n",
       " [36.3, 95.4, 3936.0, 1975.0, 3.0, 12.2, 3.7],\n",
       " [36.3, 95.6, 2576.0, 1975.0, 3.0, 12.2, 3.7],\n",
       " [36.3, 95.6, 2576.0, 1975.0, 3.0, 12.2, 3.7],\n",
       " [36.3, 84.6, 2576.0, 1975.0, 3.0, 12.2, 3.7],\n",
       " [36.3, 84.6, 2634.0, 1975.0, 3.0, 12.2, 3.7],\n",
       " [36.3, 84.6, 2634.0, 1975.0, 3.0, 12.2, 3.7],\n",
       " [36.3, 84.6, 2634.0, 1975.0, 3.0, 12.2, 3.7],\n",
       " [27.2, 51.2, 2634.0, 1975.0, 3.0, 12.2, 3.7],\n",
       " [27.2, 51.2, 2634.0, 1975.0, 3.0, 12.2, 3.7],\n",
       " [27.2, 51.2, 3204.0, 1975.0, 3.0, 12.2, 3.7],\n",
       " [47.7, 96.4, 4202.0, 1987.0, 2.0, 8.5, 3.7],\n",
       " [47.7, 96.2, 5564.0, 1987.0, 2.0, 8.5, 3.7],\n",
       " [47.7, 96.2, 5564.0, 1987.0, 2.0, 8.5, 3.7],\n",
       " [47.7, 96.2, 5564.0, 1987.0, 2.0, 8.5, 3.7],\n",
       " [47.7, 96.2, 5564.0, 1987.0, 2.0, 8.5, 3.7],\n",
       " [48.1, 96.7, 5564.0, 1987.0, 2.0, 10.4, 4.0],\n",
       " [48.1, 96.4, 5564.0, 1987.0, 2.0, 10.4, 3.7],\n",
       " [48.1, 96.4, 5518.0, 1987.0, 2.0, 10.4, 4.0],\n",
       " [48.1, 96.4, 5518.0, 1987.0, 2.0, 10.4, 4.0],\n",
       " [48.6, 95.6, 5518.0, 1987.0, 2.0, 10.4, 3.7],\n",
       " [48.6, 95.6, 5518.0, 1987.0, 2.0, 10.4, 3.7],\n",
       " [48.6, 95.6, 5518.0, 1987.0, 2.0, 10.4, 3.7],\n",
       " [48.6, 95.6, 5518.0, 1987.0, 2.0, 10.4, 3.7],\n",
       " [48.6, 95.6, 5306.0, 1987.0, 2.0, 10.4, 3.7],\n",
       " [48.6, 95.6, 5306.0, 1987.0, 2.0, 10.4, 3.7],\n",
       " [48.6, 95.6, 5306.0, 1987.0, 2.0, 10.4, 3.7],\n",
       " [48.6, 95.6, 5413.0, 1987.0, 2.0, 10.4, 3.7],\n",
       " [48.6, 95.6, 5413.0, 1987.0, 2.0, 10.4, 3.7],\n",
       " [48.6, 95.6, 5413.0, 1987.0, 2.0, 10.4, 3.7],\n",
       " [48.6, 95.6, 5413.0, 1987.0, 2.0, 10.4, 3.7],\n",
       " [48.6, 95.6, 5413.0, 1987.0, 2.0, 10.4, 3.7],\n",
       " [48.6, 95.6, 5666.0, 1987.0, 2.0, 10.4, 3.7],\n",
       " [36.0, 92.1, 1272.0, 1955.0, 2.0, 9.1, 14.3],\n",
       " [36.0, 92.1, 1931.0, 1955.0, 2.0, 9.1, 14.3],\n",
       " [36.0, 92.1, 1931.0, 1955.0, 2.0, 9.1, 14.3],\n",
       " [36.0, 92.1, 1931.0, 1955.0, 2.0, 9.1, 14.3],\n",
       " [36.0, 92.1, 1931.0, 1955.0, 2.0, 9.1, 14.0],\n",
       " [36.3, 92.2, 1931.0, 1955.0, 2.0, 9.1, 14.0],\n",
       " [36.3, 92.1, 1931.0, 1955.0, 2.0, 9.1, 14.0],\n",
       " [36.3, 96.9, 696.0, 1955.0, 2.0, 9.1, 14.0],\n",
       " [36.3, 96.9, 696.0, 1955.0, 2.0, 9.1, 14.0],\n",
       " [36.3, 96.9, 696.0, 1955.0, 2.0, 9.1, 13.7],\n",
       " ...]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# list_of_row_components = np.array(list_of_row_components)\n",
    "\n",
    "list_of_row_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36.0, 97.0, 428.0, 1949.0, 2.0, 10.9, 7.3]\n",
      "[36.0, 96.9, 955.0, 1949.0, 2.0, 10.9, 7.3]\n",
      "[36.0, 96.9, 955.0, 1949.0, 2.0, 10.9, 7.3]\n",
      "[36.0, 96.9, 955.0, 1949.0, 2.0, 10.9, 7.3]\n",
      "[36.0, 96.9, 955.0, 1949.0, 2.0, 10.9, 7.3]\n",
      "[36.3, 97.0, 955.0, 1949.0, 2.0, 11.0, 7.0]\n",
      "[36.3, 96.9, 955.0, 1949.0, 2.0, 11.0, 7.3]\n",
      "[36.3, 96.9, 983.0, 1949.0, 2.0, 11.0, 7.3]\n",
      "[36.3, 96.9, 983.0, 1949.0, 2.0, 11.0, 7.3]\n",
      "[36.3, 96.9, 983.0, 1949.0, 2.0, 11.0, 7.3]\n",
      "[36.3, 96.9, 983.0, 1949.0, 2.0, 11.0, 7.3]\n",
      "[36.3, 97.0, 422.0, 1949.0, 2.0, 11.0, 7.3]\n",
      "[36.3, 97.0, 422.0, 1949.0, 2.0, 11.0, 7.3]\n",
      "[36.3, 97.0, 422.0, 1949.0, 2.0, 11.0, 7.3]\n",
      "[36.3, 97.0, 422.0, 1949.0, 2.0, 11.0, 7.3]\n",
      "[36.3, 97.0, 422.0, 1949.0, 2.0, 9.7, 7.3]\n",
      "[36.3, 97.0, 369.0, 1949.0, 2.0, 9.7, 7.3]\n",
      "[36.3, 86.0, 369.0, 1949.0, 2.0, 9.7, 7.3]\n",
      "[36.3, 86.0, 369.0, 1949.0, 2.0, 9.7, 7.3]\n",
      "[36.3, 86.0, 369.0, 1949.0, 2.0, 9.7, 7.3]\n",
      "[36.3, 86.0, 369.0, 1949.0, 2.0, 9.7, 7.3]\n",
      "[36.3, 86.0, 522.0, 1949.0, 2.0, 9.7, 7.3]\n"
     ]
    }
   ],
   "source": [
    "for i in range(22):\n",
    "    print(list_of_row_components[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11506"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_of_row_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, component in enumerate(list_of_row_components):\n",
    "    temp = component[6]\n",
    "    list_of_row_components[idx][6] = list_of_row_components[idx][1]\n",
    "    list_of_row_components[idx][1] = temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = tf.keras.models.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "    tf.keras.layers.LSTM(50, return_sequences=True),\n",
    "#     tf.keras.layers.LSTM(30, return_sequences=True),\n",
    "#     tf.keras.layers.LSTM(100, return_sequences=True),\n",
    "#     tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "#     tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "#     tf.keras.layers.Dense(units=16, activation='relu'),\n",
    "#     tf.keras.layers.Dense(units=8, activation='relu'),\n",
    "#     tf.keras.layers.Dense(units=4, activation='relu'),\n",
    "#     tf.keras.layers.Dense(units=2, activation='relu'),\n",
    "#     Shape => [batch, time, features]\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_examples = []\n",
    "temp_list = []\n",
    "\n",
    "max_num = 22\n",
    "iter = 0;\n",
    "\n",
    "for row_component in list_of_row_components:\n",
    "    if iter == max_num:\n",
    "        list_of_examples.append(np.array(temp_list))\n",
    "        temp_list = []\n",
    "        iter = 0\n",
    "        \n",
    "    temp_list.append(np.array(row_component))\n",
    "    iter += 1\n",
    "\n",
    "list_of_examples = np.array(list_of_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "522"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_of_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  36. ,    7.3,  428. , 1949. ,    2. ,   10.9,   97. ],\n",
       "       [  36. ,    7.3,  955. , 1949. ,    2. ,   10.9,   96.9],\n",
       "       [  36. ,    7.3,  955. , 1949. ,    2. ,   10.9,   96.9],\n",
       "       [  36. ,    7.3,  955. , 1949. ,    2. ,   10.9,   96.9],\n",
       "       [  36. ,    7.3,  955. , 1949. ,    2. ,   10.9,   96.9],\n",
       "       [  36.3,    7. ,  955. , 1949. ,    2. ,   11. ,   97. ],\n",
       "       [  36.3,    7.3,  955. , 1949. ,    2. ,   11. ,   96.9],\n",
       "       [  36.3,    7.3,  983. , 1949. ,    2. ,   11. ,   96.9],\n",
       "       [  36.3,    7.3,  983. , 1949. ,    2. ,   11. ,   96.9],\n",
       "       [  36.3,    7.3,  983. , 1949. ,    2. ,   11. ,   96.9],\n",
       "       [  36.3,    7.3,  983. , 1949. ,    2. ,   11. ,   96.9],\n",
       "       [  36.3,    7.3,  422. , 1949. ,    2. ,   11. ,   97. ],\n",
       "       [  36.3,    7.3,  422. , 1949. ,    2. ,   11. ,   97. ],\n",
       "       [  36.3,    7.3,  422. , 1949. ,    2. ,   11. ,   97. ],\n",
       "       [  36.3,    7.3,  422. , 1949. ,    2. ,   11. ,   97. ],\n",
       "       [  36.3,    7.3,  422. , 1949. ,    2. ,    9.7,   97. ],\n",
       "       [  36.3,    7.3,  369. , 1949. ,    2. ,    9.7,   97. ],\n",
       "       [  36.3,    7.3,  369. , 1949. ,    2. ,    9.7,   86. ],\n",
       "       [  36.3,    7.3,  369. , 1949. ,    2. ,    9.7,   86. ],\n",
       "       [  36.3,    7.3,  369. , 1949. ,    2. ,    9.7,   86. ],\n",
       "       [  36.3,    7.3,  369. , 1949. ,    2. ,    9.7,   86. ],\n",
       "       [  36.3,    7.3,  522. , 1949. ,    2. ,    9.7,   86. ]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_examples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.0\n",
      "55.7\n",
      "50.2\n",
      "100.0\n",
      "70.9\n",
      "71.7\n",
      "98.9\n",
      "65.9\n",
      "79.5\n",
      "97.6\n",
      "49.5\n",
      "66.2\n",
      "19.9\n",
      "99.0\n",
      "81.3\n",
      "90.6\n",
      "58.8\n",
      "98.0\n",
      "89.5\n",
      "95.4\n",
      "84.0\n",
      "100.0\n",
      "78.9\n",
      "83.4\n",
      "95.8\n",
      "98.0\n",
      "99.9\n",
      "75.3\n",
      "82.0\n",
      "62.7\n",
      "81.7\n",
      "71.2\n",
      "84.0\n",
      "99.0\n",
      "40.6\n",
      "98.9\n",
      "97.7\n",
      "73.0\n",
      "69.4\n",
      "74.0\n",
      "61.9\n",
      "43.5\n",
      "98.9\n",
      "51.2\n",
      "95.6\n",
      "92.0\n",
      "91.9\n",
      "47.8\n",
      "83.4\n",
      "97.8\n",
      "99.9\n",
      "96.7\n",
      "47.9\n",
      "79.7\n",
      "95.8\n",
      "96.8\n",
      "87.6\n",
      "92.0\n",
      "63.9\n",
      "97.4\n",
      "71.4\n",
      "92.0\n",
      "99.9\n",
      "98.9\n",
      "78.4\n",
      "84.2\n",
      "91.7\n",
      "55.2\n",
      "95.3\n",
      "34.0\n",
      "93.4\n",
      "63.1\n",
      "95.1\n",
      "39.5\n",
      "97.3\n",
      "63.9\n",
      "87.3\n",
      "71.4\n",
      "87.6\n",
      "58.3\n",
      "71.6\n",
      "97.0\n",
      "63.7\n",
      "78.7\n",
      "23.3\n",
      "79.2\n",
      "97.9\n",
      "89.6\n",
      "89.6\n",
      "78.0\n",
      "11.0\n",
      "96.0\n",
      "93.1\n",
      "94.1\n",
      "94.8\n",
      "63.2\n",
      "97.3\n",
      "90.0\n",
      "96.7\n",
      "80.9\n",
      "97.0\n",
      "90.7\n",
      "94.9\n",
      "95.4\n",
      "76.4\n",
      "83.5\n",
      "75.8\n",
      "95.8\n",
      "87.0\n",
      "91.1\n",
      "63.8\n",
      "96.9\n",
      "44.5\n",
      "81.5\n",
      "96.9\n",
      "81.8\n",
      "49.4\n",
      "81.3\n",
      "96.8\n",
      "96.7\n",
      "95.0\n",
      "97.9\n",
      "57.3\n",
      "56.1\n",
      "93.1\n",
      "88.1\n",
      "97.0\n",
      "59.4\n",
      "93.8\n",
      "90.5\n",
      "84.0\n",
      "69.1\n",
      "66.3\n",
      "98.8\n",
      "99.8\n",
      "99.0\n",
      "98.7\n",
      "97.0\n",
      "85.9\n",
      "98.3\n",
      "99.2\n",
      "62.2\n",
      "73.5\n",
      "99.9\n",
      "95.8\n",
      "97.2\n",
      "84.1\n",
      "100.0\n",
      "74.8\n",
      "77.4\n",
      "100.0\n",
      "88.9\n",
      "100.0\n",
      "100.0\n",
      "98.1\n",
      "98.3\n",
      "92.8\n",
      "96.9\n",
      "78.9\n",
      "55.3\n",
      "54.3\n",
      "98.1\n",
      "91.2\n",
      "95.1\n",
      "67.1\n",
      "98.0\n",
      "97.0\n",
      "100.0\n",
      "99.6\n",
      "74.8\n",
      "98.9\n",
      "100.0\n",
      "100.0\n",
      "79.3\n",
      "87.2\n",
      "96.4\n",
      "74.8\n",
      "99.1\n",
      "99.3\n",
      "91.6\n",
      "99.8\n",
      "58.5\n",
      "92.9\n",
      "55.3\n",
      "100.0\n",
      "88.9\n",
      "47.1\n",
      "81.4\n",
      "100.0\n",
      "100.0\n",
      "96.9\n",
      "95.4\n",
      "99.9\n",
      "99.9\n",
      "99.8\n",
      "100.0\n",
      "96.8\n",
      "92.4\n",
      "73.8\n",
      "57.1\n",
      "99.3\n",
      "98.4\n",
      "99.4\n",
      "82.9\n",
      "98.9\n",
      "56.1\n",
      "100.0\n",
      "97.5\n",
      "60.3\n",
      "99.4\n",
      "98.3\n",
      "100.0\n",
      "95.1\n",
      "96.9\n",
      "100.0\n",
      "86.0\n",
      "100.0\n",
      "89.9\n",
      "39.7\n",
      "98.0\n",
      "72.0\n",
      "100.0\n",
      "100.0\n",
      "97.0\n",
      "99.9\n",
      "99.9\n",
      "100.0\n",
      "100.0\n",
      "57.1\n",
      "74.8\n",
      "64.3\n",
      "65.5\n",
      "95.3\n",
      "93.8\n",
      "93.9\n",
      "99.4\n",
      "98.4\n",
      "72.0\n",
      "64.7\n",
      "98.8\n",
      "81.0\n",
      "80.0\n",
      "100.0\n",
      "65.3\n",
      "72.0\n",
      "100.0\n",
      "99.6\n",
      "99.5\n",
      "99.6\n",
      "75.5\n",
      "36.2\n",
      "100.0\n",
      "65.8\n",
      "40.0\n",
      "94.0\n",
      "71.9\n",
      "100.0\n",
      "41.0\n",
      "41.0\n",
      "51.6\n",
      "36.0\n",
      "48.9\n",
      "100.0\n",
      "55.0\n",
      "53.3\n",
      "34.0\n",
      "87.4\n",
      "42.6\n",
      "63.0\n",
      "100.0\n",
      "63.6\n",
      "94.7\n",
      "48.9\n",
      "84.2\n",
      "97.1\n",
      "96.9\n",
      "98.3\n",
      "93.2\n",
      "86.0\n",
      "99.9\n",
      "45.1\n",
      "64.3\n",
      "92.7\n",
      "60.8\n",
      "45.5\n",
      "88.9\n",
      "100.0\n",
      "95.8\n",
      "99.9\n",
      "86.6\n",
      "54.7\n",
      "48.9\n",
      "77.8\n",
      "85.0\n",
      "80.8\n",
      "67.1\n",
      "68.1\n",
      "63.5\n",
      "59.6\n",
      "80.8\n",
      "80.8\n",
      "66.6\n",
      "76.1\n",
      "70.0\n",
      "80.5\n",
      "43.3\n",
      "72.3\n",
      "60.7\n",
      "48.7\n",
      "96.4\n",
      "96.4\n",
      "95.7\n",
      "58.6\n",
      "73.8\n",
      "65.5\n",
      "95.7\n",
      "65.5\n",
      "73.1\n",
      "89.6\n",
      "99.2\n",
      "99.2\n",
      "74.6\n",
      "75.9\n",
      "74.6\n",
      "64.6\n",
      "76.7\n",
      "76.7\n",
      "65.2\n",
      "52.2\n",
      "78.3\n",
      "69.1\n",
      "99.4\n",
      "66.7\n",
      "50.1\n",
      "65.2\n",
      "67.9\n",
      "67.9\n",
      "74.7\n",
      "61.0\n",
      "79.0\n",
      "26.5\n",
      "9.0\n",
      "73.5\n",
      "29.2\n",
      "9.0\n",
      "22.0\n",
      "93.3\n",
      "81.2\n",
      "55.9\n",
      "55.9\n",
      "59.9\n",
      "57.9\n",
      "78.9\n",
      "70.0\n",
      "78.9\n",
      "70.1\n",
      "68.1\n",
      "75.8\n",
      "64.5\n",
      "62.8\n",
      "64.0\n",
      "89.9\n",
      "67.9\n",
      "86.4\n",
      "77.0\n",
      "82.0\n",
      "90.7\n",
      "88.5\n",
      "89.5\n",
      "79.3\n",
      "88.7\n",
      "76.0\n",
      "92.1\n",
      "86.3\n",
      "93.0\n",
      "55.3\n",
      "81.7\n",
      "99.0\n",
      "77.5\n",
      "77.5\n",
      "71.1\n",
      "68.1\n",
      "80.4\n",
      "79.5\n",
      "90.3\n",
      "99.2\n",
      "99.2\n",
      "49.0\n",
      "87.1\n",
      "99.4\n",
      "69.0\n",
      "83.1\n",
      "70.0\n",
      "72.3\n",
      "94.1\n",
      "99.2\n",
      "99.7\n",
      "90.6\n",
      "95.8\n",
      "92.7\n",
      "99.8\n",
      "100.0\n",
      "96.8\n",
      "92.7\n",
      "87.0\n",
      "70.0\n",
      "83.0\n",
      "82.3\n",
      "81.0\n",
      "71.4\n",
      "84.1\n",
      "83.8\n",
      "61.5\n",
      "53.3\n",
      "46.3\n",
      "84.1\n",
      "64.3\n",
      "67.0\n",
      "54.0\n",
      "99.4\n",
      "71.0\n",
      "79.3\n",
      "93.1\n",
      "93.1\n",
      "72.8\n",
      "84.3\n",
      "84.0\n",
      "85.0\n",
      "89.0\n",
      "98.1\n",
      "67.3\n",
      "82.7\n",
      "98.1\n",
      "82.8\n",
      "97.8\n",
      "40.1\n",
      "40.3\n",
      "40.9\n",
      "33.5\n",
      "6.9\n",
      "46.2\n",
      "69.7\n",
      "89.2\n",
      "99.4\n",
      "97.0\n",
      "84.2\n",
      "75.7\n",
      "99.5\n",
      "99.6\n",
      "99.5\n",
      "98.7\n",
      "96.9\n",
      "76.7\n",
      "65.2\n",
      "58.4\n",
      "53.5\n",
      "50.0\n",
      "57.2\n",
      "84.2\n",
      "60.7\n",
      "59.7\n",
      "49.1\n",
      "80.7\n",
      "96.4\n",
      "60.1\n",
      "60.8\n",
      "96.4\n",
      "95.0\n",
      "97.1\n",
      "97.1\n",
      "54.9\n",
      "81.2\n",
      "84.7\n",
      "55.8\n",
      "97.2\n",
      "79.0\n",
      "97.3\n",
      "92.9\n",
      "86.3\n",
      "85.5\n",
      "97.3\n",
      "91.0\n",
      "58.3\n",
      "77.1\n",
      "77.1\n",
      "68.3\n",
      "35.2\n",
      "38.6\n",
      "52.2\n",
      "77.0\n",
      "55.3\n",
      "98.5\n",
      "79.9\n",
      "62.8\n",
      "92.6\n",
      "39.9\n",
      "66.3\n",
      "79.1\n",
      "95.9\n",
      "82.0\n",
      "82.0\n",
      "82.0\n",
      "82.0\n",
      "82.0\n",
      "82.0\n",
      "82.0\n",
      "82.0\n",
      "82.0\n",
      "82.0\n",
      "82.0\n",
      "82.0\n",
      "82.0\n",
      "82.0\n",
      "82.0\n",
      "82.0\n",
      "82.0\n",
      "82.0\n",
      "82.0\n",
      "82.0\n",
      "82.0\n",
      "82.0\n",
      "82.0\n"
     ]
    }
   ],
   "source": [
    "for idx, example in enumerate(list_of_examples):\n",
    "#     print('here')\n",
    "    print(list_of_examples[idx][21][6])\n",
    "    list_of_examples[idx][21] = [list_of_examples[idx][21][6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(522, 22, 7)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_examples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[3.6000e+01, 7.3000e+00, 4.2800e+02, ..., 2.0000e+00,\n",
       "         1.0900e+01, 9.7000e+01],\n",
       "        [3.6000e+01, 7.3000e+00, 9.5500e+02, ..., 2.0000e+00,\n",
       "         1.0900e+01, 9.6900e+01],\n",
       "        [3.6000e+01, 7.3000e+00, 9.5500e+02, ..., 2.0000e+00,\n",
       "         1.0900e+01, 9.6900e+01],\n",
       "        ...,\n",
       "        [3.6300e+01, 7.3000e+00, 3.6900e+02, ..., 2.0000e+00,\n",
       "         9.7000e+00, 8.6000e+01],\n",
       "        [3.6300e+01, 7.3000e+00, 3.6900e+02, ..., 2.0000e+00,\n",
       "         9.7000e+00, 8.6000e+01],\n",
       "        [8.6000e+01, 8.6000e+01, 8.6000e+01, ..., 8.6000e+01,\n",
       "         8.6000e+01, 8.6000e+01]],\n",
       "\n",
       "       [[3.6000e+01, 6.4000e+00, 4.1700e+02, ..., 2.0000e+00,\n",
       "         6.6000e+00, 8.3900e+01],\n",
       "        [3.6000e+01, 3.0000e+00, 3.5100e+02, ..., 2.0000e+00,\n",
       "         6.6000e+00, 7.0900e+01],\n",
       "        [3.6000e+01, 3.0000e+00, 3.5100e+02, ..., 2.0000e+00,\n",
       "         6.6000e+00, 7.0900e+01],\n",
       "        ...,\n",
       "        [3.2700e+01, 2.9000e+00, 6.2300e+02, ..., 2.0000e+00,\n",
       "         6.6000e+00, 5.5700e+01],\n",
       "        [3.2700e+01, 2.9000e+00, 6.2300e+02, ..., 2.0000e+00,\n",
       "         6.6000e+00, 5.5700e+01],\n",
       "        [5.5700e+01, 5.5700e+01, 5.5700e+01, ..., 5.5700e+01,\n",
       "         5.5700e+01, 5.5700e+01]],\n",
       "\n",
       "       [[3.6000e+01, 4.0000e+00, 1.8360e+03, ..., 2.0000e+00,\n",
       "         7.6000e+00, 8.2000e+01],\n",
       "        [3.6000e+01, 4.0000e+00, 1.4590e+03, ..., 2.0000e+00,\n",
       "         7.7000e+00, 8.4300e+01],\n",
       "        [3.6000e+01, 4.0000e+00, 1.4590e+03, ..., 2.0000e+00,\n",
       "         7.7000e+00, 8.4300e+01],\n",
       "        ...,\n",
       "        [2.7200e+01, 3.4000e+00, 1.4460e+03, ..., 2.0000e+00,\n",
       "         7.7000e+00, 5.0200e+01],\n",
       "        [2.7200e+01, 3.4000e+00, 1.4460e+03, ..., 2.0000e+00,\n",
       "         7.7000e+00, 5.0200e+01],\n",
       "        [5.0200e+01, 5.0200e+01, 5.0200e+01, ..., 5.0200e+01,\n",
       "         5.0200e+01, 5.0200e+01]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[8.7300e+01, 3.5100e+01, 3.8400e+04, ..., 0.0000e+00,\n",
       "         2.2500e+01, 8.2000e+01],\n",
       "        [8.7300e+01, 3.5100e+01, 3.8000e+04, ..., 0.0000e+00,\n",
       "         2.2500e+01, 8.2000e+01],\n",
       "        [8.7300e+01, 3.5100e+01, 3.8000e+04, ..., 0.0000e+00,\n",
       "         2.2500e+01, 8.2000e+01],\n",
       "        ...,\n",
       "        [8.7300e+01, 3.5100e+01, 3.8000e+04, ..., 0.0000e+00,\n",
       "         2.2500e+01, 8.2000e+01],\n",
       "        [8.7300e+01, 3.5100e+01, 3.8000e+04, ..., 0.0000e+00,\n",
       "         2.2500e+01, 8.2000e+01],\n",
       "        [8.2000e+01, 8.2000e+01, 8.2000e+01, ..., 8.2000e+01,\n",
       "         8.2000e+01, 8.2000e+01]],\n",
       "\n",
       "       [[8.7300e+01, 2.0700e+01, 1.0500e+04, ..., 0.0000e+00,\n",
       "         1.2900e+01, 8.2000e+01],\n",
       "        [8.7300e+01, 2.0700e+01, 3.2904e+04, ..., 0.0000e+00,\n",
       "         1.2900e+01, 8.2000e+01],\n",
       "        [8.7300e+01, 2.0700e+01, 3.2904e+04, ..., 0.0000e+00,\n",
       "         1.2900e+01, 8.2000e+01],\n",
       "        ...,\n",
       "        [8.7300e+01, 2.1300e+01, 3.5800e+04, ..., 0.0000e+00,\n",
       "         1.2200e+01, 8.2000e+01],\n",
       "        [8.7300e+01, 2.1300e+01, 3.5800e+04, ..., 0.0000e+00,\n",
       "         1.2200e+01, 8.2000e+01],\n",
       "        [8.2000e+01, 8.2000e+01, 8.2000e+01, ..., 8.2000e+01,\n",
       "         8.2000e+01, 8.2000e+01]],\n",
       "\n",
       "       [[8.7300e+01, 2.8000e+01, 2.1800e+04, ..., 0.0000e+00,\n",
       "         1.1500e+01, 8.2000e+01],\n",
       "        [8.7300e+01, 2.8000e+01, 2.5600e+04, ..., 0.0000e+00,\n",
       "         1.1500e+01, 8.2000e+01],\n",
       "        [8.7300e+01, 2.8000e+01, 2.5600e+04, ..., 0.0000e+00,\n",
       "         1.1500e+01, 8.2000e+01],\n",
       "        ...,\n",
       "        [8.7300e+01, 2.8000e+01, 3.2300e+04, ..., 0.0000e+00,\n",
       "         1.1600e+01, 8.2000e+01],\n",
       "        [8.7300e+01, 2.8000e+01, 3.2300e+04, ..., 0.0000e+00,\n",
       "         1.1600e+01, 8.2000e+01],\n",
       "        [8.2000e+01, 8.2000e+01, 8.2000e+01, ..., 8.2000e+01,\n",
       "         8.2000e+01, 8.2000e+01]]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_examples.astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([86., 86., 86., 86., 86., 86., 86.])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_examples[0][21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "n_train_periods = 300\n",
    "train = list_of_examples[:n_train_periods, :]\n",
    "test = list_of_examples[n_train_periods:, :]\n",
    "\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1, 1:], train[:, -1, 0]\n",
    "test_X, test_y = test[:, :-1, 1:], test[:, -1, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_X: (300, 21, 6)\n",
      "Shape of train_y: (300,)\n",
      "Shape of test_X: (222, 21, 6)\n",
      "Shape of test_y: (222,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of train_X: \" + str(train_X.shape))\n",
    "print(\"Shape of train_y: \" + str(train_y.shape))\n",
    "print(\"Shape of test_X: \" + str(test_X.shape))\n",
    "print(\"Shape of test_y: \" + str(test_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.800e+01, 5.350e+02, 1.990e+03, 2.000e+00, 1.230e+01, 9.990e+01],\n",
       "       [2.800e+01, 2.218e+03, 1.990e+03, 2.000e+00, 1.230e+01, 9.950e+01],\n",
       "       [2.800e+01, 2.218e+03, 1.990e+03, 2.000e+00, 1.230e+01, 9.950e+01],\n",
       "       [2.800e+01, 2.218e+03, 1.990e+03, 2.000e+00, 1.230e+01, 9.950e+01],\n",
       "       [2.710e+01, 2.218e+03, 1.990e+03, 2.000e+00, 1.230e+01, 9.950e+01],\n",
       "       [2.700e+01, 2.218e+03, 1.990e+03, 2.000e+00, 1.230e+01, 9.950e+01],\n",
       "       [2.710e+01, 2.218e+03, 1.990e+03, 2.000e+00, 1.230e+01, 9.950e+01],\n",
       "       [2.710e+01, 3.713e+03, 1.990e+03, 2.000e+00, 1.230e+01, 9.910e+01],\n",
       "       [2.710e+01, 3.713e+03, 1.990e+03, 2.000e+00, 1.230e+01, 9.910e+01],\n",
       "       [2.710e+01, 3.713e+03, 1.990e+03, 2.000e+00, 1.230e+01, 9.910e+01],\n",
       "       [2.710e+01, 3.713e+03, 1.990e+03, 2.000e+00, 1.230e+01, 9.910e+01],\n",
       "       [2.710e+01, 3.713e+03, 1.990e+03, 2.000e+00, 1.230e+01, 9.910e+01],\n",
       "       [2.710e+01, 3.713e+03, 1.990e+03, 2.000e+00, 1.230e+01, 9.910e+01],\n",
       "       [2.710e+01, 3.371e+03, 1.990e+03, 2.000e+00, 1.230e+01, 9.920e+01],\n",
       "       [2.710e+01, 3.371e+03, 1.990e+03, 2.000e+00, 1.230e+01, 9.920e+01],\n",
       "       [2.700e+01, 3.371e+03, 1.990e+03, 2.000e+00, 1.230e+01, 9.920e+01],\n",
       "       [2.700e+01, 3.119e+03, 1.990e+03, 2.000e+00, 1.230e+01, 9.930e+01],\n",
       "       [2.700e+01, 3.119e+03, 1.990e+03, 2.000e+00, 1.230e+01, 9.930e+01],\n",
       "       [2.700e+01, 3.119e+03, 1.990e+03, 2.000e+00, 1.230e+01, 9.930e+01],\n",
       "       [2.700e+01, 3.119e+03, 1.990e+03, 2.000e+00, 1.230e+01, 9.930e+01],\n",
       "       [2.700e+01, 3.119e+03, 1.990e+03, 2.000e+00, 1.230e+01, 9.930e+01]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.4600e+01, 1.0550e+04, 1.9310e+03, 2.0000e+00, 9.1000e+00,\n",
       "        5.8200e+01],\n",
       "       [1.4600e+01, 1.3464e+04, 1.9310e+03, 2.0000e+00, 9.1000e+00,\n",
       "        5.7700e+01],\n",
       "       [1.4600e+01, 1.3464e+04, 1.9310e+03, 2.0000e+00, 9.1000e+00,\n",
       "        5.7700e+01],\n",
       "       [1.4600e+01, 1.3464e+04, 1.9310e+03, 2.0000e+00, 9.1000e+00,\n",
       "        5.7700e+01],\n",
       "       [1.4600e+01, 1.3857e+04, 1.9310e+03, 2.0000e+00, 9.1000e+00,\n",
       "        5.7600e+01],\n",
       "       [1.5000e+01, 1.3857e+04, 1.9310e+03, 2.0000e+00, 9.1000e+00,\n",
       "        4.5400e+01],\n",
       "       [1.5000e+01, 1.3857e+04, 1.9310e+03, 2.0000e+00, 9.1000e+00,\n",
       "        4.5400e+01],\n",
       "       [1.5000e+01, 1.2767e+04, 1.9310e+03, 2.0000e+00, 9.1000e+00,\n",
       "        4.5600e+01],\n",
       "       [1.4500e+01, 1.2767e+04, 1.9310e+03, 2.0000e+00, 9.1000e+00,\n",
       "        4.5600e+01],\n",
       "       [1.4500e+01, 1.3750e+04, 1.9310e+03, 2.0000e+00, 9.1000e+00,\n",
       "        4.5400e+01],\n",
       "       [1.4500e+01, 1.3750e+04, 1.9310e+03, 2.0000e+00, 9.1000e+00,\n",
       "        4.5400e+01],\n",
       "       [1.4700e+01, 2.6200e+04, 1.9310e+03, 2.0000e+00, 8.2000e+00,\n",
       "        4.3900e+01],\n",
       "       [1.4700e+01, 1.3100e+04, 1.9310e+03, 2.0000e+00, 8.2000e+00,\n",
       "        4.5500e+01],\n",
       "       [1.4700e+01, 1.3100e+04, 1.9310e+03, 2.0000e+00, 8.6000e+00,\n",
       "        6.2100e+01],\n",
       "       [1.4700e+01, 1.3100e+04, 1.9310e+03, 2.0000e+00, 8.6000e+00,\n",
       "        6.2100e+01],\n",
       "       [1.4700e+01, 1.3100e+04, 1.9310e+03, 2.0000e+00, 8.7000e+00,\n",
       "        6.9100e+01],\n",
       "       [1.4700e+01, 1.3100e+04, 1.9310e+03, 2.0000e+00, 8.7000e+00,\n",
       "        6.9100e+01],\n",
       "       [1.4700e+01, 1.3000e+04, 1.9310e+03, 2.0000e+00, 8.7000e+00,\n",
       "        6.9100e+01],\n",
       "       [1.4700e+01, 1.3000e+04, 1.9310e+03, 2.0000e+00, 8.7000e+00,\n",
       "        6.9100e+01],\n",
       "       [1.5200e+01, 1.3000e+04, 1.9310e+03, 2.0000e+00, 8.7000e+00,\n",
       "        6.9100e+01],\n",
       "       [1.5200e+01, 1.3000e+04, 1.9310e+03, 2.0000e+00, 8.7000e+00,\n",
       "        6.9100e+01]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X[30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "lstm_model = tf.keras.models.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "    tf.keras.layers.LSTM(50, dropout=0.2, recurrent_dropout=0.2, input_shape=(train_X.shape[1], train_X.shape[2])),\n",
    "    tf.keras.layers.Dense(units=32),\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.compile(loss='mae', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "5/5 - 0s - loss: 82.3491 - val_loss: 76.0591\n",
      "Epoch 2/1000\n",
      "5/5 - 0s - loss: 81.8622 - val_loss: 75.6672\n",
      "Epoch 3/1000\n",
      "5/5 - 0s - loss: 81.3985 - val_loss: 75.2834\n",
      "Epoch 4/1000\n",
      "5/5 - 0s - loss: 80.9772 - val_loss: 74.8738\n",
      "Epoch 5/1000\n",
      "5/5 - 0s - loss: 80.4692 - val_loss: 74.3910\n",
      "Epoch 6/1000\n",
      "5/5 - 0s - loss: 80.0571 - val_loss: 73.9313\n",
      "Epoch 7/1000\n",
      "5/5 - 0s - loss: 79.4469 - val_loss: 73.3435\n",
      "Epoch 8/1000\n",
      "5/5 - 0s - loss: 78.7353 - val_loss: 72.6187\n",
      "Epoch 9/1000\n",
      "5/5 - 0s - loss: 77.9752 - val_loss: 71.8518\n",
      "Epoch 10/1000\n",
      "5/5 - 0s - loss: 77.1535 - val_loss: 71.1017\n",
      "Epoch 11/1000\n",
      "5/5 - 0s - loss: 76.1665 - val_loss: 69.7630\n",
      "Epoch 12/1000\n",
      "5/5 - 0s - loss: 75.0166 - val_loss: 68.4342\n",
      "Epoch 13/1000\n",
      "5/5 - 0s - loss: 73.6643 - val_loss: 66.7211\n",
      "Epoch 14/1000\n",
      "5/5 - 0s - loss: 71.8561 - val_loss: 65.4150\n",
      "Epoch 15/1000\n",
      "5/5 - 0s - loss: 69.9034 - val_loss: 63.9877\n",
      "Epoch 16/1000\n",
      "5/5 - 0s - loss: 67.9349 - val_loss: 62.1610\n",
      "Epoch 17/1000\n",
      "5/5 - 0s - loss: 65.9075 - val_loss: 60.4708\n",
      "Epoch 18/1000\n",
      "5/5 - 0s - loss: 63.6432 - val_loss: 58.7011\n",
      "Epoch 19/1000\n",
      "5/5 - 0s - loss: 61.2594 - val_loss: 56.8699\n",
      "Epoch 20/1000\n",
      "5/5 - 0s - loss: 58.4698 - val_loss: 54.5574\n",
      "Epoch 21/1000\n",
      "5/5 - 0s - loss: 55.7175 - val_loss: 51.9736\n",
      "Epoch 22/1000\n",
      "5/5 - 0s - loss: 53.0040 - val_loss: 49.1407\n",
      "Epoch 23/1000\n",
      "5/5 - 0s - loss: 49.6815 - val_loss: 46.5337\n",
      "Epoch 24/1000\n",
      "5/5 - 0s - loss: 46.6223 - val_loss: 43.5129\n",
      "Epoch 25/1000\n",
      "5/5 - 0s - loss: 43.2808 - val_loss: 40.1539\n",
      "Epoch 26/1000\n",
      "5/5 - 0s - loss: 39.1718 - val_loss: 36.2499\n",
      "Epoch 27/1000\n",
      "5/5 - 0s - loss: 35.1717 - val_loss: 32.9487\n",
      "Epoch 28/1000\n",
      "5/5 - 0s - loss: 32.0425 - val_loss: 29.3393\n",
      "Epoch 29/1000\n",
      "5/5 - 0s - loss: 28.1183 - val_loss: 25.9542\n",
      "Epoch 30/1000\n",
      "5/5 - 0s - loss: 25.2817 - val_loss: 23.1630\n",
      "Epoch 31/1000\n",
      "5/5 - 0s - loss: 23.3425 - val_loss: 20.9249\n",
      "Epoch 32/1000\n",
      "5/5 - 0s - loss: 20.7452 - val_loss: 18.7945\n",
      "Epoch 33/1000\n",
      "5/5 - 0s - loss: 19.1996 - val_loss: 17.2512\n",
      "Epoch 34/1000\n",
      "5/5 - 0s - loss: 18.0230 - val_loss: 16.4498\n",
      "Epoch 35/1000\n",
      "5/5 - 0s - loss: 16.9502 - val_loss: 16.0035\n",
      "Epoch 36/1000\n",
      "5/5 - 0s - loss: 16.3663 - val_loss: 15.6405\n",
      "Epoch 37/1000\n",
      "5/5 - 0s - loss: 15.8206 - val_loss: 14.9919\n",
      "Epoch 38/1000\n",
      "5/5 - 0s - loss: 15.3806 - val_loss: 14.8143\n",
      "Epoch 39/1000\n",
      "5/5 - 0s - loss: 14.8820 - val_loss: 14.8300\n",
      "Epoch 40/1000\n",
      "5/5 - 0s - loss: 14.6240 - val_loss: 14.8990\n",
      "Epoch 41/1000\n",
      "5/5 - 0s - loss: 14.7516 - val_loss: 15.3955\n",
      "Epoch 42/1000\n",
      "5/5 - 0s - loss: 14.7782 - val_loss: 15.5731\n",
      "Epoch 43/1000\n",
      "5/5 - 0s - loss: 15.2199 - val_loss: 15.7136\n",
      "Epoch 44/1000\n",
      "5/5 - 0s - loss: 14.3004 - val_loss: 15.8135\n",
      "Epoch 45/1000\n",
      "5/5 - 0s - loss: 14.5223 - val_loss: 15.5978\n",
      "Epoch 46/1000\n",
      "5/5 - 0s - loss: 15.1889 - val_loss: 15.4367\n",
      "Epoch 47/1000\n",
      "5/5 - 0s - loss: 15.0750 - val_loss: 15.3564\n",
      "Epoch 48/1000\n",
      "5/5 - 0s - loss: 14.8855 - val_loss: 15.2188\n",
      "Epoch 49/1000\n",
      "5/5 - 0s - loss: 14.6027 - val_loss: 15.1431\n",
      "Epoch 50/1000\n",
      "5/5 - 0s - loss: 14.6126 - val_loss: 15.0817\n",
      "Epoch 51/1000\n",
      "5/5 - 0s - loss: 14.5849 - val_loss: 15.1544\n",
      "Epoch 52/1000\n",
      "5/5 - 0s - loss: 14.9742 - val_loss: 15.2967\n",
      "Epoch 53/1000\n",
      "5/5 - 0s - loss: 14.8325 - val_loss: 15.5099\n",
      "Epoch 54/1000\n",
      "5/5 - 0s - loss: 14.4437 - val_loss: 15.5238\n",
      "Epoch 55/1000\n",
      "5/5 - 0s - loss: 14.5562 - val_loss: 15.5635\n",
      "Epoch 56/1000\n",
      "5/5 - 0s - loss: 14.7241 - val_loss: 15.6135\n",
      "Epoch 57/1000\n",
      "5/5 - 0s - loss: 14.5541 - val_loss: 15.6659\n",
      "Epoch 58/1000\n",
      "5/5 - 0s - loss: 14.5550 - val_loss: 15.6684\n",
      "Epoch 59/1000\n",
      "5/5 - 0s - loss: 14.5382 - val_loss: 15.3765\n",
      "Epoch 60/1000\n",
      "5/5 - 0s - loss: 14.3866 - val_loss: 15.4336\n",
      "Epoch 61/1000\n",
      "5/5 - 0s - loss: 14.7252 - val_loss: 15.4490\n",
      "Epoch 62/1000\n",
      "5/5 - 0s - loss: 14.4674 - val_loss: 15.5018\n",
      "Epoch 63/1000\n",
      "5/5 - 0s - loss: 14.3144 - val_loss: 15.2334\n",
      "Epoch 64/1000\n",
      "5/5 - 0s - loss: 14.8022 - val_loss: 15.1561\n",
      "Epoch 65/1000\n",
      "5/5 - 0s - loss: 14.6532 - val_loss: 15.0594\n",
      "Epoch 66/1000\n",
      "5/5 - 0s - loss: 14.2383 - val_loss: 15.0538\n",
      "Epoch 67/1000\n",
      "5/5 - 0s - loss: 14.5896 - val_loss: 15.0281\n",
      "Epoch 68/1000\n",
      "5/5 - 0s - loss: 14.4334 - val_loss: 14.9981\n",
      "Epoch 69/1000\n",
      "5/5 - 0s - loss: 14.4295 - val_loss: 15.0476\n",
      "Epoch 70/1000\n",
      "5/5 - 0s - loss: 13.8948 - val_loss: 15.0728\n",
      "Epoch 71/1000\n",
      "5/5 - 0s - loss: 14.0370 - val_loss: 15.0978\n",
      "Epoch 72/1000\n",
      "5/5 - 0s - loss: 14.2658 - val_loss: 15.1786\n",
      "Epoch 73/1000\n",
      "5/5 - 0s - loss: 14.3067 - val_loss: 15.2401\n",
      "Epoch 74/1000\n",
      "5/5 - 0s - loss: 14.4913 - val_loss: 15.2884\n",
      "Epoch 75/1000\n",
      "5/5 - 0s - loss: 14.5289 - val_loss: 15.3630\n",
      "Epoch 76/1000\n",
      "5/5 - 0s - loss: 14.3921 - val_loss: 15.3400\n",
      "Epoch 77/1000\n",
      "5/5 - 0s - loss: 14.2024 - val_loss: 15.3760\n",
      "Epoch 78/1000\n",
      "5/5 - 0s - loss: 13.8245 - val_loss: 15.2816\n",
      "Epoch 79/1000\n",
      "5/5 - 0s - loss: 13.9365 - val_loss: 15.2056\n",
      "Epoch 80/1000\n",
      "5/5 - 0s - loss: 13.9810 - val_loss: 15.1396\n",
      "Epoch 81/1000\n",
      "5/5 - 0s - loss: 14.3348 - val_loss: 15.0144\n",
      "Epoch 82/1000\n",
      "5/5 - 0s - loss: 14.4040 - val_loss: 15.4315\n",
      "Epoch 83/1000\n",
      "5/5 - 0s - loss: 14.0833 - val_loss: 15.5199\n",
      "Epoch 84/1000\n",
      "5/5 - 0s - loss: 14.1516 - val_loss: 15.5635\n",
      "Epoch 85/1000\n",
      "5/5 - 0s - loss: 13.7411 - val_loss: 15.4405\n",
      "Epoch 86/1000\n",
      "5/5 - 0s - loss: 13.7978 - val_loss: 15.3367\n",
      "Epoch 87/1000\n",
      "5/5 - 0s - loss: 13.9525 - val_loss: 15.1288\n",
      "Epoch 88/1000\n",
      "5/5 - 0s - loss: 14.0502 - val_loss: 15.1381\n",
      "Epoch 89/1000\n",
      "5/5 - 0s - loss: 13.7137 - val_loss: 14.9598\n",
      "Epoch 90/1000\n",
      "5/5 - 0s - loss: 13.7587 - val_loss: 14.9585\n",
      "Epoch 91/1000\n",
      "5/5 - 0s - loss: 13.5223 - val_loss: 14.8973\n",
      "Epoch 92/1000\n",
      "5/5 - 0s - loss: 13.6234 - val_loss: 14.9494\n",
      "Epoch 93/1000\n",
      "5/5 - 0s - loss: 14.0257 - val_loss: 15.0195\n",
      "Epoch 94/1000\n",
      "5/5 - 0s - loss: 13.6772 - val_loss: 15.1140\n",
      "Epoch 95/1000\n",
      "5/5 - 0s - loss: 13.9473 - val_loss: 15.1163\n",
      "Epoch 96/1000\n",
      "5/5 - 0s - loss: 13.7208 - val_loss: 15.1300\n",
      "Epoch 97/1000\n",
      "5/5 - 0s - loss: 13.7476 - val_loss: 15.1827\n",
      "Epoch 98/1000\n",
      "5/5 - 0s - loss: 13.9375 - val_loss: 15.2524\n",
      "Epoch 99/1000\n",
      "5/5 - 0s - loss: 13.9025 - val_loss: 15.4035\n",
      "Epoch 100/1000\n",
      "5/5 - 0s - loss: 13.6517 - val_loss: 15.3824\n",
      "Epoch 101/1000\n",
      "5/5 - 0s - loss: 13.8594 - val_loss: 15.2444\n",
      "Epoch 102/1000\n",
      "5/5 - 0s - loss: 13.8887 - val_loss: 15.4662\n",
      "Epoch 103/1000\n",
      "5/5 - 0s - loss: 13.4944 - val_loss: 15.5214\n",
      "Epoch 104/1000\n",
      "5/5 - 0s - loss: 13.5727 - val_loss: 15.5548\n",
      "Epoch 105/1000\n",
      "5/5 - 0s - loss: 13.6020 - val_loss: 15.3695\n",
      "Epoch 106/1000\n",
      "5/5 - 0s - loss: 13.4827 - val_loss: 15.6828\n",
      "Epoch 107/1000\n",
      "5/5 - 0s - loss: 13.2119 - val_loss: 15.2833\n",
      "Epoch 108/1000\n",
      "5/5 - 0s - loss: 13.5503 - val_loss: 15.1225\n",
      "Epoch 109/1000\n",
      "5/5 - 0s - loss: 13.5821 - val_loss: 15.0679\n",
      "Epoch 110/1000\n",
      "5/5 - 0s - loss: 13.5948 - val_loss: 15.1367\n",
      "Epoch 111/1000\n",
      "5/5 - 0s - loss: 13.3629 - val_loss: 15.3278\n",
      "Epoch 112/1000\n",
      "5/5 - 0s - loss: 13.1250 - val_loss: 15.4685\n",
      "Epoch 113/1000\n",
      "5/5 - 0s - loss: 13.3953 - val_loss: 15.5159\n",
      "Epoch 114/1000\n",
      "5/5 - 0s - loss: 13.4190 - val_loss: 15.5579\n",
      "Epoch 115/1000\n",
      "5/5 - 0s - loss: 13.3951 - val_loss: 15.1271\n",
      "Epoch 116/1000\n",
      "5/5 - 0s - loss: 13.2386 - val_loss: 15.5200\n",
      "Epoch 117/1000\n",
      "5/5 - 0s - loss: 13.4011 - val_loss: 15.6829\n",
      "Epoch 118/1000\n",
      "5/5 - 0s - loss: 13.4701 - val_loss: 15.6959\n",
      "Epoch 119/1000\n",
      "5/5 - 0s - loss: 13.1231 - val_loss: 15.6870\n",
      "Epoch 120/1000\n",
      "5/5 - 0s - loss: 13.1731 - val_loss: 15.7381\n",
      "Epoch 121/1000\n",
      "5/5 - 0s - loss: 13.6106 - val_loss: 15.8289\n",
      "Epoch 122/1000\n",
      "5/5 - 0s - loss: 13.2444 - val_loss: 15.9094\n",
      "Epoch 123/1000\n",
      "5/5 - 0s - loss: 12.9988 - val_loss: 15.8680\n",
      "Epoch 124/1000\n",
      "5/5 - 0s - loss: 13.4703 - val_loss: 15.8356\n",
      "Epoch 125/1000\n",
      "5/5 - 0s - loss: 13.0350 - val_loss: 15.8700\n",
      "Epoch 126/1000\n",
      "5/5 - 0s - loss: 13.1262 - val_loss: 15.9513\n",
      "Epoch 127/1000\n",
      "5/5 - 0s - loss: 13.3576 - val_loss: 15.9868\n",
      "Epoch 128/1000\n",
      "5/5 - 0s - loss: 12.9810 - val_loss: 15.9970\n",
      "Epoch 129/1000\n",
      "5/5 - 0s - loss: 12.7236 - val_loss: 15.9235\n",
      "Epoch 130/1000\n",
      "5/5 - 0s - loss: 12.9824 - val_loss: 15.0225\n",
      "Epoch 131/1000\n",
      "5/5 - 0s - loss: 13.2473 - val_loss: 16.8569\n",
      "Epoch 132/1000\n",
      "5/5 - 0s - loss: 13.0176 - val_loss: 16.5501\n",
      "Epoch 133/1000\n",
      "5/5 - 0s - loss: 13.3129 - val_loss: 16.7836\n",
      "Epoch 134/1000\n",
      "5/5 - 0s - loss: 13.0864 - val_loss: 16.6923\n",
      "Epoch 135/1000\n",
      "5/5 - 0s - loss: 13.7137 - val_loss: 16.5404\n",
      "Epoch 136/1000\n",
      "5/5 - 0s - loss: 13.1729 - val_loss: 16.5289\n",
      "Epoch 137/1000\n",
      "5/5 - 0s - loss: 13.3606 - val_loss: 16.5440\n",
      "Epoch 138/1000\n",
      "5/5 - 0s - loss: 13.5874 - val_loss: 16.4815\n",
      "Epoch 139/1000\n",
      "5/5 - 0s - loss: 12.8472 - val_loss: 16.3430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140/1000\n",
      "5/5 - 0s - loss: 13.2502 - val_loss: 16.3803\n",
      "Epoch 141/1000\n",
      "5/5 - 0s - loss: 12.8973 - val_loss: 16.5078\n",
      "Epoch 142/1000\n",
      "5/5 - 0s - loss: 12.5306 - val_loss: 17.2089\n",
      "Epoch 143/1000\n",
      "5/5 - 0s - loss: 12.5093 - val_loss: 17.1127\n",
      "Epoch 144/1000\n",
      "5/5 - 0s - loss: 12.4208 - val_loss: 17.1225\n",
      "Epoch 145/1000\n",
      "5/5 - 0s - loss: 12.4931 - val_loss: 17.0723\n",
      "Epoch 146/1000\n",
      "5/5 - 0s - loss: 12.6584 - val_loss: 17.1014\n",
      "Epoch 147/1000\n",
      "5/5 - 0s - loss: 12.5922 - val_loss: 16.9267\n",
      "Epoch 148/1000\n",
      "5/5 - 0s - loss: 12.2842 - val_loss: 16.5254\n",
      "Epoch 149/1000\n",
      "5/5 - 0s - loss: 12.6678 - val_loss: 16.4614\n",
      "Epoch 150/1000\n",
      "5/5 - 0s - loss: 12.1200 - val_loss: 16.4200\n",
      "Epoch 151/1000\n",
      "5/5 - 0s - loss: 12.7013 - val_loss: 15.9442\n",
      "Epoch 152/1000\n",
      "5/5 - 0s - loss: 12.9918 - val_loss: 16.2369\n",
      "Epoch 153/1000\n",
      "5/5 - 0s - loss: 12.3913 - val_loss: 16.2679\n",
      "Epoch 154/1000\n",
      "5/5 - 0s - loss: 13.1231 - val_loss: 16.3282\n",
      "Epoch 155/1000\n",
      "5/5 - 0s - loss: 13.1561 - val_loss: 16.3989\n",
      "Epoch 156/1000\n",
      "5/5 - 0s - loss: 13.3194 - val_loss: 17.1488\n",
      "Epoch 157/1000\n",
      "5/5 - 0s - loss: 13.1564 - val_loss: 17.2200\n",
      "Epoch 158/1000\n",
      "5/5 - 0s - loss: 13.4577 - val_loss: 17.1501\n",
      "Epoch 159/1000\n",
      "5/5 - 0s - loss: 12.4269 - val_loss: 17.1781\n",
      "Epoch 160/1000\n",
      "5/5 - 0s - loss: 13.7230 - val_loss: 16.7622\n",
      "Epoch 161/1000\n",
      "5/5 - 0s - loss: 15.1428 - val_loss: 16.4781\n",
      "Epoch 162/1000\n",
      "5/5 - 0s - loss: 14.3494 - val_loss: 16.2615\n",
      "Epoch 163/1000\n",
      "5/5 - 0s - loss: 13.6272 - val_loss: 17.0182\n",
      "Epoch 164/1000\n",
      "5/5 - 0s - loss: 13.3124 - val_loss: 15.5525\n",
      "Epoch 165/1000\n",
      "5/5 - 0s - loss: 13.2304 - val_loss: 15.2500\n",
      "Epoch 166/1000\n",
      "5/5 - 0s - loss: 13.4502 - val_loss: 15.4411\n",
      "Epoch 167/1000\n",
      "5/5 - 0s - loss: 13.3593 - val_loss: 15.5905\n",
      "Epoch 168/1000\n",
      "5/5 - 0s - loss: 13.2874 - val_loss: 14.5229\n",
      "Epoch 169/1000\n",
      "5/5 - 0s - loss: 12.5664 - val_loss: 14.8478\n",
      "Epoch 170/1000\n",
      "5/5 - 0s - loss: 12.6908 - val_loss: 16.2682\n",
      "Epoch 171/1000\n",
      "5/5 - 0s - loss: 12.9198 - val_loss: 16.3518\n",
      "Epoch 172/1000\n",
      "5/5 - 0s - loss: 13.5040 - val_loss: 16.2265\n",
      "Epoch 173/1000\n",
      "5/5 - 0s - loss: 13.3470 - val_loss: 16.1232\n",
      "Epoch 174/1000\n",
      "5/5 - 0s - loss: 13.2785 - val_loss: 15.9702\n",
      "Epoch 175/1000\n",
      "5/5 - 0s - loss: 13.1082 - val_loss: 14.6274\n",
      "Epoch 176/1000\n",
      "5/5 - 0s - loss: 12.5945 - val_loss: 15.1795\n",
      "Epoch 177/1000\n",
      "5/5 - 0s - loss: 13.3250 - val_loss: 14.5238\n",
      "Epoch 178/1000\n",
      "5/5 - 0s - loss: 12.8105 - val_loss: 15.9299\n",
      "Epoch 179/1000\n",
      "5/5 - 0s - loss: 13.1780 - val_loss: 14.3503\n",
      "Epoch 180/1000\n",
      "5/5 - 0s - loss: 12.8192 - val_loss: 15.0817\n",
      "Epoch 181/1000\n",
      "5/5 - 0s - loss: 13.0466 - val_loss: 15.1856\n",
      "Epoch 182/1000\n",
      "5/5 - 0s - loss: 13.1574 - val_loss: 15.2360\n",
      "Epoch 183/1000\n",
      "5/5 - 0s - loss: 13.3108 - val_loss: 15.2281\n",
      "Epoch 184/1000\n",
      "5/5 - 0s - loss: 13.1785 - val_loss: 15.2178\n",
      "Epoch 185/1000\n",
      "5/5 - 0s - loss: 13.2908 - val_loss: 15.1859\n",
      "Epoch 186/1000\n",
      "5/5 - 0s - loss: 12.8821 - val_loss: 15.1544\n",
      "Epoch 187/1000\n",
      "5/5 - 0s - loss: 12.8108 - val_loss: 14.7947\n",
      "Epoch 188/1000\n",
      "5/5 - 0s - loss: 12.6794 - val_loss: 13.4936\n",
      "Epoch 189/1000\n",
      "5/5 - 0s - loss: 12.6078 - val_loss: 12.9389\n",
      "Epoch 190/1000\n",
      "5/5 - 0s - loss: 12.0829 - val_loss: 14.6550\n",
      "Epoch 191/1000\n",
      "5/5 - 0s - loss: 12.8407 - val_loss: 14.7464\n",
      "Epoch 192/1000\n",
      "5/5 - 0s - loss: 12.9868 - val_loss: 14.7222\n",
      "Epoch 193/1000\n",
      "5/5 - 0s - loss: 13.0467 - val_loss: 14.3950\n",
      "Epoch 194/1000\n",
      "5/5 - 0s - loss: 12.7074 - val_loss: 14.1374\n",
      "Epoch 195/1000\n",
      "5/5 - 0s - loss: 12.6111 - val_loss: 14.4211\n",
      "Epoch 196/1000\n",
      "5/5 - 0s - loss: 12.7276 - val_loss: 14.8098\n",
      "Epoch 197/1000\n",
      "5/5 - 0s - loss: 12.4307 - val_loss: 14.4278\n",
      "Epoch 198/1000\n",
      "5/5 - 0s - loss: 12.4487 - val_loss: 15.9683\n",
      "Epoch 199/1000\n",
      "5/5 - 0s - loss: 13.1564 - val_loss: 15.7346\n",
      "Epoch 200/1000\n",
      "5/5 - 0s - loss: 13.2183 - val_loss: 15.4787\n",
      "Epoch 201/1000\n",
      "5/5 - 0s - loss: 12.8699 - val_loss: 15.1026\n",
      "Epoch 202/1000\n",
      "5/5 - 0s - loss: 12.9825 - val_loss: 14.9581\n",
      "Epoch 203/1000\n",
      "5/5 - 0s - loss: 12.7591 - val_loss: 14.9095\n",
      "Epoch 204/1000\n",
      "5/5 - 0s - loss: 12.7867 - val_loss: 14.7241\n",
      "Epoch 205/1000\n",
      "5/5 - 0s - loss: 12.9562 - val_loss: 13.6786\n",
      "Epoch 206/1000\n",
      "5/5 - 0s - loss: 12.3787 - val_loss: 15.5055\n",
      "Epoch 207/1000\n",
      "5/5 - 0s - loss: 12.5925 - val_loss: 14.9325\n",
      "Epoch 208/1000\n",
      "5/5 - 0s - loss: 13.2748 - val_loss: 14.8940\n",
      "Epoch 209/1000\n",
      "5/5 - 0s - loss: 12.3483 - val_loss: 14.8795\n",
      "Epoch 210/1000\n",
      "5/5 - 0s - loss: 12.8973 - val_loss: 14.7746\n",
      "Epoch 211/1000\n",
      "5/5 - 0s - loss: 13.1505 - val_loss: 14.7407\n",
      "Epoch 212/1000\n",
      "5/5 - 0s - loss: 13.0807 - val_loss: 14.6778\n",
      "Epoch 213/1000\n",
      "5/5 - 0s - loss: 12.3201 - val_loss: 14.3194\n",
      "Epoch 214/1000\n",
      "5/5 - 0s - loss: 12.9136 - val_loss: 15.9947\n",
      "Epoch 215/1000\n",
      "5/5 - 0s - loss: 12.6662 - val_loss: 16.0184\n",
      "Epoch 216/1000\n",
      "5/5 - 0s - loss: 12.4950 - val_loss: 16.0609\n",
      "Epoch 217/1000\n",
      "5/5 - 0s - loss: 12.8410 - val_loss: 16.5016\n",
      "Epoch 218/1000\n",
      "5/5 - 0s - loss: 12.9369 - val_loss: 16.9886\n",
      "Epoch 219/1000\n",
      "5/5 - 0s - loss: 12.9170 - val_loss: 17.1948\n",
      "Epoch 220/1000\n",
      "5/5 - 0s - loss: 13.0338 - val_loss: 16.5163\n",
      "Epoch 221/1000\n",
      "5/5 - 0s - loss: 13.2446 - val_loss: 16.6129\n",
      "Epoch 222/1000\n",
      "5/5 - 0s - loss: 13.1041 - val_loss: 16.6243\n",
      "Epoch 223/1000\n",
      "5/5 - 0s - loss: 13.0252 - val_loss: 16.3860\n",
      "Epoch 224/1000\n",
      "5/5 - 0s - loss: 12.9084 - val_loss: 15.8744\n",
      "Epoch 225/1000\n",
      "5/5 - 0s - loss: 12.2760 - val_loss: 15.1346\n",
      "Epoch 226/1000\n",
      "5/5 - 0s - loss: 11.7675 - val_loss: 15.0476\n",
      "Epoch 227/1000\n",
      "5/5 - 0s - loss: 12.0725 - val_loss: 15.1728\n",
      "Epoch 228/1000\n",
      "5/5 - 0s - loss: 12.2194 - val_loss: 15.5444\n",
      "Epoch 229/1000\n",
      "5/5 - 0s - loss: 12.2907 - val_loss: 15.2387\n",
      "Epoch 230/1000\n",
      "5/5 - 0s - loss: 12.4836 - val_loss: 16.0141\n",
      "Epoch 231/1000\n",
      "5/5 - 0s - loss: 13.4700 - val_loss: 15.9861\n",
      "Epoch 232/1000\n",
      "5/5 - 0s - loss: 12.5181 - val_loss: 15.8201\n",
      "Epoch 233/1000\n",
      "5/5 - 0s - loss: 12.3809 - val_loss: 15.4287\n",
      "Epoch 234/1000\n",
      "5/5 - 0s - loss: 12.5827 - val_loss: 15.4455\n",
      "Epoch 235/1000\n",
      "5/5 - 0s - loss: 12.7800 - val_loss: 15.4676\n",
      "Epoch 236/1000\n",
      "5/5 - 0s - loss: 12.6497 - val_loss: 15.5300\n",
      "Epoch 237/1000\n",
      "5/5 - 0s - loss: 12.6340 - val_loss: 15.5501\n",
      "Epoch 238/1000\n",
      "5/5 - 0s - loss: 12.6682 - val_loss: 15.6407\n",
      "Epoch 239/1000\n",
      "5/5 - 0s - loss: 12.8959 - val_loss: 15.5663\n",
      "Epoch 240/1000\n",
      "5/5 - 0s - loss: 12.4186 - val_loss: 15.5111\n",
      "Epoch 241/1000\n",
      "5/5 - 0s - loss: 12.9398 - val_loss: 15.5373\n",
      "Epoch 242/1000\n",
      "5/5 - 0s - loss: 13.1429 - val_loss: 15.5724\n",
      "Epoch 243/1000\n",
      "5/5 - 0s - loss: 12.9097 - val_loss: 15.5419\n",
      "Epoch 244/1000\n",
      "5/5 - 0s - loss: 12.5569 - val_loss: 15.3504\n",
      "Epoch 245/1000\n",
      "5/5 - 0s - loss: 12.5020 - val_loss: 15.2606\n",
      "Epoch 246/1000\n",
      "5/5 - 0s - loss: 12.2555 - val_loss: 15.0205\n",
      "Epoch 247/1000\n",
      "5/5 - 0s - loss: 12.1524 - val_loss: 14.7275\n",
      "Epoch 248/1000\n",
      "5/5 - 0s - loss: 12.3113 - val_loss: 13.5071\n",
      "Epoch 249/1000\n",
      "5/5 - 0s - loss: 12.2456 - val_loss: 16.6058\n",
      "Epoch 250/1000\n",
      "5/5 - 0s - loss: 13.5152 - val_loss: 16.9252\n",
      "Epoch 251/1000\n",
      "5/5 - 0s - loss: 13.2122 - val_loss: 17.0150\n",
      "Epoch 252/1000\n",
      "5/5 - 0s - loss: 13.6729 - val_loss: 16.6232\n",
      "Epoch 253/1000\n",
      "5/5 - 0s - loss: 13.2743 - val_loss: 16.5089\n",
      "Epoch 254/1000\n",
      "5/5 - 0s - loss: 12.8639 - val_loss: 17.0673\n",
      "Epoch 255/1000\n",
      "5/5 - 0s - loss: 12.9552 - val_loss: 16.7290\n",
      "Epoch 256/1000\n",
      "5/5 - 0s - loss: 12.7401 - val_loss: 12.6632\n",
      "Epoch 257/1000\n",
      "5/5 - 0s - loss: 12.0715 - val_loss: 13.9617\n",
      "Epoch 258/1000\n",
      "5/5 - 0s - loss: 12.3218 - val_loss: 14.9023\n",
      "Epoch 259/1000\n",
      "5/5 - 0s - loss: 12.5327 - val_loss: 14.9801\n",
      "Epoch 260/1000\n",
      "5/5 - 0s - loss: 12.6013 - val_loss: 14.7774\n",
      "Epoch 261/1000\n",
      "5/5 - 0s - loss: 12.6474 - val_loss: 15.2310\n",
      "Epoch 262/1000\n",
      "5/5 - 0s - loss: 12.7379 - val_loss: 15.1775\n",
      "Epoch 263/1000\n",
      "5/5 - 0s - loss: 13.2994 - val_loss: 15.1974\n",
      "Epoch 264/1000\n",
      "5/5 - 0s - loss: 12.5645 - val_loss: 15.1776\n",
      "Epoch 265/1000\n",
      "5/5 - 0s - loss: 12.6494 - val_loss: 15.1940\n",
      "Epoch 266/1000\n",
      "5/5 - 0s - loss: 12.6918 - val_loss: 15.2707\n",
      "Epoch 267/1000\n",
      "5/5 - 0s - loss: 12.5336 - val_loss: 15.2404\n",
      "Epoch 268/1000\n",
      "5/5 - 0s - loss: 12.2649 - val_loss: 14.9582\n",
      "Epoch 269/1000\n",
      "5/5 - 0s - loss: 12.3161 - val_loss: 14.8387\n",
      "Epoch 270/1000\n",
      "5/5 - 0s - loss: 12.4665 - val_loss: 14.9894\n",
      "Epoch 271/1000\n",
      "5/5 - 0s - loss: 12.3179 - val_loss: 14.9725\n",
      "Epoch 272/1000\n",
      "5/5 - 0s - loss: 12.3559 - val_loss: 15.3818\n",
      "Epoch 273/1000\n",
      "5/5 - 0s - loss: 12.1221 - val_loss: 15.9195\n",
      "Epoch 274/1000\n",
      "5/5 - 0s - loss: 12.3853 - val_loss: 15.8208\n",
      "Epoch 275/1000\n",
      "5/5 - 0s - loss: 11.9467 - val_loss: 15.6325\n",
      "Epoch 276/1000\n",
      "5/5 - 0s - loss: 11.9984 - val_loss: 15.6598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 277/1000\n",
      "5/5 - 0s - loss: 12.4135 - val_loss: 15.6081\n",
      "Epoch 278/1000\n",
      "5/5 - 0s - loss: 12.4146 - val_loss: 15.7671\n",
      "Epoch 279/1000\n",
      "5/5 - 0s - loss: 12.1116 - val_loss: 15.6365\n",
      "Epoch 280/1000\n",
      "5/5 - 0s - loss: 12.6619 - val_loss: 15.5278\n",
      "Epoch 281/1000\n",
      "5/5 - 0s - loss: 12.2818 - val_loss: 15.4906\n",
      "Epoch 282/1000\n",
      "5/5 - 0s - loss: 12.3360 - val_loss: 15.5048\n",
      "Epoch 283/1000\n",
      "5/5 - 0s - loss: 11.8633 - val_loss: 15.4027\n",
      "Epoch 284/1000\n",
      "5/5 - 0s - loss: 12.3684 - val_loss: 15.3064\n",
      "Epoch 285/1000\n",
      "5/5 - 0s - loss: 12.1822 - val_loss: 15.3511\n",
      "Epoch 286/1000\n",
      "5/5 - 0s - loss: 12.2944 - val_loss: 15.6360\n",
      "Epoch 287/1000\n",
      "5/5 - 0s - loss: 12.0741 - val_loss: 15.7976\n",
      "Epoch 288/1000\n",
      "5/5 - 0s - loss: 12.1229 - val_loss: 15.8318\n",
      "Epoch 289/1000\n",
      "5/5 - 0s - loss: 12.0147 - val_loss: 15.7908\n",
      "Epoch 290/1000\n",
      "5/5 - 0s - loss: 12.2653 - val_loss: 15.6704\n",
      "Epoch 291/1000\n",
      "5/5 - 0s - loss: 12.1233 - val_loss: 15.5595\n",
      "Epoch 292/1000\n",
      "5/5 - 0s - loss: 12.0211 - val_loss: 15.0665\n",
      "Epoch 293/1000\n",
      "5/5 - 0s - loss: 12.6360 - val_loss: 15.0131\n",
      "Epoch 294/1000\n",
      "5/5 - 0s - loss: 11.8151 - val_loss: 14.9211\n",
      "Epoch 295/1000\n",
      "5/5 - 0s - loss: 12.3572 - val_loss: 14.8000\n",
      "Epoch 296/1000\n",
      "5/5 - 0s - loss: 12.7025 - val_loss: 14.7859\n",
      "Epoch 297/1000\n",
      "5/5 - 0s - loss: 12.7130 - val_loss: 14.8911\n",
      "Epoch 298/1000\n",
      "5/5 - 0s - loss: 11.9241 - val_loss: 14.7296\n",
      "Epoch 299/1000\n",
      "5/5 - 0s - loss: 12.4472 - val_loss: 14.6279\n",
      "Epoch 300/1000\n",
      "5/5 - 0s - loss: 12.5639 - val_loss: 14.5634\n",
      "Epoch 301/1000\n",
      "5/5 - 0s - loss: 12.4558 - val_loss: 14.7727\n",
      "Epoch 302/1000\n",
      "5/5 - 0s - loss: 12.0834 - val_loss: 14.6885\n",
      "Epoch 303/1000\n",
      "5/5 - 0s - loss: 12.1661 - val_loss: 14.6490\n",
      "Epoch 304/1000\n",
      "5/5 - 0s - loss: 12.2299 - val_loss: 14.6077\n",
      "Epoch 305/1000\n",
      "5/5 - 0s - loss: 12.7461 - val_loss: 14.6473\n",
      "Epoch 306/1000\n",
      "5/5 - 0s - loss: 12.4872 - val_loss: 14.4383\n",
      "Epoch 307/1000\n",
      "5/5 - 0s - loss: 12.4363 - val_loss: 14.3125\n",
      "Epoch 308/1000\n",
      "5/5 - 0s - loss: 12.1522 - val_loss: 14.4469\n",
      "Epoch 309/1000\n",
      "5/5 - 0s - loss: 11.9129 - val_loss: 14.2563\n",
      "Epoch 310/1000\n",
      "5/5 - 0s - loss: 12.3798 - val_loss: 14.2383\n",
      "Epoch 311/1000\n",
      "5/5 - 0s - loss: 12.8303 - val_loss: 14.2210\n",
      "Epoch 312/1000\n",
      "5/5 - 0s - loss: 12.1328 - val_loss: 14.1608\n",
      "Epoch 313/1000\n",
      "5/5 - 0s - loss: 12.3385 - val_loss: 14.0602\n",
      "Epoch 314/1000\n",
      "5/5 - 0s - loss: 12.4090 - val_loss: 14.0649\n",
      "Epoch 315/1000\n",
      "5/5 - 0s - loss: 12.5585 - val_loss: 14.1950\n",
      "Epoch 316/1000\n",
      "5/5 - 0s - loss: 11.8758 - val_loss: 14.2936\n",
      "Epoch 317/1000\n",
      "5/5 - 0s - loss: 12.2123 - val_loss: 14.0681\n",
      "Epoch 318/1000\n",
      "5/5 - 0s - loss: 12.2726 - val_loss: 14.0297\n",
      "Epoch 319/1000\n",
      "5/5 - 0s - loss: 11.8030 - val_loss: 13.8626\n",
      "Epoch 320/1000\n",
      "5/5 - 0s - loss: 12.0202 - val_loss: 13.9788\n",
      "Epoch 321/1000\n",
      "5/5 - 0s - loss: 11.6538 - val_loss: 14.0381\n",
      "Epoch 322/1000\n",
      "5/5 - 0s - loss: 11.8190 - val_loss: 14.0023\n",
      "Epoch 323/1000\n",
      "5/5 - 0s - loss: 12.6308 - val_loss: 14.0573\n",
      "Epoch 324/1000\n",
      "5/5 - 0s - loss: 12.5363 - val_loss: 13.9777\n",
      "Epoch 325/1000\n",
      "5/5 - 0s - loss: 11.9690 - val_loss: 14.1874\n",
      "Epoch 326/1000\n",
      "5/5 - 0s - loss: 12.2274 - val_loss: 14.1272\n",
      "Epoch 327/1000\n",
      "5/5 - 0s - loss: 11.9684 - val_loss: 14.2210\n",
      "Epoch 328/1000\n",
      "5/5 - 0s - loss: 12.9585 - val_loss: 14.4006\n",
      "Epoch 329/1000\n",
      "5/5 - 0s - loss: 11.8279 - val_loss: 14.4511\n",
      "Epoch 330/1000\n",
      "5/5 - 0s - loss: 12.2611 - val_loss: 14.4314\n",
      "Epoch 331/1000\n",
      "5/5 - 0s - loss: 11.9059 - val_loss: 14.3405\n",
      "Epoch 332/1000\n",
      "5/5 - 0s - loss: 12.4130 - val_loss: 14.2290\n",
      "Epoch 333/1000\n",
      "5/5 - 0s - loss: 12.1258 - val_loss: 14.5591\n",
      "Epoch 334/1000\n",
      "5/5 - 0s - loss: 12.0450 - val_loss: 14.6974\n",
      "Epoch 335/1000\n",
      "5/5 - 0s - loss: 12.1465 - val_loss: 14.9458\n",
      "Epoch 336/1000\n",
      "5/5 - 0s - loss: 11.3802 - val_loss: 14.6787\n",
      "Epoch 337/1000\n",
      "5/5 - 0s - loss: 11.7762 - val_loss: 14.5516\n",
      "Epoch 338/1000\n",
      "5/5 - 0s - loss: 11.7378 - val_loss: 14.4038\n",
      "Epoch 339/1000\n",
      "5/5 - 0s - loss: 11.7103 - val_loss: 14.5340\n",
      "Epoch 340/1000\n",
      "5/5 - 0s - loss: 11.3998 - val_loss: 14.5498\n",
      "Epoch 341/1000\n",
      "5/5 - 0s - loss: 11.7045 - val_loss: 14.8884\n",
      "Epoch 342/1000\n",
      "5/5 - 0s - loss: 12.0690 - val_loss: 14.8987\n",
      "Epoch 343/1000\n",
      "5/5 - 0s - loss: 12.1360 - val_loss: 15.0293\n",
      "Epoch 344/1000\n",
      "5/5 - 0s - loss: 11.7311 - val_loss: 15.0295\n",
      "Epoch 345/1000\n",
      "5/5 - 0s - loss: 11.8291 - val_loss: 14.8395\n",
      "Epoch 346/1000\n",
      "5/5 - 0s - loss: 12.2817 - val_loss: 14.8056\n",
      "Epoch 347/1000\n",
      "5/5 - 0s - loss: 11.7350 - val_loss: 14.7010\n",
      "Epoch 348/1000\n",
      "5/5 - 0s - loss: 12.2603 - val_loss: 14.5875\n",
      "Epoch 349/1000\n",
      "5/5 - 0s - loss: 11.9835 - val_loss: 14.4693\n",
      "Epoch 350/1000\n",
      "5/5 - 0s - loss: 11.3740 - val_loss: 14.4386\n",
      "Epoch 351/1000\n",
      "5/5 - 0s - loss: 11.8489 - val_loss: 14.2446\n",
      "Epoch 352/1000\n",
      "5/5 - 0s - loss: 11.8508 - val_loss: 14.0998\n",
      "Epoch 353/1000\n",
      "5/5 - 0s - loss: 11.7374 - val_loss: 13.9944\n",
      "Epoch 354/1000\n",
      "5/5 - 0s - loss: 11.5146 - val_loss: 14.1445\n",
      "Epoch 355/1000\n",
      "5/5 - 0s - loss: 11.3330 - val_loss: 14.1401\n",
      "Epoch 356/1000\n",
      "5/5 - 0s - loss: 11.5124 - val_loss: 14.1102\n",
      "Epoch 357/1000\n",
      "5/5 - 0s - loss: 11.3458 - val_loss: 13.9025\n",
      "Epoch 358/1000\n",
      "5/5 - 0s - loss: 11.3492 - val_loss: 13.5541\n",
      "Epoch 359/1000\n",
      "5/5 - 0s - loss: 11.3688 - val_loss: 12.5029\n",
      "Epoch 360/1000\n",
      "5/5 - 0s - loss: 11.2626 - val_loss: 17.2087\n",
      "Epoch 361/1000\n",
      "5/5 - 0s - loss: 13.2114 - val_loss: 16.6833\n",
      "Epoch 362/1000\n",
      "5/5 - 0s - loss: 12.6503 - val_loss: 15.9758\n",
      "Epoch 363/1000\n",
      "5/5 - 0s - loss: 12.1864 - val_loss: 13.7423\n",
      "Epoch 364/1000\n",
      "5/5 - 0s - loss: 11.3862 - val_loss: 13.6148\n",
      "Epoch 365/1000\n",
      "5/5 - 0s - loss: 12.0543 - val_loss: 13.2652\n",
      "Epoch 366/1000\n",
      "5/5 - 0s - loss: 11.5646 - val_loss: 12.1273\n",
      "Epoch 367/1000\n",
      "5/5 - 0s - loss: 10.9249 - val_loss: 15.2204\n",
      "Epoch 368/1000\n",
      "5/5 - 0s - loss: 11.6362 - val_loss: 13.0794\n",
      "Epoch 369/1000\n",
      "5/5 - 0s - loss: 11.7140 - val_loss: 13.0742\n",
      "Epoch 370/1000\n",
      "5/5 - 0s - loss: 11.5674 - val_loss: 13.4623\n",
      "Epoch 371/1000\n",
      "5/5 - 0s - loss: 11.6024 - val_loss: 13.9335\n",
      "Epoch 372/1000\n",
      "5/5 - 0s - loss: 11.7267 - val_loss: 14.1454\n",
      "Epoch 373/1000\n",
      "5/5 - 0s - loss: 11.5684 - val_loss: 14.1710\n",
      "Epoch 374/1000\n",
      "5/5 - 0s - loss: 10.8881 - val_loss: 13.6015\n",
      "Epoch 375/1000\n",
      "5/5 - 0s - loss: 10.8850 - val_loss: 12.8110\n",
      "Epoch 376/1000\n",
      "5/5 - 0s - loss: 10.9130 - val_loss: 16.6092\n",
      "Epoch 377/1000\n",
      "5/5 - 0s - loss: 11.9958 - val_loss: 16.1274\n",
      "Epoch 378/1000\n",
      "5/5 - 0s - loss: 11.4899 - val_loss: 16.2508\n",
      "Epoch 379/1000\n",
      "5/5 - 0s - loss: 11.5377 - val_loss: 15.6028\n",
      "Epoch 380/1000\n",
      "5/5 - 0s - loss: 11.0940 - val_loss: 15.5808\n",
      "Epoch 381/1000\n",
      "5/5 - 0s - loss: 11.7000 - val_loss: 16.6981\n",
      "Epoch 382/1000\n",
      "5/5 - 0s - loss: 12.3441 - val_loss: 16.3128\n",
      "Epoch 383/1000\n",
      "5/5 - 0s - loss: 12.6685 - val_loss: 16.1632\n",
      "Epoch 384/1000\n",
      "5/5 - 0s - loss: 12.0450 - val_loss: 15.8248\n",
      "Epoch 385/1000\n",
      "5/5 - 0s - loss: 13.4024 - val_loss: 15.4679\n",
      "Epoch 386/1000\n",
      "5/5 - 0s - loss: 12.0056 - val_loss: 16.6177\n",
      "Epoch 387/1000\n",
      "5/5 - 0s - loss: 12.0161 - val_loss: 15.3170\n",
      "Epoch 388/1000\n",
      "5/5 - 0s - loss: 12.0009 - val_loss: 14.3804\n",
      "Epoch 389/1000\n",
      "5/5 - 0s - loss: 11.6030 - val_loss: 14.4484\n",
      "Epoch 390/1000\n",
      "5/5 - 0s - loss: 11.1517 - val_loss: 13.8231\n",
      "Epoch 391/1000\n",
      "5/5 - 0s - loss: 10.6016 - val_loss: 14.1020\n",
      "Epoch 392/1000\n",
      "5/5 - 0s - loss: 10.6011 - val_loss: 14.1507\n",
      "Epoch 393/1000\n",
      "5/5 - 0s - loss: 11.2186 - val_loss: 14.1397\n",
      "Epoch 394/1000\n",
      "5/5 - 0s - loss: 10.3108 - val_loss: 15.0026\n",
      "Epoch 395/1000\n",
      "5/5 - 0s - loss: 11.3813 - val_loss: 15.2163\n",
      "Epoch 396/1000\n",
      "5/5 - 0s - loss: 11.9104 - val_loss: 15.4244\n",
      "Epoch 397/1000\n",
      "5/5 - 0s - loss: 11.4367 - val_loss: 16.3326\n",
      "Epoch 398/1000\n",
      "5/5 - 0s - loss: 11.0901 - val_loss: 16.4703\n",
      "Epoch 399/1000\n",
      "5/5 - 0s - loss: 11.3044 - val_loss: 15.9789\n",
      "Epoch 400/1000\n",
      "5/5 - 0s - loss: 10.7846 - val_loss: 15.8776\n",
      "Epoch 401/1000\n",
      "5/5 - 0s - loss: 11.1875 - val_loss: 15.6694\n",
      "Epoch 402/1000\n",
      "5/5 - 0s - loss: 10.8089 - val_loss: 15.2664\n",
      "Epoch 403/1000\n",
      "5/5 - 0s - loss: 11.0379 - val_loss: 10.7840\n",
      "Epoch 404/1000\n",
      "5/5 - 0s - loss: 10.3871 - val_loss: 12.0957\n",
      "Epoch 405/1000\n",
      "5/5 - 0s - loss: 10.6454 - val_loss: 15.2295\n",
      "Epoch 406/1000\n",
      "5/5 - 0s - loss: 11.1911 - val_loss: 15.2610\n",
      "Epoch 407/1000\n",
      "5/5 - 0s - loss: 10.8666 - val_loss: 15.2170\n",
      "Epoch 408/1000\n",
      "5/5 - 0s - loss: 10.7816 - val_loss: 13.3802\n",
      "Epoch 409/1000\n",
      "5/5 - 0s - loss: 11.2290 - val_loss: 13.6294\n",
      "Epoch 410/1000\n",
      "5/5 - 0s - loss: 11.1019 - val_loss: 13.8848\n",
      "Epoch 411/1000\n",
      "5/5 - 0s - loss: 11.1875 - val_loss: 13.7379\n",
      "Epoch 412/1000\n",
      "5/5 - 0s - loss: 11.1785 - val_loss: 13.8069\n",
      "Epoch 413/1000\n",
      "5/5 - 0s - loss: 11.2765 - val_loss: 13.8322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 414/1000\n",
      "5/5 - 0s - loss: 10.9227 - val_loss: 13.5921\n",
      "Epoch 415/1000\n",
      "5/5 - 0s - loss: 12.1085 - val_loss: 13.4786\n",
      "Epoch 416/1000\n",
      "5/5 - 0s - loss: 11.6201 - val_loss: 13.9571\n",
      "Epoch 417/1000\n",
      "5/5 - 0s - loss: 11.8977 - val_loss: 13.4273\n",
      "Epoch 418/1000\n",
      "5/5 - 0s - loss: 11.0082 - val_loss: 12.3737\n",
      "Epoch 419/1000\n",
      "5/5 - 0s - loss: 11.3740 - val_loss: 16.2344\n",
      "Epoch 420/1000\n",
      "5/5 - 0s - loss: 11.0870 - val_loss: 12.6874\n",
      "Epoch 421/1000\n",
      "5/5 - 0s - loss: 11.3342 - val_loss: 13.7784\n",
      "Epoch 422/1000\n",
      "5/5 - 0s - loss: 11.4602 - val_loss: 14.1934\n",
      "Epoch 423/1000\n",
      "5/5 - 0s - loss: 11.1006 - val_loss: 14.2815\n",
      "Epoch 424/1000\n",
      "5/5 - 0s - loss: 11.2277 - val_loss: 14.1392\n",
      "Epoch 425/1000\n",
      "5/5 - 0s - loss: 11.0669 - val_loss: 14.1744\n",
      "Epoch 426/1000\n",
      "5/5 - 0s - loss: 10.5403 - val_loss: 13.8036\n",
      "Epoch 427/1000\n",
      "5/5 - 0s - loss: 10.6416 - val_loss: 12.0521\n",
      "Epoch 428/1000\n",
      "5/5 - 0s - loss: 10.5064 - val_loss: 12.4778\n",
      "Epoch 429/1000\n",
      "5/5 - 0s - loss: 10.6768 - val_loss: 13.4629\n",
      "Epoch 430/1000\n",
      "5/5 - 0s - loss: 11.0876 - val_loss: 13.1280\n",
      "Epoch 431/1000\n",
      "5/5 - 0s - loss: 10.8973 - val_loss: 12.6901\n",
      "Epoch 432/1000\n",
      "5/5 - 0s - loss: 10.4830 - val_loss: 12.4896\n",
      "Epoch 433/1000\n",
      "5/5 - 0s - loss: 10.9914 - val_loss: 12.4387\n",
      "Epoch 434/1000\n",
      "5/5 - 0s - loss: 10.2965 - val_loss: 13.7944\n",
      "Epoch 435/1000\n",
      "5/5 - 0s - loss: 10.3442 - val_loss: 13.4950\n",
      "Epoch 436/1000\n",
      "5/5 - 0s - loss: 11.1814 - val_loss: 13.7555\n",
      "Epoch 437/1000\n",
      "5/5 - 0s - loss: 11.0859 - val_loss: 12.9129\n",
      "Epoch 438/1000\n",
      "5/5 - 0s - loss: 11.2246 - val_loss: 16.6547\n",
      "Epoch 439/1000\n",
      "5/5 - 0s - loss: 11.5207 - val_loss: 12.5508\n",
      "Epoch 440/1000\n",
      "5/5 - 0s - loss: 11.2337 - val_loss: 10.8214\n",
      "Epoch 441/1000\n",
      "5/5 - 0s - loss: 11.2343 - val_loss: 13.4417\n",
      "Epoch 442/1000\n",
      "5/5 - 0s - loss: 10.6428 - val_loss: 14.1234\n",
      "Epoch 443/1000\n",
      "5/5 - 0s - loss: 10.5141 - val_loss: 14.2609\n",
      "Epoch 444/1000\n",
      "5/5 - 0s - loss: 11.1020 - val_loss: 14.2728\n",
      "Epoch 445/1000\n",
      "5/5 - 0s - loss: 10.6930 - val_loss: 14.2492\n",
      "Epoch 446/1000\n",
      "5/5 - 0s - loss: 11.0775 - val_loss: 14.2530\n",
      "Epoch 447/1000\n",
      "5/5 - 0s - loss: 10.7438 - val_loss: 14.2642\n",
      "Epoch 448/1000\n",
      "5/5 - 0s - loss: 10.9441 - val_loss: 14.1466\n",
      "Epoch 449/1000\n",
      "5/5 - 0s - loss: 10.7546 - val_loss: 13.7039\n",
      "Epoch 450/1000\n",
      "5/5 - 0s - loss: 10.1316 - val_loss: 13.8206\n",
      "Epoch 451/1000\n",
      "5/5 - 0s - loss: 10.1617 - val_loss: 13.6925\n",
      "Epoch 452/1000\n",
      "5/5 - 0s - loss: 10.7951 - val_loss: 13.1695\n",
      "Epoch 453/1000\n",
      "5/5 - 0s - loss: 10.8166 - val_loss: 13.3191\n",
      "Epoch 454/1000\n",
      "5/5 - 0s - loss: 10.7493 - val_loss: 11.8548\n",
      "Epoch 455/1000\n",
      "5/5 - 0s - loss: 10.0367 - val_loss: 13.6967\n",
      "Epoch 456/1000\n",
      "5/5 - 0s - loss: 11.5278 - val_loss: 14.1640\n",
      "Epoch 457/1000\n",
      "5/5 - 0s - loss: 12.2946 - val_loss: 14.0606\n",
      "Epoch 458/1000\n",
      "5/5 - 0s - loss: 11.8591 - val_loss: 13.8925\n",
      "Epoch 459/1000\n",
      "5/5 - 0s - loss: 11.1098 - val_loss: 13.9328\n",
      "Epoch 460/1000\n",
      "5/5 - 0s - loss: 10.8401 - val_loss: 13.9094\n",
      "Epoch 461/1000\n",
      "5/5 - 0s - loss: 10.9255 - val_loss: 13.9938\n",
      "Epoch 462/1000\n",
      "5/5 - 0s - loss: 10.8129 - val_loss: 13.9697\n",
      "Epoch 463/1000\n",
      "5/5 - 0s - loss: 10.8239 - val_loss: 13.9755\n",
      "Epoch 464/1000\n",
      "5/5 - 0s - loss: 11.8262 - val_loss: 13.9302\n",
      "Epoch 465/1000\n",
      "5/5 - 0s - loss: 10.6937 - val_loss: 13.9942\n",
      "Epoch 466/1000\n",
      "5/5 - 0s - loss: 11.1276 - val_loss: 14.0941\n",
      "Epoch 467/1000\n",
      "5/5 - 0s - loss: 11.7284 - val_loss: 14.4365\n",
      "Epoch 468/1000\n",
      "5/5 - 0s - loss: 11.3184 - val_loss: 14.3422\n",
      "Epoch 469/1000\n",
      "5/5 - 0s - loss: 11.5971 - val_loss: 14.3474\n",
      "Epoch 470/1000\n",
      "5/5 - 0s - loss: 11.1734 - val_loss: 14.4159\n",
      "Epoch 471/1000\n",
      "5/5 - 0s - loss: 11.0529 - val_loss: 14.3739\n",
      "Epoch 472/1000\n",
      "5/5 - 0s - loss: 10.6944 - val_loss: 14.3521\n",
      "Epoch 473/1000\n",
      "5/5 - 0s - loss: 11.2273 - val_loss: 14.3401\n",
      "Epoch 474/1000\n",
      "5/5 - 0s - loss: 10.8985 - val_loss: 14.3389\n",
      "Epoch 475/1000\n",
      "5/5 - 0s - loss: 10.9537 - val_loss: 14.3548\n",
      "Epoch 476/1000\n",
      "5/5 - 0s - loss: 11.0420 - val_loss: 14.3271\n",
      "Epoch 477/1000\n",
      "5/5 - 0s - loss: 11.6794 - val_loss: 14.3548\n",
      "Epoch 478/1000\n",
      "5/5 - 0s - loss: 10.9982 - val_loss: 14.1396\n",
      "Epoch 479/1000\n",
      "5/5 - 0s - loss: 11.5038 - val_loss: 14.0014\n",
      "Epoch 480/1000\n",
      "5/5 - 0s - loss: 10.7110 - val_loss: 14.0038\n",
      "Epoch 481/1000\n",
      "5/5 - 0s - loss: 11.5470 - val_loss: 14.1605\n",
      "Epoch 482/1000\n",
      "5/5 - 0s - loss: 11.3856 - val_loss: 14.3216\n",
      "Epoch 483/1000\n",
      "5/5 - 0s - loss: 11.4351 - val_loss: 14.5669\n",
      "Epoch 484/1000\n",
      "5/5 - 0s - loss: 10.9719 - val_loss: 14.1989\n",
      "Epoch 485/1000\n",
      "5/5 - 0s - loss: 11.4857 - val_loss: 14.1973\n",
      "Epoch 486/1000\n",
      "5/5 - 0s - loss: 11.3378 - val_loss: 14.0628\n",
      "Epoch 487/1000\n",
      "5/5 - 0s - loss: 11.9708 - val_loss: 14.2699\n",
      "Epoch 488/1000\n",
      "5/5 - 0s - loss: 11.0453 - val_loss: 14.4002\n",
      "Epoch 489/1000\n",
      "5/5 - 0s - loss: 11.2202 - val_loss: 14.5976\n",
      "Epoch 490/1000\n",
      "5/5 - 0s - loss: 11.3947 - val_loss: 14.6636\n",
      "Epoch 491/1000\n",
      "5/5 - 0s - loss: 11.1080 - val_loss: 14.5514\n",
      "Epoch 492/1000\n",
      "5/5 - 0s - loss: 11.1190 - val_loss: 14.6739\n",
      "Epoch 493/1000\n",
      "5/5 - 0s - loss: 11.8440 - val_loss: 14.7240\n",
      "Epoch 494/1000\n",
      "5/5 - 0s - loss: 10.9753 - val_loss: 14.7615\n",
      "Epoch 495/1000\n",
      "5/5 - 0s - loss: 11.3204 - val_loss: 14.7078\n",
      "Epoch 496/1000\n",
      "5/5 - 0s - loss: 11.8126 - val_loss: 14.6825\n",
      "Epoch 497/1000\n",
      "5/5 - 0s - loss: 11.5780 - val_loss: 14.5665\n",
      "Epoch 498/1000\n",
      "5/5 - 0s - loss: 10.9055 - val_loss: 14.4665\n",
      "Epoch 499/1000\n",
      "5/5 - 0s - loss: 10.9948 - val_loss: 14.4063\n",
      "Epoch 500/1000\n",
      "5/5 - 0s - loss: 11.0958 - val_loss: 14.3854\n",
      "Epoch 501/1000\n",
      "5/5 - 0s - loss: 11.2367 - val_loss: 14.3702\n",
      "Epoch 502/1000\n",
      "5/5 - 0s - loss: 11.3388 - val_loss: 14.4522\n",
      "Epoch 503/1000\n",
      "5/5 - 0s - loss: 11.6949 - val_loss: 14.6234\n",
      "Epoch 504/1000\n",
      "5/5 - 0s - loss: 10.6372 - val_loss: 14.4734\n",
      "Epoch 505/1000\n",
      "5/5 - 0s - loss: 11.4321 - val_loss: 14.3599\n",
      "Epoch 506/1000\n",
      "5/5 - 0s - loss: 11.1148 - val_loss: 14.1338\n",
      "Epoch 507/1000\n",
      "5/5 - 0s - loss: 11.2582 - val_loss: 14.5277\n",
      "Epoch 508/1000\n",
      "5/5 - 0s - loss: 11.7046 - val_loss: 14.5960\n",
      "Epoch 509/1000\n",
      "5/5 - 0s - loss: 11.0233 - val_loss: 14.5927\n",
      "Epoch 510/1000\n",
      "5/5 - 0s - loss: 10.8724 - val_loss: 14.4777\n",
      "Epoch 511/1000\n",
      "5/5 - 0s - loss: 10.5808 - val_loss: 14.4307\n",
      "Epoch 512/1000\n",
      "5/5 - 0s - loss: 11.0566 - val_loss: 14.5161\n",
      "Epoch 513/1000\n",
      "5/5 - 0s - loss: 10.9369 - val_loss: 14.5685\n",
      "Epoch 514/1000\n",
      "5/5 - 0s - loss: 11.2285 - val_loss: 14.4971\n",
      "Epoch 515/1000\n",
      "5/5 - 0s - loss: 11.0189 - val_loss: 14.5285\n",
      "Epoch 516/1000\n",
      "5/5 - 0s - loss: 10.6440 - val_loss: 14.5145\n",
      "Epoch 517/1000\n",
      "5/5 - 0s - loss: 11.1233 - val_loss: 14.4107\n",
      "Epoch 518/1000\n",
      "5/5 - 0s - loss: 11.4956 - val_loss: 14.4225\n",
      "Epoch 519/1000\n",
      "5/5 - 0s - loss: 11.0633 - val_loss: 14.3994\n",
      "Epoch 520/1000\n",
      "5/5 - 0s - loss: 11.3271 - val_loss: 14.3688\n",
      "Epoch 521/1000\n",
      "5/5 - 0s - loss: 11.5799 - val_loss: 14.2876\n",
      "Epoch 522/1000\n",
      "5/5 - 0s - loss: 11.5598 - val_loss: 14.3448\n",
      "Epoch 523/1000\n",
      "5/5 - 0s - loss: 11.3529 - val_loss: 14.4244\n",
      "Epoch 524/1000\n",
      "5/5 - 0s - loss: 11.1879 - val_loss: 14.4235\n",
      "Epoch 525/1000\n",
      "5/5 - 0s - loss: 11.0129 - val_loss: 14.3901\n",
      "Epoch 526/1000\n",
      "5/5 - 0s - loss: 10.5384 - val_loss: 14.3811\n",
      "Epoch 527/1000\n",
      "5/5 - 0s - loss: 11.3586 - val_loss: 14.2913\n",
      "Epoch 528/1000\n",
      "5/5 - 0s - loss: 10.7748 - val_loss: 14.2939\n",
      "Epoch 529/1000\n",
      "5/5 - 0s - loss: 10.8945 - val_loss: 14.3859\n",
      "Epoch 530/1000\n",
      "5/5 - 0s - loss: 11.3179 - val_loss: 14.2787\n",
      "Epoch 531/1000\n",
      "5/5 - 0s - loss: 10.9434 - val_loss: 14.2985\n",
      "Epoch 532/1000\n",
      "5/5 - 0s - loss: 10.5648 - val_loss: 14.1949\n",
      "Epoch 533/1000\n",
      "5/5 - 0s - loss: 11.2671 - val_loss: 14.0764\n",
      "Epoch 534/1000\n",
      "5/5 - 0s - loss: 11.1552 - val_loss: 14.4924\n",
      "Epoch 535/1000\n",
      "5/5 - 0s - loss: 10.9029 - val_loss: 14.5399\n",
      "Epoch 536/1000\n",
      "5/5 - 0s - loss: 11.1500 - val_loss: 14.4746\n",
      "Epoch 537/1000\n",
      "5/5 - 0s - loss: 11.2825 - val_loss: 14.3785\n",
      "Epoch 538/1000\n",
      "5/5 - 0s - loss: 10.7659 - val_loss: 14.4530\n",
      "Epoch 539/1000\n",
      "5/5 - 0s - loss: 11.5557 - val_loss: 14.5799\n",
      "Epoch 540/1000\n",
      "5/5 - 0s - loss: 10.4427 - val_loss: 14.5104\n",
      "Epoch 541/1000\n",
      "5/5 - 0s - loss: 11.5983 - val_loss: 14.4820\n",
      "Epoch 542/1000\n",
      "5/5 - 0s - loss: 10.9781 - val_loss: 14.5207\n",
      "Epoch 543/1000\n",
      "5/5 - 0s - loss: 10.5095 - val_loss: 14.4734\n",
      "Epoch 544/1000\n",
      "5/5 - 0s - loss: 10.3071 - val_loss: 14.4282\n",
      "Epoch 545/1000\n",
      "5/5 - 0s - loss: 10.6449 - val_loss: 14.5040\n",
      "Epoch 546/1000\n",
      "5/5 - 0s - loss: 10.8940 - val_loss: 14.5279\n",
      "Epoch 547/1000\n",
      "5/5 - 0s - loss: 10.1699 - val_loss: 14.4572\n",
      "Epoch 548/1000\n",
      "5/5 - 0s - loss: 10.5963 - val_loss: 14.5024\n",
      "Epoch 549/1000\n",
      "5/5 - 0s - loss: 10.7325 - val_loss: 14.7572\n",
      "Epoch 550/1000\n",
      "5/5 - 0s - loss: 11.0108 - val_loss: 14.6633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 551/1000\n",
      "5/5 - 0s - loss: 11.5158 - val_loss: 14.6380\n",
      "Epoch 552/1000\n",
      "5/5 - 0s - loss: 10.9438 - val_loss: 14.6274\n",
      "Epoch 553/1000\n",
      "5/5 - 0s - loss: 10.4649 - val_loss: 14.5693\n",
      "Epoch 554/1000\n",
      "5/5 - 0s - loss: 10.4936 - val_loss: 14.5090\n",
      "Epoch 555/1000\n",
      "5/5 - 0s - loss: 10.7775 - val_loss: 14.5091\n",
      "Epoch 556/1000\n",
      "5/5 - 0s - loss: 11.0815 - val_loss: 14.4628\n",
      "Epoch 557/1000\n",
      "5/5 - 0s - loss: 11.3675 - val_loss: 14.4347\n",
      "Epoch 558/1000\n",
      "5/5 - 0s - loss: 11.4582 - val_loss: 14.4513\n",
      "Epoch 559/1000\n",
      "5/5 - 0s - loss: 11.3214 - val_loss: 14.4321\n",
      "Epoch 560/1000\n",
      "5/5 - 0s - loss: 10.8928 - val_loss: 14.4513\n",
      "Epoch 561/1000\n",
      "5/5 - 0s - loss: 11.3136 - val_loss: 14.5852\n",
      "Epoch 562/1000\n",
      "5/5 - 0s - loss: 11.5274 - val_loss: 14.7189\n",
      "Epoch 563/1000\n",
      "5/5 - 0s - loss: 11.3633 - val_loss: 14.4374\n",
      "Epoch 564/1000\n",
      "5/5 - 0s - loss: 11.1898 - val_loss: 14.4971\n",
      "Epoch 565/1000\n",
      "5/5 - 0s - loss: 11.3229 - val_loss: 14.8380\n",
      "Epoch 566/1000\n",
      "5/5 - 0s - loss: 11.7999 - val_loss: 14.8815\n",
      "Epoch 567/1000\n",
      "5/5 - 0s - loss: 11.4684 - val_loss: 14.9985\n",
      "Epoch 568/1000\n",
      "5/5 - 0s - loss: 10.9109 - val_loss: 14.8514\n",
      "Epoch 569/1000\n",
      "5/5 - 0s - loss: 11.9577 - val_loss: 15.0150\n",
      "Epoch 570/1000\n",
      "5/5 - 0s - loss: 10.7742 - val_loss: 15.1418\n",
      "Epoch 571/1000\n",
      "5/5 - 0s - loss: 10.4390 - val_loss: 14.9947\n",
      "Epoch 572/1000\n",
      "5/5 - 0s - loss: 11.4546 - val_loss: 14.8213\n",
      "Epoch 573/1000\n",
      "5/5 - 0s - loss: 10.6843 - val_loss: 14.8161\n",
      "Epoch 574/1000\n",
      "5/5 - 0s - loss: 10.2351 - val_loss: 14.7584\n",
      "Epoch 575/1000\n",
      "5/5 - 0s - loss: 10.8000 - val_loss: 14.7685\n",
      "Epoch 576/1000\n",
      "5/5 - 0s - loss: 9.5733 - val_loss: 14.7869\n",
      "Epoch 577/1000\n",
      "5/5 - 0s - loss: 11.1652 - val_loss: 14.7556\n",
      "Epoch 578/1000\n",
      "5/5 - 0s - loss: 10.7176 - val_loss: 14.8111\n",
      "Epoch 579/1000\n",
      "5/5 - 0s - loss: 11.2548 - val_loss: 14.7144\n",
      "Epoch 580/1000\n",
      "5/5 - 0s - loss: 10.6889 - val_loss: 14.6866\n",
      "Epoch 581/1000\n",
      "5/5 - 0s - loss: 11.2157 - val_loss: 14.7825\n",
      "Epoch 582/1000\n",
      "5/5 - 0s - loss: 11.5800 - val_loss: 14.8070\n",
      "Epoch 583/1000\n",
      "5/5 - 0s - loss: 10.6101 - val_loss: 14.7681\n",
      "Epoch 584/1000\n",
      "5/5 - 0s - loss: 10.9785 - val_loss: 14.6992\n",
      "Epoch 585/1000\n",
      "5/5 - 0s - loss: 10.3374 - val_loss: 14.7039\n",
      "Epoch 586/1000\n",
      "5/5 - 0s - loss: 11.0184 - val_loss: 14.7359\n",
      "Epoch 587/1000\n",
      "5/5 - 0s - loss: 11.9028 - val_loss: 14.7283\n",
      "Epoch 588/1000\n",
      "5/5 - 0s - loss: 10.8822 - val_loss: 14.7285\n",
      "Epoch 589/1000\n",
      "5/5 - 0s - loss: 11.0504 - val_loss: 14.8051\n",
      "Epoch 590/1000\n",
      "5/5 - 0s - loss: 10.4590 - val_loss: 14.9645\n",
      "Epoch 591/1000\n",
      "5/5 - 0s - loss: 10.7625 - val_loss: 14.9545\n",
      "Epoch 592/1000\n",
      "5/5 - 0s - loss: 10.4933 - val_loss: 15.1030\n",
      "Epoch 593/1000\n",
      "5/5 - 0s - loss: 10.6474 - val_loss: 15.1237\n",
      "Epoch 594/1000\n",
      "5/5 - 0s - loss: 11.2000 - val_loss: 15.1050\n",
      "Epoch 595/1000\n",
      "5/5 - 0s - loss: 11.1149 - val_loss: 15.0862\n",
      "Epoch 596/1000\n",
      "5/5 - 0s - loss: 10.6231 - val_loss: 15.0465\n",
      "Epoch 597/1000\n",
      "5/5 - 0s - loss: 10.0115 - val_loss: 15.0745\n",
      "Epoch 598/1000\n",
      "5/5 - 0s - loss: 10.4540 - val_loss: 14.9130\n",
      "Epoch 599/1000\n",
      "5/5 - 0s - loss: 10.8046 - val_loss: 14.9492\n",
      "Epoch 600/1000\n",
      "5/5 - 0s - loss: 10.9465 - val_loss: 14.8858\n",
      "Epoch 601/1000\n",
      "5/5 - 0s - loss: 11.0458 - val_loss: 14.7889\n",
      "Epoch 602/1000\n",
      "5/5 - 0s - loss: 10.7893 - val_loss: 14.8521\n",
      "Epoch 603/1000\n",
      "5/5 - 0s - loss: 11.3306 - val_loss: 14.9786\n",
      "Epoch 604/1000\n",
      "5/5 - 0s - loss: 10.7564 - val_loss: 14.8062\n",
      "Epoch 605/1000\n",
      "5/5 - 0s - loss: 10.7387 - val_loss: 14.7389\n",
      "Epoch 606/1000\n",
      "5/5 - 0s - loss: 11.1713 - val_loss: 14.7874\n",
      "Epoch 607/1000\n",
      "5/5 - 0s - loss: 10.7724 - val_loss: 14.7308\n",
      "Epoch 608/1000\n",
      "5/5 - 0s - loss: 10.3890 - val_loss: 14.6998\n",
      "Epoch 609/1000\n",
      "5/5 - 0s - loss: 10.8327 - val_loss: 14.6540\n",
      "Epoch 610/1000\n",
      "5/5 - 0s - loss: 10.6743 - val_loss: 14.8329\n",
      "Epoch 611/1000\n",
      "5/5 - 0s - loss: 11.2406 - val_loss: 14.7367\n",
      "Epoch 612/1000\n",
      "5/5 - 0s - loss: 10.7340 - val_loss: 14.4333\n",
      "Epoch 613/1000\n",
      "5/5 - 0s - loss: 10.7323 - val_loss: 14.2352\n",
      "Epoch 614/1000\n",
      "5/5 - 0s - loss: 11.0873 - val_loss: 14.2853\n",
      "Epoch 615/1000\n",
      "5/5 - 0s - loss: 11.2950 - val_loss: 14.3655\n",
      "Epoch 616/1000\n",
      "5/5 - 0s - loss: 11.0253 - val_loss: 14.4620\n",
      "Epoch 617/1000\n",
      "5/5 - 0s - loss: 10.2947 - val_loss: 14.5474\n",
      "Epoch 618/1000\n",
      "5/5 - 0s - loss: 10.9703 - val_loss: 14.5687\n",
      "Epoch 619/1000\n",
      "5/5 - 0s - loss: 10.4842 - val_loss: 14.5153\n",
      "Epoch 620/1000\n",
      "5/5 - 0s - loss: 10.9114 - val_loss: 14.5483\n",
      "Epoch 621/1000\n",
      "5/5 - 0s - loss: 9.8196 - val_loss: 14.6983\n",
      "Epoch 622/1000\n",
      "5/5 - 0s - loss: 11.3326 - val_loss: 14.6643\n",
      "Epoch 623/1000\n",
      "5/5 - 0s - loss: 10.6461 - val_loss: 14.5343\n",
      "Epoch 624/1000\n",
      "5/5 - 0s - loss: 10.6982 - val_loss: 14.5240\n",
      "Epoch 625/1000\n",
      "5/5 - 0s - loss: 10.5200 - val_loss: 14.6002\n",
      "Epoch 626/1000\n",
      "5/5 - 0s - loss: 11.2107 - val_loss: 14.5581\n",
      "Epoch 627/1000\n",
      "5/5 - 0s - loss: 11.5323 - val_loss: 14.4883\n",
      "Epoch 628/1000\n",
      "5/5 - 0s - loss: 9.7256 - val_loss: 14.6793\n",
      "Epoch 629/1000\n",
      "5/5 - 0s - loss: 10.2383 - val_loss: 14.6762\n",
      "Epoch 630/1000\n",
      "5/5 - 0s - loss: 10.5721 - val_loss: 14.5571\n",
      "Epoch 631/1000\n",
      "5/5 - 0s - loss: 10.7008 - val_loss: 14.5393\n",
      "Epoch 632/1000\n",
      "5/5 - 0s - loss: 10.6803 - val_loss: 14.6891\n",
      "Epoch 633/1000\n",
      "5/5 - 0s - loss: 9.8785 - val_loss: 14.5798\n",
      "Epoch 634/1000\n",
      "5/5 - 0s - loss: 10.3873 - val_loss: 14.4972\n",
      "Epoch 635/1000\n",
      "5/5 - 0s - loss: 10.3329 - val_loss: 14.4947\n",
      "Epoch 636/1000\n",
      "5/5 - 0s - loss: 10.0528 - val_loss: 14.3332\n",
      "Epoch 637/1000\n",
      "5/5 - 0s - loss: 10.4167 - val_loss: 14.4296\n",
      "Epoch 638/1000\n",
      "5/5 - 0s - loss: 10.9713 - val_loss: 14.6098\n",
      "Epoch 639/1000\n",
      "5/5 - 0s - loss: 10.9053 - val_loss: 14.7581\n",
      "Epoch 640/1000\n",
      "5/5 - 0s - loss: 11.3486 - val_loss: 16.4043\n",
      "Epoch 641/1000\n",
      "5/5 - 0s - loss: 11.6251 - val_loss: 15.8172\n",
      "Epoch 642/1000\n",
      "5/5 - 0s - loss: 11.5964 - val_loss: 15.9155\n",
      "Epoch 643/1000\n",
      "5/5 - 0s - loss: 11.6032 - val_loss: 14.7347\n",
      "Epoch 644/1000\n",
      "5/5 - 0s - loss: 10.5333 - val_loss: 14.3761\n",
      "Epoch 645/1000\n",
      "5/5 - 0s - loss: 10.0852 - val_loss: 14.4342\n",
      "Epoch 646/1000\n",
      "5/5 - 0s - loss: 10.2846 - val_loss: 14.6878\n",
      "Epoch 647/1000\n",
      "5/5 - 0s - loss: 10.1832 - val_loss: 14.6553\n",
      "Epoch 648/1000\n",
      "5/5 - 0s - loss: 11.2441 - val_loss: 14.7867\n",
      "Epoch 649/1000\n",
      "5/5 - 0s - loss: 9.9110 - val_loss: 15.0002\n",
      "Epoch 650/1000\n",
      "5/5 - 0s - loss: 10.8246 - val_loss: 15.1919\n",
      "Epoch 651/1000\n",
      "5/5 - 0s - loss: 10.6938 - val_loss: 15.0429\n",
      "Epoch 652/1000\n",
      "5/5 - 0s - loss: 10.1859 - val_loss: 14.9078\n",
      "Epoch 653/1000\n",
      "5/5 - 0s - loss: 11.1036 - val_loss: 15.0466\n",
      "Epoch 654/1000\n",
      "5/5 - 0s - loss: 10.6977 - val_loss: 15.1635\n",
      "Epoch 655/1000\n",
      "5/5 - 0s - loss: 10.8136 - val_loss: 15.1216\n",
      "Epoch 656/1000\n",
      "5/5 - 0s - loss: 10.5158 - val_loss: 14.9226\n",
      "Epoch 657/1000\n",
      "5/5 - 0s - loss: 10.5377 - val_loss: 14.8862\n",
      "Epoch 658/1000\n",
      "5/5 - 0s - loss: 10.8907 - val_loss: 14.8705\n",
      "Epoch 659/1000\n",
      "5/5 - 0s - loss: 10.9349 - val_loss: 14.7027\n",
      "Epoch 660/1000\n",
      "5/5 - 0s - loss: 10.0386 - val_loss: 14.5796\n",
      "Epoch 661/1000\n",
      "5/5 - 0s - loss: 10.2426 - val_loss: 14.9350\n",
      "Epoch 662/1000\n",
      "5/5 - 0s - loss: 10.6787 - val_loss: 15.8744\n",
      "Epoch 663/1000\n",
      "5/5 - 0s - loss: 10.9702 - val_loss: 15.2271\n",
      "Epoch 664/1000\n",
      "5/5 - 0s - loss: 10.9685 - val_loss: 15.3304\n",
      "Epoch 665/1000\n",
      "5/5 - 0s - loss: 11.3292 - val_loss: 15.3754\n",
      "Epoch 666/1000\n",
      "5/5 - 0s - loss: 10.4391 - val_loss: 14.8957\n",
      "Epoch 667/1000\n",
      "5/5 - 0s - loss: 11.3287 - val_loss: 14.5593\n",
      "Epoch 668/1000\n",
      "5/5 - 0s - loss: 11.0809 - val_loss: 14.0503\n",
      "Epoch 669/1000\n",
      "5/5 - 0s - loss: 11.1250 - val_loss: 13.8262\n",
      "Epoch 670/1000\n",
      "5/5 - 0s - loss: 10.4573 - val_loss: 13.1034\n",
      "Epoch 671/1000\n",
      "5/5 - 0s - loss: 11.7492 - val_loss: 13.3388\n",
      "Epoch 672/1000\n",
      "5/5 - 0s - loss: 10.8818 - val_loss: 13.3932\n",
      "Epoch 673/1000\n",
      "5/5 - 0s - loss: 11.5489 - val_loss: 13.6738\n",
      "Epoch 674/1000\n",
      "5/5 - 0s - loss: 11.6114 - val_loss: 13.7725\n",
      "Epoch 675/1000\n",
      "5/5 - 0s - loss: 11.4906 - val_loss: 13.9704\n",
      "Epoch 676/1000\n",
      "5/5 - 0s - loss: 11.2138 - val_loss: 14.4414\n",
      "Epoch 677/1000\n",
      "5/5 - 0s - loss: 11.0908 - val_loss: 13.9759\n",
      "Epoch 678/1000\n",
      "5/5 - 0s - loss: 12.6244 - val_loss: 13.5187\n",
      "Epoch 679/1000\n",
      "5/5 - 0s - loss: 11.2889 - val_loss: 13.3140\n",
      "Epoch 680/1000\n",
      "5/5 - 0s - loss: 12.2396 - val_loss: 13.3081\n",
      "Epoch 681/1000\n",
      "5/5 - 0s - loss: 12.5462 - val_loss: 13.3519\n",
      "Epoch 682/1000\n",
      "5/5 - 0s - loss: 10.4818 - val_loss: 13.4136\n",
      "Epoch 683/1000\n",
      "5/5 - 0s - loss: 12.1513 - val_loss: 13.3961\n",
      "Epoch 684/1000\n",
      "5/5 - 0s - loss: 10.9057 - val_loss: 13.4590\n",
      "Epoch 685/1000\n",
      "5/5 - 0s - loss: 12.5001 - val_loss: 13.5284\n",
      "Epoch 686/1000\n",
      "5/5 - 0s - loss: 11.8677 - val_loss: 13.5304\n",
      "Epoch 687/1000\n",
      "5/5 - 0s - loss: 11.1854 - val_loss: 13.6527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 688/1000\n",
      "5/5 - 0s - loss: 11.4100 - val_loss: 13.5170\n",
      "Epoch 689/1000\n",
      "5/5 - 0s - loss: 10.8576 - val_loss: 14.0448\n",
      "Epoch 690/1000\n",
      "5/5 - 0s - loss: 10.5605 - val_loss: 14.3501\n",
      "Epoch 691/1000\n",
      "5/5 - 0s - loss: 10.9091 - val_loss: 14.4116\n",
      "Epoch 692/1000\n",
      "5/5 - 0s - loss: 11.2271 - val_loss: 14.4688\n",
      "Epoch 693/1000\n",
      "5/5 - 0s - loss: 10.9785 - val_loss: 14.5407\n",
      "Epoch 694/1000\n",
      "5/5 - 0s - loss: 10.3221 - val_loss: 14.4284\n",
      "Epoch 695/1000\n",
      "5/5 - 0s - loss: 11.2119 - val_loss: 14.4238\n",
      "Epoch 696/1000\n",
      "5/5 - 0s - loss: 10.4567 - val_loss: 14.5033\n",
      "Epoch 697/1000\n",
      "5/5 - 0s - loss: 10.7766 - val_loss: 14.4019\n",
      "Epoch 698/1000\n",
      "5/5 - 0s - loss: 10.4677 - val_loss: 14.7482\n",
      "Epoch 699/1000\n",
      "5/5 - 0s - loss: 10.3637 - val_loss: 14.0618\n",
      "Epoch 700/1000\n",
      "5/5 - 0s - loss: 11.1258 - val_loss: 12.6754\n",
      "Epoch 701/1000\n",
      "5/5 - 0s - loss: 11.2102 - val_loss: 15.7503\n",
      "Epoch 702/1000\n",
      "5/5 - 0s - loss: 11.3264 - val_loss: 15.5775\n",
      "Epoch 703/1000\n",
      "5/5 - 0s - loss: 11.2468 - val_loss: 15.3164\n",
      "Epoch 704/1000\n",
      "5/5 - 0s - loss: 10.6551 - val_loss: 14.8900\n",
      "Epoch 705/1000\n",
      "5/5 - 0s - loss: 12.5460 - val_loss: 14.9168\n",
      "Epoch 706/1000\n",
      "5/5 - 0s - loss: 10.6196 - val_loss: 14.3238\n",
      "Epoch 707/1000\n",
      "5/5 - 0s - loss: 11.4500 - val_loss: 14.0577\n",
      "Epoch 708/1000\n",
      "5/5 - 0s - loss: 11.1228 - val_loss: 13.8472\n",
      "Epoch 709/1000\n",
      "5/5 - 0s - loss: 10.3520 - val_loss: 13.8496\n",
      "Epoch 710/1000\n",
      "5/5 - 0s - loss: 10.7218 - val_loss: 13.9152\n",
      "Epoch 711/1000\n",
      "5/5 - 0s - loss: 10.2693 - val_loss: 13.7079\n",
      "Epoch 712/1000\n",
      "5/5 - 0s - loss: 10.4957 - val_loss: 13.5668\n",
      "Epoch 713/1000\n",
      "5/5 - 0s - loss: 11.1948 - val_loss: 13.5128\n",
      "Epoch 714/1000\n",
      "5/5 - 0s - loss: 11.2638 - val_loss: 13.8070\n",
      "Epoch 715/1000\n",
      "5/5 - 0s - loss: 10.9119 - val_loss: 13.7895\n",
      "Epoch 716/1000\n",
      "5/5 - 0s - loss: 10.6971 - val_loss: 13.2254\n",
      "Epoch 717/1000\n",
      "5/5 - 0s - loss: 11.2702 - val_loss: 13.8005\n",
      "Epoch 718/1000\n",
      "5/5 - 0s - loss: 10.6246 - val_loss: 12.9148\n",
      "Epoch 719/1000\n",
      "5/5 - 0s - loss: 10.3008 - val_loss: 14.7692\n",
      "Epoch 720/1000\n",
      "5/5 - 0s - loss: 11.1742 - val_loss: 15.0162\n",
      "Epoch 721/1000\n",
      "5/5 - 0s - loss: 10.4625 - val_loss: 14.4305\n",
      "Epoch 722/1000\n",
      "5/5 - 0s - loss: 11.5403 - val_loss: 14.5187\n",
      "Epoch 723/1000\n",
      "5/5 - 0s - loss: 11.4291 - val_loss: 14.7075\n",
      "Epoch 724/1000\n",
      "5/5 - 0s - loss: 10.9715 - val_loss: 14.4473\n",
      "Epoch 725/1000\n",
      "5/5 - 0s - loss: 10.8092 - val_loss: 14.3809\n",
      "Epoch 726/1000\n",
      "5/5 - 0s - loss: 11.7132 - val_loss: 13.5929\n",
      "Epoch 727/1000\n",
      "5/5 - 0s - loss: 10.6729 - val_loss: 13.2704\n",
      "Epoch 728/1000\n",
      "5/5 - 0s - loss: 10.4897 - val_loss: 14.1363\n",
      "Epoch 729/1000\n",
      "5/5 - 0s - loss: 11.1017 - val_loss: 13.8899\n",
      "Epoch 730/1000\n",
      "5/5 - 0s - loss: 10.5579 - val_loss: 14.1793\n",
      "Epoch 731/1000\n",
      "5/5 - 0s - loss: 10.5164 - val_loss: 13.9704\n",
      "Epoch 732/1000\n",
      "5/5 - 0s - loss: 11.0436 - val_loss: 14.7257\n",
      "Epoch 733/1000\n",
      "5/5 - 0s - loss: 11.2864 - val_loss: 15.0862\n",
      "Epoch 734/1000\n",
      "5/5 - 0s - loss: 11.1439 - val_loss: 14.8966\n",
      "Epoch 735/1000\n",
      "5/5 - 0s - loss: 11.4916 - val_loss: 14.8938\n",
      "Epoch 736/1000\n",
      "5/5 - 0s - loss: 11.5158 - val_loss: 14.7878\n",
      "Epoch 737/1000\n",
      "5/5 - 0s - loss: 11.2945 - val_loss: 14.6581\n",
      "Epoch 738/1000\n",
      "5/5 - 0s - loss: 11.2010 - val_loss: 14.6915\n",
      "Epoch 739/1000\n",
      "5/5 - 0s - loss: 11.4847 - val_loss: 14.6556\n",
      "Epoch 740/1000\n",
      "5/5 - 0s - loss: 11.2526 - val_loss: 14.3246\n",
      "Epoch 741/1000\n",
      "5/5 - 0s - loss: 11.4993 - val_loss: 14.3343\n",
      "Epoch 742/1000\n",
      "5/5 - 0s - loss: 10.2572 - val_loss: 14.6483\n",
      "Epoch 743/1000\n",
      "5/5 - 0s - loss: 11.5226 - val_loss: 14.7233\n",
      "Epoch 744/1000\n",
      "5/5 - 0s - loss: 11.4964 - val_loss: 15.0373\n",
      "Epoch 745/1000\n",
      "5/5 - 0s - loss: 11.8030 - val_loss: 15.1007\n",
      "Epoch 746/1000\n",
      "5/5 - 0s - loss: 10.6831 - val_loss: 14.9299\n",
      "Epoch 747/1000\n",
      "5/5 - 0s - loss: 10.7184 - val_loss: 14.8436\n",
      "Epoch 748/1000\n",
      "5/5 - 0s - loss: 11.1735 - val_loss: 14.8233\n",
      "Epoch 749/1000\n",
      "5/5 - 0s - loss: 10.7708 - val_loss: 14.7167\n",
      "Epoch 750/1000\n",
      "5/5 - 0s - loss: 11.0877 - val_loss: 14.7549\n",
      "Epoch 751/1000\n",
      "5/5 - 0s - loss: 10.8000 - val_loss: 14.7244\n",
      "Epoch 752/1000\n",
      "5/5 - 0s - loss: 10.6460 - val_loss: 14.7072\n",
      "Epoch 753/1000\n",
      "5/5 - 0s - loss: 10.2976 - val_loss: 14.6076\n",
      "Epoch 754/1000\n",
      "5/5 - 0s - loss: 11.4257 - val_loss: 14.3982\n",
      "Epoch 755/1000\n",
      "5/5 - 0s - loss: 10.0120 - val_loss: 14.4069\n",
      "Epoch 756/1000\n",
      "5/5 - 0s - loss: 10.8667 - val_loss: 14.1343\n",
      "Epoch 757/1000\n",
      "5/5 - 0s - loss: 10.9158 - val_loss: 13.9622\n",
      "Epoch 758/1000\n",
      "5/5 - 0s - loss: 10.6774 - val_loss: 13.9219\n",
      "Epoch 759/1000\n",
      "5/5 - 0s - loss: 11.3243 - val_loss: 13.2647\n",
      "Epoch 760/1000\n",
      "5/5 - 0s - loss: 10.9422 - val_loss: 12.6318\n",
      "Epoch 761/1000\n",
      "5/5 - 0s - loss: 10.5481 - val_loss: 12.1162\n",
      "Epoch 762/1000\n",
      "5/5 - 0s - loss: 10.1178 - val_loss: 15.1103\n",
      "Epoch 763/1000\n",
      "5/5 - 0s - loss: 12.9342 - val_loss: 15.1386\n",
      "Epoch 764/1000\n",
      "5/5 - 0s - loss: 12.9810 - val_loss: 14.7748\n",
      "Epoch 765/1000\n",
      "5/5 - 0s - loss: 12.7226 - val_loss: 14.7141\n",
      "Epoch 766/1000\n",
      "5/5 - 0s - loss: 11.6292 - val_loss: 14.6583\n",
      "Epoch 767/1000\n",
      "5/5 - 0s - loss: 12.0546 - val_loss: 14.4936\n",
      "Epoch 768/1000\n",
      "5/5 - 0s - loss: 12.7751 - val_loss: 14.3507\n",
      "Epoch 769/1000\n",
      "5/5 - 0s - loss: 11.4938 - val_loss: 14.2948\n",
      "Epoch 770/1000\n",
      "5/5 - 0s - loss: 11.1291 - val_loss: 14.2370\n",
      "Epoch 771/1000\n",
      "5/5 - 0s - loss: 11.8394 - val_loss: 14.2440\n",
      "Epoch 772/1000\n",
      "5/5 - 0s - loss: 11.6988 - val_loss: 14.0996\n",
      "Epoch 773/1000\n",
      "5/5 - 0s - loss: 10.6871 - val_loss: 14.0870\n",
      "Epoch 774/1000\n",
      "5/5 - 0s - loss: 11.1385 - val_loss: 14.0668\n",
      "Epoch 775/1000\n",
      "5/5 - 0s - loss: 11.4932 - val_loss: 14.1560\n",
      "Epoch 776/1000\n",
      "5/5 - 0s - loss: 11.5946 - val_loss: 14.1199\n",
      "Epoch 777/1000\n",
      "5/5 - 0s - loss: 11.8341 - val_loss: 14.1263\n",
      "Epoch 778/1000\n",
      "5/5 - 0s - loss: 11.2830 - val_loss: 14.0908\n",
      "Epoch 779/1000\n",
      "5/5 - 0s - loss: 11.7143 - val_loss: 13.8406\n",
      "Epoch 780/1000\n",
      "5/5 - 0s - loss: 11.4369 - val_loss: 13.6801\n",
      "Epoch 781/1000\n",
      "5/5 - 0s - loss: 11.7192 - val_loss: 13.8402\n",
      "Epoch 782/1000\n",
      "5/5 - 0s - loss: 11.4015 - val_loss: 14.0016\n",
      "Epoch 783/1000\n",
      "5/5 - 0s - loss: 11.4944 - val_loss: 13.9562\n",
      "Epoch 784/1000\n",
      "5/5 - 0s - loss: 11.0463 - val_loss: 13.9022\n",
      "Epoch 785/1000\n",
      "5/5 - 0s - loss: 11.5115 - val_loss: 13.8756\n",
      "Epoch 786/1000\n",
      "5/5 - 0s - loss: 11.4576 - val_loss: 14.0597\n",
      "Epoch 787/1000\n",
      "5/5 - 0s - loss: 11.8198 - val_loss: 13.9884\n",
      "Epoch 788/1000\n",
      "5/5 - 0s - loss: 12.1247 - val_loss: 13.9683\n",
      "Epoch 789/1000\n",
      "5/5 - 0s - loss: 11.1987 - val_loss: 13.9840\n",
      "Epoch 790/1000\n",
      "5/5 - 0s - loss: 10.9139 - val_loss: 14.1412\n",
      "Epoch 791/1000\n",
      "5/5 - 0s - loss: 11.0635 - val_loss: 14.0540\n",
      "Epoch 792/1000\n",
      "5/5 - 0s - loss: 11.3271 - val_loss: 13.6430\n",
      "Epoch 793/1000\n",
      "5/5 - 0s - loss: 11.5960 - val_loss: 13.3793\n",
      "Epoch 794/1000\n",
      "5/5 - 0s - loss: 11.2977 - val_loss: 13.3319\n",
      "Epoch 795/1000\n",
      "5/5 - 0s - loss: 10.8649 - val_loss: 13.3404\n",
      "Epoch 796/1000\n",
      "5/5 - 0s - loss: 11.5521 - val_loss: 13.4090\n",
      "Epoch 797/1000\n",
      "5/5 - 0s - loss: 10.8401 - val_loss: 13.4271\n",
      "Epoch 798/1000\n",
      "5/5 - 0s - loss: 10.9245 - val_loss: 13.5503\n",
      "Epoch 799/1000\n",
      "5/5 - 0s - loss: 11.1241 - val_loss: 13.5087\n",
      "Epoch 800/1000\n",
      "5/5 - 0s - loss: 11.2666 - val_loss: 13.8000\n",
      "Epoch 801/1000\n",
      "5/5 - 0s - loss: 12.0508 - val_loss: 14.1145\n",
      "Epoch 802/1000\n",
      "5/5 - 0s - loss: 11.8342 - val_loss: 14.3071\n",
      "Epoch 803/1000\n",
      "5/5 - 0s - loss: 10.8663 - val_loss: 14.3457\n",
      "Epoch 804/1000\n",
      "5/5 - 0s - loss: 11.1285 - val_loss: 14.2006\n",
      "Epoch 805/1000\n",
      "5/5 - 0s - loss: 10.6976 - val_loss: 14.1405\n",
      "Epoch 806/1000\n",
      "5/5 - 0s - loss: 11.0704 - val_loss: 14.2971\n",
      "Epoch 807/1000\n",
      "5/5 - 0s - loss: 10.0713 - val_loss: 14.6676\n",
      "Epoch 808/1000\n",
      "5/5 - 0s - loss: 10.8336 - val_loss: 14.5460\n",
      "Epoch 809/1000\n",
      "5/5 - 0s - loss: 11.2205 - val_loss: 14.4169\n",
      "Epoch 810/1000\n",
      "5/5 - 0s - loss: 10.9396 - val_loss: 14.3075\n",
      "Epoch 811/1000\n",
      "5/5 - 0s - loss: 11.2311 - val_loss: 14.4561\n",
      "Epoch 812/1000\n",
      "5/5 - 0s - loss: 10.3613 - val_loss: 14.4583\n",
      "Epoch 813/1000\n",
      "5/5 - 0s - loss: 10.7657 - val_loss: 14.4201\n",
      "Epoch 814/1000\n",
      "5/5 - 0s - loss: 10.6482 - val_loss: 14.3293\n",
      "Epoch 815/1000\n",
      "5/5 - 0s - loss: 10.9281 - val_loss: 14.2889\n",
      "Epoch 816/1000\n",
      "5/5 - 0s - loss: 11.4591 - val_loss: 14.7471\n",
      "Epoch 817/1000\n",
      "5/5 - 0s - loss: 11.0965 - val_loss: 13.6332\n",
      "Epoch 818/1000\n",
      "5/5 - 0s - loss: 11.3266 - val_loss: 13.4813\n",
      "Epoch 819/1000\n",
      "5/5 - 0s - loss: 11.5875 - val_loss: 13.6313\n",
      "Epoch 820/1000\n",
      "5/5 - 0s - loss: 11.8626 - val_loss: 14.0938\n",
      "Epoch 821/1000\n",
      "5/5 - 0s - loss: 11.0232 - val_loss: 14.0863\n",
      "Epoch 822/1000\n",
      "5/5 - 0s - loss: 11.1881 - val_loss: 14.5137\n",
      "Epoch 823/1000\n",
      "5/5 - 0s - loss: 11.2180 - val_loss: 14.4055\n",
      "Epoch 824/1000\n",
      "5/5 - 0s - loss: 11.4593 - val_loss: 13.9538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 825/1000\n",
      "5/5 - 0s - loss: 11.1451 - val_loss: 13.7725\n",
      "Epoch 826/1000\n",
      "5/5 - 0s - loss: 11.4748 - val_loss: 13.8964\n",
      "Epoch 827/1000\n",
      "5/5 - 0s - loss: 11.3407 - val_loss: 14.0759\n",
      "Epoch 828/1000\n",
      "5/5 - 0s - loss: 10.6524 - val_loss: 14.1075\n",
      "Epoch 829/1000\n",
      "5/5 - 0s - loss: 11.2764 - val_loss: 14.1463\n",
      "Epoch 830/1000\n",
      "5/5 - 0s - loss: 10.8591 - val_loss: 14.2504\n",
      "Epoch 831/1000\n",
      "5/5 - 0s - loss: 11.0464 - val_loss: 14.3468\n",
      "Epoch 832/1000\n",
      "5/5 - 0s - loss: 11.1542 - val_loss: 14.2854\n",
      "Epoch 833/1000\n",
      "5/5 - 0s - loss: 10.1237 - val_loss: 13.9854\n",
      "Epoch 834/1000\n",
      "5/5 - 0s - loss: 10.2592 - val_loss: 14.0926\n",
      "Epoch 835/1000\n",
      "5/5 - 0s - loss: 10.7001 - val_loss: 14.2550\n",
      "Epoch 836/1000\n",
      "5/5 - 0s - loss: 10.5793 - val_loss: 14.6244\n",
      "Epoch 837/1000\n",
      "5/5 - 0s - loss: 10.6157 - val_loss: 14.1828\n",
      "Epoch 838/1000\n",
      "5/5 - 0s - loss: 11.0206 - val_loss: 13.8951\n",
      "Epoch 839/1000\n",
      "5/5 - 0s - loss: 10.5867 - val_loss: 13.7682\n",
      "Epoch 840/1000\n",
      "5/5 - 0s - loss: 10.2678 - val_loss: 13.8931\n",
      "Epoch 841/1000\n",
      "5/5 - 0s - loss: 11.1337 - val_loss: 13.8072\n",
      "Epoch 842/1000\n",
      "5/5 - 0s - loss: 10.2031 - val_loss: 14.0367\n",
      "Epoch 843/1000\n",
      "5/5 - 0s - loss: 11.0119 - val_loss: 14.1615\n",
      "Epoch 844/1000\n",
      "5/5 - 0s - loss: 11.0377 - val_loss: 14.0043\n",
      "Epoch 845/1000\n",
      "5/5 - 0s - loss: 10.5327 - val_loss: 14.8489\n",
      "Epoch 846/1000\n",
      "5/5 - 0s - loss: 10.2963 - val_loss: 14.6290\n",
      "Epoch 847/1000\n",
      "5/5 - 0s - loss: 10.4693 - val_loss: 14.5081\n",
      "Epoch 848/1000\n",
      "5/5 - 0s - loss: 10.7217 - val_loss: 14.0190\n",
      "Epoch 849/1000\n",
      "5/5 - 0s - loss: 10.4957 - val_loss: 13.7887\n",
      "Epoch 850/1000\n",
      "5/5 - 0s - loss: 10.5142 - val_loss: 13.8347\n",
      "Epoch 851/1000\n",
      "5/5 - 0s - loss: 10.2814 - val_loss: 13.8570\n",
      "Epoch 852/1000\n",
      "5/5 - 0s - loss: 10.8245 - val_loss: 13.9852\n",
      "Epoch 853/1000\n",
      "5/5 - 0s - loss: 10.1697 - val_loss: 13.9395\n",
      "Epoch 854/1000\n",
      "5/5 - 0s - loss: 10.5706 - val_loss: 14.7704\n",
      "Epoch 855/1000\n",
      "5/5 - 0s - loss: 10.1773 - val_loss: 14.6375\n",
      "Epoch 856/1000\n",
      "5/5 - 0s - loss: 11.0259 - val_loss: 14.2777\n",
      "Epoch 857/1000\n",
      "5/5 - 0s - loss: 9.9116 - val_loss: 13.7463\n",
      "Epoch 858/1000\n",
      "5/5 - 0s - loss: 9.9680 - val_loss: 15.3680\n",
      "Epoch 859/1000\n",
      "5/5 - 0s - loss: 9.8205 - val_loss: 13.1574\n",
      "Epoch 860/1000\n",
      "5/5 - 0s - loss: 9.8760 - val_loss: 18.7934\n",
      "Epoch 861/1000\n",
      "5/5 - 0s - loss: 11.7124 - val_loss: 19.0533\n",
      "Epoch 862/1000\n",
      "5/5 - 0s - loss: 12.3977 - val_loss: 18.4940\n",
      "Epoch 863/1000\n",
      "5/5 - 0s - loss: 12.1506 - val_loss: 17.5470\n",
      "Epoch 864/1000\n",
      "5/5 - 0s - loss: 11.9071 - val_loss: 16.7123\n",
      "Epoch 865/1000\n",
      "5/5 - 0s - loss: 11.5802 - val_loss: 16.2118\n",
      "Epoch 866/1000\n",
      "5/5 - 0s - loss: 11.5024 - val_loss: 15.5956\n",
      "Epoch 867/1000\n",
      "5/5 - 0s - loss: 11.2824 - val_loss: 15.3383\n",
      "Epoch 868/1000\n",
      "5/5 - 0s - loss: 10.4220 - val_loss: 15.2296\n",
      "Epoch 869/1000\n",
      "5/5 - 0s - loss: 10.8206 - val_loss: 15.6463\n",
      "Epoch 870/1000\n",
      "5/5 - 0s - loss: 11.8886 - val_loss: 14.9306\n",
      "Epoch 871/1000\n",
      "5/5 - 0s - loss: 10.6073 - val_loss: 14.6525\n",
      "Epoch 872/1000\n",
      "5/5 - 0s - loss: 11.4932 - val_loss: 14.5689\n",
      "Epoch 873/1000\n",
      "5/5 - 0s - loss: 11.2235 - val_loss: 14.7148\n",
      "Epoch 874/1000\n",
      "5/5 - 0s - loss: 10.9443 - val_loss: 14.7070\n",
      "Epoch 875/1000\n",
      "5/5 - 0s - loss: 10.9911 - val_loss: 14.6508\n",
      "Epoch 876/1000\n",
      "5/5 - 0s - loss: 10.5175 - val_loss: 14.6273\n",
      "Epoch 877/1000\n",
      "5/5 - 0s - loss: 11.1534 - val_loss: 14.6238\n",
      "Epoch 878/1000\n",
      "5/5 - 0s - loss: 10.8231 - val_loss: 14.6352\n",
      "Epoch 879/1000\n",
      "5/5 - 0s - loss: 11.0960 - val_loss: 14.5273\n",
      "Epoch 880/1000\n",
      "5/5 - 0s - loss: 11.0336 - val_loss: 14.3485\n",
      "Epoch 881/1000\n",
      "5/5 - 0s - loss: 10.5417 - val_loss: 14.2359\n",
      "Epoch 882/1000\n",
      "5/5 - 0s - loss: 10.0593 - val_loss: 14.1927\n",
      "Epoch 883/1000\n",
      "5/5 - 0s - loss: 10.7715 - val_loss: 13.2098\n",
      "Epoch 884/1000\n",
      "5/5 - 0s - loss: 10.3601 - val_loss: 16.5853\n",
      "Epoch 885/1000\n",
      "5/5 - 0s - loss: 11.7354 - val_loss: 16.7797\n",
      "Epoch 886/1000\n",
      "5/5 - 0s - loss: 12.8925 - val_loss: 15.9781\n",
      "Epoch 887/1000\n",
      "5/5 - 0s - loss: 12.4987 - val_loss: 15.1742\n",
      "Epoch 888/1000\n",
      "5/5 - 0s - loss: 11.5146 - val_loss: 15.0216\n",
      "Epoch 889/1000\n",
      "5/5 - 0s - loss: 11.8181 - val_loss: 14.9426\n",
      "Epoch 890/1000\n",
      "5/5 - 0s - loss: 11.7606 - val_loss: 14.8939\n",
      "Epoch 891/1000\n",
      "5/5 - 0s - loss: 11.3135 - val_loss: 14.8429\n",
      "Epoch 892/1000\n",
      "5/5 - 0s - loss: 12.0173 - val_loss: 14.8350\n",
      "Epoch 893/1000\n",
      "5/5 - 0s - loss: 11.9358 - val_loss: 14.6986\n",
      "Epoch 894/1000\n",
      "5/5 - 0s - loss: 11.4813 - val_loss: 14.6433\n",
      "Epoch 895/1000\n",
      "5/5 - 0s - loss: 11.8950 - val_loss: 14.7157\n",
      "Epoch 896/1000\n",
      "5/5 - 0s - loss: 11.8427 - val_loss: 14.8045\n",
      "Epoch 897/1000\n",
      "5/5 - 0s - loss: 11.6406 - val_loss: 14.9237\n",
      "Epoch 898/1000\n",
      "5/5 - 0s - loss: 11.6990 - val_loss: 14.9013\n",
      "Epoch 899/1000\n",
      "5/5 - 0s - loss: 11.8053 - val_loss: 14.7765\n",
      "Epoch 900/1000\n",
      "5/5 - 0s - loss: 11.8637 - val_loss: 14.5812\n",
      "Epoch 901/1000\n",
      "5/5 - 0s - loss: 11.4943 - val_loss: 14.5884\n",
      "Epoch 902/1000\n",
      "5/5 - 0s - loss: 11.0724 - val_loss: 14.5957\n",
      "Epoch 903/1000\n",
      "5/5 - 0s - loss: 11.4835 - val_loss: 15.0045\n",
      "Epoch 904/1000\n",
      "5/5 - 0s - loss: 11.5813 - val_loss: 15.1616\n",
      "Epoch 905/1000\n",
      "5/5 - 0s - loss: 11.9244 - val_loss: 15.0686\n",
      "Epoch 906/1000\n",
      "5/5 - 0s - loss: 11.0475 - val_loss: 15.0167\n",
      "Epoch 907/1000\n",
      "5/5 - 0s - loss: 11.5234 - val_loss: 15.0024\n",
      "Epoch 908/1000\n",
      "5/5 - 0s - loss: 11.3847 - val_loss: 14.9353\n",
      "Epoch 909/1000\n",
      "5/5 - 0s - loss: 11.4847 - val_loss: 14.9129\n",
      "Epoch 910/1000\n",
      "5/5 - 0s - loss: 10.7898 - val_loss: 14.9571\n",
      "Epoch 911/1000\n",
      "5/5 - 0s - loss: 11.5474 - val_loss: 14.9409\n",
      "Epoch 912/1000\n",
      "5/5 - 0s - loss: 11.6054 - val_loss: 14.8723\n",
      "Epoch 913/1000\n",
      "5/5 - 0s - loss: 11.7941 - val_loss: 14.8299\n",
      "Epoch 914/1000\n",
      "5/5 - 0s - loss: 12.0262 - val_loss: 14.8330\n",
      "Epoch 915/1000\n",
      "5/5 - 0s - loss: 11.7618 - val_loss: 14.8226\n",
      "Epoch 916/1000\n",
      "5/5 - 0s - loss: 11.5643 - val_loss: 14.3932\n",
      "Epoch 917/1000\n",
      "5/5 - 0s - loss: 11.6637 - val_loss: 13.9991\n",
      "Epoch 918/1000\n",
      "5/5 - 0s - loss: 10.3792 - val_loss: 13.9592\n",
      "Epoch 919/1000\n",
      "5/5 - 0s - loss: 11.6097 - val_loss: 13.6946\n",
      "Epoch 920/1000\n",
      "5/5 - 0s - loss: 10.8358 - val_loss: 13.4995\n",
      "Epoch 921/1000\n",
      "5/5 - 0s - loss: 10.5036 - val_loss: 13.3851\n",
      "Epoch 922/1000\n",
      "5/5 - 0s - loss: 11.0470 - val_loss: 13.5308\n",
      "Epoch 923/1000\n",
      "5/5 - 0s - loss: 10.7512 - val_loss: 13.7439\n",
      "Epoch 924/1000\n",
      "5/5 - 0s - loss: 11.6006 - val_loss: 13.7713\n",
      "Epoch 925/1000\n",
      "5/5 - 0s - loss: 10.8147 - val_loss: 13.6978\n",
      "Epoch 926/1000\n",
      "5/5 - 0s - loss: 11.4033 - val_loss: 13.8346\n",
      "Epoch 927/1000\n",
      "5/5 - 0s - loss: 10.7544 - val_loss: 13.9106\n",
      "Epoch 928/1000\n",
      "5/5 - 0s - loss: 11.3269 - val_loss: 14.0723\n",
      "Epoch 929/1000\n",
      "5/5 - 0s - loss: 10.9429 - val_loss: 14.2063\n",
      "Epoch 930/1000\n",
      "5/5 - 0s - loss: 11.2169 - val_loss: 14.3225\n",
      "Epoch 931/1000\n",
      "5/5 - 0s - loss: 11.4321 - val_loss: 14.3636\n",
      "Epoch 932/1000\n",
      "5/5 - 0s - loss: 11.0244 - val_loss: 14.4539\n",
      "Epoch 933/1000\n",
      "5/5 - 0s - loss: 10.3942 - val_loss: 14.5972\n",
      "Epoch 934/1000\n",
      "5/5 - 0s - loss: 10.9442 - val_loss: 14.5238\n",
      "Epoch 935/1000\n",
      "5/5 - 0s - loss: 10.8799 - val_loss: 14.5357\n",
      "Epoch 936/1000\n",
      "5/5 - 0s - loss: 10.2225 - val_loss: 14.4986\n",
      "Epoch 937/1000\n",
      "5/5 - 0s - loss: 10.7247 - val_loss: 14.5852\n",
      "Epoch 938/1000\n",
      "5/5 - 0s - loss: 10.3406 - val_loss: 15.0062\n",
      "Epoch 939/1000\n",
      "5/5 - 0s - loss: 10.7717 - val_loss: 14.8511\n",
      "Epoch 940/1000\n",
      "5/5 - 0s - loss: 11.5861 - val_loss: 14.5840\n",
      "Epoch 941/1000\n",
      "5/5 - 0s - loss: 11.0682 - val_loss: 13.6052\n",
      "Epoch 942/1000\n",
      "5/5 - 0s - loss: 11.4379 - val_loss: 13.3522\n",
      "Epoch 943/1000\n",
      "5/5 - 0s - loss: 11.0010 - val_loss: 13.3720\n",
      "Epoch 944/1000\n",
      "5/5 - 0s - loss: 11.6311 - val_loss: 13.2983\n",
      "Epoch 945/1000\n",
      "5/5 - 0s - loss: 10.8192 - val_loss: 13.3705\n",
      "Epoch 946/1000\n",
      "5/5 - 0s - loss: 10.7868 - val_loss: 13.3447\n",
      "Epoch 947/1000\n",
      "5/5 - 0s - loss: 10.9181 - val_loss: 13.3101\n",
      "Epoch 948/1000\n",
      "5/5 - 0s - loss: 11.4571 - val_loss: 13.3308\n",
      "Epoch 949/1000\n",
      "5/5 - 0s - loss: 11.3842 - val_loss: 13.3395\n",
      "Epoch 950/1000\n",
      "5/5 - 0s - loss: 10.9494 - val_loss: 13.3836\n",
      "Epoch 951/1000\n",
      "5/5 - 0s - loss: 10.3562 - val_loss: 13.3697\n",
      "Epoch 952/1000\n",
      "5/5 - 0s - loss: 11.0548 - val_loss: 13.3683\n",
      "Epoch 953/1000\n",
      "5/5 - 0s - loss: 10.8912 - val_loss: 13.2994\n",
      "Epoch 954/1000\n",
      "5/5 - 0s - loss: 10.5745 - val_loss: 13.2754\n",
      "Epoch 955/1000\n",
      "5/5 - 0s - loss: 11.1353 - val_loss: 13.2618\n",
      "Epoch 956/1000\n",
      "5/5 - 0s - loss: 11.0250 - val_loss: 13.2460\n",
      "Epoch 957/1000\n",
      "5/5 - 0s - loss: 10.5311 - val_loss: 13.3820\n",
      "Epoch 958/1000\n",
      "5/5 - 0s - loss: 10.8583 - val_loss: 13.4098\n",
      "Epoch 959/1000\n",
      "5/5 - 0s - loss: 11.1337 - val_loss: 13.3750\n",
      "Epoch 960/1000\n",
      "5/5 - 0s - loss: 10.5427 - val_loss: 13.4596\n",
      "Epoch 961/1000\n",
      "5/5 - 0s - loss: 10.3668 - val_loss: 13.4581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 962/1000\n",
      "5/5 - 0s - loss: 10.8374 - val_loss: 13.5489\n",
      "Epoch 963/1000\n",
      "5/5 - 0s - loss: 11.1518 - val_loss: 13.4760\n",
      "Epoch 964/1000\n",
      "5/5 - 0s - loss: 11.0374 - val_loss: 13.5550\n",
      "Epoch 965/1000\n",
      "5/5 - 0s - loss: 10.7490 - val_loss: 13.7031\n",
      "Epoch 966/1000\n",
      "5/5 - 0s - loss: 10.9532 - val_loss: 13.7236\n",
      "Epoch 967/1000\n",
      "5/5 - 0s - loss: 11.1228 - val_loss: 13.6785\n",
      "Epoch 968/1000\n",
      "5/5 - 0s - loss: 10.9286 - val_loss: 13.6293\n",
      "Epoch 969/1000\n",
      "5/5 - 0s - loss: 10.9300 - val_loss: 13.6177\n",
      "Epoch 970/1000\n",
      "5/5 - 0s - loss: 11.0304 - val_loss: 13.6837\n",
      "Epoch 971/1000\n",
      "5/5 - 0s - loss: 11.0492 - val_loss: 13.6298\n",
      "Epoch 972/1000\n",
      "5/5 - 0s - loss: 11.0741 - val_loss: 13.6224\n",
      "Epoch 973/1000\n",
      "5/5 - 0s - loss: 10.7854 - val_loss: 13.5526\n",
      "Epoch 974/1000\n",
      "5/5 - 0s - loss: 11.0050 - val_loss: 13.5640\n",
      "Epoch 975/1000\n",
      "5/5 - 0s - loss: 10.7270 - val_loss: 13.5623\n",
      "Epoch 976/1000\n",
      "5/5 - 0s - loss: 10.1656 - val_loss: 13.5494\n",
      "Epoch 977/1000\n",
      "5/5 - 0s - loss: 10.3347 - val_loss: 13.5681\n",
      "Epoch 978/1000\n",
      "5/5 - 0s - loss: 10.7554 - val_loss: 13.5751\n",
      "Epoch 979/1000\n",
      "5/5 - 0s - loss: 10.8007 - val_loss: 13.5080\n",
      "Epoch 980/1000\n",
      "5/5 - 0s - loss: 10.8917 - val_loss: 13.5167\n",
      "Epoch 981/1000\n",
      "5/5 - 0s - loss: 10.7628 - val_loss: 13.5744\n",
      "Epoch 982/1000\n",
      "5/5 - 0s - loss: 11.1078 - val_loss: 13.5937\n",
      "Epoch 983/1000\n",
      "5/5 - 0s - loss: 11.3024 - val_loss: 13.5674\n",
      "Epoch 984/1000\n",
      "5/5 - 0s - loss: 10.8823 - val_loss: 13.5212\n",
      "Epoch 985/1000\n",
      "5/5 - 0s - loss: 10.3708 - val_loss: 13.5172\n",
      "Epoch 986/1000\n",
      "5/5 - 0s - loss: 10.8329 - val_loss: 13.4052\n",
      "Epoch 987/1000\n",
      "5/5 - 0s - loss: 10.7324 - val_loss: 13.4737\n",
      "Epoch 988/1000\n",
      "5/5 - 0s - loss: 11.0471 - val_loss: 13.5128\n",
      "Epoch 989/1000\n",
      "5/5 - 0s - loss: 10.9113 - val_loss: 13.6665\n",
      "Epoch 990/1000\n",
      "5/5 - 0s - loss: 11.0448 - val_loss: 13.7033\n",
      "Epoch 991/1000\n",
      "5/5 - 0s - loss: 11.5633 - val_loss: 13.5757\n",
      "Epoch 992/1000\n",
      "5/5 - 0s - loss: 10.7938 - val_loss: 13.5192\n",
      "Epoch 993/1000\n",
      "5/5 - 0s - loss: 11.2443 - val_loss: 13.4865\n",
      "Epoch 994/1000\n",
      "5/5 - 0s - loss: 10.6465 - val_loss: 13.5381\n",
      "Epoch 995/1000\n",
      "5/5 - 0s - loss: 10.7825 - val_loss: 13.5611\n",
      "Epoch 996/1000\n",
      "5/5 - 0s - loss: 10.2278 - val_loss: 13.5889\n",
      "Epoch 997/1000\n",
      "5/5 - 0s - loss: 10.3035 - val_loss: 13.5105\n",
      "Epoch 998/1000\n",
      "5/5 - 0s - loss: 10.4630 - val_loss: 13.5018\n",
      "Epoch 999/1000\n",
      "5/5 - 0s - loss: 11.0335 - val_loss: 13.5058\n",
      "Epoch 1000/1000\n",
      "5/5 - 0s - loss: 10.6216 - val_loss: 13.5230\n"
     ]
    }
   ],
   "source": [
    "history = lstm_model.fit(train_X, train_y, epochs=1000, batch_size=72, validation_data=(test_X, test_y), verbose=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Based on the num_predictions we choose, we predict on that many random time series and derive a resulting root mean square error\n",
    "\n",
    "# The resulting prediction is sufficiency rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "yhat = lstm_model.predict(test_X)\n",
    "mse = mean_squared_error(test_y, yhat)\n",
    "rmse = math.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.466341842349166"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# will need to plot loss and val_loss, figure out model predict error, as well as train the model for longer to reduce loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_bridge_management_kernel",
   "language": "python",
   "name": "tf_bridge_management"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
