{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the Python version being used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.6\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check that the available gpu is being utilized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available\")\n",
    "print(len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in clustering dataset, note that this one is still missing the aggregated weather data, but this can easily be added in later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "\n",
    "df = read_csv('Time_Series_For_Clustering_El_Paso_Final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bridge_ID</th>\n",
       "      <th>time_0</th>\n",
       "      <th>time_1</th>\n",
       "      <th>time_2</th>\n",
       "      <th>time_3</th>\n",
       "      <th>time_4</th>\n",
       "      <th>time_5</th>\n",
       "      <th>time_6</th>\n",
       "      <th>time_7</th>\n",
       "      <th>time_8</th>\n",
       "      <th>...</th>\n",
       "      <th>time_12</th>\n",
       "      <th>time_13</th>\n",
       "      <th>time_14</th>\n",
       "      <th>time_15</th>\n",
       "      <th>time_16</th>\n",
       "      <th>time_17</th>\n",
       "      <th>time_18</th>\n",
       "      <th>time_19</th>\n",
       "      <th>time_20</th>\n",
       "      <th>time_21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.12E+13</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CALHAN-8TH ST.</td>\n",
       "      <td>[36.0, 97.0, 428, 1949, 2, 10.9, 7.3]</td>\n",
       "      <td>[36.0, 96.9, 955, 1949, 2, 10.9, 7.3]</td>\n",
       "      <td>[36.0, 96.9, 955, 1949, 2, 10.9, 7.3]</td>\n",
       "      <td>[36.0, 96.9, 955, 1949, 2, 10.9, 7.3]</td>\n",
       "      <td>[36.0, 96.9, 955, 1949, 2, 10.9, 7.3]</td>\n",
       "      <td>[36.3, 97.0, 955, 1949, 2, 11.0, 7.0]</td>\n",
       "      <td>[36.3, 96.9, 955, 1949, 2, 11.0, 7.3]</td>\n",
       "      <td>[36.3, 96.9, 983, 1949, 2, 11.0, 7.3]</td>\n",
       "      <td>[36.3, 96.9, 983, 1949, 2, 11.0, 7.3]</td>\n",
       "      <td>...</td>\n",
       "      <td>[36.3, 97.0, 422, 1949, 2, 11.0, 7.3]</td>\n",
       "      <td>[36.3, 97.0, 422, 1949, 2, 11.0, 7.3]</td>\n",
       "      <td>[36.3, 97.0, 422, 1949, 2, 11.0, 7.3]</td>\n",
       "      <td>[36.3, 97.0, 422, 1949, 2, 9.7, 7.3]</td>\n",
       "      <td>[36.3, 97.0, 369, 1949, 2, 9.7, 7.3]</td>\n",
       "      <td>[36.3, 86.0, 369, 1949, 2, 9.7, 7.3]</td>\n",
       "      <td>[36.3, 86.0, 369, 1949, 2, 9.7, 7.3]</td>\n",
       "      <td>[36.3, 86.0, 369, 1949, 2, 9.7, 7.3]</td>\n",
       "      <td>[36.3, 86.0, 369, 1949, 2, 9.7, 7.3]</td>\n",
       "      <td>[36.3, 86.0, 522, 1949, 2, 9.7, 7.3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CSG-C.80-07.65</td>\n",
       "      <td>[36.0, 83.9, 417, 1970, 2, 6.6, 6.4]</td>\n",
       "      <td>[36.0, 70.9, 351, 1970, 2, 6.6, 3.0]</td>\n",
       "      <td>[36.0, 70.9, 351, 1970, 2, 6.6, 3.0]</td>\n",
       "      <td>[36.0, 70.9, 351, 1970, 2, 6.6, 3.0]</td>\n",
       "      <td>[36.0, 70.9, 351, 1970, 2, 6.6, 3.0]</td>\n",
       "      <td>[36.3, 76.0, 351, 1970, 2, 6.6, 3.0]</td>\n",
       "      <td>[36.3, 69.0, 351, 1970, 2, 6.6, 3.0]</td>\n",
       "      <td>[36.3, 66.9, 478, 1970, 2, 6.6, 2.9]</td>\n",
       "      <td>[36.3, 66.9, 478, 1970, 2, 6.6, 2.9]</td>\n",
       "      <td>...</td>\n",
       "      <td>[36.3, 62.9, 478, 1970, 2, 6.6, 2.9]</td>\n",
       "      <td>[36.3, 62.9, 777, 1970, 2, 6.6, 2.9]</td>\n",
       "      <td>[36.3, 62.9, 777, 1970, 2, 6.6, 2.9]</td>\n",
       "      <td>[36.3, 62.9, 777, 1970, 2, 6.6, 2.9]</td>\n",
       "      <td>[36.3, 62.9, 623, 1970, 2, 6.6, 2.9]</td>\n",
       "      <td>[36.3, 62.9, 623, 1970, 2, 6.6, 2.9]</td>\n",
       "      <td>[36.3, 62.9, 623, 1970, 2, 6.6, 2.9]</td>\n",
       "      <td>[32.7, 55.7, 623, 1970, 2, 6.6, 2.9]</td>\n",
       "      <td>[32.7, 55.7, 623, 1970, 2, 6.6, 2.9]</td>\n",
       "      <td>[32.7, 55.7, 717, 1970, 2, 6.6, 2.9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CSG-D.04-10.42</td>\n",
       "      <td>[36.0, 82.0, 1836, 1955, 2, 7.6, 4.0]</td>\n",
       "      <td>[36.0, 84.3, 1459, 1955, 2, 7.7, 4.0]</td>\n",
       "      <td>[36.0, 84.3, 1459, 1955, 2, 7.7, 4.0]</td>\n",
       "      <td>[36.0, 84.3, 1459, 1955, 2, 7.7, 4.0]</td>\n",
       "      <td>[36.0, 84.3, 1459, 1955, 2, 7.7, 3.4]</td>\n",
       "      <td>[36.3, 83.4, 1459, 1955, 2, 7.7, 3.0]</td>\n",
       "      <td>[36.3, 84.3, 1459, 1955, 2, 7.7, 3.4]</td>\n",
       "      <td>[36.3, 84.4, 1295, 1955, 2, 7.7, 3.4]</td>\n",
       "      <td>[36.3, 84.4, 1295, 1955, 2, 7.7, 3.4]</td>\n",
       "      <td>...</td>\n",
       "      <td>[36.3, 72.3, 1295, 1955, 2, 7.7, 3.4]</td>\n",
       "      <td>[36.3, 72.3, 1329, 1955, 2, 7.7, 3.4]</td>\n",
       "      <td>[36.3, 72.3, 1329, 1955, 2, 7.7, 3.4]</td>\n",
       "      <td>[36.3, 72.3, 1329, 1955, 2, 7.7, 3.4]</td>\n",
       "      <td>[36.3, 72.3, 1446, 1955, 2, 7.7, 3.4]</td>\n",
       "      <td>[36.3, 72.3, 1446, 1955, 2, 7.7, 3.4]</td>\n",
       "      <td>[36.3, 72.3, 1446, 1955, 2, 7.7, 3.4]</td>\n",
       "      <td>[27.2, 50.2, 1446, 1955, 2, 7.7, 3.4]</td>\n",
       "      <td>[27.2, 50.2, 1446, 1955, 2, 7.7, 3.4]</td>\n",
       "      <td>[27.2, 50.2, 2696, 1955, 2, 7.7, 3.4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CSG-D.37-15.67</td>\n",
       "      <td>[36.0, 97.0, 87, 1984, 2, 12.8, 3.0]</td>\n",
       "      <td>[36.0, 97.0, 305, 1984, 2, 12.8, 3.0]</td>\n",
       "      <td>[36.0, 97.0, 305, 1984, 2, 12.8, 3.0]</td>\n",
       "      <td>[36.0, 97.0, 305, 1984, 2, 12.8, 3.0]</td>\n",
       "      <td>[36.0, 97.0, 305, 1984, 2, 12.8, 3.0]</td>\n",
       "      <td>[36.3, 97.0, 305, 1984, 2, 12.8, 3.0]</td>\n",
       "      <td>[36.3, 97.0, 305, 1984, 2, 12.8, 3.0]</td>\n",
       "      <td>[36.3, 97.0, 397, 1984, 2, 12.8, 3.0]</td>\n",
       "      <td>[36.3, 97.0, 397, 1984, 2, 12.8, 3.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>[36.3, 98.0, 397, 1984, 2, 13.3, 3.0]</td>\n",
       "      <td>[36.3, 98.0, 287, 1984, 2, 13.3, 3.0]</td>\n",
       "      <td>[36.3, 98.0, 287, 1984, 2, 13.3, 3.0]</td>\n",
       "      <td>[36.3, 99.0, 287, 1984, 2, 12.8, 3.0]</td>\n",
       "      <td>[36.3, 99.0, 302, 1984, 2, 12.8, 3.0]</td>\n",
       "      <td>[36.3, 100.0, 302, 1984, 2, 12.8, 3.0]</td>\n",
       "      <td>[36.3, 100.0, 302, 1984, 2, 12.8, 3.0]</td>\n",
       "      <td>[36.3, 100.0, 302, 1984, 2, 12.8, 3.0]</td>\n",
       "      <td>[36.3, 100.0, 302, 1984, 2, 12.8, 3.0]</td>\n",
       "      <td>[36.3, 100.0, 268, 1984, 2, 12.8, 3.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>I-17-G</td>\n",
       "      <td>[87.3, 82.0, 13500, 1942, 0, 10.9, 14.0]</td>\n",
       "      <td>[87.3, 82.0, 13500, 1942, 0, 10.9, 14.0]</td>\n",
       "      <td>[87.3, 82.0, 13500, 1942, 0, 10.9, 14.0]</td>\n",
       "      <td>[87.3, 82.0, 13500, 1942, 0, 10.9, 14.0]</td>\n",
       "      <td>[87.3, 82.0, 13500, 1942, 0, 10.9, 14.0]</td>\n",
       "      <td>[87.3, 82.0, 13500, 1942, 0, 10.9, 14.0]</td>\n",
       "      <td>[87.3, 82.0, 13500, 1942, 0, 10.9, 14.0]</td>\n",
       "      <td>[87.3, 82.0, 13500, 1942, 0, 10.9, 14.0]</td>\n",
       "      <td>[87.3, 82.0, 39228, 1972, 0, 24.1, 26.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>[87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]</td>\n",
       "      <td>[87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]</td>\n",
       "      <td>[87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]</td>\n",
       "      <td>[87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]</td>\n",
       "      <td>[87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]</td>\n",
       "      <td>[87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]</td>\n",
       "      <td>[87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]</td>\n",
       "      <td>[87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]</td>\n",
       "      <td>[87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]</td>\n",
       "      <td>[87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>I-17-HK</td>\n",
       "      <td>[87.3, 82.0, 38400, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>...</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>I-17-JH</td>\n",
       "      <td>[87.3, 82.0, 10500, 1995, 0, 12.9, 20.7]</td>\n",
       "      <td>[87.3, 82.0, 32904, 1995, 0, 12.9, 20.7]</td>\n",
       "      <td>[87.3, 82.0, 32904, 1995, 0, 12.9, 20.7]</td>\n",
       "      <td>[87.3, 82.0, 32904, 1995, 0, 12.9, 20.7]</td>\n",
       "      <td>[87.3, 82.0, 36024, 1995, 0, 12.1, 20.7]</td>\n",
       "      <td>[87.3, 82.0, 36024, 1995, 0, 12.2, 21.0]</td>\n",
       "      <td>[87.3, 82.0, 36024, 1995, 0, 12.2, 21.0]</td>\n",
       "      <td>[87.3, 82.0, 39072, 1995, 0, 12.2, 21.0]</td>\n",
       "      <td>[87.3, 82.0, 39072, 1995, 0, 12.2, 21.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>[87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]</td>\n",
       "      <td>[87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]</td>\n",
       "      <td>[87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]</td>\n",
       "      <td>[87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]</td>\n",
       "      <td>[87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]</td>\n",
       "      <td>[87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]</td>\n",
       "      <td>[87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]</td>\n",
       "      <td>[87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]</td>\n",
       "      <td>[87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]</td>\n",
       "      <td>[87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>J-18-BK</td>\n",
       "      <td>[87.3, 82.0, 21800, 1976, 0, 11.5, 28.0]</td>\n",
       "      <td>[87.3, 82.0, 25600, 1976, 0, 11.5, 28.0]</td>\n",
       "      <td>[87.3, 82.0, 25600, 1976, 0, 11.5, 28.0]</td>\n",
       "      <td>[87.3, 82.0, 25600, 1976, 0, 11.5, 28.0]</td>\n",
       "      <td>[87.3, 82.0, 21055, 1976, 0, 11.5, 28.0]</td>\n",
       "      <td>[87.3, 82.0, 21055, 1976, 0, 11.6, 28.0]</td>\n",
       "      <td>[87.3, 82.0, 21055, 1976, 0, 11.6, 28.0]</td>\n",
       "      <td>[87.3, 82.0, 26371, 1976, 0, 11.6, 28.0]</td>\n",
       "      <td>[87.3, 82.0, 26371, 1976, 0, 11.6, 28.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>[87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]</td>\n",
       "      <td>[87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]</td>\n",
       "      <td>[87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]</td>\n",
       "      <td>[87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]</td>\n",
       "      <td>[87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]</td>\n",
       "      <td>[87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]</td>\n",
       "      <td>[87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]</td>\n",
       "      <td>[87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]</td>\n",
       "      <td>[87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]</td>\n",
       "      <td>[87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>TELL-8-TUN</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.7, 4.9]</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.7, 4.9]</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.7, 4.9]</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.7, 4.9]</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.7, 4.9]</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.8, 5.0]</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.8, 4.9]</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.8, 4.9]</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.8, 74.1]</td>\n",
       "      <td>...</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.8, 74.1]</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.8, 74.1]</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.8, 74.1]</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.8, 74.1]</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.8, 74.1]</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.8, 74.1]</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.8, 74.1]</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.8, 74.1]</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.8, 74.1]</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.8, 74.1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>524 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Bridge_ID                                    time_0  \\\n",
       "0           2.12E+13       [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]   \n",
       "1    CALHAN-8TH ST.      [36.0, 97.0, 428, 1949, 2, 10.9, 7.3]   \n",
       "2    CSG-C.80-07.65       [36.0, 83.9, 417, 1970, 2, 6.6, 6.4]   \n",
       "3    CSG-D.04-10.42      [36.0, 82.0, 1836, 1955, 2, 7.6, 4.0]   \n",
       "4    CSG-D.37-15.67       [36.0, 97.0, 87, 1984, 2, 12.8, 3.0]   \n",
       "..               ...                                       ...   \n",
       "519  I-17-G           [87.3, 82.0, 13500, 1942, 0, 10.9, 14.0]   \n",
       "520  I-17-HK          [87.3, 82.0, 38400, 1972, 0, 22.5, 35.1]   \n",
       "521  I-17-JH          [87.3, 82.0, 10500, 1995, 0, 12.9, 20.7]   \n",
       "522  J-18-BK          [87.3, 82.0, 21800, 1976, 0, 11.5, 28.0]   \n",
       "523  TELL-8-TUN            [87.3, 82.0, 28, 1900, 0, 4.7, 4.9]   \n",
       "\n",
       "                                       time_1  \\\n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]   \n",
       "1       [36.0, 96.9, 955, 1949, 2, 10.9, 7.3]   \n",
       "2        [36.0, 70.9, 351, 1970, 2, 6.6, 3.0]   \n",
       "3       [36.0, 84.3, 1459, 1955, 2, 7.7, 4.0]   \n",
       "4       [36.0, 97.0, 305, 1984, 2, 12.8, 3.0]   \n",
       "..                                        ...   \n",
       "519  [87.3, 82.0, 13500, 1942, 0, 10.9, 14.0]   \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]   \n",
       "521  [87.3, 82.0, 32904, 1995, 0, 12.9, 20.7]   \n",
       "522  [87.3, 82.0, 25600, 1976, 0, 11.5, 28.0]   \n",
       "523       [87.3, 82.0, 28, 1900, 0, 4.7, 4.9]   \n",
       "\n",
       "                                       time_2  \\\n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]   \n",
       "1       [36.0, 96.9, 955, 1949, 2, 10.9, 7.3]   \n",
       "2        [36.0, 70.9, 351, 1970, 2, 6.6, 3.0]   \n",
       "3       [36.0, 84.3, 1459, 1955, 2, 7.7, 4.0]   \n",
       "4       [36.0, 97.0, 305, 1984, 2, 12.8, 3.0]   \n",
       "..                                        ...   \n",
       "519  [87.3, 82.0, 13500, 1942, 0, 10.9, 14.0]   \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]   \n",
       "521  [87.3, 82.0, 32904, 1995, 0, 12.9, 20.7]   \n",
       "522  [87.3, 82.0, 25600, 1976, 0, 11.5, 28.0]   \n",
       "523       [87.3, 82.0, 28, 1900, 0, 4.7, 4.9]   \n",
       "\n",
       "                                       time_3  \\\n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]   \n",
       "1       [36.0, 96.9, 955, 1949, 2, 10.9, 7.3]   \n",
       "2        [36.0, 70.9, 351, 1970, 2, 6.6, 3.0]   \n",
       "3       [36.0, 84.3, 1459, 1955, 2, 7.7, 4.0]   \n",
       "4       [36.0, 97.0, 305, 1984, 2, 12.8, 3.0]   \n",
       "..                                        ...   \n",
       "519  [87.3, 82.0, 13500, 1942, 0, 10.9, 14.0]   \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]   \n",
       "521  [87.3, 82.0, 32904, 1995, 0, 12.9, 20.7]   \n",
       "522  [87.3, 82.0, 25600, 1976, 0, 11.5, 28.0]   \n",
       "523       [87.3, 82.0, 28, 1900, 0, 4.7, 4.9]   \n",
       "\n",
       "                                       time_4  \\\n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]   \n",
       "1       [36.0, 96.9, 955, 1949, 2, 10.9, 7.3]   \n",
       "2        [36.0, 70.9, 351, 1970, 2, 6.6, 3.0]   \n",
       "3       [36.0, 84.3, 1459, 1955, 2, 7.7, 3.4]   \n",
       "4       [36.0, 97.0, 305, 1984, 2, 12.8, 3.0]   \n",
       "..                                        ...   \n",
       "519  [87.3, 82.0, 13500, 1942, 0, 10.9, 14.0]   \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]   \n",
       "521  [87.3, 82.0, 36024, 1995, 0, 12.1, 20.7]   \n",
       "522  [87.3, 82.0, 21055, 1976, 0, 11.5, 28.0]   \n",
       "523       [87.3, 82.0, 28, 1900, 0, 4.7, 4.9]   \n",
       "\n",
       "                                       time_5  \\\n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]   \n",
       "1       [36.3, 97.0, 955, 1949, 2, 11.0, 7.0]   \n",
       "2        [36.3, 76.0, 351, 1970, 2, 6.6, 3.0]   \n",
       "3       [36.3, 83.4, 1459, 1955, 2, 7.7, 3.0]   \n",
       "4       [36.3, 97.0, 305, 1984, 2, 12.8, 3.0]   \n",
       "..                                        ...   \n",
       "519  [87.3, 82.0, 13500, 1942, 0, 10.9, 14.0]   \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]   \n",
       "521  [87.3, 82.0, 36024, 1995, 0, 12.2, 21.0]   \n",
       "522  [87.3, 82.0, 21055, 1976, 0, 11.6, 28.0]   \n",
       "523       [87.3, 82.0, 28, 1900, 0, 4.8, 5.0]   \n",
       "\n",
       "                                       time_6  \\\n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]   \n",
       "1       [36.3, 96.9, 955, 1949, 2, 11.0, 7.3]   \n",
       "2        [36.3, 69.0, 351, 1970, 2, 6.6, 3.0]   \n",
       "3       [36.3, 84.3, 1459, 1955, 2, 7.7, 3.4]   \n",
       "4       [36.3, 97.0, 305, 1984, 2, 12.8, 3.0]   \n",
       "..                                        ...   \n",
       "519  [87.3, 82.0, 13500, 1942, 0, 10.9, 14.0]   \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]   \n",
       "521  [87.3, 82.0, 36024, 1995, 0, 12.2, 21.0]   \n",
       "522  [87.3, 82.0, 21055, 1976, 0, 11.6, 28.0]   \n",
       "523       [87.3, 82.0, 28, 1900, 0, 4.8, 4.9]   \n",
       "\n",
       "                                       time_7  \\\n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]   \n",
       "1       [36.3, 96.9, 983, 1949, 2, 11.0, 7.3]   \n",
       "2        [36.3, 66.9, 478, 1970, 2, 6.6, 2.9]   \n",
       "3       [36.3, 84.4, 1295, 1955, 2, 7.7, 3.4]   \n",
       "4       [36.3, 97.0, 397, 1984, 2, 12.8, 3.0]   \n",
       "..                                        ...   \n",
       "519  [87.3, 82.0, 13500, 1942, 0, 10.9, 14.0]   \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]   \n",
       "521  [87.3, 82.0, 39072, 1995, 0, 12.2, 21.0]   \n",
       "522  [87.3, 82.0, 26371, 1976, 0, 11.6, 28.0]   \n",
       "523       [87.3, 82.0, 28, 1900, 0, 4.8, 4.9]   \n",
       "\n",
       "                                       time_8  ...  \\\n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]  ...   \n",
       "1       [36.3, 96.9, 983, 1949, 2, 11.0, 7.3]  ...   \n",
       "2        [36.3, 66.9, 478, 1970, 2, 6.6, 2.9]  ...   \n",
       "3       [36.3, 84.4, 1295, 1955, 2, 7.7, 3.4]  ...   \n",
       "4       [36.3, 97.0, 397, 1984, 2, 12.8, 3.0]  ...   \n",
       "..                                        ...  ...   \n",
       "519  [87.3, 82.0, 39228, 1972, 0, 24.1, 26.0]  ...   \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]  ...   \n",
       "521  [87.3, 82.0, 39072, 1995, 0, 12.2, 21.0]  ...   \n",
       "522  [87.3, 82.0, 26371, 1976, 0, 11.6, 28.0]  ...   \n",
       "523      [87.3, 82.0, 28, 1900, 0, 4.8, 74.1]  ...   \n",
       "\n",
       "                                      time_12  \\\n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]   \n",
       "1       [36.3, 97.0, 422, 1949, 2, 11.0, 7.3]   \n",
       "2        [36.3, 62.9, 478, 1970, 2, 6.6, 2.9]   \n",
       "3       [36.3, 72.3, 1295, 1955, 2, 7.7, 3.4]   \n",
       "4       [36.3, 98.0, 397, 1984, 2, 13.3, 3.0]   \n",
       "..                                        ...   \n",
       "519  [87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]   \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]   \n",
       "521  [87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]   \n",
       "522  [87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]   \n",
       "523      [87.3, 82.0, 28, 1900, 0, 4.8, 74.1]   \n",
       "\n",
       "                                      time_13  \\\n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]   \n",
       "1       [36.3, 97.0, 422, 1949, 2, 11.0, 7.3]   \n",
       "2        [36.3, 62.9, 777, 1970, 2, 6.6, 2.9]   \n",
       "3       [36.3, 72.3, 1329, 1955, 2, 7.7, 3.4]   \n",
       "4       [36.3, 98.0, 287, 1984, 2, 13.3, 3.0]   \n",
       "..                                        ...   \n",
       "519  [87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]   \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]   \n",
       "521  [87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]   \n",
       "522  [87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]   \n",
       "523      [87.3, 82.0, 28, 1900, 0, 4.8, 74.1]   \n",
       "\n",
       "                                      time_14  \\\n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]   \n",
       "1       [36.3, 97.0, 422, 1949, 2, 11.0, 7.3]   \n",
       "2        [36.3, 62.9, 777, 1970, 2, 6.6, 2.9]   \n",
       "3       [36.3, 72.3, 1329, 1955, 2, 7.7, 3.4]   \n",
       "4       [36.3, 98.0, 287, 1984, 2, 13.3, 3.0]   \n",
       "..                                        ...   \n",
       "519  [87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]   \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]   \n",
       "521  [87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]   \n",
       "522  [87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]   \n",
       "523      [87.3, 82.0, 28, 1900, 0, 4.8, 74.1]   \n",
       "\n",
       "                                      time_15  \\\n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]   \n",
       "1        [36.3, 97.0, 422, 1949, 2, 9.7, 7.3]   \n",
       "2        [36.3, 62.9, 777, 1970, 2, 6.6, 2.9]   \n",
       "3       [36.3, 72.3, 1329, 1955, 2, 7.7, 3.4]   \n",
       "4       [36.3, 99.0, 287, 1984, 2, 12.8, 3.0]   \n",
       "..                                        ...   \n",
       "519  [87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]   \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]   \n",
       "521  [87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]   \n",
       "522  [87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]   \n",
       "523      [87.3, 82.0, 28, 1900, 0, 4.8, 74.1]   \n",
       "\n",
       "                                      time_16  \\\n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]   \n",
       "1        [36.3, 97.0, 369, 1949, 2, 9.7, 7.3]   \n",
       "2        [36.3, 62.9, 623, 1970, 2, 6.6, 2.9]   \n",
       "3       [36.3, 72.3, 1446, 1955, 2, 7.7, 3.4]   \n",
       "4       [36.3, 99.0, 302, 1984, 2, 12.8, 3.0]   \n",
       "..                                        ...   \n",
       "519  [87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]   \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]   \n",
       "521  [87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]   \n",
       "522  [87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]   \n",
       "523      [87.3, 82.0, 28, 1900, 0, 4.8, 74.1]   \n",
       "\n",
       "                                      time_17  \\\n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]   \n",
       "1        [36.3, 86.0, 369, 1949, 2, 9.7, 7.3]   \n",
       "2        [36.3, 62.9, 623, 1970, 2, 6.6, 2.9]   \n",
       "3       [36.3, 72.3, 1446, 1955, 2, 7.7, 3.4]   \n",
       "4      [36.3, 100.0, 302, 1984, 2, 12.8, 3.0]   \n",
       "..                                        ...   \n",
       "519  [87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]   \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]   \n",
       "521  [87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]   \n",
       "522  [87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]   \n",
       "523      [87.3, 82.0, 28, 1900, 0, 4.8, 74.1]   \n",
       "\n",
       "                                      time_18  \\\n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]   \n",
       "1        [36.3, 86.0, 369, 1949, 2, 9.7, 7.3]   \n",
       "2        [36.3, 62.9, 623, 1970, 2, 6.6, 2.9]   \n",
       "3       [36.3, 72.3, 1446, 1955, 2, 7.7, 3.4]   \n",
       "4      [36.3, 100.0, 302, 1984, 2, 12.8, 3.0]   \n",
       "..                                        ...   \n",
       "519  [87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]   \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]   \n",
       "521  [87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]   \n",
       "522  [87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]   \n",
       "523      [87.3, 82.0, 28, 1900, 0, 4.8, 74.1]   \n",
       "\n",
       "                                      time_19  \\\n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]   \n",
       "1        [36.3, 86.0, 369, 1949, 2, 9.7, 7.3]   \n",
       "2        [32.7, 55.7, 623, 1970, 2, 6.6, 2.9]   \n",
       "3       [27.2, 50.2, 1446, 1955, 2, 7.7, 3.4]   \n",
       "4      [36.3, 100.0, 302, 1984, 2, 12.8, 3.0]   \n",
       "..                                        ...   \n",
       "519  [87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]   \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]   \n",
       "521  [87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]   \n",
       "522  [87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]   \n",
       "523      [87.3, 82.0, 28, 1900, 0, 4.8, 74.1]   \n",
       "\n",
       "                                      time_20  \\\n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]   \n",
       "1        [36.3, 86.0, 369, 1949, 2, 9.7, 7.3]   \n",
       "2        [32.7, 55.7, 623, 1970, 2, 6.6, 2.9]   \n",
       "3       [27.2, 50.2, 1446, 1955, 2, 7.7, 3.4]   \n",
       "4      [36.3, 100.0, 302, 1984, 2, 12.8, 3.0]   \n",
       "..                                        ...   \n",
       "519  [87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]   \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]   \n",
       "521  [87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]   \n",
       "522  [87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]   \n",
       "523      [87.3, 82.0, 28, 1900, 0, 4.8, 74.1]   \n",
       "\n",
       "                                      time_21  \n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]  \n",
       "1        [36.3, 86.0, 522, 1949, 2, 9.7, 7.3]  \n",
       "2        [32.7, 55.7, 717, 1970, 2, 6.6, 2.9]  \n",
       "3       [27.2, 50.2, 2696, 1955, 2, 7.7, 3.4]  \n",
       "4      [36.3, 100.0, 268, 1984, 2, 12.8, 3.0]  \n",
       "..                                        ...  \n",
       "519  [87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]  \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]  \n",
       "521  [87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]  \n",
       "522  [87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]  \n",
       "523      [87.3, 82.0, 28, 1900, 0, 4.8, 74.1]  \n",
       "\n",
       "[524 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For the first row of the dataset, plot the sufficiency rating over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_row = df.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_row = first_row.iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time_0     [36.0, 97.0, 428, 1949, 2, 10.9, 7.3]\n",
       "time_1     [36.0, 96.9, 955, 1949, 2, 10.9, 7.3]\n",
       "time_2     [36.0, 96.9, 955, 1949, 2, 10.9, 7.3]\n",
       "time_3     [36.0, 96.9, 955, 1949, 2, 10.9, 7.3]\n",
       "time_4     [36.0, 96.9, 955, 1949, 2, 10.9, 7.3]\n",
       "time_5     [36.3, 97.0, 955, 1949, 2, 11.0, 7.0]\n",
       "time_6     [36.3, 96.9, 955, 1949, 2, 11.0, 7.3]\n",
       "time_7     [36.3, 96.9, 983, 1949, 2, 11.0, 7.3]\n",
       "time_8     [36.3, 96.9, 983, 1949, 2, 11.0, 7.3]\n",
       "time_9     [36.3, 96.9, 983, 1949, 2, 11.0, 7.3]\n",
       "time_10    [36.3, 96.9, 983, 1949, 2, 11.0, 7.3]\n",
       "time_11    [36.3, 97.0, 422, 1949, 2, 11.0, 7.3]\n",
       "time_12    [36.3, 97.0, 422, 1949, 2, 11.0, 7.3]\n",
       "time_13    [36.3, 97.0, 422, 1949, 2, 11.0, 7.3]\n",
       "time_14    [36.3, 97.0, 422, 1949, 2, 11.0, 7.3]\n",
       "time_15     [36.3, 97.0, 422, 1949, 2, 9.7, 7.3]\n",
       "time_16     [36.3, 97.0, 369, 1949, 2, 9.7, 7.3]\n",
       "time_17     [36.3, 86.0, 369, 1949, 2, 9.7, 7.3]\n",
       "time_18     [36.3, 86.0, 369, 1949, 2, 9.7, 7.3]\n",
       "time_19     [36.3, 86.0, 369, 1949, 2, 9.7, 7.3]\n",
       "time_20     [36.3, 86.0, 369, 1949, 2, 9.7, 7.3]\n",
       "time_21     [36.3, 86.0, 522, 1949, 2, 9.7, 7.3]\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "non_decimal = re.compile(r'[^\\d.]+')\n",
    "\n",
    "list_of_row_components = []\n",
    "\n",
    "for i, row in first_row.iteritems():\n",
    "    current_row_components = row.split(', ')\n",
    "    current_row_components_replaced = []\n",
    "    \n",
    "#     print(current_row_components)\n",
    "    for idx, component in enumerate(current_row_components):\n",
    "    #     print(first_row_components[idx])\n",
    "        result = non_decimal.sub('', current_row_components[idx])\n",
    "        current_row_components_replaced.append(float(result))\n",
    "        \n",
    "#     print(current_row_components_replaced)\n",
    "    list_of_row_components.append(current_row_components_replaced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_row = df.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[36.0, 97.0, 428.0, 1949.0, 2.0, 10.9, 7.3],\n",
       " [36.0, 96.9, 955.0, 1949.0, 2.0, 10.9, 7.3],\n",
       " [36.0, 96.9, 955.0, 1949.0, 2.0, 10.9, 7.3],\n",
       " [36.0, 96.9, 955.0, 1949.0, 2.0, 10.9, 7.3],\n",
       " [36.0, 96.9, 955.0, 1949.0, 2.0, 10.9, 7.3],\n",
       " [36.3, 97.0, 955.0, 1949.0, 2.0, 11.0, 7.0],\n",
       " [36.3, 96.9, 955.0, 1949.0, 2.0, 11.0, 7.3],\n",
       " [36.3, 96.9, 983.0, 1949.0, 2.0, 11.0, 7.3],\n",
       " [36.3, 96.9, 983.0, 1949.0, 2.0, 11.0, 7.3],\n",
       " [36.3, 96.9, 983.0, 1949.0, 2.0, 11.0, 7.3],\n",
       " [36.3, 96.9, 983.0, 1949.0, 2.0, 11.0, 7.3],\n",
       " [36.3, 97.0, 422.0, 1949.0, 2.0, 11.0, 7.3],\n",
       " [36.3, 97.0, 422.0, 1949.0, 2.0, 11.0, 7.3],\n",
       " [36.3, 97.0, 422.0, 1949.0, 2.0, 11.0, 7.3],\n",
       " [36.3, 97.0, 422.0, 1949.0, 2.0, 11.0, 7.3],\n",
       " [36.3, 97.0, 422.0, 1949.0, 2.0, 9.7, 7.3],\n",
       " [36.3, 97.0, 369.0, 1949.0, 2.0, 9.7, 7.3],\n",
       " [36.3, 86.0, 369.0, 1949.0, 2.0, 9.7, 7.3],\n",
       " [36.3, 86.0, 369.0, 1949.0, 2.0, 9.7, 7.3],\n",
       " [36.3, 86.0, 369.0, 1949.0, 2.0, 9.7, 7.3],\n",
       " [36.3, 86.0, 369.0, 1949.0, 2.0, 9.7, 7.3],\n",
       " [36.3, 86.0, 522.0, 1949.0, 2.0, 9.7, 7.3]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_row_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_row = first_row.iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sufficiency_rating_list = []\n",
    "\n",
    "for row_component in list_of_row_components:\n",
    "    sufficiency_rating_list.append(row_component[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[97.0,\n",
       " 96.9,\n",
       " 96.9,\n",
       " 96.9,\n",
       " 96.9,\n",
       " 97.0,\n",
       " 96.9,\n",
       " 96.9,\n",
       " 96.9,\n",
       " 96.9,\n",
       " 96.9,\n",
       " 97.0,\n",
       " 97.0,\n",
       " 97.0,\n",
       " 97.0,\n",
       " 97.0,\n",
       " 97.0,\n",
       " 86.0,\n",
       " 86.0,\n",
       " 86.0,\n",
       " 86.0,\n",
       " 86.0]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sufficiency_rating_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(sufficiency_rating_list)\n",
    "plt.ylabel('Sufficiency Rating')\n",
    "plt.xlabel('Years')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of first training example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "var1 = []\n",
    "var2 = []\n",
    "var3 = []\n",
    "var4 = []\n",
    "var5 = []\n",
    "var6 = []\n",
    "varout = []\n",
    "\n",
    "for element in list_of_row_components:\n",
    "#     print(element)\n",
    "    var1.append(element[0])\n",
    "    var2.append(element[2])\n",
    "    var3.append(element[3])\n",
    "    var4.append(element[4])\n",
    "    var5.append(element[5])\n",
    "    var6.append(element[6])\n",
    "    varout.append(element[1])\n",
    "    \n",
    "dict_temp = {'var1': var1, 'var2': var2, 'var3': var3, 'var4': var4, 'var5': var5, 'var6': var6, 'varout': varout}\n",
    "\n",
    "df_temp = pd.DataFrame(dict_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>var3</th>\n",
       "      <th>var4</th>\n",
       "      <th>var5</th>\n",
       "      <th>var6</th>\n",
       "      <th>varout</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36.0</td>\n",
       "      <td>428.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>7.3</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36.0</td>\n",
       "      <td>955.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>7.3</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.0</td>\n",
       "      <td>955.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>7.3</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.0</td>\n",
       "      <td>955.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>7.3</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.0</td>\n",
       "      <td>955.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>7.3</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36.3</td>\n",
       "      <td>955.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>36.3</td>\n",
       "      <td>955.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>36.3</td>\n",
       "      <td>983.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>36.3</td>\n",
       "      <td>983.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>36.3</td>\n",
       "      <td>983.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>36.3</td>\n",
       "      <td>983.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>36.3</td>\n",
       "      <td>422.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>36.3</td>\n",
       "      <td>422.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>36.3</td>\n",
       "      <td>422.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>36.3</td>\n",
       "      <td>422.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>36.3</td>\n",
       "      <td>422.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>7.3</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>36.3</td>\n",
       "      <td>369.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>7.3</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>36.3</td>\n",
       "      <td>369.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>7.3</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>36.3</td>\n",
       "      <td>369.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>7.3</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>36.3</td>\n",
       "      <td>369.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>7.3</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>36.3</td>\n",
       "      <td>369.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>7.3</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>36.3</td>\n",
       "      <td>522.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>7.3</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    var1   var2    var3  var4  var5  var6  varout\n",
       "0   36.0  428.0  1949.0   2.0  10.9   7.3    97.0\n",
       "1   36.0  955.0  1949.0   2.0  10.9   7.3    96.9\n",
       "2   36.0  955.0  1949.0   2.0  10.9   7.3    96.9\n",
       "3   36.0  955.0  1949.0   2.0  10.9   7.3    96.9\n",
       "4   36.0  955.0  1949.0   2.0  10.9   7.3    96.9\n",
       "5   36.3  955.0  1949.0   2.0  11.0   7.0    97.0\n",
       "6   36.3  955.0  1949.0   2.0  11.0   7.3    96.9\n",
       "7   36.3  983.0  1949.0   2.0  11.0   7.3    96.9\n",
       "8   36.3  983.0  1949.0   2.0  11.0   7.3    96.9\n",
       "9   36.3  983.0  1949.0   2.0  11.0   7.3    96.9\n",
       "10  36.3  983.0  1949.0   2.0  11.0   7.3    96.9\n",
       "11  36.3  422.0  1949.0   2.0  11.0   7.3    97.0\n",
       "12  36.3  422.0  1949.0   2.0  11.0   7.3    97.0\n",
       "13  36.3  422.0  1949.0   2.0  11.0   7.3    97.0\n",
       "14  36.3  422.0  1949.0   2.0  11.0   7.3    97.0\n",
       "15  36.3  422.0  1949.0   2.0   9.7   7.3    97.0\n",
       "16  36.3  369.0  1949.0   2.0   9.7   7.3    97.0\n",
       "17  36.3  369.0  1949.0   2.0   9.7   7.3    86.0\n",
       "18  36.3  369.0  1949.0   2.0   9.7   7.3    86.0\n",
       "19  36.3  369.0  1949.0   2.0   9.7   7.3    86.0\n",
       "20  36.3  369.0  1949.0   2.0   9.7   7.3    86.0\n",
       "21  36.3  522.0  1949.0   2.0   9.7   7.3    86.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert each rows into it's own dataframe representing an individual time series example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "non_decimal = re.compile(r'[^\\d.]+')\n",
    "\n",
    "list_of_training_df = []\n",
    "\n",
    "for i in range(1, 524):\n",
    "    \n",
    "    list_of_row_components = []\n",
    "    \n",
    "    current_row = df.iloc[i]\n",
    "    current_row = current_row.iloc[1:]\n",
    "    \n",
    "    for j, row in current_row.iteritems():\n",
    "        \n",
    "        current_row_components = row.split(', ')\n",
    "        current_row_components_replaced = []\n",
    "\n",
    "        for idx, component in enumerate(current_row_components):\n",
    "\n",
    "            result = non_decimal.sub('', current_row_components[idx])\n",
    "            current_row_components_replaced.append(float(result))\n",
    "\n",
    "        list_of_row_components.append(current_row_components_replaced)\n",
    "\n",
    "    var1 = []\n",
    "    var2 = []\n",
    "    var3 = []\n",
    "    var4 = []\n",
    "    var5 = []\n",
    "    var6 = []\n",
    "    varout = []\n",
    "\n",
    "    for element in list_of_row_components:\n",
    "\n",
    "        var1.append(element[0])\n",
    "        var2.append(element[2])\n",
    "        var3.append(element[3])\n",
    "        var4.append(element[4])\n",
    "        var5.append(element[5])\n",
    "        var6.append(element[6])\n",
    "        varout.append(element[1])\n",
    "\n",
    "    dict_temp = {'var1': var1, 'var2': var2, 'var3': var3, 'var4': var4, 'var5': var5, 'var6': var6, 'varout': varout}\n",
    "\n",
    "    df_temp = pd.DataFrame(dict_temp)\n",
    "\n",
    "    list_of_training_df.append(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "523"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_of_training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>var3</th>\n",
       "      <th>var4</th>\n",
       "      <th>var5</th>\n",
       "      <th>var6</th>\n",
       "      <th>varout</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>2.4</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36.0</td>\n",
       "      <td>950.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.0</td>\n",
       "      <td>950.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.0</td>\n",
       "      <td>950.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.0</td>\n",
       "      <td>950.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36.3</td>\n",
       "      <td>950.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>36.3</td>\n",
       "      <td>950.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>36.3</td>\n",
       "      <td>700.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>36.3</td>\n",
       "      <td>700.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>36.3</td>\n",
       "      <td>700.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>85.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>36.3</td>\n",
       "      <td>700.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>85.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>36.3</td>\n",
       "      <td>700.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>85.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>36.3</td>\n",
       "      <td>700.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>85.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>36.3</td>\n",
       "      <td>780.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>85.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>36.3</td>\n",
       "      <td>780.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>85.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>36.3</td>\n",
       "      <td>780.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>87.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>36.3</td>\n",
       "      <td>771.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>87.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>36.3</td>\n",
       "      <td>771.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>87.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>36.3</td>\n",
       "      <td>771.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>87.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>27.2</td>\n",
       "      <td>771.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>65.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>27.2</td>\n",
       "      <td>771.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>65.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>27.2</td>\n",
       "      <td>391.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>65.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    var1   var2    var3  var4  var5  var6  varout\n",
       "0   36.0  660.0  1970.0   2.0  11.2   2.4    96.9\n",
       "1   36.0  950.0  1970.0   2.0  11.1   2.4    96.9\n",
       "2   36.0  950.0  1970.0   2.0  11.1   2.4    96.9\n",
       "3   36.0  950.0  1970.0   2.0  11.1   2.4    96.9\n",
       "4   36.0  950.0  1970.0   2.0  11.1   2.4    96.9\n",
       "5   36.3  950.0  1970.0   2.0  11.1   2.0    97.0\n",
       "6   36.3  950.0  1970.0   2.0  11.1   2.4    96.9\n",
       "7   36.3  700.0  1970.0   2.0  11.1   2.0    96.9\n",
       "8   36.3  700.0  1970.0   2.0  11.1   2.0    96.9\n",
       "9   36.3  700.0  1970.0   2.0  11.1   2.6    85.9\n",
       "10  36.3  700.0  1970.0   2.0  11.1   2.6    85.9\n",
       "11  36.3  700.0  1970.0   2.0  11.1   2.6    85.9\n",
       "12  36.3  700.0  1970.0   2.0  11.1   2.6    85.9\n",
       "13  36.3  780.0  1970.0   2.0  11.1   2.6    85.9\n",
       "14  36.3  780.0  1970.0   2.0  11.1   2.6    85.9\n",
       "15  36.3  780.0  1970.0   2.0  11.1   2.6    87.9\n",
       "16  36.3  771.0  1970.0   2.0  11.1   2.6    87.9\n",
       "17  36.3  771.0  1970.0   2.0  11.1   2.6    87.9\n",
       "18  36.3  771.0  1970.0   2.0  11.1   2.6    87.9\n",
       "19  27.2  771.0  1970.0   2.0  11.1   2.6    65.9\n",
       "20  27.2  771.0  1970.0   2.0  11.1   2.6    65.9\n",
       "21  27.2  391.0  1970.0   2.0  11.1   2.6    65.9"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_training_df[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "list_of_scaled_training_df = []\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "for training_df in list_of_training_df:\n",
    "    temp_df = scaler.fit_transform(training_df)\n",
    "    list_of_scaled_training_df.append(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.00194932, 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.00194932, 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.00194932, 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.00194932, 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "        0.00194932, 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "        0.00194932, 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_scaled_training_df[500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single example of a time series example for a single bridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = list_of_training_df[7].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n"
     ]
    }
   ],
   "source": [
    "n_train_hours = 21\n",
    "train = values[:n_train_hours, :]\n",
    "test = values[n_train_hours:, :]\n",
    "\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confirm gpu is being used before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/device:GPU:0']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = tf.keras.models.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "    tf.keras.layers.LSTM(50, return_sequences=True),\n",
    "    tf.keras.layers.LSTM(30, return_sequences=True),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=16, activation='relu'),\n",
    "    # Shape => [batch, time, features]\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.compile(loss='mae', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Because we have individual time series for each bridge, we define an epoch number and for each epoch we train the model an a random bridge time series\n",
    "\n",
    "# At the end, we plot the loss and validation loss over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 96.9895 - val_loss: 96.3657\n",
      "EPOCH: 2 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 98.0752 - val_loss: 98.9391\n",
      "EPOCH: 3 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 81.9765 - val_loss: 81.9591\n",
      "EPOCH: 4 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 42.7650 - val_loss: 33.9068\n",
      "EPOCH: 5 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 60.0389 - val_loss: 57.1923\n",
      "EPOCH: 6 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 99.4029 - val_loss: 99.3865\n",
      "EPOCH: 7 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 63.8224 - val_loss: 63.8089\n",
      "EPOCH: 8 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 81.8566 - val_loss: 81.8380\n",
      "EPOCH: 9 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 24.8260 - val_loss: 6.7056\n",
      "EPOCH: 10 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 98.0713 - val_loss: 97.8644\n",
      "EPOCH: 11 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 74.6659 - val_loss: 74.6478\n",
      "EPOCH: 12 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 94.6870 - val_loss: 85.7970\n",
      "EPOCH: 13 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 96.7311 - val_loss: 96.1215\n",
      "EPOCH: 14 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 65.8691 - val_loss: 61.5957\n",
      "EPOCH: 15 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 92.1027 - val_loss: 92.2876\n",
      "EPOCH: 16 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 63.4401 - val_loss: 63.6388\n",
      "EPOCH: 17 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 96.3953 - val_loss: 96.7056\n",
      "EPOCH: 18 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 96.0756 - val_loss: 97.4743\n",
      "EPOCH: 19 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 70.6134 - val_loss: 64.1671\n",
      "EPOCH: 20 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 47.9225 - val_loss: 44.7246\n",
      "EPOCH: 21 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 94.5410 - val_loss: 94.4556\n",
      "EPOCH: 22 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 98.9962 - val_loss: 99.0404\n",
      "EPOCH: 23 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 68.0918 - val_loss: 69.0615\n",
      "EPOCH: 24 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 59.3002 - val_loss: 59.2499\n",
      "EPOCH: 25 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 97.6344 - val_loss: 97.3744\n",
      "EPOCH: 26 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 71.4982 - val_loss: 72.2872\n",
      "EPOCH: 27 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 37.9960 - val_loss: 22.4014\n",
      "EPOCH: 28 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 78.8930 - val_loss: 75.0407\n",
      "EPOCH: 29 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 80.8693 - val_loss: 70.2129\n",
      "EPOCH: 30 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 83.5219 - val_loss: 78.0684\n",
      "EPOCH: 31 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 72.9513 - val_loss: 76.5196\n",
      "EPOCH: 32 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 71.2678 - val_loss: 73.2643\n",
      "EPOCH: 33 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 83.5149 - val_loss: 83.5684\n",
      "EPOCH: 34 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 98.1547 - val_loss: 98.3970\n",
      "EPOCH: 35 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 64.1228 - val_loss: 56.7330\n",
      "EPOCH: 36 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 95.5044 - val_loss: 95.4982\n",
      "EPOCH: 37 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 48.7751 - val_loss: 48.0075\n",
      "EPOCH: 38 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 90.6613 - val_loss: 93.3039\n",
      "EPOCH: 39 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 95.9193 - val_loss: 95.4272\n",
      "EPOCH: 40 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 78.5979 - val_loss: 86.7278\n",
      "EPOCH: 41 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 74.0617 - val_loss: 74.3836\n",
      "EPOCH: 42 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 97.2157 - val_loss: 96.8552\n",
      "EPOCH: 43 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 45.4375 - val_loss: 43.3886\n",
      "EPOCH: 44 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 97.0666 - val_loss: 96.9461\n",
      "EPOCH: 45 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 59.9830 - val_loss: 58.0073\n",
      "EPOCH: 46 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 77.8630 - val_loss: 78.3276\n",
      "EPOCH: 47 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 92.6670 - val_loss: 93.2705\n",
      "EPOCH: 48 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 94.2515 - val_loss: 94.8600\n",
      "EPOCH: 49 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 87.0734 - val_loss: 96.6904\n",
      "EPOCH: 50 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 88.2661 - val_loss: 88.2006\n",
      "EPOCH: 51 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 93.8121 - val_loss: 95.2611\n",
      "EPOCH: 52 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 76.5842 - val_loss: 76.1724\n",
      "EPOCH: 53 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 47.3724 - val_loss: 42.8229\n",
      "EPOCH: 54 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 62.4753 - val_loss: 57.7339\n",
      "EPOCH: 55 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 92.1084 - val_loss: 91.4057\n",
      "EPOCH: 56 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 57.7127 - val_loss: 50.1268\n",
      "EPOCH: 57 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 61.5281 - val_loss: 60.9123\n",
      "EPOCH: 58 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 66.0926 - val_loss: 65.6470\n",
      "EPOCH: 59 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 82.1165 - val_loss: 78.8713\n",
      "EPOCH: 60 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 67.3054 - val_loss: 87.9176\n",
      "EPOCH: 61 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 70.0367 - val_loss: 69.8050\n",
      "EPOCH: 62 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 74.1436 - val_loss: 73.5567\n",
      "EPOCH: 63 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 77.0415 - val_loss: 75.0844\n",
      "EPOCH: 64 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 86.5724 - val_loss: 86.6704\n",
      "EPOCH: 65 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 55.4811 - val_loss: 56.0730\n",
      "EPOCH: 66 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 67.8101 - val_loss: 66.8477\n",
      "EPOCH: 67 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 64.9905 - val_loss: 78.0745\n",
      "EPOCH: 68 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 54.5469 - val_loss: 44.1151\n",
      "EPOCH: 69 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 48.4580 - val_loss: 47.9665\n",
      "EPOCH: 70 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 79.4401 - val_loss: 82.1594\n",
      "EPOCH: 71 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 48.9406 - val_loss: 36.6633\n",
      "EPOCH: 72 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 68.4021 - val_loss: 65.2857\n",
      "EPOCH: 73 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 53.7228 - val_loss: 47.1765\n",
      "EPOCH: 74 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 70.6215 - val_loss: 68.8569\n",
      "EPOCH: 75 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 66.0759 - val_loss: 64.2339\n",
      "EPOCH: 76 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 50.6958 - val_loss: 48.8917\n",
      "EPOCH: 77 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 75.7031 - val_loss: 72.5235\n",
      "EPOCH: 78 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 59.3489 - val_loss: 57.3984\n",
      "EPOCH: 79 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 50.8995 - val_loss: 50.9413\n",
      "EPOCH: 80 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.7499 - val_loss: 3.8804\n",
      "EPOCH: 81 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 51.7641 - val_loss: 49.8852\n",
      "EPOCH: 82 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 24.5688 - val_loss: 22.8617\n",
      "EPOCH: 83 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 42.7601 - val_loss: 39.3849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 84 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 37.6230 - val_loss: 34.9560\n",
      "EPOCH: 85 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 46.9103 - val_loss: 46.0090\n",
      "EPOCH: 86 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 14.6692 - val_loss: 16.9453\n",
      "EPOCH: 87 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4.9590 - val_loss: 0.9568\n",
      "EPOCH: 88 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 13.4985 - val_loss: 16.8481\n",
      "EPOCH: 89 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 29.1896 - val_loss: 27.6506\n",
      "EPOCH: 90 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 25.7178 - val_loss: 22.6679\n",
      "EPOCH: 91 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 34.6733 - val_loss: 23.7712\n",
      "EPOCH: 92 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 12.1804 - val_loss: 17.4188\n",
      "EPOCH: 93 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 10.0003 - val_loss: 8.0627\n",
      "EPOCH: 94 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 21.5595 - val_loss: 22.9658\n",
      "EPOCH: 95 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.8661 - val_loss: 20.0080\n",
      "EPOCH: 96 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 26.5093 - val_loss: 16.2172\n",
      "EPOCH: 97 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 39.7159 - val_loss: 37.7024\n",
      "EPOCH: 98 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7.4263 - val_loss: 7.9118\n",
      "EPOCH: 99 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 12.8314 - val_loss: 15.5709\n",
      "EPOCH: 100 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 29.7816 - val_loss: 28.9108\n",
      "EPOCH: 101 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 10.8868 - val_loss: 12.7650\n",
      "EPOCH: 102 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.7317 - val_loss: 6.3707\n",
      "EPOCH: 103 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 25.6694 - val_loss: 16.1781\n",
      "EPOCH: 104 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 18.7153 - val_loss: 15.6811\n",
      "EPOCH: 105 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2.3073 - val_loss: 1.2542\n",
      "EPOCH: 106 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 35.1590 - val_loss: 36.4492\n",
      "EPOCH: 107 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 16.4565 - val_loss: 14.7250\n",
      "EPOCH: 108 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 12.3231 - val_loss: 11.8284\n",
      "EPOCH: 109 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 16.9277 - val_loss: 15.3988\n",
      "EPOCH: 110 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 12.7644 - val_loss: 12.5643\n",
      "EPOCH: 111 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 29.3251 - val_loss: 29.9788\n",
      "EPOCH: 112 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.4714 - val_loss: 2.1079\n",
      "EPOCH: 113 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 49.5838 - val_loss: 49.1840\n",
      "EPOCH: 114 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.9399 - val_loss: 5.3092\n",
      "EPOCH: 115 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 16.9655 - val_loss: 18.4329\n",
      "EPOCH: 116 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 10.6433 - val_loss: 9.9663\n",
      "EPOCH: 117 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 35.1554 - val_loss: 34.1000\n",
      "EPOCH: 118 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 18.4968 - val_loss: 14.6150\n",
      "EPOCH: 119 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 11.5658 - val_loss: 4.6232\n",
      "EPOCH: 120 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5.2375 - val_loss: 5.9800\n",
      "EPOCH: 121 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4.8748 - val_loss: 8.0038\n",
      "EPOCH: 122 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.3800 - val_loss: 9.3873\n",
      "EPOCH: 123 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 15.1560 - val_loss: 14.2685\n",
      "EPOCH: 124 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 31.1593 - val_loss: 30.7073\n",
      "EPOCH: 125 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7.7760 - val_loss: 4.8223\n",
      "EPOCH: 126 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.9894 - val_loss: 9.6491\n",
      "EPOCH: 127 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 24.6388 - val_loss: 24.2210\n",
      "EPOCH: 128 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6.8797 - val_loss: 12.6745\n",
      "EPOCH: 129 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2.6535 - val_loss: 0.8115\n",
      "EPOCH: 130 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.4736 - val_loss: 9.0728\n",
      "EPOCH: 131 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.9666 - val_loss: 9.6345\n",
      "EPOCH: 132 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 22.6583 - val_loss: 21.4053\n",
      "EPOCH: 133 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.0787 - val_loss: 8.1555\n",
      "EPOCH: 134 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2.0835 - val_loss: 1.5180\n",
      "EPOCH: 135 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7.1319 - val_loss: 6.9034\n",
      "EPOCH: 136 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7.3891 - val_loss: 2.8637\n",
      "EPOCH: 137 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 10.1939 - val_loss: 9.3838\n",
      "EPOCH: 138 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 41.4803 - val_loss: 45.2296\n",
      "EPOCH: 139 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3.1233 - val_loss: 0.5075\n",
      "EPOCH: 140 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 28.0357 - val_loss: 25.6508\n",
      "EPOCH: 141 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 17.2283 - val_loss: 52.9625\n",
      "EPOCH: 142 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4.4266 - val_loss: 5.5809\n",
      "EPOCH: 143 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 42.8585 - val_loss: 28.7971\n",
      "EPOCH: 144 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 50.6362 - val_loss: 51.8274\n",
      "EPOCH: 145 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7.1434 - val_loss: 1.9458\n",
      "EPOCH: 146 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4.2312 - val_loss: 1.8153\n",
      "EPOCH: 147 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7.7094 - val_loss: 9.8364\n",
      "EPOCH: 148 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 21.3396 - val_loss: 10.4805\n",
      "EPOCH: 149 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4.6265 - val_loss: 1.4857\n",
      "EPOCH: 150 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 28.9217 - val_loss: 29.0755\n",
      "EPOCH: 151 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7.9765 - val_loss: 6.3722\n",
      "EPOCH: 152 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7.6979 - val_loss: 5.6243\n",
      "EPOCH: 153 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4.8937 - val_loss: 3.5257\n",
      "EPOCH: 154 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 12.8950 - val_loss: 33.2110\n",
      "EPOCH: 155 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4.3932 - val_loss: 5.0892\n",
      "EPOCH: 156 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 45.0158 - val_loss: 44.2501\n",
      "EPOCH: 157 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.8849 - val_loss: 12.3115\n",
      "EPOCH: 158 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2.1207 - val_loss: 1.3719\n",
      "EPOCH: 159 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.6623 - val_loss: 12.0661\n",
      "EPOCH: 160 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 12.1239 - val_loss: 11.9195\n",
      "EPOCH: 161 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 25.6425 - val_loss: 22.5303\n",
      "EPOCH: 162 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.8619 - val_loss: 8.4127\n",
      "EPOCH: 163 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 14.3014 - val_loss: 12.4353\n",
      "EPOCH: 164 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 14.6658 - val_loss: 19.1339\n",
      "EPOCH: 165 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 21.9747 - val_loss: 22.5780\n",
      "EPOCH: 166 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3.1345 - val_loss: 5.4258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 167 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 11.5548 - val_loss: 17.0322\n",
      "EPOCH: 168 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 17.9088 - val_loss: 19.4831\n",
      "EPOCH: 169 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7.4741 - val_loss: 7.1157\n",
      "EPOCH: 170 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 12.2241 - val_loss: 11.3766\n",
      "EPOCH: 171 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1.8577 - val_loss: 1.6012\n",
      "EPOCH: 172 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 48.7715 - val_loss: 49.4582\n",
      "EPOCH: 173 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 27.6257 - val_loss: 34.4866\n",
      "EPOCH: 174 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 16.5977 - val_loss: 17.2961\n",
      "EPOCH: 175 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3.2039 - val_loss: 3.2754\n",
      "EPOCH: 176 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7.5817 - val_loss: 6.9431\n",
      "EPOCH: 177 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 20.7853 - val_loss: 20.0885\n",
      "EPOCH: 178 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 31.5713 - val_loss: 30.4676\n",
      "EPOCH: 179 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 33.6501 - val_loss: 41.7463\n",
      "EPOCH: 180 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 44.8557 - val_loss: 43.9168\n",
      "EPOCH: 181 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 18.2952 - val_loss: 17.9920\n",
      "EPOCH: 182 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 15.9025 - val_loss: 24.1897\n",
      "EPOCH: 183 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.6644 - val_loss: 32.5956\n",
      "EPOCH: 184 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.8579 - val_loss: 10.4661\n",
      "EPOCH: 185 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.6312 - val_loss: 10.4677\n",
      "EPOCH: 186 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 29.4679 - val_loss: 59.8715\n",
      "EPOCH: 187 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 20.5523 - val_loss: 22.0882\n",
      "EPOCH: 188 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6.0609 - val_loss: 0.1711\n",
      "EPOCH: 189 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7.6844 - val_loss: 6.9172\n",
      "EPOCH: 190 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.0652 - val_loss: 8.5599\n",
      "EPOCH: 191 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4.3762 - val_loss: 3.2648\n",
      "EPOCH: 192 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.2172 - val_loss: 8.5012\n",
      "EPOCH: 193 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 10.1631 - val_loss: 9.9963\n",
      "EPOCH: 194 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 23.2862 - val_loss: 23.1335\n",
      "EPOCH: 195 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1.3696 - val_loss: 0.5862\n",
      "EPOCH: 196 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 10.4263 - val_loss: 10.4867\n",
      "EPOCH: 197 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2.2140 - val_loss: 0.1983\n",
      "EPOCH: 198 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 23.4840 - val_loss: 24.7802\n",
      "EPOCH: 199 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 22.5504 - val_loss: 22.0837\n",
      "EPOCH: 200 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 19.8054 - val_loss: 21.7538\n",
      "EPOCH: 201 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 18.9907 - val_loss: 17.8138\n",
      "EPOCH: 202 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2.2267 - val_loss: 1.8734\n",
      "EPOCH: 203 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.6202 - val_loss: 9.7515\n",
      "EPOCH: 204 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 18.9996 - val_loss: 11.3640\n",
      "EPOCH: 205 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 12.2719 - val_loss: 12.1481\n",
      "EPOCH: 206 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 20.3481 - val_loss: 20.7042\n",
      "EPOCH: 207 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 11.9359 - val_loss: 9.0424\n",
      "EPOCH: 208 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 11.1009 - val_loss: 7.4891\n",
      "EPOCH: 209 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.4590 - val_loss: 8.8721\n",
      "EPOCH: 210 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 10.1749 - val_loss: 9.0657\n",
      "EPOCH: 211 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 20.9538 - val_loss: 15.3859\n",
      "EPOCH: 212 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 29.1871 - val_loss: 29.1220\n",
      "EPOCH: 213 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 13.5177 - val_loss: 13.0444\n",
      "EPOCH: 214 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 21.3103 - val_loss: 29.9439\n",
      "EPOCH: 215 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 15.3217 - val_loss: 15.2060\n",
      "EPOCH: 216 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5.0601 - val_loss: 6.9518\n",
      "EPOCH: 217 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 11.0236 - val_loss: 3.2019\n",
      "EPOCH: 218 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 10.2331 - val_loss: 5.4062\n",
      "EPOCH: 219 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7.4317 - val_loss: 30.9689\n",
      "EPOCH: 220 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 26.4018 - val_loss: 26.4976\n",
      "EPOCH: 221 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2.3976 - val_loss: 2.0761\n",
      "EPOCH: 222 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.4200 - val_loss: 0.2367\n",
      "EPOCH: 223 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 23.9175 - val_loss: 37.1534\n",
      "EPOCH: 224 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 12.9840 - val_loss: 8.6048\n",
      "EPOCH: 225 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 26.4592 - val_loss: 13.7635\n",
      "EPOCH: 226 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 10.3613 - val_loss: 9.2867\n",
      "EPOCH: 227 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 15.7558 - val_loss: 16.5433\n",
      "EPOCH: 228 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 18.7113 - val_loss: 19.7327\n",
      "EPOCH: 229 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 18.3184 - val_loss: 19.5351\n",
      "EPOCH: 230 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2.8889 - val_loss: 3.9474\n",
      "EPOCH: 231 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 18.1606 - val_loss: 17.6538\n",
      "EPOCH: 232 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 18.7157 - val_loss: 18.1809\n",
      "EPOCH: 233 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 16.7329 - val_loss: 12.8983\n",
      "EPOCH: 234 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 11.3223 - val_loss: 9.7662\n",
      "EPOCH: 235 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 15.2576 - val_loss: 15.4054\n",
      "EPOCH: 236 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 24.3879 - val_loss: 23.8508\n",
      "EPOCH: 237 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 20.8451 - val_loss: 29.1648\n",
      "EPOCH: 238 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.0145 - val_loss: 11.8810\n",
      "EPOCH: 239 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4.2009 - val_loss: 3.7367\n",
      "EPOCH: 240 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6.1277 - val_loss: 6.0075\n",
      "EPOCH: 241 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.3335 - val_loss: 7.5248\n",
      "EPOCH: 242 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 11.6896 - val_loss: 19.6127\n",
      "EPOCH: 243 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 11.3508 - val_loss: 11.5602\n",
      "EPOCH: 244 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 11.6348 - val_loss: 9.1010\n",
      "EPOCH: 245 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6.8096 - val_loss: 5.9616\n",
      "EPOCH: 246 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5.8765 - val_loss: 4.7510\n",
      "EPOCH: 247 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 54.2205 - val_loss: 78.0013\n",
      "EPOCH: 248 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.8278 - val_loss: 27.5800\n",
      "EPOCH: 249 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4.9800 - val_loss: 4.6365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 250 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5.8460 - val_loss: 5.3075\n",
      "EPOCH: 251 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 14.4131 - val_loss: 22.4285\n",
      "EPOCH: 252 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6.1952 - val_loss: 4.7333\n",
      "EPOCH: 253 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5.9794 - val_loss: 4.0832\n",
      "EPOCH: 254 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 11.7392 - val_loss: 8.5095\n",
      "EPOCH: 255 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 11.6458 - val_loss: 16.8077\n",
      "EPOCH: 256 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.0260 - val_loss: 11.5179\n",
      "EPOCH: 257 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4.1130 - val_loss: 4.7613\n",
      "EPOCH: 258 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 20.6577 - val_loss: 18.6881\n",
      "EPOCH: 259 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2399 - val_loss: 0.7168\n",
      "EPOCH: 260 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 12.1620 - val_loss: 10.8827\n",
      "EPOCH: 261 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 12.6929 - val_loss: 22.1936\n",
      "EPOCH: 262 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 13.3239 - val_loss: 4.6971\n",
      "EPOCH: 263 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 10.3031 - val_loss: 10.6897\n",
      "EPOCH: 264 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 21.2588 - val_loss: 20.3468\n",
      "EPOCH: 265 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 12.1540 - val_loss: 19.2998\n",
      "EPOCH: 266 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7.6616 - val_loss: 9.2983\n",
      "EPOCH: 267 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 22.8907 - val_loss: 22.6048\n",
      "EPOCH: 268 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7.7300 - val_loss: 5.0923\n",
      "EPOCH: 269 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1.7922 - val_loss: 0.5370\n",
      "EPOCH: 270 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.4805 - val_loss: 8.7611\n",
      "EPOCH: 271 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 14.2148 - val_loss: 19.7633\n",
      "EPOCH: 272 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1.7040 - val_loss: 8.0920\n",
      "EPOCH: 273 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.5838 - val_loss: 11.2121\n",
      "EPOCH: 274 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 11.9760 - val_loss: 8.1209\n",
      "EPOCH: 275 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 29.7573 - val_loss: 17.1226\n",
      "EPOCH: 276 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3583 - val_loss: 0.2553\n",
      "EPOCH: 277 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 25.3080 - val_loss: 30.4150\n",
      "EPOCH: 278 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7.1612 - val_loss: 7.3343\n",
      "EPOCH: 279 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 32.0451 - val_loss: 31.9178\n",
      "EPOCH: 280 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 15.3913 - val_loss: 15.5092\n",
      "EPOCH: 281 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 34.1956 - val_loss: 46.1246\n",
      "EPOCH: 282 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.6754 - val_loss: 0.6275\n",
      "EPOCH: 283 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 34.0923 - val_loss: 33.7275\n",
      "EPOCH: 284 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 16.0157 - val_loss: 16.0268\n",
      "EPOCH: 285 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 12.0078 - val_loss: 11.0488\n",
      "EPOCH: 286 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 15.3060 - val_loss: 14.8213\n",
      "EPOCH: 287 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.8839 - val_loss: 7.4380\n",
      "EPOCH: 288 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1.1032 - val_loss: 1.5549\n",
      "EPOCH: 289 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.8073 - val_loss: 6.6675\n",
      "EPOCH: 290 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 14.4420 - val_loss: 14.9364\n",
      "EPOCH: 291 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.1740 - val_loss: 6.1209\n",
      "EPOCH: 292 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 26.7410 - val_loss: 22.4562\n",
      "EPOCH: 293 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4.4687 - val_loss: 3.6389\n",
      "EPOCH: 294 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4.9062 - val_loss: 3.5337\n",
      "EPOCH: 295 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5.1684 - val_loss: 4.1992\n",
      "EPOCH: 296 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2.2709 - val_loss: 3.8036\n",
      "EPOCH: 297 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3.5315 - val_loss: 10.3253\n",
      "EPOCH: 298 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2.9200 - val_loss: 0.7582\n",
      "EPOCH: 299 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 24.6465 - val_loss: 25.1201\n",
      "EPOCH: 300 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 30.0077 - val_loss: 31.8275\n",
      "EPOCH: 301 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4.0929 - val_loss: 2.3796\n",
      "EPOCH: 302 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3.2824 - val_loss: 2.8752\n",
      "EPOCH: 303 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 33.6857 - val_loss: 34.5979\n",
      "EPOCH: 304 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 37.5652 - val_loss: 44.9673\n",
      "EPOCH: 305 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 17.3620 - val_loss: 8.8583\n",
      "EPOCH: 306 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 20.0266 - val_loss: 10.8111\n",
      "EPOCH: 307 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3.9429 - val_loss: 2.4303\n",
      "EPOCH: 308 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4.2862 - val_loss: 2.2457\n",
      "EPOCH: 309 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 12.2258 - val_loss: 13.2127\n",
      "EPOCH: 310 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5.8281 - val_loss: 5.5261\n",
      "EPOCH: 311 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.4624 - val_loss: 26.1839\n",
      "EPOCH: 312 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3.4711 - val_loss: 6.0044\n",
      "EPOCH: 313 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 46.0019 - val_loss: 45.3318\n",
      "EPOCH: 314 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.7387 - val_loss: 17.6105\n",
      "EPOCH: 315 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 16.0585 - val_loss: 24.9163\n",
      "EPOCH: 316 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 14.6110 - val_loss: 13.9859\n",
      "EPOCH: 317 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 38.0824 - val_loss: 34.3316\n",
      "EPOCH: 318 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 15.7926 - val_loss: 13.3475\n",
      "EPOCH: 319 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 36.0915 - val_loss: 67.6386\n",
      "EPOCH: 320 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 12.0179 - val_loss: 18.7316\n",
      "EPOCH: 321 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 11.1148 - val_loss: 9.4670\n",
      "EPOCH: 322 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 11.6347 - val_loss: 12.5486\n",
      "EPOCH: 323 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 11.3712 - val_loss: 13.8709\n",
      "EPOCH: 324 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6.5233 - val_loss: 6.5591\n",
      "EPOCH: 325 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 18.9718 - val_loss: 18.9114\n",
      "EPOCH: 326 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 49.4563 - val_loss: 61.0726\n",
      "EPOCH: 327 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.8174 - val_loss: 0.8275\n",
      "EPOCH: 328 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3.8244 - val_loss: 2.9029\n",
      "EPOCH: 329 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.4481 - val_loss: 1.5609\n",
      "EPOCH: 330 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 17.3963 - val_loss: 16.7846\n",
      "EPOCH: 331 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 13.2726 - val_loss: 12.8293\n",
      "EPOCH: 332 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.7735 - val_loss: 13.1668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 333 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5.9235 - val_loss: 5.3362\n",
      "EPOCH: 334 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.4571 - val_loss: 41.0984\n",
      "EPOCH: 335 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7.1559 - val_loss: 9.4698\n",
      "EPOCH: 336 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1.8963 - val_loss: 1.8261\n",
      "EPOCH: 337 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 38.5395 - val_loss: 38.0795\n",
      "EPOCH: 338 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 18.4688 - val_loss: 18.5475\n",
      "EPOCH: 339 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7.8590 - val_loss: 8.6506\n",
      "EPOCH: 340 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 16.8844 - val_loss: 17.8388\n",
      "EPOCH: 341 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 22.8028 - val_loss: 27.9289\n",
      "EPOCH: 342 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 38.1785 - val_loss: 45.9283\n",
      "EPOCH: 343 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 10.5145 - val_loss: 10.8788\n",
      "EPOCH: 344 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 10.3842 - val_loss: 12.1847\n",
      "EPOCH: 345 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4.0047 - val_loss: 2.6290\n",
      "EPOCH: 346 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 18.0961 - val_loss: 16.9682\n",
      "EPOCH: 347 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.0865 - val_loss: 10.1342\n",
      "EPOCH: 348 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 32.3741 - val_loss: 32.4219\n",
      "EPOCH: 349 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 30.3087 - val_loss: 29.4476\n",
      "EPOCH: 350 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 16.3822 - val_loss: 13.6518\n",
      "EPOCH: 351 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 10.6248 - val_loss: 13.2066\n",
      "EPOCH: 352 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1.9260 - val_loss: 3.1071\n",
      "EPOCH: 353 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6.8745 - val_loss: 32.7630\n",
      "EPOCH: 354 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.7962 - val_loss: 9.0356\n",
      "EPOCH: 355 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 14.3826 - val_loss: 15.9033\n",
      "EPOCH: 356 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 33.4663 - val_loss: 33.8471\n",
      "EPOCH: 357 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5.2079 - val_loss: 13.7445\n",
      "EPOCH: 358 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 18.5089 - val_loss: 18.3350\n",
      "EPOCH: 359 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.0650 - val_loss: 8.0428\n",
      "EPOCH: 360 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 26.2428 - val_loss: 25.8560\n",
      "EPOCH: 361 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 16.2249 - val_loss: 15.9158\n",
      "EPOCH: 362 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7.7831 - val_loss: 10.5127\n",
      "EPOCH: 363 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.3776 - val_loss: 9.8620\n",
      "EPOCH: 364 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4.7372 - val_loss: 4.1878\n",
      "EPOCH: 365 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 11.7466 - val_loss: 18.0260\n",
      "EPOCH: 366 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4.8392 - val_loss: 4.7529\n",
      "EPOCH: 367 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 17.7566 - val_loss: 17.3225\n",
      "EPOCH: 368 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 12.6892 - val_loss: 15.5076\n",
      "EPOCH: 369 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 14.2943 - val_loss: 13.8931\n",
      "EPOCH: 370 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7.9233 - val_loss: 35.4816\n",
      "EPOCH: 371 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 14.3893 - val_loss: 13.6069\n",
      "EPOCH: 372 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5.9564 - val_loss: 6.1836\n",
      "EPOCH: 373 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 21.2994 - val_loss: 24.3774\n",
      "EPOCH: 374 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1.1155 - val_loss: 0.8234\n",
      "EPOCH: 375 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 13.4526 - val_loss: 14.4648\n",
      "EPOCH: 376 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 17.3129 - val_loss: 17.0761\n",
      "EPOCH: 377 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4.0217 - val_loss: 0.1905\n",
      "EPOCH: 378 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7.9409 - val_loss: 8.3327\n",
      "EPOCH: 379 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 14.1940 - val_loss: 13.1239\n",
      "EPOCH: 380 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3.4992 - val_loss: 1.8681\n",
      "EPOCH: 381 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 25.5960 - val_loss: 28.8300\n",
      "EPOCH: 382 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.5253 - val_loss: 5.8128\n",
      "EPOCH: 383 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 11.5470 - val_loss: 12.5549\n",
      "EPOCH: 384 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.3616 - val_loss: 9.5048\n",
      "EPOCH: 385 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3.2298 - val_loss: 4.0388\n",
      "EPOCH: 386 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 46.7633 - val_loss: 46.6187\n",
      "EPOCH: 387 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3.1438 - val_loss: 3.4016\n",
      "EPOCH: 388 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 17.4872 - val_loss: 16.8891\n",
      "EPOCH: 389 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 29.6272 - val_loss: 16.3700\n",
      "EPOCH: 390 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 19.8448 - val_loss: 18.7890\n",
      "EPOCH: 391 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.1141 - val_loss: 29.3723\n",
      "EPOCH: 392 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 34.8795 - val_loss: 21.0930\n",
      "EPOCH: 393 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 10.8969 - val_loss: 11.4175\n",
      "EPOCH: 394 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 11.1936 - val_loss: 11.4752\n",
      "EPOCH: 395 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.1336 - val_loss: 7.2789\n",
      "EPOCH: 396 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 34.5083 - val_loss: 42.5633\n",
      "EPOCH: 397 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7.6374 - val_loss: 6.6806\n",
      "EPOCH: 398 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7.5634 - val_loss: 6.9566\n",
      "EPOCH: 399 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4.6174 - val_loss: 4.2933\n",
      "EPOCH: 400 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2.6527 - val_loss: 3.2691\n",
      "EPOCH: 401 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 39.2351 - val_loss: 36.8149\n",
      "EPOCH: 402 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 23.4583 - val_loss: 20.9904\n",
      "EPOCH: 403 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 12.6846 - val_loss: 13.0320\n",
      "EPOCH: 404 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 11.5488 - val_loss: 0.4503\n",
      "EPOCH: 405 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 33.7797 - val_loss: 35.3192\n",
      "EPOCH: 406 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 37.4231 - val_loss: 36.8112\n",
      "EPOCH: 407 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 15.5367 - val_loss: 14.9186\n",
      "EPOCH: 408 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 36.5048 - val_loss: 34.1090\n",
      "EPOCH: 409 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 17.4548 - val_loss: 17.8475\n",
      "EPOCH: 410 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 14.5684 - val_loss: 14.0915\n",
      "EPOCH: 411 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5.0401 - val_loss: 13.0059\n",
      "EPOCH: 412 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 10.6991 - val_loss: 32.0888\n",
      "EPOCH: 413 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 12.6124 - val_loss: 0.9339\n",
      "EPOCH: 414 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 26.5422 - val_loss: 25.5089\n",
      "EPOCH: 415 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 10.9851 - val_loss: 9.5797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 416 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 17.7796 - val_loss: 17.5059\n",
      "EPOCH: 417 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 12.6413 - val_loss: 14.8903\n",
      "EPOCH: 418 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 10.1603 - val_loss: 9.8985\n",
      "EPOCH: 419 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 10.8167 - val_loss: 13.1109\n",
      "EPOCH: 420 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 43.5177 - val_loss: 69.1152\n",
      "EPOCH: 421 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 45.9934 - val_loss: 45.9792\n",
      "EPOCH: 422 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.4107 - val_loss: 3.6584\n",
      "EPOCH: 423 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 21.0511 - val_loss: 21.8055\n",
      "EPOCH: 424 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 20.8645 - val_loss: 34.4554\n",
      "EPOCH: 425 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 37.4830 - val_loss: 48.7582\n",
      "EPOCH: 426 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7.0808 - val_loss: 6.4875\n",
      "EPOCH: 427 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 42.0329 - val_loss: 67.0329\n",
      "EPOCH: 428 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 12.9675 - val_loss: 14.6896\n",
      "EPOCH: 429 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 15.2896 - val_loss: 12.2013\n",
      "EPOCH: 430 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.0346 - val_loss: 9.8572\n",
      "EPOCH: 431 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 15.0071 - val_loss: 13.9816\n",
      "EPOCH: 432 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5.8829 - val_loss: 4.8907\n",
      "EPOCH: 433 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 11.9420 - val_loss: 21.4340\n",
      "EPOCH: 434 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2.5063 - val_loss: 2.2934\n",
      "EPOCH: 435 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.8486 - val_loss: 0.0874\n",
      "EPOCH: 436 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2.3983 - val_loss: 1.5761\n",
      "EPOCH: 437 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 27.0575 - val_loss: 41.3260\n",
      "EPOCH: 438 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7.3801 - val_loss: 4.7654\n",
      "EPOCH: 439 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 23.5574 - val_loss: 26.4281\n",
      "EPOCH: 440 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 36.1058 - val_loss: 34.8245\n",
      "EPOCH: 441 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 13.3612 - val_loss: 14.8224\n",
      "EPOCH: 442 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 23.2399 - val_loss: 23.4674\n",
      "EPOCH: 443 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 17.1252 - val_loss: 14.6683\n",
      "EPOCH: 444 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4.0772 - val_loss: 3.8355\n",
      "EPOCH: 445 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 59.1536 - val_loss: 76.3109\n",
      "EPOCH: 446 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 32.2870 - val_loss: 30.6000\n",
      "EPOCH: 447 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 47.6975 - val_loss: 49.1069\n",
      "EPOCH: 448 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 54.2164 - val_loss: 51.9996\n",
      "EPOCH: 449 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 20.2254 - val_loss: 11.4097\n",
      "EPOCH: 450 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4.0035 - val_loss: 5.4908\n",
      "EPOCH: 451 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 16.8705 - val_loss: 17.9968\n",
      "EPOCH: 452 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 11.9614 - val_loss: 11.2773\n",
      "EPOCH: 453 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2.2126 - val_loss: 1.6255\n",
      "EPOCH: 454 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2.4132 - val_loss: 2.9118\n",
      "EPOCH: 455 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 17.1882 - val_loss: 16.7026\n",
      "EPOCH: 456 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7.7391 - val_loss: 6.0385\n",
      "EPOCH: 457 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 12.8111 - val_loss: 16.3289\n",
      "EPOCH: 458 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 15.2168 - val_loss: 11.0837\n",
      "EPOCH: 459 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 10.8342 - val_loss: 14.7976\n",
      "EPOCH: 460 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5.3056 - val_loss: 7.2904\n",
      "EPOCH: 461 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 21.8251 - val_loss: 22.3601\n",
      "EPOCH: 462 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 11.4799 - val_loss: 11.3675\n",
      "EPOCH: 463 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 21.3006 - val_loss: 21.2258\n",
      "EPOCH: 464 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 37.2456 - val_loss: 56.3795\n",
      "EPOCH: 465 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6.8077 - val_loss: 10.2609\n",
      "EPOCH: 466 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 18.8821 - val_loss: 19.0215\n",
      "EPOCH: 467 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 35.4070 - val_loss: 57.7678\n",
      "EPOCH: 468 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5.9036 - val_loss: 6.1759\n",
      "EPOCH: 469 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 50.3872 - val_loss: 50.3425\n",
      "EPOCH: 470 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.3904 - val_loss: 7.4964\n",
      "EPOCH: 471 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 17.8131 - val_loss: 18.5365\n",
      "EPOCH: 472 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 29.5397 - val_loss: 28.1529\n",
      "EPOCH: 473 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 16.6328 - val_loss: 15.8867\n",
      "EPOCH: 474 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.6486 - val_loss: 6.6818\n",
      "EPOCH: 475 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 15.5548 - val_loss: 15.4637\n",
      "EPOCH: 476 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 14.5161 - val_loss: 18.2721\n",
      "EPOCH: 477 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 36.1223 - val_loss: 35.9667\n",
      "EPOCH: 478 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2.0244 - val_loss: 1.7632\n",
      "EPOCH: 479 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7.9161 - val_loss: 8.6075\n",
      "EPOCH: 480 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1.7035 - val_loss: 1.5525\n",
      "EPOCH: 481 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 14.8079 - val_loss: 15.1018\n",
      "EPOCH: 482 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.6294 - val_loss: 0.2744\n",
      "EPOCH: 483 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1.1256 - val_loss: 1.2407\n",
      "EPOCH: 484 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 23.1026 - val_loss: 25.7741\n",
      "EPOCH: 485 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6.5449 - val_loss: 3.8064\n",
      "EPOCH: 486 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 13.8394 - val_loss: 10.5230\n",
      "EPOCH: 487 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 11.2837 - val_loss: 23.6565\n",
      "EPOCH: 488 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 17.9184 - val_loss: 17.6085\n",
      "EPOCH: 489 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7.3307 - val_loss: 4.7505\n",
      "EPOCH: 490 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.1037 - val_loss: 8.4638\n",
      "EPOCH: 491 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2.0393 - val_loss: 1.3349\n",
      "EPOCH: 492 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 10.9318 - val_loss: 10.0201\n",
      "EPOCH: 493 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7.7934 - val_loss: 9.7209\n",
      "EPOCH: 494 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.8867 - val_loss: 11.1177\n",
      "EPOCH: 495 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6.9271 - val_loss: 5.7441\n",
      "EPOCH: 496 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 10.8257 - val_loss: 12.3274\n",
      "EPOCH: 497 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 30.4892 - val_loss: 17.5135\n",
      "EPOCH: 498 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.4605 - val_loss: 2.8159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 499 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 12.6271 - val_loss: 8.2460\n",
      "EPOCH: 500 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.5902 - val_loss: 9.7016\n",
      "EPOCH: 501 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 11.3724 - val_loss: 15.6437\n",
      "EPOCH: 502 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6.7087 - val_loss: 4.1842\n",
      "EPOCH: 503 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 17.7017 - val_loss: 27.0529\n",
      "EPOCH: 504 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.1221 - val_loss: 12.5906\n",
      "EPOCH: 505 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 53.4280 - val_loss: 51.0147\n",
      "EPOCH: 506 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 16.8539 - val_loss: 17.1074\n",
      "EPOCH: 507 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 46.3555 - val_loss: 46.1404\n",
      "EPOCH: 508 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 21.6404 - val_loss: 23.7739\n",
      "EPOCH: 509 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.6956 - val_loss: 15.5520\n",
      "EPOCH: 510 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3.5115 - val_loss: 3.5876\n",
      "EPOCH: 511 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 28.9043 - val_loss: 40.1811\n",
      "EPOCH: 512 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 19.3881 - val_loss: 21.3305\n",
      "EPOCH: 513 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 19.1162 - val_loss: 18.4021\n",
      "EPOCH: 514 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6.4697 - val_loss: 27.5342\n",
      "EPOCH: 515 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5.1217 - val_loss: 6.2841\n",
      "EPOCH: 516 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 11.9087 - val_loss: 10.5375\n",
      "EPOCH: 517 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 14.9664 - val_loss: 12.5892\n",
      "EPOCH: 518 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 13.4980 - val_loss: 7.8707\n",
      "EPOCH: 519 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 31.7833 - val_loss: 31.7287\n",
      "EPOCH: 520 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 14.7254 - val_loss: 14.1142\n",
      "EPOCH: 521 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 20.8815 - val_loss: 27.0806\n",
      "EPOCH: 522 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5.9113 - val_loss: 6.1942\n",
      "EPOCH: 523 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 16.0360 - val_loss: 16.0050\n",
      "EPOCH: 524 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.0563 - val_loss: 10.7399\n",
      "EPOCH: 525 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4.1209 - val_loss: 4.0211\n",
      "EPOCH: 526 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 10.8242 - val_loss: 8.5654\n",
      "EPOCH: 527 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.4437 - val_loss: 5.1939\n",
      "EPOCH: 528 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 16.6656 - val_loss: 14.1586\n",
      "EPOCH: 529 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2557 - val_loss: 0.3259\n",
      "EPOCH: 530 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 24.3319 - val_loss: 24.1789\n",
      "EPOCH: 531 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 20.2488 - val_loss: 20.7469\n",
      "EPOCH: 532 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7.5389 - val_loss: 10.2723\n",
      "EPOCH: 533 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.2405 - val_loss: 1.6597\n",
      "EPOCH: 534 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 29.3737 - val_loss: 16.4010\n",
      "EPOCH: 535 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 41.0010 - val_loss: 40.6176\n",
      "EPOCH: 536 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.2101 - val_loss: 18.2791\n",
      "EPOCH: 537 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 13.2811 - val_loss: 11.8627\n",
      "EPOCH: 538 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 18.6335 - val_loss: 19.6721\n",
      "EPOCH: 539 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5.3292 - val_loss: 4.6345\n",
      "EPOCH: 540 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 19.5274 - val_loss: 22.0600\n",
      "EPOCH: 541 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2.4257 - val_loss: 2.6661\n",
      "EPOCH: 542 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 10.5815 - val_loss: 14.5626\n",
      "EPOCH: 543 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.9530 - val_loss: 0.2399\n",
      "EPOCH: 544 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3.6685 - val_loss: 3.0660\n",
      "EPOCH: 545 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 16.1231 - val_loss: 8.0438\n",
      "EPOCH: 546 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.4912 - val_loss: 7.1389\n",
      "EPOCH: 547 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.0493 - val_loss: 35.0593\n",
      "EPOCH: 548 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 17.4264 - val_loss: 16.4398\n",
      "EPOCH: 549 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.9984 - val_loss: 9.3623\n",
      "EPOCH: 550 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 10.4153 - val_loss: 9.3894\n",
      "EPOCH: 551 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.9360 - val_loss: 6.4395\n",
      "EPOCH: 552 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1.6986 - val_loss: 2.0585\n",
      "EPOCH: 553 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6.7058 - val_loss: 5.5893\n",
      "EPOCH: 554 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7.0179 - val_loss: 17.7825\n",
      "EPOCH: 555 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1.2727 - val_loss: 0.9949\n",
      "EPOCH: 556 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5.1377 - val_loss: 9.1913\n",
      "EPOCH: 557 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5.2457 - val_loss: 13.2550\n",
      "EPOCH: 558 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 16.9513 - val_loss: 17.7240\n",
      "EPOCH: 559 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6.5660 - val_loss: 3.0820\n",
      "EPOCH: 560 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.6330 - val_loss: 0.3032\n",
      "EPOCH: 561 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 14.1169 - val_loss: 22.7644\n",
      "EPOCH: 562 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.2120 - val_loss: 7.5505\n",
      "EPOCH: 563 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 16.3867 - val_loss: 15.9159\n",
      "EPOCH: 564 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3.0013 - val_loss: 0.0912\n",
      "EPOCH: 565 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 19.1953 - val_loss: 29.1799\n",
      "EPOCH: 566 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 13.0513 - val_loss: 14.1431\n",
      "EPOCH: 567 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.1955 - val_loss: 7.8265\n",
      "EPOCH: 568 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5.0757 - val_loss: 2.7782\n",
      "EPOCH: 569 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3.4264 - val_loss: 7.9829\n",
      "EPOCH: 570 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5.7703 - val_loss: 1.0656\n",
      "EPOCH: 571 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6.0935 - val_loss: 6.5543\n",
      "EPOCH: 572 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.8021 - val_loss: 12.1333\n",
      "EPOCH: 573 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 37.0418 - val_loss: 68.5565\n",
      "EPOCH: 574 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 13.7902 - val_loss: 17.2616\n",
      "EPOCH: 575 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5.1872 - val_loss: 8.2217\n",
      "EPOCH: 576 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 27.3783 - val_loss: 27.1847\n",
      "EPOCH: 577 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 39.1870 - val_loss: 38.3080\n",
      "EPOCH: 578 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.5517 - val_loss: 9.0767\n",
      "EPOCH: 579 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5.1278 - val_loss: 2.9670\n",
      "EPOCH: 580 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3.1483 - val_loss: 0.5701\n",
      "EPOCH: 581 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 14.7823 - val_loss: 34.9659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 582 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3.6120 - val_loss: 4.5159\n",
      "EPOCH: 583 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 16.8077 - val_loss: 12.7672\n",
      "EPOCH: 584 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 12.0052 - val_loss: 8.4020\n",
      "EPOCH: 585 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 18.0559 - val_loss: 17.6584\n",
      "EPOCH: 586 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 12.5898 - val_loss: 10.6348\n",
      "EPOCH: 587 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6.3305 - val_loss: 6.1330\n",
      "EPOCH: 588 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 11.7378 - val_loss: 1.5626\n",
      "EPOCH: 589 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 16.5768 - val_loss: 16.1971\n",
      "EPOCH: 590 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7.5721 - val_loss: 1.9247\n",
      "EPOCH: 591 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1.8965 - val_loss: 2.8791\n",
      "EPOCH: 592 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7.3624 - val_loss: 5.0565\n",
      "EPOCH: 593 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7.6782 - val_loss: 1.8476\n",
      "EPOCH: 594 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 23.9475 - val_loss: 23.7453\n",
      "EPOCH: 595 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 19.1323 - val_loss: 18.7240\n",
      "EPOCH: 596 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 13.3334 - val_loss: 7.7031\n",
      "EPOCH: 597 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 10.5648 - val_loss: 1.0737\n",
      "EPOCH: 598 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7.1479 - val_loss: 6.1338\n",
      "EPOCH: 599 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 36.9608 - val_loss: 45.6638\n",
      "EPOCH: 600 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4.0868 - val_loss: 3.0749\n",
      "EPOCH: 601 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 10.9685 - val_loss: 7.9981\n",
      "EPOCH: 602 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6.4275 - val_loss: 11.7683\n",
      "EPOCH: 603 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3.9410 - val_loss: 3.8489\n",
      "EPOCH: 604 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4.1634 - val_loss: 19.7700\n",
      "EPOCH: 605 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 11.6877 - val_loss: 7.6670\n",
      "EPOCH: 606 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.9198 - val_loss: 10.3478\n",
      "EPOCH: 607 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 26.8862 - val_loss: 10.6857\n",
      "EPOCH: 608 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7.6867 - val_loss: 7.2471\n",
      "EPOCH: 609 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 16.5266 - val_loss: 15.9202\n",
      "EPOCH: 610 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4.9703 - val_loss: 28.0363\n",
      "EPOCH: 611 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6.6895 - val_loss: 5.7214\n",
      "EPOCH: 612 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 14.2609 - val_loss: 15.4010\n",
      "EPOCH: 613 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 22.4609 - val_loss: 25.7382\n",
      "EPOCH: 614 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 19.8075 - val_loss: 20.2149\n",
      "EPOCH: 615 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 28.3669 - val_loss: 17.8948\n",
      "EPOCH: 616 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 17.9569 - val_loss: 24.2122\n",
      "EPOCH: 617 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 15.1393 - val_loss: 42.3863\n",
      "EPOCH: 618 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3.9428 - val_loss: 0.0701\n",
      "EPOCH: 619 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5.3556 - val_loss: 26.3364\n",
      "EPOCH: 620 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 10.0376 - val_loss: 10.4648\n",
      "EPOCH: 621 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1.0806 - val_loss: 1.2805\n",
      "EPOCH: 622 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.8132 - val_loss: 8.4674\n",
      "EPOCH: 623 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 12.8175 - val_loss: 32.0323\n",
      "EPOCH: 624 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.7291 - val_loss: 7.9940\n",
      "EPOCH: 625 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 25.0939 - val_loss: 24.4451\n",
      "EPOCH: 626 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 10.0023 - val_loss: 14.1656\n",
      "EPOCH: 627 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5.3521 - val_loss: 0.7687\n",
      "EPOCH: 628 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6.8422 - val_loss: 7.8090\n",
      "EPOCH: 629 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 17.6352 - val_loss: 17.7660\n",
      "EPOCH: 630 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 26.0818 - val_loss: 24.4808\n",
      "EPOCH: 631 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5.1049 - val_loss: 5.6254\n",
      "EPOCH: 632 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5.6254 - val_loss: 5.6696\n",
      "EPOCH: 633 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.7884 - val_loss: 9.3766\n",
      "EPOCH: 634 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1.7859 - val_loss: 1.5224\n",
      "EPOCH: 635 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 14.7316 - val_loss: 15.3438\n",
      "EPOCH: 636 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5.6937 - val_loss: 5.5754\n",
      "EPOCH: 637 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 15.6032 - val_loss: 7.5157\n",
      "EPOCH: 638 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 10.2224 - val_loss: 10.2711\n",
      "EPOCH: 639 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 20.4286 - val_loss: 21.8556\n",
      "EPOCH: 640 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 49.3629 - val_loss: 64.9103\n",
      "EPOCH: 641 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3.3978 - val_loss: 2.9297\n",
      "EPOCH: 642 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2.4794 - val_loss: 3.4979\n",
      "EPOCH: 643 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 14.2255 - val_loss: 16.6101\n",
      "EPOCH: 644 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 13.4767 - val_loss: 20.6336\n",
      "EPOCH: 645 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 14.4813 - val_loss: 12.7353\n",
      "EPOCH: 646 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 25.3289 - val_loss: 24.7882\n",
      "EPOCH: 647 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.0878 - val_loss: 8.9825\n",
      "EPOCH: 648 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.4789 - val_loss: 0.4479\n",
      "EPOCH: 649 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 16.7378 - val_loss: 17.4032\n",
      "EPOCH: 650 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.9408 - val_loss: 8.0646\n",
      "EPOCH: 651 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 12.3789 - val_loss: 7.0945\n",
      "EPOCH: 652 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7.2356 - val_loss: 8.2166\n",
      "EPOCH: 653 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.5109 - val_loss: 6.1936\n",
      "EPOCH: 654 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 13.5483 - val_loss: 12.4001\n",
      "EPOCH: 655 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 13.0069 - val_loss: 13.2276\n",
      "EPOCH: 656 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 35.1486 - val_loss: 36.2054\n",
      "EPOCH: 657 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.2532 - val_loss: 0.2699\n",
      "EPOCH: 658 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 51.8430 - val_loss: 51.5961\n",
      "EPOCH: 659 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.4032 - val_loss: 8.3155\n",
      "EPOCH: 660 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.7537 - val_loss: 9.1095\n",
      "EPOCH: 661 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7.9725 - val_loss: 26.2023\n",
      "EPOCH: 662 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 14.3627 - val_loss: 14.6296\n",
      "EPOCH: 663 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2.4153 - val_loss: 4.2395\n",
      "EPOCH: 664 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 10.1743 - val_loss: 17.2914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 665 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 26.0014 - val_loss: 36.0025\n",
      "EPOCH: 666 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 10.3541 - val_loss: 8.6447\n",
      "EPOCH: 667 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 25.0630 - val_loss: 39.7586\n",
      "EPOCH: 668 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 36.9742 - val_loss: 32.8349\n",
      "EPOCH: 669 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.8724 - val_loss: 13.4489\n",
      "EPOCH: 670 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5.8846 - val_loss: 25.3906\n",
      "EPOCH: 671 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 35.8271 - val_loss: 47.3814\n",
      "EPOCH: 672 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 11.6424 - val_loss: 14.7693\n",
      "EPOCH: 673 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6.0065 - val_loss: 4.1723\n",
      "EPOCH: 674 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 14.4804 - val_loss: 12.9564\n",
      "EPOCH: 675 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.0274 - val_loss: 12.1335\n",
      "EPOCH: 676 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4.9322 - val_loss: 4.7121\n",
      "EPOCH: 677 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 13.2080 - val_loss: 12.3285\n",
      "EPOCH: 678 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5.6715 - val_loss: 5.8164\n",
      "EPOCH: 679 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2.8575 - val_loss: 2.6430\n",
      "EPOCH: 680 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 10.3091 - val_loss: 10.2952\n",
      "EPOCH: 681 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 11.1708 - val_loss: 8.4865\n",
      "EPOCH: 682 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 14.4284 - val_loss: 11.7655\n",
      "EPOCH: 683 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 11.5243 - val_loss: 0.6848\n",
      "EPOCH: 684 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2.2295 - val_loss: 2.0467\n",
      "EPOCH: 685 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 32.1295 - val_loss: 32.7432\n",
      "EPOCH: 686 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5.3384 - val_loss: 4.4823\n",
      "EPOCH: 687 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3.8656 - val_loss: 1.8745\n",
      "EPOCH: 688 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1.2715 - val_loss: 0.7052\n",
      "EPOCH: 689 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 14.0523 - val_loss: 14.7097\n",
      "EPOCH: 690 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 10.3693 - val_loss: 9.6266\n",
      "EPOCH: 691 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.8397 - val_loss: 7.6382\n",
      "EPOCH: 692 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 40.5486 - val_loss: 43.3876\n",
      "EPOCH: 693 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7.6504 - val_loss: 8.4764\n",
      "EPOCH: 694 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 19.7845 - val_loss: 30.0348\n",
      "EPOCH: 695 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.5750 - val_loss: 8.7031\n",
      "EPOCH: 696 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6.2240 - val_loss: 5.3253\n",
      "EPOCH: 697 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5.3918 - val_loss: 6.3213\n",
      "EPOCH: 698 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.4336 - val_loss: 7.5959\n",
      "EPOCH: 699 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5.1966 - val_loss: 5.2100\n",
      "EPOCH: 700 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 20.3856 - val_loss: 26.5605\n",
      "EPOCH: 701 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2.2490 - val_loss: 1.9116\n",
      "EPOCH: 702 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 36.2191 - val_loss: 59.5129\n",
      "EPOCH: 703 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2.2853 - val_loss: 1.8907\n",
      "EPOCH: 704 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 38.0198 - val_loss: 38.6488\n",
      "EPOCH: 705 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 32.3152 - val_loss: 19.5664\n",
      "EPOCH: 706 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 10.9430 - val_loss: 11.6130\n",
      "EPOCH: 707 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 13.1804 - val_loss: 12.0643\n",
      "EPOCH: 708 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 15.4357 - val_loss: 16.4039\n",
      "EPOCH: 709 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7.5451 - val_loss: 40.0288\n",
      "EPOCH: 710 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.7019 - val_loss: 6.3438\n",
      "EPOCH: 711 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 28.8438 - val_loss: 27.9191\n",
      "EPOCH: 712 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 11.6660 - val_loss: 12.0446\n",
      "EPOCH: 713 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1.0853 - val_loss: 0.2082\n",
      "EPOCH: 714 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 27.2270 - val_loss: 37.9557\n",
      "EPOCH: 715 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 20.9558 - val_loss: 19.9607\n",
      "EPOCH: 716 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 10.0528 - val_loss: 26.2026\n",
      "EPOCH: 717 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.8266 - val_loss: 9.2308\n",
      "EPOCH: 718 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.4139 - val_loss: 7.5224\n",
      "EPOCH: 719 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6.8173 - val_loss: 7.0476\n",
      "EPOCH: 720 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 11.8895 - val_loss: 10.8024\n",
      "EPOCH: 721 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6.4632 - val_loss: 5.3085\n",
      "EPOCH: 722 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 35.5581 - val_loss: 67.6139\n",
      "EPOCH: 723 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.2186 - val_loss: 8.9036\n",
      "EPOCH: 724 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 11.0159 - val_loss: 10.9881\n",
      "EPOCH: 725 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4.4349 - val_loss: 4.6267\n",
      "EPOCH: 726 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4.4063 - val_loss: 4.2019\n",
      "EPOCH: 727 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 11.8309 - val_loss: 11.1293\n",
      "EPOCH: 728 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.1684 - val_loss: 1.3865\n",
      "EPOCH: 729 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.2870 - val_loss: 9.6758\n",
      "EPOCH: 730 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 10.1200 - val_loss: 10.5140\n",
      "EPOCH: 731 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 10.6230 - val_loss: 10.6854\n",
      "EPOCH: 732 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6.7875 - val_loss: 7.4895\n",
      "EPOCH: 733 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 46.0802 - val_loss: 71.8754\n",
      "EPOCH: 734 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 24.9754 - val_loss: 25.0138\n",
      "EPOCH: 735 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4.7576 - val_loss: 5.1976\n",
      "EPOCH: 736 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5.5843 - val_loss: 4.6014\n",
      "EPOCH: 737 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6.7496 - val_loss: 6.5862\n",
      "EPOCH: 738 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1.5939 - val_loss: 2.4726\n",
      "EPOCH: 739 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 11.2663 - val_loss: 9.9810\n",
      "EPOCH: 740 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 22.7235 - val_loss: 18.3827\n",
      "EPOCH: 741 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 35.0607 - val_loss: 34.4948\n",
      "EPOCH: 742 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 16.2472 - val_loss: 20.0846\n",
      "EPOCH: 743 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 15.0011 - val_loss: 14.5241\n",
      "EPOCH: 744 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 11.2767 - val_loss: 3.5445\n",
      "EPOCH: 745 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 17.9964 - val_loss: 12.2526\n",
      "EPOCH: 746 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 43.4802 - val_loss: 39.3119\n",
      "EPOCH: 747 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 55.1841 - val_loss: 52.8267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 748 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 28.8275 - val_loss: 45.2880\n",
      "EPOCH: 749 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.3947 - val_loss: 8.8050\n",
      "EPOCH: 750 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 10.2366 - val_loss: 9.8624\n",
      "EPOCH: 751 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.5072 - val_loss: 10.1377\n",
      "EPOCH: 752 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 18.9877 - val_loss: 17.8497\n",
      "EPOCH: 753 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 33.4691 - val_loss: 31.9512\n",
      "EPOCH: 754 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.5729 - val_loss: 8.8086\n",
      "EPOCH: 755 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 23.3015 - val_loss: 22.7199\n",
      "EPOCH: 756 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4.7555 - val_loss: 1.8988\n",
      "EPOCH: 757 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 13.0631 - val_loss: 13.6087\n",
      "EPOCH: 758 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 26.6761 - val_loss: 27.1184\n",
      "EPOCH: 759 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 10.5369 - val_loss: 10.9944\n",
      "EPOCH: 760 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 11.7597 - val_loss: 10.6914\n",
      "EPOCH: 761 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 10.7783 - val_loss: 10.4911\n",
      "EPOCH: 762 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 16.5477 - val_loss: 11.9088\n",
      "EPOCH: 763 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 19.6421 - val_loss: 17.3405\n",
      "EPOCH: 764 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 16.8301 - val_loss: 14.6192\n",
      "EPOCH: 765 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 14.4371 - val_loss: 13.4581\n",
      "EPOCH: 766 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 19.7844 - val_loss: 25.3711\n",
      "EPOCH: 767 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 26.8765 - val_loss: 26.8526\n",
      "EPOCH: 768 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 25.3533 - val_loss: 27.2326\n",
      "EPOCH: 769 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 20.9921 - val_loss: 14.6829\n",
      "EPOCH: 770 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6.9888 - val_loss: 7.5083\n",
      "EPOCH: 771 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 13.4700 - val_loss: 12.6835\n",
      "EPOCH: 772 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6.0372 - val_loss: 6.4536\n",
      "EPOCH: 773 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4.3159 - val_loss: 1.6499\n",
      "EPOCH: 774 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 10.1209 - val_loss: 11.4997\n",
      "EPOCH: 775 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 15.1893 - val_loss: 22.5185\n",
      "EPOCH: 776 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.3669 - val_loss: 10.6698\n",
      "EPOCH: 777 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6.4501 - val_loss: 11.5799\n",
      "EPOCH: 778 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 10.7053 - val_loss: 7.5599\n",
      "EPOCH: 779 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3.8183 - val_loss: 3.3060\n",
      "EPOCH: 780 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5.4640 - val_loss: 3.7641\n",
      "EPOCH: 781 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 10.2910 - val_loss: 9.2124\n",
      "EPOCH: 782 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3.2641 - val_loss: 2.2235\n",
      "EPOCH: 783 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7.4835 - val_loss: 6.3268\n",
      "EPOCH: 784 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 15.5135 - val_loss: 15.4001\n",
      "EPOCH: 785 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2.9666 - val_loss: 3.2499\n",
      "EPOCH: 786 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.6987 - val_loss: 0.8464\n",
      "EPOCH: 787 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2.6440 - val_loss: 1.8845\n",
      "EPOCH: 788 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2.7926 - val_loss: 1.6916\n",
      "EPOCH: 789 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 12.5224 - val_loss: 10.6233\n",
      "EPOCH: 790 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7.7382 - val_loss: 9.1683\n",
      "EPOCH: 791 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 30.9117 - val_loss: 29.8992\n",
      "EPOCH: 792 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 21.7580 - val_loss: 13.2342\n",
      "EPOCH: 793 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 10.2356 - val_loss: 13.9225\n",
      "EPOCH: 794 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6.5208 - val_loss: 5.8709\n",
      "EPOCH: 795 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5.9611 - val_loss: 5.7448\n",
      "EPOCH: 796 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7.3590 - val_loss: 4.2651\n",
      "EPOCH: 797 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 22.6179 - val_loss: 22.6310\n",
      "EPOCH: 798 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7.5128 - val_loss: 5.9583\n",
      "EPOCH: 799 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 25.8210 - val_loss: 26.6947\n",
      "EPOCH: 800 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 11.3317 - val_loss: 12.5161\n",
      "EPOCH: 801 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4.4158 - val_loss: 23.7914\n",
      "EPOCH: 802 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 29.0474 - val_loss: 28.2655\n",
      "EPOCH: 803 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 12.2210 - val_loss: 15.3294\n",
      "EPOCH: 804 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 14.8039 - val_loss: 21.6165\n",
      "EPOCH: 805 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 12.4099 - val_loss: 15.2739\n",
      "EPOCH: 806 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6.3616 - val_loss: 13.2501\n",
      "EPOCH: 807 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 12.9957 - val_loss: 15.3468\n",
      "EPOCH: 808 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 27.9273 - val_loss: 24.7237\n",
      "EPOCH: 809 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 16.0055 - val_loss: 15.3100\n",
      "EPOCH: 810 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1.7528 - val_loss: 2.1894\n",
      "EPOCH: 811 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 14.1983 - val_loss: 17.9518\n",
      "EPOCH: 812 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.2885 - val_loss: 28.6790\n",
      "EPOCH: 813 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 37.0731 - val_loss: 36.3273\n",
      "EPOCH: 814 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5.3113 - val_loss: 6.9428\n",
      "EPOCH: 815 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7.9473 - val_loss: 8.5669\n",
      "EPOCH: 816 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3.7540 - val_loss: 10.4469\n",
      "EPOCH: 817 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2.4543 - val_loss: 2.7087\n",
      "EPOCH: 818 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 24.2694 - val_loss: 22.8732\n",
      "EPOCH: 819 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 30.8035 - val_loss: 30.2023\n",
      "EPOCH: 820 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.1262 - val_loss: 8.1700\n",
      "EPOCH: 821 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 13.6889 - val_loss: 16.9384\n",
      "EPOCH: 822 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 38.0725 - val_loss: 52.6904\n",
      "EPOCH: 823 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 17.9885 - val_loss: 17.8874\n",
      "EPOCH: 824 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 16.8804 - val_loss: 20.3440\n",
      "EPOCH: 825 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 11.6741 - val_loss: 12.0488\n",
      "EPOCH: 826 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 29.4460 - val_loss: 29.5934\n",
      "EPOCH: 827 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 12.2282 - val_loss: 11.7078\n",
      "EPOCH: 828 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 12.7955 - val_loss: 13.5759\n",
      "EPOCH: 829 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2.2111 - val_loss: 1.3351\n",
      "EPOCH: 830 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 8.9844 - val_loss: 9.1060\n",
      "EPOCH: 831 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 12.8509 - val_loss: 12.3124\n",
      "EPOCH: 832 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4.7987 - val_loss: 3.8329\n",
      "EPOCH: 833 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 12.8431 - val_loss: 16.1164\n",
      "EPOCH: 834 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 17.3830 - val_loss: 16.4582\n",
      "EPOCH: 835 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7.1996 - val_loss: 4.0102\n",
      "EPOCH: 836 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 17.3006 - val_loss: 23.4828\n",
      "EPOCH: 837 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 43.2051 - val_loss: 43.4841\n",
      "EPOCH: 838 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.3339 - val_loss: 5.8690\n",
      "EPOCH: 839 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3.4495 - val_loss: 10.6717\n",
      "EPOCH: 840 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 18.1688 - val_loss: 23.5069\n",
      "EPOCH: 841 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.4670 - val_loss: 7.4949\n",
      "EPOCH: 842 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2.5419 - val_loss: 2.3712\n",
      "EPOCH: 843 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.2563 - val_loss: 27.7163\n",
      "EPOCH: 844 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 32.0560 - val_loss: 39.0237\n",
      "EPOCH: 845 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 13.7148 - val_loss: 13.1069\n",
      "EPOCH: 846 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 30.9879 - val_loss: 32.3400\n",
      "EPOCH: 847 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 12.5638 - val_loss: 12.5510\n",
      "EPOCH: 848 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2.2104 - val_loss: 2.4865\n",
      "EPOCH: 849 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 12.2468 - val_loss: 10.9742\n",
      "EPOCH: 850 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.5940 - val_loss: 5.3207\n",
      "EPOCH: 851 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7.7433 - val_loss: 7.1676\n",
      "EPOCH: 852 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 20.7262 - val_loss: 17.9102\n",
      "EPOCH: 853 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4.3294 - val_loss: 2.4682\n",
      "EPOCH: 854 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3.8282 - val_loss: 3.5435\n",
      "EPOCH: 855 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3.5740 - val_loss: 10.5053\n",
      "EPOCH: 856 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 16.6346 - val_loss: 15.5778\n",
      "EPOCH: 857 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6.1704 - val_loss: 6.0066\n",
      "EPOCH: 858 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3.0980 - val_loss: 2.8684\n",
      "EPOCH: 859 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1.9980 - val_loss: 0.9263\n",
      "EPOCH: 860 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6.0865 - val_loss: 14.6506\n",
      "EPOCH: 861 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 35.7311 - val_loss: 35.4984\n",
      "EPOCH: 862 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5.2074 - val_loss: 14.6745\n",
      "EPOCH: 863 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 24.8865 - val_loss: 2.6317\n",
      "EPOCH: 864 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 25.3644 - val_loss: 23.3747\n",
      "EPOCH: 865 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4.2647 - val_loss: 2.3787\n",
      "EPOCH: 866 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 40.0065 - val_loss: 39.0130\n",
      "EPOCH: 867 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1944 - val_loss: 0.7574\n",
      "EPOCH: 868 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 32.0153 - val_loss: 28.2554\n",
      "EPOCH: 869 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.2155 - val_loss: 11.2637\n",
      "EPOCH: 870 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 40.3552 - val_loss: 39.3409\n",
      "EPOCH: 871 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5.0810 - val_loss: 3.7695\n",
      "EPOCH: 872 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.1998 - val_loss: 7.7821\n",
      "EPOCH: 873 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 11.7501 - val_loss: 11.0319\n",
      "EPOCH: 874 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 14.2391 - val_loss: 15.0230\n",
      "EPOCH: 875 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 16.2758 - val_loss: 7.6449\n",
      "EPOCH: 876 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.4254 - val_loss: 7.6727\n",
      "EPOCH: 877 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4.0701 - val_loss: 1.6147\n",
      "EPOCH: 878 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 11.8817 - val_loss: 10.6984\n",
      "EPOCH: 879 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 22.9984 - val_loss: 20.9343\n",
      "EPOCH: 880 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2.2286 - val_loss: 2.9851\n",
      "EPOCH: 881 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 13.0946 - val_loss: 20.8307\n",
      "EPOCH: 882 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 18.0714 - val_loss: 17.5658\n",
      "EPOCH: 883 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 16.3409 - val_loss: 15.9962\n",
      "EPOCH: 884 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 28.3281 - val_loss: 17.1182\n",
      "EPOCH: 885 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 21.3651 - val_loss: 25.0139\n",
      "EPOCH: 886 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 17.5968 - val_loss: 24.8387\n",
      "EPOCH: 887 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 20.6577 - val_loss: 28.1671\n",
      "EPOCH: 888 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 22.2044 - val_loss: 20.6573\n",
      "EPOCH: 889 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 10.9936 - val_loss: 12.2239\n",
      "EPOCH: 890 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 26.1922 - val_loss: 26.5117\n",
      "EPOCH: 891 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 15.4459 - val_loss: 14.7468\n",
      "EPOCH: 892 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 25.3787 - val_loss: 25.6240\n",
      "EPOCH: 893 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 10.4719 - val_loss: 9.5753\n",
      "EPOCH: 894 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 10.6376 - val_loss: 2.5682\n",
      "EPOCH: 895 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1.8432 - val_loss: 1.6351\n",
      "EPOCH: 896 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 27.8222 - val_loss: 27.5876\n",
      "EPOCH: 897 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 49.2733 - val_loss: 67.1247\n",
      "EPOCH: 898 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 12.4211 - val_loss: 12.1137\n",
      "EPOCH: 899 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4.6558 - val_loss: 4.5723\n",
      "EPOCH: 900 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 15.7389 - val_loss: 17.6412\n",
      "EPOCH: 901 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.5454 - val_loss: 0.2494\n",
      "EPOCH: 902 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5.5458 - val_loss: 4.8168\n",
      "EPOCH: 903 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 11.7659 - val_loss: 10.2498\n",
      "EPOCH: 904 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 14.5846 - val_loss: 14.9919\n",
      "EPOCH: 905 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 15.7300 - val_loss: 20.5315\n",
      "EPOCH: 906 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7.9066 - val_loss: 7.7204\n",
      "EPOCH: 907 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 31.1911 - val_loss: 31.4183\n",
      "EPOCH: 908 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 31.0380 - val_loss: 28.0966\n",
      "EPOCH: 909 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3.0374 - val_loss: 3.0509\n",
      "EPOCH: 910 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3.3033 - val_loss: 3.0653\n",
      "EPOCH: 911 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2030 - val_loss: 2.8072\n",
      "EPOCH: 912 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5.1551 - val_loss: 4.2803\n",
      "EPOCH: 913 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.6222 - val_loss: 32.4576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 914 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.7683 - val_loss: 0.7174\n",
      "EPOCH: 915 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.1358 - val_loss: 10.5117\n",
      "EPOCH: 916 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2.1798 - val_loss: 3.4988\n",
      "EPOCH: 917 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3.4733 - val_loss: 0.2095\n",
      "EPOCH: 918 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3043 - val_loss: 0.5880\n",
      "EPOCH: 919 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.1404 - val_loss: 9.1330\n",
      "EPOCH: 920 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3.8711 - val_loss: 3.6803\n",
      "EPOCH: 921 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6.8461 - val_loss: 22.6839\n",
      "EPOCH: 922 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 44.0453 - val_loss: 43.9291\n",
      "EPOCH: 923 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 12.6765 - val_loss: 14.5108\n",
      "EPOCH: 924 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 12.0679 - val_loss: 11.7009\n",
      "EPOCH: 925 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 16.7800 - val_loss: 17.7043\n",
      "EPOCH: 926 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.6841 - val_loss: 18.8707\n",
      "EPOCH: 927 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 13.0102 - val_loss: 12.9014\n",
      "EPOCH: 928 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 33.8495 - val_loss: 33.5872\n",
      "EPOCH: 929 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3.0672 - val_loss: 2.6838\n",
      "EPOCH: 930 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7.1598 - val_loss: 8.5184\n",
      "EPOCH: 931 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6.6989 - val_loss: 8.0991\n",
      "EPOCH: 932 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 26.6116 - val_loss: 24.6111\n",
      "EPOCH: 933 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 22.3763 - val_loss: 21.9102\n",
      "EPOCH: 934 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4.7745 - val_loss: 3.2415\n",
      "EPOCH: 935 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3.4669 - val_loss: 3.3059\n",
      "EPOCH: 936 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.6263 - val_loss: 9.2055\n",
      "EPOCH: 937 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3.4030 - val_loss: 3.1699\n",
      "EPOCH: 938 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6.4485 - val_loss: 6.3434\n",
      "EPOCH: 939 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 11.6651 - val_loss: 13.2761\n",
      "EPOCH: 940 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 23.5619 - val_loss: 15.5898\n",
      "EPOCH: 941 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4.4977 - val_loss: 1.3847\n",
      "EPOCH: 942 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1.3721 - val_loss: 3.5520\n",
      "EPOCH: 943 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 11.2909 - val_loss: 10.9145\n",
      "EPOCH: 944 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.4805 - val_loss: 0.6988\n",
      "EPOCH: 945 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 12.4624 - val_loss: 12.2701\n",
      "EPOCH: 946 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5.3173 - val_loss: 12.3443\n",
      "EPOCH: 947 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6.7091 - val_loss: 7.4636\n",
      "EPOCH: 948 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5.3408 - val_loss: 1.1733\n",
      "EPOCH: 949 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 20.5345 - val_loss: 29.9384\n",
      "EPOCH: 950 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 10.6895 - val_loss: 23.3668\n",
      "EPOCH: 951 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 27.2006 - val_loss: 28.6095\n",
      "EPOCH: 952 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 10.3068 - val_loss: 12.3236\n",
      "EPOCH: 953 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 12.7375 - val_loss: 14.7663\n",
      "EPOCH: 954 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 27.1945 - val_loss: 26.4927\n",
      "EPOCH: 955 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 12.8295 - val_loss: 11.3967\n",
      "EPOCH: 956 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0967 - val_loss: 0.3980\n",
      "EPOCH: 957 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5.5684 - val_loss: 5.9837\n",
      "EPOCH: 958 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4.6161 - val_loss: 2.8490\n",
      "EPOCH: 959 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 18.6677 - val_loss: 18.2324\n",
      "EPOCH: 960 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3.5126 - val_loss: 3.0671\n",
      "EPOCH: 961 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4.2211 - val_loss: 2.0351\n",
      "EPOCH: 962 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4.3109 - val_loss: 6.1104\n",
      "EPOCH: 963 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.7225 - val_loss: 8.9827\n",
      "EPOCH: 964 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.9827 - val_loss: 8.8116\n",
      "EPOCH: 965 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 17.4218 - val_loss: 13.6484\n",
      "EPOCH: 966 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2.7590 - val_loss: 2.3700\n",
      "EPOCH: 967 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 19.0154 - val_loss: 21.5919\n",
      "EPOCH: 968 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4.1954 - val_loss: 4.4996\n",
      "EPOCH: 969 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3.1058 - val_loss: 2.8664\n",
      "EPOCH: 970 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3.5717 - val_loss: 3.3111\n",
      "EPOCH: 971 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2.2064 - val_loss: 1.7534\n",
      "EPOCH: 972 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 10.3958 - val_loss: 11.6611\n",
      "EPOCH: 973 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 40.1288 - val_loss: 50.8833\n",
      "EPOCH: 974 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6.0173 - val_loss: 9.8209\n",
      "EPOCH: 975 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 22.2386 - val_loss: 21.6061\n",
      "EPOCH: 976 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.4482 - val_loss: 5.7620\n",
      "EPOCH: 977 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 20.7232 - val_loss: 19.8891\n",
      "EPOCH: 978 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.2960 - val_loss: 10.3176\n",
      "EPOCH: 979 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.5261 - val_loss: 0.8494\n",
      "EPOCH: 980 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 16.7191 - val_loss: 5.9898\n",
      "EPOCH: 981 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 13.6431 - val_loss: 13.4892\n",
      "EPOCH: 982 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5.7622 - val_loss: 6.0312\n",
      "EPOCH: 983 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 19.2688 - val_loss: 19.3294\n",
      "EPOCH: 984 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 40.7579 - val_loss: 66.0630\n",
      "EPOCH: 985 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 17.1332 - val_loss: 19.0807\n",
      "EPOCH: 986 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 15.5673 - val_loss: 16.6691\n",
      "EPOCH: 987 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 14.1596 - val_loss: 21.2447\n",
      "EPOCH: 988 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 41.2663 - val_loss: 45.4919\n",
      "EPOCH: 989 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6.2088 - val_loss: 15.1267\n",
      "EPOCH: 990 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 13.5064 - val_loss: 20.9002\n",
      "EPOCH: 991 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6.2653 - val_loss: 6.1184\n",
      "EPOCH: 992 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7.2528 - val_loss: 6.8181\n",
      "EPOCH: 993 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 15.7506 - val_loss: 18.1347\n",
      "EPOCH: 994 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 12.2985 - val_loss: 7.7386\n",
      "EPOCH: 995 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 11.3593 - val_loss: 11.9912\n",
      "EPOCH: 996 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2.5092 - val_loss: 4.4107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 997 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 35.3626 - val_loss: 43.8456\n",
      "EPOCH: 998 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 18.1758 - val_loss: 17.2510\n",
      "EPOCH: 999 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 10.9693 - val_loss: 10.2736\n",
      "EPOCH: 1000 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 23.4782 - val_loss: 25.7237\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "import random\n",
    "\n",
    "EPOCHS = 1000\n",
    "\n",
    "losses = []\n",
    "val_losses = []\n",
    "\n",
    "for a in range(EPOCHS):\n",
    "    \n",
    "    print('EPOCH: ' + str(a+1) +  ' OUT OF ' + str(EPOCHS))\n",
    "\n",
    "    rand_int = random.randint(0, 522)\n",
    "\n",
    "    values = list_of_training_df[rand_int].values\n",
    "\n",
    "    n_train_hours = 21\n",
    "    train = values[:n_train_hours, :]\n",
    "    test = values[n_train_hours:, :]\n",
    "\n",
    "    train_X, train_y = train[:, :-1], train[:, -1]\n",
    "    test_X, test_y = test[:, :-1], test[:, -1]\n",
    "\n",
    "    train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "    test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "    print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "\n",
    "    # fit network\n",
    "    history = lstm_model.fit(train_X, train_y, epochs=1, batch_size=72, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "\n",
    "    for idx, h in enumerate(history.history['loss']):\n",
    "        losses.append(h)\n",
    "        val_losses.append(history.history['val_loss'])\n",
    "        \n",
    "# plot history\n",
    "pyplot.plot(losses, label='train')\n",
    "pyplot.plot(val_losses, label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Based on the num_predictions we choose, we predict on that many random time series and derive a resulting root mean square error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import concatenate\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "num_predictions = 200\n",
    "\n",
    "summation = 0\n",
    "\n",
    "actual = []\n",
    "predicted = []\n",
    "\n",
    "for a in range(num_predictions):\n",
    "    \n",
    "    rand_int = random.randint(0, 522)\n",
    "\n",
    "    values = list_of_training_df[rand_int].values\n",
    "\n",
    "    n_train_hours = 21\n",
    "    train = values[:n_train_hours, :]\n",
    "    test = values[n_train_hours:, :]\n",
    "\n",
    "    train_X, train_y = train[:, :-1], train[:, -1]\n",
    "    test_X, test_y = test[:, :-1], test[:, -1]\n",
    "\n",
    "    train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "    test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "#     print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "\n",
    "    yhat = lstm_model.predict(test_X)\n",
    "    \n",
    "    actual.append(test_y[0])\n",
    "    predicted.append(yhat[0][0][0])\n",
    "    \n",
    "#     print(yhat[0][0][0])\n",
    "#     print(test_y[0])\n",
    "    \n",
    "#     difference = test_y[0] - yhat[0][0][0]\n",
    "#     squared_difference = difference**2\n",
    "#     summation = summation + squared_difference\n",
    "    \n",
    "mse = mean_squared_error(actual, predicted)\n",
    "rmse = math.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.58019339726416"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_bridge_management_kernel",
   "language": "python",
   "name": "tf_bridge_management"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
