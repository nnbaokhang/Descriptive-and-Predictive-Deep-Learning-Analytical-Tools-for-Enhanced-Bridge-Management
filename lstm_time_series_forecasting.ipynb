{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the Python version being used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.6\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check that the available gpu is being utilized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available\")\n",
    "print(len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in clustering dataset, note that this one is still missing the aggregated weather data, but this can easily be added in later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "\n",
    "df = read_csv('Time_Series_For_Clustering_El_Paso_Final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bridge_ID</th>\n",
       "      <th>time_0</th>\n",
       "      <th>time_1</th>\n",
       "      <th>time_2</th>\n",
       "      <th>time_3</th>\n",
       "      <th>time_4</th>\n",
       "      <th>time_5</th>\n",
       "      <th>time_6</th>\n",
       "      <th>time_7</th>\n",
       "      <th>time_8</th>\n",
       "      <th>...</th>\n",
       "      <th>time_12</th>\n",
       "      <th>time_13</th>\n",
       "      <th>time_14</th>\n",
       "      <th>time_15</th>\n",
       "      <th>time_16</th>\n",
       "      <th>time_17</th>\n",
       "      <th>time_18</th>\n",
       "      <th>time_19</th>\n",
       "      <th>time_20</th>\n",
       "      <th>time_21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.12E+13</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "      <td>[36.0, 90.5, 50, 1948, 2, 6.5, 3.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CALHAN-8TH ST.</td>\n",
       "      <td>[36.0, 97.0, 428, 1949, 2, 10.9, 7.3]</td>\n",
       "      <td>[36.0, 96.9, 955, 1949, 2, 10.9, 7.3]</td>\n",
       "      <td>[36.0, 96.9, 955, 1949, 2, 10.9, 7.3]</td>\n",
       "      <td>[36.0, 96.9, 955, 1949, 2, 10.9, 7.3]</td>\n",
       "      <td>[36.0, 96.9, 955, 1949, 2, 10.9, 7.3]</td>\n",
       "      <td>[36.3, 97.0, 955, 1949, 2, 11.0, 7.0]</td>\n",
       "      <td>[36.3, 96.9, 955, 1949, 2, 11.0, 7.3]</td>\n",
       "      <td>[36.3, 96.9, 983, 1949, 2, 11.0, 7.3]</td>\n",
       "      <td>[36.3, 96.9, 983, 1949, 2, 11.0, 7.3]</td>\n",
       "      <td>...</td>\n",
       "      <td>[36.3, 97.0, 422, 1949, 2, 11.0, 7.3]</td>\n",
       "      <td>[36.3, 97.0, 422, 1949, 2, 11.0, 7.3]</td>\n",
       "      <td>[36.3, 97.0, 422, 1949, 2, 11.0, 7.3]</td>\n",
       "      <td>[36.3, 97.0, 422, 1949, 2, 9.7, 7.3]</td>\n",
       "      <td>[36.3, 97.0, 369, 1949, 2, 9.7, 7.3]</td>\n",
       "      <td>[36.3, 86.0, 369, 1949, 2, 9.7, 7.3]</td>\n",
       "      <td>[36.3, 86.0, 369, 1949, 2, 9.7, 7.3]</td>\n",
       "      <td>[36.3, 86.0, 369, 1949, 2, 9.7, 7.3]</td>\n",
       "      <td>[36.3, 86.0, 369, 1949, 2, 9.7, 7.3]</td>\n",
       "      <td>[36.3, 86.0, 522, 1949, 2, 9.7, 7.3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CSG-C.80-07.65</td>\n",
       "      <td>[36.0, 83.9, 417, 1970, 2, 6.6, 6.4]</td>\n",
       "      <td>[36.0, 70.9, 351, 1970, 2, 6.6, 3.0]</td>\n",
       "      <td>[36.0, 70.9, 351, 1970, 2, 6.6, 3.0]</td>\n",
       "      <td>[36.0, 70.9, 351, 1970, 2, 6.6, 3.0]</td>\n",
       "      <td>[36.0, 70.9, 351, 1970, 2, 6.6, 3.0]</td>\n",
       "      <td>[36.3, 76.0, 351, 1970, 2, 6.6, 3.0]</td>\n",
       "      <td>[36.3, 69.0, 351, 1970, 2, 6.6, 3.0]</td>\n",
       "      <td>[36.3, 66.9, 478, 1970, 2, 6.6, 2.9]</td>\n",
       "      <td>[36.3, 66.9, 478, 1970, 2, 6.6, 2.9]</td>\n",
       "      <td>...</td>\n",
       "      <td>[36.3, 62.9, 478, 1970, 2, 6.6, 2.9]</td>\n",
       "      <td>[36.3, 62.9, 777, 1970, 2, 6.6, 2.9]</td>\n",
       "      <td>[36.3, 62.9, 777, 1970, 2, 6.6, 2.9]</td>\n",
       "      <td>[36.3, 62.9, 777, 1970, 2, 6.6, 2.9]</td>\n",
       "      <td>[36.3, 62.9, 623, 1970, 2, 6.6, 2.9]</td>\n",
       "      <td>[36.3, 62.9, 623, 1970, 2, 6.6, 2.9]</td>\n",
       "      <td>[36.3, 62.9, 623, 1970, 2, 6.6, 2.9]</td>\n",
       "      <td>[32.7, 55.7, 623, 1970, 2, 6.6, 2.9]</td>\n",
       "      <td>[32.7, 55.7, 623, 1970, 2, 6.6, 2.9]</td>\n",
       "      <td>[32.7, 55.7, 717, 1970, 2, 6.6, 2.9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CSG-D.04-10.42</td>\n",
       "      <td>[36.0, 82.0, 1836, 1955, 2, 7.6, 4.0]</td>\n",
       "      <td>[36.0, 84.3, 1459, 1955, 2, 7.7, 4.0]</td>\n",
       "      <td>[36.0, 84.3, 1459, 1955, 2, 7.7, 4.0]</td>\n",
       "      <td>[36.0, 84.3, 1459, 1955, 2, 7.7, 4.0]</td>\n",
       "      <td>[36.0, 84.3, 1459, 1955, 2, 7.7, 3.4]</td>\n",
       "      <td>[36.3, 83.4, 1459, 1955, 2, 7.7, 3.0]</td>\n",
       "      <td>[36.3, 84.3, 1459, 1955, 2, 7.7, 3.4]</td>\n",
       "      <td>[36.3, 84.4, 1295, 1955, 2, 7.7, 3.4]</td>\n",
       "      <td>[36.3, 84.4, 1295, 1955, 2, 7.7, 3.4]</td>\n",
       "      <td>...</td>\n",
       "      <td>[36.3, 72.3, 1295, 1955, 2, 7.7, 3.4]</td>\n",
       "      <td>[36.3, 72.3, 1329, 1955, 2, 7.7, 3.4]</td>\n",
       "      <td>[36.3, 72.3, 1329, 1955, 2, 7.7, 3.4]</td>\n",
       "      <td>[36.3, 72.3, 1329, 1955, 2, 7.7, 3.4]</td>\n",
       "      <td>[36.3, 72.3, 1446, 1955, 2, 7.7, 3.4]</td>\n",
       "      <td>[36.3, 72.3, 1446, 1955, 2, 7.7, 3.4]</td>\n",
       "      <td>[36.3, 72.3, 1446, 1955, 2, 7.7, 3.4]</td>\n",
       "      <td>[27.2, 50.2, 1446, 1955, 2, 7.7, 3.4]</td>\n",
       "      <td>[27.2, 50.2, 1446, 1955, 2, 7.7, 3.4]</td>\n",
       "      <td>[27.2, 50.2, 2696, 1955, 2, 7.7, 3.4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CSG-D.37-15.67</td>\n",
       "      <td>[36.0, 97.0, 87, 1984, 2, 12.8, 3.0]</td>\n",
       "      <td>[36.0, 97.0, 305, 1984, 2, 12.8, 3.0]</td>\n",
       "      <td>[36.0, 97.0, 305, 1984, 2, 12.8, 3.0]</td>\n",
       "      <td>[36.0, 97.0, 305, 1984, 2, 12.8, 3.0]</td>\n",
       "      <td>[36.0, 97.0, 305, 1984, 2, 12.8, 3.0]</td>\n",
       "      <td>[36.3, 97.0, 305, 1984, 2, 12.8, 3.0]</td>\n",
       "      <td>[36.3, 97.0, 305, 1984, 2, 12.8, 3.0]</td>\n",
       "      <td>[36.3, 97.0, 397, 1984, 2, 12.8, 3.0]</td>\n",
       "      <td>[36.3, 97.0, 397, 1984, 2, 12.8, 3.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>[36.3, 98.0, 397, 1984, 2, 13.3, 3.0]</td>\n",
       "      <td>[36.3, 98.0, 287, 1984, 2, 13.3, 3.0]</td>\n",
       "      <td>[36.3, 98.0, 287, 1984, 2, 13.3, 3.0]</td>\n",
       "      <td>[36.3, 99.0, 287, 1984, 2, 12.8, 3.0]</td>\n",
       "      <td>[36.3, 99.0, 302, 1984, 2, 12.8, 3.0]</td>\n",
       "      <td>[36.3, 100.0, 302, 1984, 2, 12.8, 3.0]</td>\n",
       "      <td>[36.3, 100.0, 302, 1984, 2, 12.8, 3.0]</td>\n",
       "      <td>[36.3, 100.0, 302, 1984, 2, 12.8, 3.0]</td>\n",
       "      <td>[36.3, 100.0, 302, 1984, 2, 12.8, 3.0]</td>\n",
       "      <td>[36.3, 100.0, 268, 1984, 2, 12.8, 3.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>I-17-G</td>\n",
       "      <td>[87.3, 82.0, 13500, 1942, 0, 10.9, 14.0]</td>\n",
       "      <td>[87.3, 82.0, 13500, 1942, 0, 10.9, 14.0]</td>\n",
       "      <td>[87.3, 82.0, 13500, 1942, 0, 10.9, 14.0]</td>\n",
       "      <td>[87.3, 82.0, 13500, 1942, 0, 10.9, 14.0]</td>\n",
       "      <td>[87.3, 82.0, 13500, 1942, 0, 10.9, 14.0]</td>\n",
       "      <td>[87.3, 82.0, 13500, 1942, 0, 10.9, 14.0]</td>\n",
       "      <td>[87.3, 82.0, 13500, 1942, 0, 10.9, 14.0]</td>\n",
       "      <td>[87.3, 82.0, 13500, 1942, 0, 10.9, 14.0]</td>\n",
       "      <td>[87.3, 82.0, 39228, 1972, 0, 24.1, 26.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>[87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]</td>\n",
       "      <td>[87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]</td>\n",
       "      <td>[87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]</td>\n",
       "      <td>[87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]</td>\n",
       "      <td>[87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]</td>\n",
       "      <td>[87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]</td>\n",
       "      <td>[87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]</td>\n",
       "      <td>[87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]</td>\n",
       "      <td>[87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]</td>\n",
       "      <td>[87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>I-17-HK</td>\n",
       "      <td>[87.3, 82.0, 38400, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>...</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "      <td>[87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>I-17-JH</td>\n",
       "      <td>[87.3, 82.0, 10500, 1995, 0, 12.9, 20.7]</td>\n",
       "      <td>[87.3, 82.0, 32904, 1995, 0, 12.9, 20.7]</td>\n",
       "      <td>[87.3, 82.0, 32904, 1995, 0, 12.9, 20.7]</td>\n",
       "      <td>[87.3, 82.0, 32904, 1995, 0, 12.9, 20.7]</td>\n",
       "      <td>[87.3, 82.0, 36024, 1995, 0, 12.1, 20.7]</td>\n",
       "      <td>[87.3, 82.0, 36024, 1995, 0, 12.2, 21.0]</td>\n",
       "      <td>[87.3, 82.0, 36024, 1995, 0, 12.2, 21.0]</td>\n",
       "      <td>[87.3, 82.0, 39072, 1995, 0, 12.2, 21.0]</td>\n",
       "      <td>[87.3, 82.0, 39072, 1995, 0, 12.2, 21.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>[87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]</td>\n",
       "      <td>[87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]</td>\n",
       "      <td>[87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]</td>\n",
       "      <td>[87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]</td>\n",
       "      <td>[87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]</td>\n",
       "      <td>[87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]</td>\n",
       "      <td>[87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]</td>\n",
       "      <td>[87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]</td>\n",
       "      <td>[87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]</td>\n",
       "      <td>[87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>J-18-BK</td>\n",
       "      <td>[87.3, 82.0, 21800, 1976, 0, 11.5, 28.0]</td>\n",
       "      <td>[87.3, 82.0, 25600, 1976, 0, 11.5, 28.0]</td>\n",
       "      <td>[87.3, 82.0, 25600, 1976, 0, 11.5, 28.0]</td>\n",
       "      <td>[87.3, 82.0, 25600, 1976, 0, 11.5, 28.0]</td>\n",
       "      <td>[87.3, 82.0, 21055, 1976, 0, 11.5, 28.0]</td>\n",
       "      <td>[87.3, 82.0, 21055, 1976, 0, 11.6, 28.0]</td>\n",
       "      <td>[87.3, 82.0, 21055, 1976, 0, 11.6, 28.0]</td>\n",
       "      <td>[87.3, 82.0, 26371, 1976, 0, 11.6, 28.0]</td>\n",
       "      <td>[87.3, 82.0, 26371, 1976, 0, 11.6, 28.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>[87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]</td>\n",
       "      <td>[87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]</td>\n",
       "      <td>[87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]</td>\n",
       "      <td>[87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]</td>\n",
       "      <td>[87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]</td>\n",
       "      <td>[87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]</td>\n",
       "      <td>[87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]</td>\n",
       "      <td>[87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]</td>\n",
       "      <td>[87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]</td>\n",
       "      <td>[87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>TELL-8-TUN</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.7, 4.9]</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.7, 4.9]</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.7, 4.9]</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.7, 4.9]</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.7, 4.9]</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.8, 5.0]</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.8, 4.9]</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.8, 4.9]</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.8, 74.1]</td>\n",
       "      <td>...</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.8, 74.1]</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.8, 74.1]</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.8, 74.1]</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.8, 74.1]</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.8, 74.1]</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.8, 74.1]</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.8, 74.1]</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.8, 74.1]</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.8, 74.1]</td>\n",
       "      <td>[87.3, 82.0, 28, 1900, 0, 4.8, 74.1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>524 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Bridge_ID                                    time_0  \\\n",
       "0           2.12E+13       [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]   \n",
       "1    CALHAN-8TH ST.      [36.0, 97.0, 428, 1949, 2, 10.9, 7.3]   \n",
       "2    CSG-C.80-07.65       [36.0, 83.9, 417, 1970, 2, 6.6, 6.4]   \n",
       "3    CSG-D.04-10.42      [36.0, 82.0, 1836, 1955, 2, 7.6, 4.0]   \n",
       "4    CSG-D.37-15.67       [36.0, 97.0, 87, 1984, 2, 12.8, 3.0]   \n",
       "..               ...                                       ...   \n",
       "519  I-17-G           [87.3, 82.0, 13500, 1942, 0, 10.9, 14.0]   \n",
       "520  I-17-HK          [87.3, 82.0, 38400, 1972, 0, 22.5, 35.1]   \n",
       "521  I-17-JH          [87.3, 82.0, 10500, 1995, 0, 12.9, 20.7]   \n",
       "522  J-18-BK          [87.3, 82.0, 21800, 1976, 0, 11.5, 28.0]   \n",
       "523  TELL-8-TUN            [87.3, 82.0, 28, 1900, 0, 4.7, 4.9]   \n",
       "\n",
       "                                       time_1  \\\n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]   \n",
       "1       [36.0, 96.9, 955, 1949, 2, 10.9, 7.3]   \n",
       "2        [36.0, 70.9, 351, 1970, 2, 6.6, 3.0]   \n",
       "3       [36.0, 84.3, 1459, 1955, 2, 7.7, 4.0]   \n",
       "4       [36.0, 97.0, 305, 1984, 2, 12.8, 3.0]   \n",
       "..                                        ...   \n",
       "519  [87.3, 82.0, 13500, 1942, 0, 10.9, 14.0]   \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]   \n",
       "521  [87.3, 82.0, 32904, 1995, 0, 12.9, 20.7]   \n",
       "522  [87.3, 82.0, 25600, 1976, 0, 11.5, 28.0]   \n",
       "523       [87.3, 82.0, 28, 1900, 0, 4.7, 4.9]   \n",
       "\n",
       "                                       time_2  \\\n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]   \n",
       "1       [36.0, 96.9, 955, 1949, 2, 10.9, 7.3]   \n",
       "2        [36.0, 70.9, 351, 1970, 2, 6.6, 3.0]   \n",
       "3       [36.0, 84.3, 1459, 1955, 2, 7.7, 4.0]   \n",
       "4       [36.0, 97.0, 305, 1984, 2, 12.8, 3.0]   \n",
       "..                                        ...   \n",
       "519  [87.3, 82.0, 13500, 1942, 0, 10.9, 14.0]   \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]   \n",
       "521  [87.3, 82.0, 32904, 1995, 0, 12.9, 20.7]   \n",
       "522  [87.3, 82.0, 25600, 1976, 0, 11.5, 28.0]   \n",
       "523       [87.3, 82.0, 28, 1900, 0, 4.7, 4.9]   \n",
       "\n",
       "                                       time_3  \\\n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]   \n",
       "1       [36.0, 96.9, 955, 1949, 2, 10.9, 7.3]   \n",
       "2        [36.0, 70.9, 351, 1970, 2, 6.6, 3.0]   \n",
       "3       [36.0, 84.3, 1459, 1955, 2, 7.7, 4.0]   \n",
       "4       [36.0, 97.0, 305, 1984, 2, 12.8, 3.0]   \n",
       "..                                        ...   \n",
       "519  [87.3, 82.0, 13500, 1942, 0, 10.9, 14.0]   \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]   \n",
       "521  [87.3, 82.0, 32904, 1995, 0, 12.9, 20.7]   \n",
       "522  [87.3, 82.0, 25600, 1976, 0, 11.5, 28.0]   \n",
       "523       [87.3, 82.0, 28, 1900, 0, 4.7, 4.9]   \n",
       "\n",
       "                                       time_4  \\\n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]   \n",
       "1       [36.0, 96.9, 955, 1949, 2, 10.9, 7.3]   \n",
       "2        [36.0, 70.9, 351, 1970, 2, 6.6, 3.0]   \n",
       "3       [36.0, 84.3, 1459, 1955, 2, 7.7, 3.4]   \n",
       "4       [36.0, 97.0, 305, 1984, 2, 12.8, 3.0]   \n",
       "..                                        ...   \n",
       "519  [87.3, 82.0, 13500, 1942, 0, 10.9, 14.0]   \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]   \n",
       "521  [87.3, 82.0, 36024, 1995, 0, 12.1, 20.7]   \n",
       "522  [87.3, 82.0, 21055, 1976, 0, 11.5, 28.0]   \n",
       "523       [87.3, 82.0, 28, 1900, 0, 4.7, 4.9]   \n",
       "\n",
       "                                       time_5  \\\n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]   \n",
       "1       [36.3, 97.0, 955, 1949, 2, 11.0, 7.0]   \n",
       "2        [36.3, 76.0, 351, 1970, 2, 6.6, 3.0]   \n",
       "3       [36.3, 83.4, 1459, 1955, 2, 7.7, 3.0]   \n",
       "4       [36.3, 97.0, 305, 1984, 2, 12.8, 3.0]   \n",
       "..                                        ...   \n",
       "519  [87.3, 82.0, 13500, 1942, 0, 10.9, 14.0]   \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]   \n",
       "521  [87.3, 82.0, 36024, 1995, 0, 12.2, 21.0]   \n",
       "522  [87.3, 82.0, 21055, 1976, 0, 11.6, 28.0]   \n",
       "523       [87.3, 82.0, 28, 1900, 0, 4.8, 5.0]   \n",
       "\n",
       "                                       time_6  \\\n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]   \n",
       "1       [36.3, 96.9, 955, 1949, 2, 11.0, 7.3]   \n",
       "2        [36.3, 69.0, 351, 1970, 2, 6.6, 3.0]   \n",
       "3       [36.3, 84.3, 1459, 1955, 2, 7.7, 3.4]   \n",
       "4       [36.3, 97.0, 305, 1984, 2, 12.8, 3.0]   \n",
       "..                                        ...   \n",
       "519  [87.3, 82.0, 13500, 1942, 0, 10.9, 14.0]   \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]   \n",
       "521  [87.3, 82.0, 36024, 1995, 0, 12.2, 21.0]   \n",
       "522  [87.3, 82.0, 21055, 1976, 0, 11.6, 28.0]   \n",
       "523       [87.3, 82.0, 28, 1900, 0, 4.8, 4.9]   \n",
       "\n",
       "                                       time_7  \\\n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]   \n",
       "1       [36.3, 96.9, 983, 1949, 2, 11.0, 7.3]   \n",
       "2        [36.3, 66.9, 478, 1970, 2, 6.6, 2.9]   \n",
       "3       [36.3, 84.4, 1295, 1955, 2, 7.7, 3.4]   \n",
       "4       [36.3, 97.0, 397, 1984, 2, 12.8, 3.0]   \n",
       "..                                        ...   \n",
       "519  [87.3, 82.0, 13500, 1942, 0, 10.9, 14.0]   \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]   \n",
       "521  [87.3, 82.0, 39072, 1995, 0, 12.2, 21.0]   \n",
       "522  [87.3, 82.0, 26371, 1976, 0, 11.6, 28.0]   \n",
       "523       [87.3, 82.0, 28, 1900, 0, 4.8, 4.9]   \n",
       "\n",
       "                                       time_8  ...  \\\n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]  ...   \n",
       "1       [36.3, 96.9, 983, 1949, 2, 11.0, 7.3]  ...   \n",
       "2        [36.3, 66.9, 478, 1970, 2, 6.6, 2.9]  ...   \n",
       "3       [36.3, 84.4, 1295, 1955, 2, 7.7, 3.4]  ...   \n",
       "4       [36.3, 97.0, 397, 1984, 2, 12.8, 3.0]  ...   \n",
       "..                                        ...  ...   \n",
       "519  [87.3, 82.0, 39228, 1972, 0, 24.1, 26.0]  ...   \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]  ...   \n",
       "521  [87.3, 82.0, 39072, 1995, 0, 12.2, 21.0]  ...   \n",
       "522  [87.3, 82.0, 26371, 1976, 0, 11.6, 28.0]  ...   \n",
       "523      [87.3, 82.0, 28, 1900, 0, 4.8, 74.1]  ...   \n",
       "\n",
       "                                      time_12  \\\n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]   \n",
       "1       [36.3, 97.0, 422, 1949, 2, 11.0, 7.3]   \n",
       "2        [36.3, 62.9, 478, 1970, 2, 6.6, 2.9]   \n",
       "3       [36.3, 72.3, 1295, 1955, 2, 7.7, 3.4]   \n",
       "4       [36.3, 98.0, 397, 1984, 2, 13.3, 3.0]   \n",
       "..                                        ...   \n",
       "519  [87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]   \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]   \n",
       "521  [87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]   \n",
       "522  [87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]   \n",
       "523      [87.3, 82.0, 28, 1900, 0, 4.8, 74.1]   \n",
       "\n",
       "                                      time_13  \\\n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]   \n",
       "1       [36.3, 97.0, 422, 1949, 2, 11.0, 7.3]   \n",
       "2        [36.3, 62.9, 777, 1970, 2, 6.6, 2.9]   \n",
       "3       [36.3, 72.3, 1329, 1955, 2, 7.7, 3.4]   \n",
       "4       [36.3, 98.0, 287, 1984, 2, 13.3, 3.0]   \n",
       "..                                        ...   \n",
       "519  [87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]   \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]   \n",
       "521  [87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]   \n",
       "522  [87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]   \n",
       "523      [87.3, 82.0, 28, 1900, 0, 4.8, 74.1]   \n",
       "\n",
       "                                      time_14  \\\n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]   \n",
       "1       [36.3, 97.0, 422, 1949, 2, 11.0, 7.3]   \n",
       "2        [36.3, 62.9, 777, 1970, 2, 6.6, 2.9]   \n",
       "3       [36.3, 72.3, 1329, 1955, 2, 7.7, 3.4]   \n",
       "4       [36.3, 98.0, 287, 1984, 2, 13.3, 3.0]   \n",
       "..                                        ...   \n",
       "519  [87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]   \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]   \n",
       "521  [87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]   \n",
       "522  [87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]   \n",
       "523      [87.3, 82.0, 28, 1900, 0, 4.8, 74.1]   \n",
       "\n",
       "                                      time_15  \\\n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]   \n",
       "1        [36.3, 97.0, 422, 1949, 2, 9.7, 7.3]   \n",
       "2        [36.3, 62.9, 777, 1970, 2, 6.6, 2.9]   \n",
       "3       [36.3, 72.3, 1329, 1955, 2, 7.7, 3.4]   \n",
       "4       [36.3, 99.0, 287, 1984, 2, 12.8, 3.0]   \n",
       "..                                        ...   \n",
       "519  [87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]   \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]   \n",
       "521  [87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]   \n",
       "522  [87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]   \n",
       "523      [87.3, 82.0, 28, 1900, 0, 4.8, 74.1]   \n",
       "\n",
       "                                      time_16  \\\n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]   \n",
       "1        [36.3, 97.0, 369, 1949, 2, 9.7, 7.3]   \n",
       "2        [36.3, 62.9, 623, 1970, 2, 6.6, 2.9]   \n",
       "3       [36.3, 72.3, 1446, 1955, 2, 7.7, 3.4]   \n",
       "4       [36.3, 99.0, 302, 1984, 2, 12.8, 3.0]   \n",
       "..                                        ...   \n",
       "519  [87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]   \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]   \n",
       "521  [87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]   \n",
       "522  [87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]   \n",
       "523      [87.3, 82.0, 28, 1900, 0, 4.8, 74.1]   \n",
       "\n",
       "                                      time_17  \\\n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]   \n",
       "1        [36.3, 86.0, 369, 1949, 2, 9.7, 7.3]   \n",
       "2        [36.3, 62.9, 623, 1970, 2, 6.6, 2.9]   \n",
       "3       [36.3, 72.3, 1446, 1955, 2, 7.7, 3.4]   \n",
       "4      [36.3, 100.0, 302, 1984, 2, 12.8, 3.0]   \n",
       "..                                        ...   \n",
       "519  [87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]   \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]   \n",
       "521  [87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]   \n",
       "522  [87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]   \n",
       "523      [87.3, 82.0, 28, 1900, 0, 4.8, 74.1]   \n",
       "\n",
       "                                      time_18  \\\n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]   \n",
       "1        [36.3, 86.0, 369, 1949, 2, 9.7, 7.3]   \n",
       "2        [36.3, 62.9, 623, 1970, 2, 6.6, 2.9]   \n",
       "3       [36.3, 72.3, 1446, 1955, 2, 7.7, 3.4]   \n",
       "4      [36.3, 100.0, 302, 1984, 2, 12.8, 3.0]   \n",
       "..                                        ...   \n",
       "519  [87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]   \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]   \n",
       "521  [87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]   \n",
       "522  [87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]   \n",
       "523      [87.3, 82.0, 28, 1900, 0, 4.8, 74.1]   \n",
       "\n",
       "                                      time_19  \\\n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]   \n",
       "1        [36.3, 86.0, 369, 1949, 2, 9.7, 7.3]   \n",
       "2        [32.7, 55.7, 623, 1970, 2, 6.6, 2.9]   \n",
       "3       [27.2, 50.2, 1446, 1955, 2, 7.7, 3.4]   \n",
       "4      [36.3, 100.0, 302, 1984, 2, 12.8, 3.0]   \n",
       "..                                        ...   \n",
       "519  [87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]   \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]   \n",
       "521  [87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]   \n",
       "522  [87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]   \n",
       "523      [87.3, 82.0, 28, 1900, 0, 4.8, 74.1]   \n",
       "\n",
       "                                      time_20  \\\n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]   \n",
       "1        [36.3, 86.0, 369, 1949, 2, 9.7, 7.3]   \n",
       "2        [32.7, 55.7, 623, 1970, 2, 6.6, 2.9]   \n",
       "3       [27.2, 50.2, 1446, 1955, 2, 7.7, 3.4]   \n",
       "4      [36.3, 100.0, 302, 1984, 2, 12.8, 3.0]   \n",
       "..                                        ...   \n",
       "519  [87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]   \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]   \n",
       "521  [87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]   \n",
       "522  [87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]   \n",
       "523      [87.3, 82.0, 28, 1900, 0, 4.8, 74.1]   \n",
       "\n",
       "                                      time_21  \n",
       "0         [36.0, 90.5, 50, 1948, 2, 6.5, 3.0]  \n",
       "1        [36.3, 86.0, 522, 1949, 2, 9.7, 7.3]  \n",
       "2        [32.7, 55.7, 717, 1970, 2, 6.6, 2.9]  \n",
       "3       [27.2, 50.2, 2696, 1955, 2, 7.7, 3.4]  \n",
       "4      [36.3, 100.0, 268, 1984, 2, 12.8, 3.0]  \n",
       "..                                        ...  \n",
       "519  [87.3, 82.0, 44100, 1972, 0, 24.1, 26.0]  \n",
       "520  [87.3, 82.0, 38000, 1972, 0, 22.5, 35.1]  \n",
       "521  [87.3, 82.0, 35800, 1995, 0, 12.2, 21.3]  \n",
       "522  [87.3, 82.0, 32300, 1976, 0, 11.6, 28.0]  \n",
       "523      [87.3, 82.0, 28, 1900, 0, 4.8, 74.1]  \n",
       "\n",
       "[524 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For the first row of the dataset, plot the sufficiency rating over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_row = df.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_row = first_row.iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time_0     [36.0, 97.0, 428, 1949, 2, 10.9, 7.3]\n",
       "time_1     [36.0, 96.9, 955, 1949, 2, 10.9, 7.3]\n",
       "time_2     [36.0, 96.9, 955, 1949, 2, 10.9, 7.3]\n",
       "time_3     [36.0, 96.9, 955, 1949, 2, 10.9, 7.3]\n",
       "time_4     [36.0, 96.9, 955, 1949, 2, 10.9, 7.3]\n",
       "time_5     [36.3, 97.0, 955, 1949, 2, 11.0, 7.0]\n",
       "time_6     [36.3, 96.9, 955, 1949, 2, 11.0, 7.3]\n",
       "time_7     [36.3, 96.9, 983, 1949, 2, 11.0, 7.3]\n",
       "time_8     [36.3, 96.9, 983, 1949, 2, 11.0, 7.3]\n",
       "time_9     [36.3, 96.9, 983, 1949, 2, 11.0, 7.3]\n",
       "time_10    [36.3, 96.9, 983, 1949, 2, 11.0, 7.3]\n",
       "time_11    [36.3, 97.0, 422, 1949, 2, 11.0, 7.3]\n",
       "time_12    [36.3, 97.0, 422, 1949, 2, 11.0, 7.3]\n",
       "time_13    [36.3, 97.0, 422, 1949, 2, 11.0, 7.3]\n",
       "time_14    [36.3, 97.0, 422, 1949, 2, 11.0, 7.3]\n",
       "time_15     [36.3, 97.0, 422, 1949, 2, 9.7, 7.3]\n",
       "time_16     [36.3, 97.0, 369, 1949, 2, 9.7, 7.3]\n",
       "time_17     [36.3, 86.0, 369, 1949, 2, 9.7, 7.3]\n",
       "time_18     [36.3, 86.0, 369, 1949, 2, 9.7, 7.3]\n",
       "time_19     [36.3, 86.0, 369, 1949, 2, 9.7, 7.3]\n",
       "time_20     [36.3, 86.0, 369, 1949, 2, 9.7, 7.3]\n",
       "time_21     [36.3, 86.0, 522, 1949, 2, 9.7, 7.3]\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "non_decimal = re.compile(r'[^\\d.]+')\n",
    "\n",
    "list_of_row_components = []\n",
    "\n",
    "for i, row in first_row.iteritems():\n",
    "    current_row_components = row.split(', ')\n",
    "    current_row_components_replaced = []\n",
    "    \n",
    "#     print(current_row_components)\n",
    "    for idx, component in enumerate(current_row_components):\n",
    "    #     print(first_row_components[idx])\n",
    "        result = non_decimal.sub('', current_row_components[idx])\n",
    "        current_row_components_replaced.append(float(result))\n",
    "        \n",
    "#     print(current_row_components_replaced)\n",
    "    list_of_row_components.append(current_row_components_replaced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_row = df.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[36.0, 97.0, 428.0, 1949.0, 2.0, 10.9, 7.3],\n",
       " [36.0, 96.9, 955.0, 1949.0, 2.0, 10.9, 7.3],\n",
       " [36.0, 96.9, 955.0, 1949.0, 2.0, 10.9, 7.3],\n",
       " [36.0, 96.9, 955.0, 1949.0, 2.0, 10.9, 7.3],\n",
       " [36.0, 96.9, 955.0, 1949.0, 2.0, 10.9, 7.3],\n",
       " [36.3, 97.0, 955.0, 1949.0, 2.0, 11.0, 7.0],\n",
       " [36.3, 96.9, 955.0, 1949.0, 2.0, 11.0, 7.3],\n",
       " [36.3, 96.9, 983.0, 1949.0, 2.0, 11.0, 7.3],\n",
       " [36.3, 96.9, 983.0, 1949.0, 2.0, 11.0, 7.3],\n",
       " [36.3, 96.9, 983.0, 1949.0, 2.0, 11.0, 7.3],\n",
       " [36.3, 96.9, 983.0, 1949.0, 2.0, 11.0, 7.3],\n",
       " [36.3, 97.0, 422.0, 1949.0, 2.0, 11.0, 7.3],\n",
       " [36.3, 97.0, 422.0, 1949.0, 2.0, 11.0, 7.3],\n",
       " [36.3, 97.0, 422.0, 1949.0, 2.0, 11.0, 7.3],\n",
       " [36.3, 97.0, 422.0, 1949.0, 2.0, 11.0, 7.3],\n",
       " [36.3, 97.0, 422.0, 1949.0, 2.0, 9.7, 7.3],\n",
       " [36.3, 97.0, 369.0, 1949.0, 2.0, 9.7, 7.3],\n",
       " [36.3, 86.0, 369.0, 1949.0, 2.0, 9.7, 7.3],\n",
       " [36.3, 86.0, 369.0, 1949.0, 2.0, 9.7, 7.3],\n",
       " [36.3, 86.0, 369.0, 1949.0, 2.0, 9.7, 7.3],\n",
       " [36.3, 86.0, 369.0, 1949.0, 2.0, 9.7, 7.3],\n",
       " [36.3, 86.0, 522.0, 1949.0, 2.0, 9.7, 7.3]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_row_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_row = first_row.iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sufficiency_rating_list = []\n",
    "\n",
    "for row_component in list_of_row_components:\n",
    "    sufficiency_rating_list.append(row_component[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[97.0,\n",
       " 96.9,\n",
       " 96.9,\n",
       " 96.9,\n",
       " 96.9,\n",
       " 97.0,\n",
       " 96.9,\n",
       " 96.9,\n",
       " 96.9,\n",
       " 96.9,\n",
       " 96.9,\n",
       " 97.0,\n",
       " 97.0,\n",
       " 97.0,\n",
       " 97.0,\n",
       " 97.0,\n",
       " 97.0,\n",
       " 86.0,\n",
       " 86.0,\n",
       " 86.0,\n",
       " 86.0,\n",
       " 86.0]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sufficiency_rating_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(sufficiency_rating_list)\n",
    "plt.ylabel('Sufficiency Rating')\n",
    "plt.xlabel('Years')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of first training example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "var1 = []\n",
    "var2 = []\n",
    "var3 = []\n",
    "var4 = []\n",
    "var5 = []\n",
    "var6 = []\n",
    "varout = []\n",
    "\n",
    "for element in list_of_row_components:\n",
    "#     print(element)\n",
    "    var1.append(element[0])\n",
    "    var2.append(element[2])\n",
    "    var3.append(element[3])\n",
    "    var4.append(element[4])\n",
    "    var5.append(element[5])\n",
    "    var6.append(element[6])\n",
    "    varout.append(element[1])\n",
    "    \n",
    "dict_temp = {'var1': var1, 'var2': var2, 'var3': var3, 'var4': var4, 'var5': var5, 'var6': var6, 'varout': varout}\n",
    "\n",
    "df_temp = pd.DataFrame(dict_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>var3</th>\n",
       "      <th>var4</th>\n",
       "      <th>var5</th>\n",
       "      <th>var6</th>\n",
       "      <th>varout</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36.0</td>\n",
       "      <td>428.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>7.3</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36.0</td>\n",
       "      <td>955.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>7.3</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.0</td>\n",
       "      <td>955.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>7.3</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.0</td>\n",
       "      <td>955.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>7.3</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.0</td>\n",
       "      <td>955.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>7.3</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36.3</td>\n",
       "      <td>955.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>36.3</td>\n",
       "      <td>955.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>36.3</td>\n",
       "      <td>983.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>36.3</td>\n",
       "      <td>983.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>36.3</td>\n",
       "      <td>983.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>36.3</td>\n",
       "      <td>983.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>36.3</td>\n",
       "      <td>422.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>36.3</td>\n",
       "      <td>422.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>36.3</td>\n",
       "      <td>422.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>36.3</td>\n",
       "      <td>422.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>36.3</td>\n",
       "      <td>422.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>7.3</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>36.3</td>\n",
       "      <td>369.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>7.3</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>36.3</td>\n",
       "      <td>369.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>7.3</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>36.3</td>\n",
       "      <td>369.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>7.3</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>36.3</td>\n",
       "      <td>369.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>7.3</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>36.3</td>\n",
       "      <td>369.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>7.3</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>36.3</td>\n",
       "      <td>522.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>7.3</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    var1   var2    var3  var4  var5  var6  varout\n",
       "0   36.0  428.0  1949.0   2.0  10.9   7.3    97.0\n",
       "1   36.0  955.0  1949.0   2.0  10.9   7.3    96.9\n",
       "2   36.0  955.0  1949.0   2.0  10.9   7.3    96.9\n",
       "3   36.0  955.0  1949.0   2.0  10.9   7.3    96.9\n",
       "4   36.0  955.0  1949.0   2.0  10.9   7.3    96.9\n",
       "5   36.3  955.0  1949.0   2.0  11.0   7.0    97.0\n",
       "6   36.3  955.0  1949.0   2.0  11.0   7.3    96.9\n",
       "7   36.3  983.0  1949.0   2.0  11.0   7.3    96.9\n",
       "8   36.3  983.0  1949.0   2.0  11.0   7.3    96.9\n",
       "9   36.3  983.0  1949.0   2.0  11.0   7.3    96.9\n",
       "10  36.3  983.0  1949.0   2.0  11.0   7.3    96.9\n",
       "11  36.3  422.0  1949.0   2.0  11.0   7.3    97.0\n",
       "12  36.3  422.0  1949.0   2.0  11.0   7.3    97.0\n",
       "13  36.3  422.0  1949.0   2.0  11.0   7.3    97.0\n",
       "14  36.3  422.0  1949.0   2.0  11.0   7.3    97.0\n",
       "15  36.3  422.0  1949.0   2.0   9.7   7.3    97.0\n",
       "16  36.3  369.0  1949.0   2.0   9.7   7.3    97.0\n",
       "17  36.3  369.0  1949.0   2.0   9.7   7.3    86.0\n",
       "18  36.3  369.0  1949.0   2.0   9.7   7.3    86.0\n",
       "19  36.3  369.0  1949.0   2.0   9.7   7.3    86.0\n",
       "20  36.3  369.0  1949.0   2.0   9.7   7.3    86.0\n",
       "21  36.3  522.0  1949.0   2.0   9.7   7.3    86.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert each rows into it's own dataframe representing an individual time series example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "non_decimal = re.compile(r'[^\\d.]+')\n",
    "\n",
    "list_of_training_df = []\n",
    "\n",
    "for i in range(1, 524):\n",
    "    \n",
    "    list_of_row_components = []\n",
    "    \n",
    "    current_row = df.iloc[i]\n",
    "    current_row = current_row.iloc[1:]\n",
    "    \n",
    "    for j, row in current_row.iteritems():\n",
    "        \n",
    "        current_row_components = row.split(', ')\n",
    "        current_row_components_replaced = []\n",
    "\n",
    "        for idx, component in enumerate(current_row_components):\n",
    "\n",
    "            result = non_decimal.sub('', current_row_components[idx])\n",
    "            current_row_components_replaced.append(float(result))\n",
    "\n",
    "        list_of_row_components.append(current_row_components_replaced)\n",
    "\n",
    "    var1 = []\n",
    "    var2 = []\n",
    "    var3 = []\n",
    "    var4 = []\n",
    "    var5 = []\n",
    "    var6 = []\n",
    "    varout = []\n",
    "\n",
    "    for element in list_of_row_components:\n",
    "\n",
    "        var1.append(element[0])\n",
    "        var2.append(element[2])\n",
    "        var3.append(element[3])\n",
    "        var4.append(element[4])\n",
    "        var5.append(element[5])\n",
    "        var6.append(element[6])\n",
    "        varout.append(element[1])\n",
    "\n",
    "    dict_temp = {'var1': var1, 'var2': var2, 'var3': var3, 'var4': var4, 'var5': var5, 'var6': var6, 'varout': varout}\n",
    "\n",
    "    df_temp = pd.DataFrame(dict_temp)\n",
    "\n",
    "    list_of_training_df.append(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "523"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_of_training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>var3</th>\n",
       "      <th>var4</th>\n",
       "      <th>var5</th>\n",
       "      <th>var6</th>\n",
       "      <th>varout</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>2.4</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36.0</td>\n",
       "      <td>950.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.0</td>\n",
       "      <td>950.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.0</td>\n",
       "      <td>950.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.0</td>\n",
       "      <td>950.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36.3</td>\n",
       "      <td>950.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>36.3</td>\n",
       "      <td>950.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>36.3</td>\n",
       "      <td>700.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>36.3</td>\n",
       "      <td>700.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>36.3</td>\n",
       "      <td>700.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>85.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>36.3</td>\n",
       "      <td>700.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>85.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>36.3</td>\n",
       "      <td>700.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>85.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>36.3</td>\n",
       "      <td>700.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>85.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>36.3</td>\n",
       "      <td>780.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>85.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>36.3</td>\n",
       "      <td>780.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>85.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>36.3</td>\n",
       "      <td>780.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>87.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>36.3</td>\n",
       "      <td>771.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>87.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>36.3</td>\n",
       "      <td>771.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>87.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>36.3</td>\n",
       "      <td>771.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>87.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>27.2</td>\n",
       "      <td>771.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>65.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>27.2</td>\n",
       "      <td>771.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>65.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>27.2</td>\n",
       "      <td>391.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>65.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    var1   var2    var3  var4  var5  var6  varout\n",
       "0   36.0  660.0  1970.0   2.0  11.2   2.4    96.9\n",
       "1   36.0  950.0  1970.0   2.0  11.1   2.4    96.9\n",
       "2   36.0  950.0  1970.0   2.0  11.1   2.4    96.9\n",
       "3   36.0  950.0  1970.0   2.0  11.1   2.4    96.9\n",
       "4   36.0  950.0  1970.0   2.0  11.1   2.4    96.9\n",
       "5   36.3  950.0  1970.0   2.0  11.1   2.0    97.0\n",
       "6   36.3  950.0  1970.0   2.0  11.1   2.4    96.9\n",
       "7   36.3  700.0  1970.0   2.0  11.1   2.0    96.9\n",
       "8   36.3  700.0  1970.0   2.0  11.1   2.0    96.9\n",
       "9   36.3  700.0  1970.0   2.0  11.1   2.6    85.9\n",
       "10  36.3  700.0  1970.0   2.0  11.1   2.6    85.9\n",
       "11  36.3  700.0  1970.0   2.0  11.1   2.6    85.9\n",
       "12  36.3  700.0  1970.0   2.0  11.1   2.6    85.9\n",
       "13  36.3  780.0  1970.0   2.0  11.1   2.6    85.9\n",
       "14  36.3  780.0  1970.0   2.0  11.1   2.6    85.9\n",
       "15  36.3  780.0  1970.0   2.0  11.1   2.6    87.9\n",
       "16  36.3  771.0  1970.0   2.0  11.1   2.6    87.9\n",
       "17  36.3  771.0  1970.0   2.0  11.1   2.6    87.9\n",
       "18  36.3  771.0  1970.0   2.0  11.1   2.6    87.9\n",
       "19  27.2  771.0  1970.0   2.0  11.1   2.6    65.9\n",
       "20  27.2  771.0  1970.0   2.0  11.1   2.6    65.9\n",
       "21  27.2  391.0  1970.0   2.0  11.1   2.6    65.9"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_training_df[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "list_of_scaled_training_df = []\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "for training_df in list_of_training_df:\n",
    "    temp_df = scaler.fit_transform(training_df)\n",
    "    list_of_scaled_training_df.append(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.00194932, 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.00194932, 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.00194932, 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.00194932, 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "        0.00194932, 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "        0.00194932, 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_scaled_training_df[500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single example of a time series example for a single bridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = list_of_training_df[7].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n"
     ]
    }
   ],
   "source": [
    "n_train_hours = 21\n",
    "train = values[:n_train_hours, :]\n",
    "test = values[n_train_hours:, :]\n",
    "\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confirm gpu is being used before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/device:GPU:0']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = tf.keras.models.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "    tf.keras.layers.LSTM(50, return_sequences=True),\n",
    "#     tf.keras.layers.LSTM(30, return_sequences=True),\n",
    "#     tf.keras.layers.LSTM(100, return_sequences=True),\n",
    "#     tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "#     tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "#     tf.keras.layers.Dense(units=16, activation='relu'),\n",
    "#     tf.keras.layers.Dense(units=8, activation='relu'),\n",
    "#     tf.keras.layers.Dense(units=4, activation='relu'),\n",
    "#     tf.keras.layers.Dense(units=2, activation='relu'),\n",
    "#     Shape => [batch, time, features]\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Because we have individual time series for each bridge, we define an epoch number and for each epoch we train the model an a random bridge time series\n",
    "\n",
    "# At the end, we plot the loss and validation loss over time\n",
    "\n",
    "# This experiment is run with min max scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9.0233 - val_loss: 11.9058\n",
      "EPOCH: 2 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 14.4345 - val_loss: 17.6573\n",
      "EPOCH: 3 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 11.1922 - val_loss: 11.0103\n",
      "EPOCH: 4 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 11.2293 - val_loss: 7.8483\n",
      "EPOCH: 5 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3.7649 - val_loss: 3.8782\n",
      "EPOCH: 6 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8.8049 - val_loss: 4.7503\n",
      "EPOCH: 7 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6.4057 - val_loss: 5.5895\n",
      "EPOCH: 8 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3.0426 - val_loss: 3.2458\n",
      "EPOCH: 9 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4.4008 - val_loss: 4.1935\n",
      "EPOCH: 10 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4.1935 - val_loss: 3.9923\n",
      "EPOCH: 11 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5.1369 - val_loss: 2.4761\n",
      "EPOCH: 12 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4.4471 - val_loss: 4.1577\n",
      "EPOCH: 13 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3.6068 - val_loss: 3.4253\n",
      "EPOCH: 14 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2.9133 - val_loss: 3.1975\n",
      "EPOCH: 15 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6.2363 - val_loss: 7.9237\n",
      "EPOCH: 16 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2.1372 - val_loss: 2.9545\n",
      "EPOCH: 17 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1.5311 - val_loss: 1.1513\n",
      "EPOCH: 18 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1.7984 - val_loss: 1.9501\n",
      "EPOCH: 19 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.7530 - val_loss: 0.1799\n",
      "EPOCH: 20 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1.4651 - val_loss: 3.0605\n",
      "EPOCH: 21 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.4341 - val_loss: 1.7795\n",
      "EPOCH: 22 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1.3879 - val_loss: 1.1432\n",
      "EPOCH: 23 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2.1700 - val_loss: 2.0683\n",
      "EPOCH: 24 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2669 - val_loss: 0.1438\n",
      "EPOCH: 25 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.8327 - val_loss: 1.1014\n",
      "EPOCH: 26 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.5252 - val_loss: 0.5601\n",
      "EPOCH: 27 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2327 - val_loss: 0.3277\n",
      "EPOCH: 28 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1551 - val_loss: 0.0852\n",
      "EPOCH: 29 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2691 - val_loss: 1.8859e-04\n",
      "EPOCH: 30 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1587 - val_loss: 0.2246\n",
      "EPOCH: 31 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3082 - val_loss: 0.0362\n",
      "EPOCH: 32 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.9251 - val_loss: 0.8123\n",
      "EPOCH: 33 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2918 - val_loss: 1.0643\n",
      "EPOCH: 34 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0424 - val_loss: 0.2388\n",
      "EPOCH: 35 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1853 - val_loss: 0.2013\n",
      "EPOCH: 36 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1824 - val_loss: 0.1108\n",
      "EPOCH: 37 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1275 - val_loss: 0.9053\n",
      "EPOCH: 38 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2322 - val_loss: 0.5921\n",
      "EPOCH: 39 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2803 - val_loss: 0.1623\n",
      "EPOCH: 40 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1556 - val_loss: 1.0158e-04\n",
      "EPOCH: 41 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1440 - val_loss: 0.0015\n",
      "EPOCH: 42 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1538 - val_loss: 0.2325\n",
      "EPOCH: 43 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1406 - val_loss: 0.0493\n",
      "EPOCH: 44 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0123 - val_loss: 6.7804e-05\n",
      "EPOCH: 45 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0908 - val_loss: 0.0681\n",
      "EPOCH: 46 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1115 - val_loss: 0.0277\n",
      "EPOCH: 47 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2241 - val_loss: 0.1819\n",
      "EPOCH: 48 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0633 - val_loss: 0.1389\n",
      "EPOCH: 49 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2469 - val_loss: 0.6270\n",
      "EPOCH: 50 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.6959 - val_loss: 0.9254\n",
      "EPOCH: 51 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.8114 - val_loss: 1.0214\n",
      "EPOCH: 52 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2650 - val_loss: 0.1988\n",
      "EPOCH: 53 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2157 - val_loss: 0.3576\n",
      "EPOCH: 54 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1068 - val_loss: 0.0121\n",
      "EPOCH: 55 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1716 - val_loss: 0.2461\n",
      "EPOCH: 56 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0848 - val_loss: 0.0012\n",
      "EPOCH: 57 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0554 - val_loss: 0.7008\n",
      "EPOCH: 58 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3136 - val_loss: 0.5622\n",
      "EPOCH: 59 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.5593 - val_loss: 0.7402\n",
      "EPOCH: 60 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0727 - val_loss: 5.2440e-04\n",
      "EPOCH: 61 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0318 - val_loss: 0.0145\n",
      "EPOCH: 62 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1.1491 - val_loss: 0.1035\n",
      "EPOCH: 63 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1408 - val_loss: 0.0507\n",
      "EPOCH: 64 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.4479 - val_loss: 0.4340\n",
      "EPOCH: 65 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2310 - val_loss: 0.0335\n",
      "EPOCH: 66 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.4605 - val_loss: 0.6049\n",
      "EPOCH: 67 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3846 - val_loss: 0.4679\n",
      "EPOCH: 68 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2242 - val_loss: 0.1972\n",
      "EPOCH: 69 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1156 - val_loss: 0.6159\n",
      "EPOCH: 70 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2980 - val_loss: 0.1080\n",
      "EPOCH: 71 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1474 - val_loss: 0.2044\n",
      "EPOCH: 72 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3305 - val_loss: 0.4243\n",
      "EPOCH: 73 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2206 - val_loss: 0.6003\n",
      "EPOCH: 74 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1503 - val_loss: 0.0074\n",
      "EPOCH: 75 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1337 - val_loss: 0.4851\n",
      "EPOCH: 76 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.5083 - val_loss: 0.5897\n",
      "EPOCH: 77 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0346 - val_loss: 0.0027\n",
      "EPOCH: 78 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1247 - val_loss: 0.1043\n",
      "EPOCH: 79 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1450 - val_loss: 0.4322\n",
      "EPOCH: 80 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2745 - val_loss: 0.5636\n",
      "EPOCH: 81 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.5890 - val_loss: 0.8024\n",
      "EPOCH: 82 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1110 - val_loss: 0.1098\n",
      "EPOCH: 83 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.5075 - val_loss: 0.5702\n",
      "EPOCH: 84 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3266 - val_loss: 0.1268\n",
      "EPOCH: 85 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 0.3854 - val_loss: 0.1026\n",
      "EPOCH: 86 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3785 - val_loss: 0.0360\n",
      "EPOCH: 87 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.5565 - val_loss: 0.2509\n",
      "EPOCH: 88 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2449 - val_loss: 0.1360\n",
      "EPOCH: 89 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.5252 - val_loss: 0.3973\n",
      "EPOCH: 90 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2071 - val_loss: 0.1872\n",
      "EPOCH: 91 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1999 - val_loss: 0.2475\n",
      "EPOCH: 92 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1993 - val_loss: 0.2530\n",
      "EPOCH: 93 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1119 - val_loss: 0.0919\n",
      "EPOCH: 94 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1038 - val_loss: 0.1593\n",
      "EPOCH: 95 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1865 - val_loss: 0.1281\n",
      "EPOCH: 96 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2109 - val_loss: 0.0923\n",
      "EPOCH: 97 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0953 - val_loss: 0.5797\n",
      "EPOCH: 98 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.5369 - val_loss: 0.4957\n",
      "EPOCH: 99 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1562 - val_loss: 0.0376\n",
      "EPOCH: 100 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.8904 - val_loss: 1.0748\n",
      "EPOCH: 101 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2620 - val_loss: 0.3381\n",
      "EPOCH: 102 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0594 - val_loss: 0.0841\n",
      "EPOCH: 103 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.4503 - val_loss: 0.1046\n",
      "EPOCH: 104 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1102 - val_loss: 0.3364\n",
      "EPOCH: 105 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3094 - val_loss: 0.8211\n",
      "EPOCH: 106 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0379 - val_loss: 0.0136\n",
      "EPOCH: 107 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1762 - val_loss: 0.0628\n",
      "EPOCH: 108 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2372 - val_loss: 0.0282\n",
      "EPOCH: 109 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2365 - val_loss: 0.1301\n",
      "EPOCH: 110 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1.0111 - val_loss: 1.0036\n",
      "EPOCH: 111 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.4566 - val_loss: 0.5217\n",
      "EPOCH: 112 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.4496 - val_loss: 0.3055\n",
      "EPOCH: 113 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1790 - val_loss: 0.2206\n",
      "EPOCH: 114 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.4221 - val_loss: 0.3841\n",
      "EPOCH: 115 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0991 - val_loss: 0.1051\n",
      "EPOCH: 116 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2326 - val_loss: 0.3799\n",
      "EPOCH: 117 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0803 - val_loss: 0.2235\n",
      "EPOCH: 118 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.9449 - val_loss: 0.9325\n",
      "EPOCH: 119 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1216 - val_loss: 0.0195\n",
      "EPOCH: 120 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1947 - val_loss: 0.1741\n",
      "EPOCH: 121 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0312 - val_loss: 0.0111\n",
      "EPOCH: 122 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1011 - val_loss: 0.0441\n",
      "EPOCH: 123 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0678 - val_loss: 0.2284\n",
      "EPOCH: 124 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1603 - val_loss: 0.2663\n",
      "EPOCH: 125 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1310 - val_loss: 0.1030\n",
      "EPOCH: 126 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2270 - val_loss: 0.0335\n",
      "EPOCH: 127 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1691 - val_loss: 0.4279\n",
      "EPOCH: 128 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0961 - val_loss: 0.4551\n",
      "EPOCH: 129 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.8469 - val_loss: 0.8388\n",
      "EPOCH: 130 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1982 - val_loss: 0.0312\n",
      "EPOCH: 131 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3184 - val_loss: 0.3383\n",
      "EPOCH: 132 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0580 - val_loss: 0.0524\n",
      "EPOCH: 133 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2743 - val_loss: 0.1843\n",
      "EPOCH: 134 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0484 - val_loss: 0.0234\n",
      "EPOCH: 135 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1607 - val_loss: 0.2610\n",
      "EPOCH: 136 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.4705 - val_loss: 0.4617\n",
      "EPOCH: 137 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.8151 - val_loss: 0.8103\n",
      "EPOCH: 138 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0592 - val_loss: 0.0029\n",
      "EPOCH: 139 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2023 - val_loss: 0.2401\n",
      "EPOCH: 140 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1976 - val_loss: 0.2002\n",
      "EPOCH: 141 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.5834 - val_loss: 0.3011\n",
      "EPOCH: 142 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1974 - val_loss: 0.2986\n",
      "EPOCH: 143 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2585 - val_loss: 0.6004\n",
      "EPOCH: 144 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.7807 - val_loss: 0.7731\n",
      "EPOCH: 145 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1019 - val_loss: 0.2054\n",
      "EPOCH: 146 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2131 - val_loss: 0.2171\n",
      "EPOCH: 147 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0814 - val_loss: 0.0225\n",
      "EPOCH: 148 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2129 - val_loss: 0.1484\n",
      "EPOCH: 149 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3699 - val_loss: 0.2073\n",
      "EPOCH: 150 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.7386 - val_loss: 0.7284\n",
      "EPOCH: 151 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0833 - val_loss: 0.0528\n",
      "EPOCH: 152 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2668 - val_loss: 0.2320\n",
      "EPOCH: 153 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2220 - val_loss: 0.0117\n",
      "EPOCH: 154 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1490 - val_loss: 0.1905\n",
      "EPOCH: 155 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1785 - val_loss: 0.2148\n",
      "EPOCH: 156 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2828 - val_loss: 0.3255\n",
      "EPOCH: 157 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2096 - val_loss: 0.2095\n",
      "EPOCH: 158 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1306 - val_loss: 0.0385\n",
      "EPOCH: 159 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2654 - val_loss: 0.2694\n",
      "EPOCH: 160 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0853 - val_loss: 0.0478\n",
      "EPOCH: 161 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1190 - val_loss: 0.1638\n",
      "EPOCH: 162 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2676 - val_loss: 0.5305\n",
      "EPOCH: 163 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0824 - val_loss: 0.0142\n",
      "EPOCH: 164 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.5822 - val_loss: 0.1824\n",
      "EPOCH: 165 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2314 - val_loss: 6.4331e-05\n",
      "EPOCH: 166 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.6473 - val_loss: 0.6400\n",
      "EPOCH: 167 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0562 - val_loss: 4.6176e-04\n",
      "EPOCH: 168 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2727 - val_loss: 0.4390\n",
      "EPOCH: 169 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2524 - val_loss: 0.0367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 170 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1226 - val_loss: 0.1863\n",
      "EPOCH: 171 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1777 - val_loss: 0.1597\n",
      "EPOCH: 172 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0579 - val_loss: 0.1319\n",
      "EPOCH: 173 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3871 - val_loss: 0.2302\n",
      "EPOCH: 174 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3432 - val_loss: 0.3873\n",
      "EPOCH: 175 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1979 - val_loss: 0.2004\n",
      "EPOCH: 176 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2648 - val_loss: 0.3058\n",
      "EPOCH: 177 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.6204 - val_loss: 0.6205\n",
      "EPOCH: 178 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1216 - val_loss: 0.1386\n",
      "EPOCH: 179 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1491 - val_loss: 0.0989\n",
      "EPOCH: 180 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0967 - val_loss: 0.0026\n",
      "EPOCH: 181 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1513 - val_loss: 0.1569\n",
      "EPOCH: 182 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1702 - val_loss: 0.1928\n",
      "EPOCH: 183 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2448 - val_loss: 0.1592\n",
      "EPOCH: 184 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1320 - val_loss: 0.7351\n",
      "EPOCH: 185 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1262 - val_loss: 0.1701\n",
      "EPOCH: 186 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3802 - val_loss: 0.4638\n",
      "EPOCH: 187 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0378 - val_loss: 0.0427\n",
      "EPOCH: 188 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1651 - val_loss: 0.0748\n",
      "EPOCH: 189 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1822 - val_loss: 0.0390\n",
      "EPOCH: 190 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1831 - val_loss: 0.4337\n",
      "EPOCH: 191 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1090 - val_loss: 0.0209\n",
      "EPOCH: 192 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.6204 - val_loss: 0.6184\n",
      "EPOCH: 193 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1189 - val_loss: 0.2155\n",
      "EPOCH: 194 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0772 - val_loss: 0.0027\n",
      "EPOCH: 195 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.4758 - val_loss: 0.4950\n",
      "EPOCH: 196 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0980 - val_loss: 0.1507\n",
      "EPOCH: 197 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.5911 - val_loss: 0.6085\n",
      "EPOCH: 198 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1216 - val_loss: 0.1480\n",
      "EPOCH: 199 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2254 - val_loss: 0.2631\n",
      "EPOCH: 200 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0324 - val_loss: 0.3870\n",
      "EPOCH: 201 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3206 - val_loss: 0.2366\n",
      "EPOCH: 202 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2315 - val_loss: 0.3191\n",
      "EPOCH: 203 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1285 - val_loss: 0.0128\n",
      "EPOCH: 204 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1196 - val_loss: 0.0645\n",
      "EPOCH: 205 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.4181 - val_loss: 0.7448\n",
      "EPOCH: 206 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0648 - val_loss: 0.1416\n",
      "EPOCH: 207 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1981 - val_loss: 0.3296\n",
      "EPOCH: 208 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0831 - val_loss: 0.1940\n",
      "EPOCH: 209 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0401 - val_loss: 0.0022\n",
      "EPOCH: 210 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.4178 - val_loss: 0.7964\n",
      "EPOCH: 211 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2565 - val_loss: 0.2293\n",
      "EPOCH: 212 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1536 - val_loss: 0.1204\n",
      "EPOCH: 213 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3329 - val_loss: 0.6968\n",
      "EPOCH: 214 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1354 - val_loss: 0.0190\n",
      "EPOCH: 215 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1560 - val_loss: 0.2901\n",
      "EPOCH: 216 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3763 - val_loss: 0.2501\n",
      "EPOCH: 217 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0704 - val_loss: 0.2450\n",
      "EPOCH: 218 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1537 - val_loss: 0.1287\n",
      "EPOCH: 219 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1376 - val_loss: 0.0212\n",
      "EPOCH: 220 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1552 - val_loss: 0.6142\n",
      "EPOCH: 221 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.5492 - val_loss: 0.5630\n",
      "EPOCH: 222 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0297 - val_loss: 0.0012\n",
      "EPOCH: 223 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1125 - val_loss: 0.0805\n",
      "EPOCH: 224 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1623 - val_loss: 0.1709\n",
      "EPOCH: 225 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1583 - val_loss: 0.1574\n",
      "EPOCH: 226 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.5414 - val_loss: 0.5328\n",
      "EPOCH: 227 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1207 - val_loss: 0.2485\n",
      "EPOCH: 228 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0927 - val_loss: 0.0336\n",
      "EPOCH: 229 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0775 - val_loss: 0.1096\n",
      "EPOCH: 230 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2251 - val_loss: 0.0237\n",
      "EPOCH: 231 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2879 - val_loss: 0.3405\n",
      "EPOCH: 232 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0321 - val_loss: 0.0177\n",
      "EPOCH: 233 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2278 - val_loss: 0.2554\n",
      "EPOCH: 234 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1260 - val_loss: 0.1217\n",
      "EPOCH: 235 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2617 - val_loss: 0.1256\n",
      "EPOCH: 236 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1572 - val_loss: 0.0334\n",
      "EPOCH: 237 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0854 - val_loss: 0.2099\n",
      "EPOCH: 238 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1290 - val_loss: 0.0660\n",
      "EPOCH: 239 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2415 - val_loss: 0.1494\n",
      "EPOCH: 240 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1880 - val_loss: 0.2030\n",
      "EPOCH: 241 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1087 - val_loss: 0.1432\n",
      "EPOCH: 242 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0659 - val_loss: 0.1467\n",
      "EPOCH: 243 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2559 - val_loss: 0.1714\n",
      "EPOCH: 244 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0734 - val_loss: 0.0994\n",
      "EPOCH: 245 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1447 - val_loss: 0.0632\n",
      "EPOCH: 246 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0359 - val_loss: 0.4111\n",
      "EPOCH: 247 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3545 - val_loss: 0.4611\n",
      "EPOCH: 248 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1412 - val_loss: 0.2254\n",
      "EPOCH: 249 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0581 - val_loss: 0.0361\n",
      "EPOCH: 250 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1919 - val_loss: 0.4492\n",
      "EPOCH: 251 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3578 - val_loss: 0.4489\n",
      "EPOCH: 252 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0731 - val_loss: 0.0288\n",
      "EPOCH: 253 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2395 - val_loss: 0.1880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 254 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1071 - val_loss: 0.1396\n",
      "EPOCH: 255 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1925 - val_loss: 0.0706\n",
      "EPOCH: 256 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1225 - val_loss: 0.0409\n",
      "EPOCH: 257 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1128 - val_loss: 0.0615\n",
      "EPOCH: 258 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0660 - val_loss: 0.1260\n",
      "EPOCH: 259 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2711 - val_loss: 0.3544\n",
      "EPOCH: 260 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2209 - val_loss: 0.0208\n",
      "EPOCH: 261 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1248 - val_loss: 0.2318\n",
      "EPOCH: 262 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1418 - val_loss: 0.0316\n",
      "EPOCH: 263 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3191 - val_loss: 0.1156\n",
      "EPOCH: 264 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2063 - val_loss: 0.1272\n",
      "EPOCH: 265 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1126 - val_loss: 0.1374\n",
      "EPOCH: 266 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0907 - val_loss: 0.0281\n",
      "EPOCH: 267 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1661 - val_loss: 0.1511\n",
      "EPOCH: 268 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2628 - val_loss: 0.4727\n",
      "EPOCH: 269 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2096 - val_loss: 0.1652\n",
      "EPOCH: 270 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1250 - val_loss: 0.0300\n",
      "EPOCH: 271 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3075 - val_loss: 0.2754\n",
      "EPOCH: 272 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1448 - val_loss: 0.3484\n",
      "EPOCH: 273 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1335 - val_loss: 0.1151\n",
      "EPOCH: 274 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1846 - val_loss: 0.0033\n",
      "EPOCH: 275 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2238 - val_loss: 0.1733\n",
      "EPOCH: 276 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0978 - val_loss: 0.1445\n",
      "EPOCH: 277 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1710 - val_loss: 0.2034\n",
      "EPOCH: 278 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1316 - val_loss: 0.1077\n",
      "EPOCH: 279 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1224 - val_loss: 0.1661\n",
      "EPOCH: 280 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1028 - val_loss: 0.1666\n",
      "EPOCH: 281 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3448 - val_loss: 0.3711\n",
      "EPOCH: 282 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.4570 - val_loss: 0.4520\n",
      "EPOCH: 283 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1207 - val_loss: 0.0463\n",
      "EPOCH: 284 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2343 - val_loss: 0.1938\n",
      "EPOCH: 285 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1474 - val_loss: 0.0050\n",
      "EPOCH: 286 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1988 - val_loss: 0.0859\n",
      "EPOCH: 287 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0882 - val_loss: 0.1468\n",
      "EPOCH: 288 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2096 - val_loss: 0.1518\n",
      "EPOCH: 289 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0695 - val_loss: 0.1364\n",
      "EPOCH: 290 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1395 - val_loss: 0.4276\n",
      "EPOCH: 291 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1110 - val_loss: 0.1870\n",
      "EPOCH: 292 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0560 - val_loss: 0.0421\n",
      "EPOCH: 293 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0476 - val_loss: 1.2150e-04\n",
      "EPOCH: 294 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1716 - val_loss: 0.1403\n",
      "EPOCH: 295 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1485 - val_loss: 0.2052\n",
      "EPOCH: 296 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0547 - val_loss: 0.0386\n",
      "EPOCH: 297 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1707 - val_loss: 0.2128\n",
      "EPOCH: 298 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3269 - val_loss: 0.3545\n",
      "EPOCH: 299 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2707 - val_loss: 0.3236\n",
      "EPOCH: 300 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0829 - val_loss: 0.2169\n",
      "EPOCH: 301 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1000 - val_loss: 0.1250\n",
      "EPOCH: 302 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2546 - val_loss: 0.4378\n",
      "EPOCH: 303 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1768 - val_loss: 0.2830\n",
      "EPOCH: 304 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0546 - val_loss: 0.0138\n",
      "EPOCH: 305 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0693 - val_loss: 0.2455\n",
      "EPOCH: 306 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1368 - val_loss: 0.2648\n",
      "EPOCH: 307 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1750 - val_loss: 0.0923\n",
      "EPOCH: 308 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1270 - val_loss: 0.2445\n",
      "EPOCH: 309 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0746 - val_loss: 0.1557\n",
      "EPOCH: 310 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0816 - val_loss: 0.1459\n",
      "EPOCH: 311 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1272 - val_loss: 0.1122\n",
      "EPOCH: 312 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0646 - val_loss: 0.2257\n",
      "EPOCH: 313 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1173 - val_loss: 0.1166\n",
      "EPOCH: 314 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0879 - val_loss: 0.2359\n",
      "EPOCH: 315 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2802 - val_loss: 0.3074\n",
      "EPOCH: 316 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2808 - val_loss: 0.2517\n",
      "EPOCH: 317 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0392 - val_loss: 0.1189\n",
      "EPOCH: 318 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1818 - val_loss: 0.4928\n",
      "EPOCH: 319 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1407 - val_loss: 0.0548\n",
      "EPOCH: 320 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3284 - val_loss: 0.1604\n",
      "EPOCH: 321 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1077 - val_loss: 0.0999\n",
      "EPOCH: 322 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.4500 - val_loss: 0.2056\n",
      "EPOCH: 323 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1310 - val_loss: 0.0577\n",
      "EPOCH: 324 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0620 - val_loss: 0.0494\n",
      "EPOCH: 325 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1064 - val_loss: 0.0136\n",
      "EPOCH: 326 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1655 - val_loss: 0.0827\n",
      "EPOCH: 327 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2477 - val_loss: 0.1480\n",
      "EPOCH: 328 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1219 - val_loss: 0.1327\n",
      "EPOCH: 329 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3726 - val_loss: 0.3675\n",
      "EPOCH: 330 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1182 - val_loss: 0.0735\n",
      "EPOCH: 331 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3563 - val_loss: 0.4645\n",
      "EPOCH: 332 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2477 - val_loss: 0.0122\n",
      "EPOCH: 333 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0342 - val_loss: 0.1392\n",
      "EPOCH: 334 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1603 - val_loss: 2.5362e-04\n",
      "EPOCH: 335 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.5718 - val_loss: 0.5837\n",
      "EPOCH: 336 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1601 - val_loss: 0.1726\n",
      "EPOCH: 337 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1112 - val_loss: 1.7054e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 338 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2631 - val_loss: 0.4563\n",
      "EPOCH: 339 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0393 - val_loss: 0.0745\n",
      "EPOCH: 340 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1306 - val_loss: 0.1332\n",
      "EPOCH: 341 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2959 - val_loss: 0.2848\n",
      "EPOCH: 342 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0420 - val_loss: 5.5819e-05\n",
      "EPOCH: 343 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1351 - val_loss: 0.2635\n",
      "EPOCH: 344 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1179 - val_loss: 0.0823\n",
      "EPOCH: 345 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0746 - val_loss: 0.1443\n",
      "EPOCH: 346 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1065 - val_loss: 0.1204\n",
      "EPOCH: 347 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3256 - val_loss: 0.3384\n",
      "EPOCH: 348 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0990 - val_loss: 0.1726\n",
      "EPOCH: 349 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0643 - val_loss: 0.0644\n",
      "EPOCH: 350 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0770 - val_loss: 0.0380\n",
      "EPOCH: 351 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1981 - val_loss: 0.1999\n",
      "EPOCH: 352 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0445 - val_loss: 8.0496e-04\n",
      "EPOCH: 353 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3325 - val_loss: 0.3290\n",
      "EPOCH: 354 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2893 - val_loss: 0.3747\n",
      "EPOCH: 355 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1650 - val_loss: 0.1941\n",
      "EPOCH: 356 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1334 - val_loss: 0.0312\n",
      "EPOCH: 357 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1923 - val_loss: 0.1677\n",
      "EPOCH: 358 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1581 - val_loss: 0.1776\n",
      "EPOCH: 359 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1293 - val_loss: 0.1069\n",
      "EPOCH: 360 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3053 - val_loss: 0.1493\n",
      "EPOCH: 361 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1203 - val_loss: 0.3436\n",
      "EPOCH: 362 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0437 - val_loss: 0.0339\n",
      "EPOCH: 363 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0669 - val_loss: 0.0606\n",
      "EPOCH: 364 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1145 - val_loss: 0.0454\n",
      "EPOCH: 365 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3219 - val_loss: 0.3207\n",
      "EPOCH: 366 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0670 - val_loss: 0.0340\n",
      "EPOCH: 367 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1122 - val_loss: 0.1661\n",
      "EPOCH: 368 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2301 - val_loss: 0.2012\n",
      "EPOCH: 369 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0395 - val_loss: 0.0292\n",
      "EPOCH: 370 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0949 - val_loss: 0.1471\n",
      "EPOCH: 371 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2388 - val_loss: 0.2557\n",
      "EPOCH: 372 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0596 - val_loss: 0.1218\n",
      "EPOCH: 373 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3334 - val_loss: 0.5516\n",
      "EPOCH: 374 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3815 - val_loss: 0.4500\n",
      "EPOCH: 375 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1654 - val_loss: 0.3048\n",
      "EPOCH: 376 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1569 - val_loss: 0.0334\n",
      "EPOCH: 377 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0790 - val_loss: 0.0145\n",
      "EPOCH: 378 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1552 - val_loss: 0.3267\n",
      "EPOCH: 379 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2523 - val_loss: 0.4109\n",
      "EPOCH: 380 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1386 - val_loss: 0.1367\n",
      "EPOCH: 381 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1907 - val_loss: 0.0773\n",
      "EPOCH: 382 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1068 - val_loss: 0.0955\n",
      "EPOCH: 383 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1208 - val_loss: 0.0616\n",
      "EPOCH: 384 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3330 - val_loss: 0.3433\n",
      "EPOCH: 385 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1375 - val_loss: 0.1186\n",
      "EPOCH: 386 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1488 - val_loss: 0.2454\n",
      "EPOCH: 387 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3458 - val_loss: 0.1029\n",
      "EPOCH: 388 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1074 - val_loss: 0.0301\n",
      "EPOCH: 389 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2369 - val_loss: 0.2135\n",
      "EPOCH: 390 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0930 - val_loss: 0.0862\n",
      "EPOCH: 391 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2840 - val_loss: 0.2539\n",
      "EPOCH: 392 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0812 - val_loss: 0.0386\n",
      "EPOCH: 393 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1472 - val_loss: 0.1625\n",
      "EPOCH: 394 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0578 - val_loss: 0.0034\n",
      "EPOCH: 395 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1415 - val_loss: 0.3034\n",
      "EPOCH: 396 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1731 - val_loss: 0.2310\n",
      "EPOCH: 397 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1325 - val_loss: 0.0446\n",
      "EPOCH: 398 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0986 - val_loss: 0.0361\n",
      "EPOCH: 399 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2133 - val_loss: 0.1161\n",
      "EPOCH: 400 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2018 - val_loss: 0.1766\n",
      "EPOCH: 401 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2806 - val_loss: 0.3205\n",
      "EPOCH: 402 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1065 - val_loss: 0.1980\n",
      "EPOCH: 403 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0437 - val_loss: 0.0124\n",
      "EPOCH: 404 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0955 - val_loss: 0.0820\n",
      "EPOCH: 405 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2034 - val_loss: 0.2403\n",
      "EPOCH: 406 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2906 - val_loss: 0.2675\n",
      "EPOCH: 407 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3306 - val_loss: 0.1455\n",
      "EPOCH: 408 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1291 - val_loss: 0.1550\n",
      "EPOCH: 409 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1022 - val_loss: 0.0844\n",
      "EPOCH: 410 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2097 - val_loss: 0.3606\n",
      "EPOCH: 411 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0799 - val_loss: 0.0857\n",
      "EPOCH: 412 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1929 - val_loss: 0.2574\n",
      "EPOCH: 413 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1805 - val_loss: 0.4106\n",
      "EPOCH: 414 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1828 - val_loss: 0.1454\n",
      "EPOCH: 415 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1670 - val_loss: 0.0682\n",
      "EPOCH: 416 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3104 - val_loss: 0.3619\n",
      "EPOCH: 417 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1714 - val_loss: 0.1816\n",
      "EPOCH: 418 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1427 - val_loss: 0.2786\n",
      "EPOCH: 419 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2313 - val_loss: 0.5978\n",
      "EPOCH: 420 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1716 - val_loss: 0.0505\n",
      "EPOCH: 421 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 0.0896 - val_loss: 0.1901\n",
      "EPOCH: 422 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0562 - val_loss: 0.0020\n",
      "EPOCH: 423 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0368 - val_loss: 0.0137\n",
      "EPOCH: 424 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1116 - val_loss: 0.0466\n",
      "EPOCH: 425 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1892 - val_loss: 0.0792\n",
      "EPOCH: 426 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2036 - val_loss: 0.1522\n",
      "EPOCH: 427 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1717 - val_loss: 0.2007\n",
      "EPOCH: 428 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1308 - val_loss: 0.0601\n",
      "EPOCH: 429 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2256 - val_loss: 0.6512\n",
      "EPOCH: 430 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0526 - val_loss: 0.0032\n",
      "EPOCH: 431 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0669 - val_loss: 0.2578\n",
      "EPOCH: 432 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1386 - val_loss: 0.0066\n",
      "EPOCH: 433 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2967 - val_loss: 0.3385\n",
      "EPOCH: 434 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2087 - val_loss: 0.3395\n",
      "EPOCH: 435 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0629 - val_loss: 0.0903\n",
      "EPOCH: 436 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0349 - val_loss: 0.0032\n",
      "EPOCH: 437 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0806 - val_loss: 0.0039\n",
      "EPOCH: 438 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3374 - val_loss: 0.3351\n",
      "EPOCH: 439 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2201 - val_loss: 0.1816\n",
      "EPOCH: 440 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0826 - val_loss: 0.1194\n",
      "EPOCH: 441 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2000 - val_loss: 0.0045\n",
      "EPOCH: 442 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2946 - val_loss: 0.2937\n",
      "EPOCH: 443 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2410 - val_loss: 0.1786\n",
      "EPOCH: 444 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1810 - val_loss: 0.0798\n",
      "EPOCH: 445 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0574 - val_loss: 0.0098\n",
      "EPOCH: 446 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2841 - val_loss: 0.3220\n",
      "EPOCH: 447 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1424 - val_loss: 0.0659\n",
      "EPOCH: 448 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1691 - val_loss: 0.1446\n",
      "EPOCH: 449 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2264 - val_loss: 0.0885\n",
      "EPOCH: 450 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2035 - val_loss: 0.1703\n",
      "EPOCH: 451 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3296 - val_loss: 0.1824\n",
      "EPOCH: 452 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1449 - val_loss: 0.0905\n",
      "EPOCH: 453 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1968 - val_loss: 0.3026\n",
      "EPOCH: 454 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1184 - val_loss: 0.0739\n",
      "EPOCH: 455 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1600 - val_loss: 0.1099\n",
      "EPOCH: 456 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1187 - val_loss: 0.0692\n",
      "EPOCH: 457 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1748 - val_loss: 0.2152\n",
      "EPOCH: 458 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0359 - val_loss: 0.0022\n",
      "EPOCH: 459 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1601 - val_loss: 0.1107\n",
      "EPOCH: 460 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3048 - val_loss: 0.3002\n",
      "EPOCH: 461 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0683 - val_loss: 0.0150\n",
      "EPOCH: 462 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1357 - val_loss: 0.2691\n",
      "EPOCH: 463 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2330 - val_loss: 0.1455\n",
      "EPOCH: 464 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2953 - val_loss: 0.2928\n",
      "EPOCH: 465 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3339 - val_loss: 0.2872\n",
      "EPOCH: 466 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0690 - val_loss: 0.0570\n",
      "EPOCH: 467 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3628 - val_loss: 0.4617\n",
      "EPOCH: 468 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1436 - val_loss: 0.2383\n",
      "EPOCH: 469 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1261 - val_loss: 0.1259\n",
      "EPOCH: 470 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2288 - val_loss: 0.3152\n",
      "EPOCH: 471 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2041 - val_loss: 0.2190\n",
      "EPOCH: 472 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2108 - val_loss: 0.1035\n",
      "EPOCH: 473 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2659 - val_loss: 0.2636\n",
      "EPOCH: 474 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0900 - val_loss: 0.2223\n",
      "EPOCH: 475 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1471 - val_loss: 0.2115\n",
      "EPOCH: 476 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1290 - val_loss: 0.1361\n",
      "EPOCH: 477 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1242 - val_loss: 0.2475\n",
      "EPOCH: 478 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0747 - val_loss: 0.0408\n",
      "EPOCH: 479 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0567 - val_loss: 0.0025\n",
      "EPOCH: 480 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3704 - val_loss: 0.3369\n",
      "EPOCH: 481 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3343 - val_loss: 0.5058\n",
      "EPOCH: 482 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0806 - val_loss: 7.1705e-04\n",
      "EPOCH: 483 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0914 - val_loss: 0.2249\n",
      "EPOCH: 484 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1367 - val_loss: 0.4014\n",
      "EPOCH: 485 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1478 - val_loss: 0.1625\n",
      "EPOCH: 486 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3091 - val_loss: 0.3930\n",
      "EPOCH: 487 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0720 - val_loss: 0.0298\n",
      "EPOCH: 488 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2583 - val_loss: 0.2565\n",
      "EPOCH: 489 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1566 - val_loss: 0.1020\n",
      "EPOCH: 490 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2659 - val_loss: 0.2764\n",
      "EPOCH: 491 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2760 - val_loss: 0.2644\n",
      "EPOCH: 492 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2529 - val_loss: 0.2511\n",
      "EPOCH: 493 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1499 - val_loss: 0.2958\n",
      "EPOCH: 494 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1285 - val_loss: 0.1350\n",
      "EPOCH: 495 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2973 - val_loss: 0.3081\n",
      "EPOCH: 496 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3435 - val_loss: 0.3529\n",
      "EPOCH: 497 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0517 - val_loss: 0.0423\n",
      "EPOCH: 498 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0404 - val_loss: 7.9319e-07\n",
      "EPOCH: 499 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0634 - val_loss: 0.0149\n",
      "EPOCH: 500 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1874 - val_loss: 0.1865\n",
      "EPOCH: 501 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0361 - val_loss: 0.0088\n",
      "EPOCH: 502 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3016 - val_loss: 0.3860\n",
      "EPOCH: 503 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2922 - val_loss: 0.2994\n",
      "EPOCH: 504 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1442 - val_loss: 0.1101\n",
      "EPOCH: 505 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 0.1984 - val_loss: 0.1968\n",
      "EPOCH: 506 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1343 - val_loss: 0.3974\n",
      "EPOCH: 507 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2410 - val_loss: 0.1630\n",
      "EPOCH: 508 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2282 - val_loss: 0.4994\n",
      "EPOCH: 509 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0822 - val_loss: 9.0668e-06\n",
      "EPOCH: 510 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2427 - val_loss: 0.3463\n",
      "EPOCH: 511 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0730 - val_loss: 0.0509\n",
      "EPOCH: 512 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0595 - val_loss: 0.0490\n",
      "EPOCH: 513 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2282 - val_loss: 0.2117\n",
      "EPOCH: 514 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1296 - val_loss: 0.1456\n",
      "EPOCH: 515 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2389 - val_loss: 0.2488\n",
      "EPOCH: 516 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0582 - val_loss: 0.0458\n",
      "EPOCH: 517 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0911 - val_loss: 0.1227\n",
      "EPOCH: 518 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0518 - val_loss: 0.0425\n",
      "EPOCH: 519 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2410 - val_loss: 0.2390\n",
      "EPOCH: 520 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0947 - val_loss: 0.0408\n",
      "EPOCH: 521 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1282 - val_loss: 0.1717\n",
      "EPOCH: 522 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0674 - val_loss: 4.1672e-04\n",
      "EPOCH: 523 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1408 - val_loss: 1.5549e-04\n",
      "EPOCH: 524 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2752 - val_loss: 0.2221\n",
      "EPOCH: 525 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1627 - val_loss: 0.3486\n",
      "EPOCH: 526 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2036 - val_loss: 0.0847\n",
      "EPOCH: 527 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3137 - val_loss: 0.1470\n",
      "EPOCH: 528 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1355 - val_loss: 0.1233\n",
      "EPOCH: 529 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1284 - val_loss: 0.0394\n",
      "EPOCH: 530 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2148 - val_loss: 0.2948\n",
      "EPOCH: 531 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2014 - val_loss: 0.1938\n",
      "EPOCH: 532 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2141 - val_loss: 0.1747\n",
      "EPOCH: 533 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1116 - val_loss: 0.2864\n",
      "EPOCH: 534 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2640 - val_loss: 0.1890\n",
      "EPOCH: 535 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1013 - val_loss: 0.1934\n",
      "EPOCH: 536 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1687 - val_loss: 0.0658\n",
      "EPOCH: 537 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2562 - val_loss: 0.2572\n",
      "EPOCH: 538 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0862 - val_loss: 0.0205\n",
      "EPOCH: 539 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0336 - val_loss: 0.2589\n",
      "EPOCH: 540 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.4086 - val_loss: 0.0556\n",
      "EPOCH: 541 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2807 - val_loss: 0.2900\n",
      "EPOCH: 542 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0305 - val_loss: 0.0394\n",
      "EPOCH: 543 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0396 - val_loss: 0.1095\n",
      "EPOCH: 544 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2072 - val_loss: 0.2132\n",
      "EPOCH: 545 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0965 - val_loss: 0.0316\n",
      "EPOCH: 546 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1585 - val_loss: 0.2641\n",
      "EPOCH: 547 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0816 - val_loss: 0.0754\n",
      "EPOCH: 548 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2926 - val_loss: 0.2914\n",
      "EPOCH: 549 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1539 - val_loss: 0.3337\n",
      "EPOCH: 550 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0688 - val_loss: 0.1427\n",
      "EPOCH: 551 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0494 - val_loss: 0.0014\n",
      "EPOCH: 552 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.4935 - val_loss: 0.4938\n",
      "EPOCH: 553 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2427 - val_loss: 0.2856\n",
      "EPOCH: 554 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0714 - val_loss: 0.0183\n",
      "EPOCH: 555 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1803 - val_loss: 0.1028\n",
      "EPOCH: 556 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0833 - val_loss: 0.0523\n",
      "EPOCH: 557 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3895 - val_loss: 0.4878\n",
      "EPOCH: 558 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2114 - val_loss: 0.1196\n",
      "EPOCH: 559 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1745 - val_loss: 0.1492\n",
      "EPOCH: 560 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0834 - val_loss: 0.0199\n",
      "EPOCH: 561 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1870 - val_loss: 0.1995\n",
      "EPOCH: 562 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1281 - val_loss: 0.2141\n",
      "EPOCH: 563 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2826 - val_loss: 0.2792\n",
      "EPOCH: 564 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1337 - val_loss: 3.9009e-04\n",
      "EPOCH: 565 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0747 - val_loss: 0.0651\n",
      "EPOCH: 566 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.4948 - val_loss: 0.4984\n",
      "EPOCH: 567 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1656 - val_loss: 0.1285\n",
      "EPOCH: 568 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1975 - val_loss: 0.1831\n",
      "EPOCH: 569 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1635 - val_loss: 0.2927\n",
      "EPOCH: 570 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3109 - val_loss: 0.2975\n",
      "EPOCH: 571 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2355 - val_loss: 0.2609\n",
      "EPOCH: 572 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1867 - val_loss: 0.1924\n",
      "EPOCH: 573 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3494 - val_loss: 0.4641\n",
      "EPOCH: 574 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2506 - val_loss: 0.1404\n",
      "EPOCH: 575 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1302 - val_loss: 0.0700\n",
      "EPOCH: 576 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0571 - val_loss: 0.0292\n",
      "EPOCH: 577 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1483 - val_loss: 0.0986\n",
      "EPOCH: 578 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1405 - val_loss: 0.2110\n",
      "EPOCH: 579 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2141 - val_loss: 0.1364\n",
      "EPOCH: 580 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1017 - val_loss: 0.0553\n",
      "EPOCH: 581 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1650 - val_loss: 0.1086\n",
      "EPOCH: 582 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1243 - val_loss: 0.0399\n",
      "EPOCH: 583 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1809 - val_loss: 0.1771\n",
      "EPOCH: 584 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2372 - val_loss: 0.2426\n",
      "EPOCH: 585 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2426 - val_loss: 0.2379\n",
      "EPOCH: 586 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0794 - val_loss: 0.0525\n",
      "EPOCH: 587 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1086 - val_loss: 0.1545\n",
      "EPOCH: 588 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1226 - val_loss: 0.1422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 589 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2296 - val_loss: 0.2266\n",
      "EPOCH: 590 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1358 - val_loss: 0.1586\n",
      "EPOCH: 591 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3481 - val_loss: 0.5797\n",
      "EPOCH: 592 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2861 - val_loss: 0.1406\n",
      "EPOCH: 593 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0536 - val_loss: 0.0455\n",
      "EPOCH: 594 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1004 - val_loss: 0.0078\n",
      "EPOCH: 595 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0875 - val_loss: 0.1056\n",
      "EPOCH: 596 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1030 - val_loss: 0.1105\n",
      "EPOCH: 597 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1123 - val_loss: 0.1312\n",
      "EPOCH: 598 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0927 - val_loss: 0.2186\n",
      "EPOCH: 599 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1180 - val_loss: 0.1258\n",
      "EPOCH: 600 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3887 - val_loss: 0.2778\n",
      "EPOCH: 601 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2225 - val_loss: 0.0918\n",
      "EPOCH: 602 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2318 - val_loss: 0.2330\n",
      "EPOCH: 603 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0947 - val_loss: 0.1230\n",
      "EPOCH: 604 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1707 - val_loss: 0.1675\n",
      "EPOCH: 605 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2392 - val_loss: 0.1178\n",
      "EPOCH: 606 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0791 - val_loss: 0.0291\n",
      "EPOCH: 607 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3621 - val_loss: 0.1911\n",
      "EPOCH: 608 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0413 - val_loss: 0.0016\n",
      "EPOCH: 609 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2395 - val_loss: 0.1900\n",
      "EPOCH: 610 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2971 - val_loss: 0.2459\n",
      "EPOCH: 611 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1238 - val_loss: 0.1314\n",
      "EPOCH: 612 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0806 - val_loss: 0.0040\n",
      "EPOCH: 613 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2508 - val_loss: 0.2518\n",
      "EPOCH: 614 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0917 - val_loss: 0.1513\n",
      "EPOCH: 615 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1265 - val_loss: 0.2399\n",
      "EPOCH: 616 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1692 - val_loss: 0.0818\n",
      "EPOCH: 617 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0908 - val_loss: 0.0672\n",
      "EPOCH: 618 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1359 - val_loss: 0.1065\n",
      "EPOCH: 619 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2299 - val_loss: 0.2460\n",
      "EPOCH: 620 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1271 - val_loss: 0.0971\n",
      "EPOCH: 621 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2519 - val_loss: 0.2501\n",
      "EPOCH: 622 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0972 - val_loss: 0.0362\n",
      "EPOCH: 623 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0912 - val_loss: 0.0727\n",
      "EPOCH: 624 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0832 - val_loss: 0.0715\n",
      "EPOCH: 625 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1599 - val_loss: 0.1582\n",
      "EPOCH: 626 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0907 - val_loss: 0.0537\n",
      "EPOCH: 627 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2721 - val_loss: 0.2197\n",
      "EPOCH: 628 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0739 - val_loss: 0.0039\n",
      "EPOCH: 629 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2318 - val_loss: 0.2276\n",
      "EPOCH: 630 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2039 - val_loss: 0.2564\n",
      "EPOCH: 631 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1699 - val_loss: 0.1577\n",
      "EPOCH: 632 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2217 - val_loss: 0.2177\n",
      "EPOCH: 633 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1614 - val_loss: 0.0551\n",
      "EPOCH: 634 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1280 - val_loss: 0.2724\n",
      "EPOCH: 635 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2087 - val_loss: 0.0659\n",
      "EPOCH: 636 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1245 - val_loss: 0.2337\n",
      "EPOCH: 637 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1357 - val_loss: 0.1214\n",
      "EPOCH: 638 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2028 - val_loss: 0.1112\n",
      "EPOCH: 639 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1222 - val_loss: 0.2236\n",
      "EPOCH: 640 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1088 - val_loss: 0.0087\n",
      "EPOCH: 641 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2539 - val_loss: 0.1755\n",
      "EPOCH: 642 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0998 - val_loss: 0.0547\n",
      "EPOCH: 643 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1245 - val_loss: 0.1179\n",
      "EPOCH: 644 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2030 - val_loss: 0.2654\n",
      "EPOCH: 645 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1544 - val_loss: 0.1082\n",
      "EPOCH: 646 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1061 - val_loss: 0.0825\n",
      "EPOCH: 647 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0545 - val_loss: 0.0411\n",
      "EPOCH: 648 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1588 - val_loss: 0.0895\n",
      "EPOCH: 649 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1830 - val_loss: 0.0821\n",
      "EPOCH: 650 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1062 - val_loss: 0.0781\n",
      "EPOCH: 651 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2014 - val_loss: 0.1695\n",
      "EPOCH: 652 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0813 - val_loss: 0.0557\n",
      "EPOCH: 653 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1988 - val_loss: 0.1993\n",
      "EPOCH: 654 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2215 - val_loss: 0.0043\n",
      "EPOCH: 655 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2047 - val_loss: 0.2674\n",
      "EPOCH: 656 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2173 - val_loss: 0.2205\n",
      "EPOCH: 657 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1020 - val_loss: 0.0370\n",
      "EPOCH: 658 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2277 - val_loss: 0.2372\n",
      "EPOCH: 659 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0801 - val_loss: 0.0823\n",
      "EPOCH: 660 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0505 - val_loss: 0.0415\n",
      "EPOCH: 661 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0715 - val_loss: 0.0399\n",
      "EPOCH: 662 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0857 - val_loss: 7.4098e-04\n",
      "EPOCH: 663 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1528 - val_loss: 0.1435\n",
      "EPOCH: 664 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1585 - val_loss: 0.0493\n",
      "EPOCH: 665 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0417 - val_loss: 0.0328\n",
      "EPOCH: 666 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1899 - val_loss: 0.0774\n",
      "EPOCH: 667 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1130 - val_loss: 0.0199\n",
      "EPOCH: 668 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0731 - val_loss: 0.0692\n",
      "EPOCH: 669 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3533 - val_loss: 0.2610\n",
      "EPOCH: 670 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1653 - val_loss: 0.1808\n",
      "EPOCH: 671 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0737 - val_loss: 1.0954e-04\n",
      "EPOCH: 672 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 0.2248 - val_loss: 0.2225\n",
      "EPOCH: 673 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0288 - val_loss: 0.0012\n",
      "EPOCH: 674 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3623 - val_loss: 0.1302\n",
      "EPOCH: 675 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0506 - val_loss: 0.0154\n",
      "EPOCH: 676 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1534 - val_loss: 0.0618\n",
      "EPOCH: 677 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0799 - val_loss: 0.2068\n",
      "EPOCH: 678 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1222 - val_loss: 0.0865\n",
      "EPOCH: 679 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2223 - val_loss: 0.2188\n",
      "EPOCH: 680 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2675 - val_loss: 0.2507\n",
      "EPOCH: 681 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2349 - val_loss: 0.1334\n",
      "EPOCH: 682 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1021 - val_loss: 0.0948\n",
      "EPOCH: 683 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1513 - val_loss: 0.2375\n",
      "EPOCH: 684 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1126 - val_loss: 0.2275\n",
      "EPOCH: 685 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0577 - val_loss: 8.4141e-04\n",
      "EPOCH: 686 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0646 - val_loss: 0.2519\n",
      "EPOCH: 687 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0828 - val_loss: 0.0944\n",
      "EPOCH: 688 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0348 - val_loss: 0.0505\n",
      "EPOCH: 689 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1403 - val_loss: 0.1980\n",
      "EPOCH: 690 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0769 - val_loss: 0.0990\n",
      "EPOCH: 691 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1637 - val_loss: 0.2139\n",
      "EPOCH: 692 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3250 - val_loss: 0.0827\n",
      "EPOCH: 693 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1289 - val_loss: 0.0922\n",
      "EPOCH: 694 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2912 - val_loss: 0.4972\n",
      "EPOCH: 695 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2427 - val_loss: 0.0939\n",
      "EPOCH: 696 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0667 - val_loss: 0.1047\n",
      "EPOCH: 697 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0848 - val_loss: 0.1131\n",
      "EPOCH: 698 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3312 - val_loss: 0.1375\n",
      "EPOCH: 699 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2647 - val_loss: 0.1714\n",
      "EPOCH: 700 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1135 - val_loss: 0.1150\n",
      "EPOCH: 701 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1731 - val_loss: 0.1735\n",
      "EPOCH: 702 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3532 - val_loss: 0.2516\n",
      "EPOCH: 703 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0358 - val_loss: 0.0298\n",
      "EPOCH: 704 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2335 - val_loss: 0.2126\n",
      "EPOCH: 705 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2158 - val_loss: 0.3321\n",
      "EPOCH: 706 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0409 - val_loss: 0.0299\n",
      "EPOCH: 707 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2548 - val_loss: 0.3571\n",
      "EPOCH: 708 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0875 - val_loss: 0.1735\n",
      "EPOCH: 709 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3406 - val_loss: 0.2377\n",
      "EPOCH: 710 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1083 - val_loss: 0.0893\n",
      "EPOCH: 711 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1624 - val_loss: 0.5540\n",
      "EPOCH: 712 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1311 - val_loss: 0.0885\n",
      "EPOCH: 713 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2000 - val_loss: 0.0489\n",
      "EPOCH: 714 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1288 - val_loss: 0.1236\n",
      "EPOCH: 715 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3944 - val_loss: 0.3068\n",
      "EPOCH: 716 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1041 - val_loss: 0.0274\n",
      "EPOCH: 717 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0889 - val_loss: 0.0530\n",
      "EPOCH: 718 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0973 - val_loss: 0.0296\n",
      "EPOCH: 719 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0623 - val_loss: 0.0512\n",
      "EPOCH: 720 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1865 - val_loss: 0.3635\n",
      "EPOCH: 721 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1800 - val_loss: 0.0991\n",
      "EPOCH: 722 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2713 - val_loss: 0.2940\n",
      "EPOCH: 723 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1813 - val_loss: 0.2079\n",
      "EPOCH: 724 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.4118 - val_loss: 0.0882\n",
      "EPOCH: 725 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2003 - val_loss: 0.2917\n",
      "EPOCH: 726 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0703 - val_loss: 0.0535\n",
      "EPOCH: 727 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1090 - val_loss: 0.1635\n",
      "EPOCH: 728 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0904 - val_loss: 0.0348\n",
      "EPOCH: 729 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1614 - val_loss: 0.0769\n",
      "EPOCH: 730 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1890 - val_loss: 0.1486\n",
      "EPOCH: 731 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0735 - val_loss: 0.0050\n",
      "EPOCH: 732 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0680 - val_loss: 0.0545\n",
      "EPOCH: 733 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0962 - val_loss: 0.0944\n",
      "EPOCH: 734 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0999 - val_loss: 0.1256\n",
      "EPOCH: 735 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1586 - val_loss: 0.1544\n",
      "EPOCH: 736 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2170 - val_loss: 0.3312\n",
      "EPOCH: 737 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0979 - val_loss: 0.1514\n",
      "EPOCH: 738 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0601 - val_loss: 0.0511\n",
      "EPOCH: 739 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2585 - val_loss: 0.3178\n",
      "EPOCH: 740 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1902 - val_loss: 0.4136\n",
      "EPOCH: 741 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2417 - val_loss: 0.0967\n",
      "EPOCH: 742 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1205 - val_loss: 0.0124\n",
      "EPOCH: 743 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2313 - val_loss: 0.4088\n",
      "EPOCH: 744 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1038 - val_loss: 0.0184\n",
      "EPOCH: 745 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1261 - val_loss: 0.0102\n",
      "EPOCH: 746 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3172 - val_loss: 0.3761\n",
      "EPOCH: 747 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0637 - val_loss: 0.0509\n",
      "EPOCH: 748 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1177 - val_loss: 0.1194\n",
      "EPOCH: 749 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1653 - val_loss: 0.0366\n",
      "EPOCH: 750 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1053 - val_loss: 0.1343\n",
      "EPOCH: 751 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0927 - val_loss: 0.1159\n",
      "EPOCH: 752 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1259 - val_loss: 0.0045\n",
      "EPOCH: 753 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2081 - val_loss: 0.2062\n",
      "EPOCH: 754 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0382 - val_loss: 0.1463\n",
      "EPOCH: 755 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0815 - val_loss: 0.0814\n",
      "EPOCH: 756 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 0.0777 - val_loss: 0.1773\n",
      "EPOCH: 757 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1003 - val_loss: 0.2691\n",
      "EPOCH: 758 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1211 - val_loss: 0.0141\n",
      "EPOCH: 759 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1214 - val_loss: 0.4626\n",
      "EPOCH: 760 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3077 - val_loss: 0.1926\n",
      "EPOCH: 761 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2333 - val_loss: 0.0031\n",
      "EPOCH: 762 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1710 - val_loss: 0.1955\n",
      "EPOCH: 763 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1838 - val_loss: 0.0623\n",
      "EPOCH: 764 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0940 - val_loss: 0.1032\n",
      "EPOCH: 765 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1734 - val_loss: 0.6031\n",
      "EPOCH: 766 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0513 - val_loss: 0.0372\n",
      "EPOCH: 767 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1288 - val_loss: 0.0526\n",
      "EPOCH: 768 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0454 - val_loss: 0.0399\n",
      "EPOCH: 769 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.6356 - val_loss: 0.6524\n",
      "EPOCH: 770 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0801 - val_loss: 0.0995\n",
      "EPOCH: 771 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2168 - val_loss: 0.0299\n",
      "EPOCH: 772 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1745 - val_loss: 0.0693\n",
      "EPOCH: 773 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1966 - val_loss: 0.2110\n",
      "EPOCH: 774 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0543 - val_loss: 0.0424\n",
      "EPOCH: 775 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1728 - val_loss: 0.2118\n",
      "EPOCH: 776 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1603 - val_loss: 0.0750\n",
      "EPOCH: 777 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0780 - val_loss: 0.2432\n",
      "EPOCH: 778 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2318 - val_loss: 0.2472\n",
      "EPOCH: 779 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1455 - val_loss: 0.4065\n",
      "EPOCH: 780 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1604 - val_loss: 0.1079\n",
      "EPOCH: 781 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1525 - val_loss: 0.0591\n",
      "EPOCH: 782 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2515 - val_loss: 0.2528\n",
      "EPOCH: 783 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2009 - val_loss: 0.1985\n",
      "EPOCH: 784 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2098 - val_loss: 0.2190\n",
      "EPOCH: 785 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2986 - val_loss: 0.1203\n",
      "EPOCH: 786 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3444 - val_loss: 0.2630\n",
      "EPOCH: 787 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0584 - val_loss: 0.0464\n",
      "EPOCH: 788 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0790 - val_loss: 0.0871\n",
      "EPOCH: 789 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2517 - val_loss: 0.2324\n",
      "EPOCH: 790 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1716 - val_loss: 0.1252\n",
      "EPOCH: 791 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2495 - val_loss: 0.6082\n",
      "EPOCH: 792 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1960 - val_loss: 0.2033\n",
      "EPOCH: 793 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3307 - val_loss: 0.2442\n",
      "EPOCH: 794 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2044 - val_loss: 0.2043\n",
      "EPOCH: 795 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1574 - val_loss: 0.2927\n",
      "EPOCH: 796 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2332 - val_loss: 0.0025\n",
      "EPOCH: 797 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0887 - val_loss: 0.0365\n",
      "EPOCH: 798 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1583 - val_loss: 0.1355\n",
      "EPOCH: 799 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2450 - val_loss: 0.2225\n",
      "EPOCH: 800 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3739 - val_loss: 0.4502\n",
      "EPOCH: 801 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1910 - val_loss: 0.1972\n",
      "EPOCH: 802 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0584 - val_loss: 0.0660\n",
      "EPOCH: 803 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0748 - val_loss: 0.0080\n",
      "EPOCH: 804 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0515 - val_loss: 0.0691\n",
      "EPOCH: 805 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3271 - val_loss: 0.1828\n",
      "EPOCH: 806 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1892 - val_loss: 0.1866\n",
      "EPOCH: 807 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0786 - val_loss: 0.0606\n",
      "EPOCH: 808 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2023 - val_loss: 0.0048\n",
      "EPOCH: 809 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1434 - val_loss: 0.1063\n",
      "EPOCH: 810 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0973 - val_loss: 0.0016\n",
      "EPOCH: 811 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0620 - val_loss: 0.1410\n",
      "EPOCH: 812 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2852 - val_loss: 0.2809\n",
      "EPOCH: 813 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0615 - val_loss: 0.0044\n",
      "EPOCH: 814 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1211 - val_loss: 0.1120\n",
      "EPOCH: 815 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1695 - val_loss: 0.2979\n",
      "EPOCH: 816 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1622 - val_loss: 0.1655\n",
      "EPOCH: 817 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0694 - val_loss: 0.2558\n",
      "EPOCH: 818 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1594 - val_loss: 0.2967\n",
      "EPOCH: 819 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2107 - val_loss: 0.1967\n",
      "EPOCH: 820 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0383 - val_loss: 0.0306\n",
      "EPOCH: 821 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0775 - val_loss: 0.0585\n",
      "EPOCH: 822 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0957 - val_loss: 0.1269\n",
      "EPOCH: 823 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0896 - val_loss: 0.0768\n",
      "EPOCH: 824 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1775 - val_loss: 0.4332\n",
      "EPOCH: 825 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2499 - val_loss: 0.2740\n",
      "EPOCH: 826 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1574 - val_loss: 0.0796\n",
      "EPOCH: 827 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0622 - val_loss: 0.0074\n",
      "EPOCH: 828 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3206 - val_loss: 0.3577\n",
      "EPOCH: 829 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1735 - val_loss: 0.3609\n",
      "EPOCH: 830 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0757 - val_loss: 0.0024\n",
      "EPOCH: 831 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0813 - val_loss: 0.0065\n",
      "EPOCH: 832 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0383 - val_loss: 0.0201\n",
      "EPOCH: 833 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3780 - val_loss: 0.1496\n",
      "EPOCH: 834 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.5330 - val_loss: 0.6485\n",
      "EPOCH: 835 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.4103 - val_loss: 0.3447\n",
      "EPOCH: 836 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0576 - val_loss: 0.0437\n",
      "EPOCH: 837 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1268 - val_loss: 0.1724\n",
      "EPOCH: 838 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0468 - val_loss: 0.2218\n",
      "EPOCH: 839 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0995 - val_loss: 0.0446\n",
      "EPOCH: 840 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 0.0247 - val_loss: 0.0106\n",
      "EPOCH: 841 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1288 - val_loss: 0.0044\n",
      "EPOCH: 842 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0608 - val_loss: 0.0201\n",
      "EPOCH: 843 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2492 - val_loss: 0.1678\n",
      "EPOCH: 844 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0752 - val_loss: 0.1542\n",
      "EPOCH: 845 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0534 - val_loss: 0.1730\n",
      "EPOCH: 846 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2467 - val_loss: 0.1717\n",
      "EPOCH: 847 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0482 - val_loss: 0.0325\n",
      "EPOCH: 848 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3929 - val_loss: 0.4528\n",
      "EPOCH: 849 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2328 - val_loss: 0.2292\n",
      "EPOCH: 850 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1174 - val_loss: 0.0602\n",
      "EPOCH: 851 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1325 - val_loss: 0.1322\n",
      "EPOCH: 852 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2720 - val_loss: 0.3368\n",
      "EPOCH: 853 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.5440 - val_loss: 0.5351\n",
      "EPOCH: 854 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1282 - val_loss: 0.1501\n",
      "EPOCH: 855 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1614 - val_loss: 0.1723\n",
      "EPOCH: 856 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1700 - val_loss: 0.1705\n",
      "EPOCH: 857 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1037 - val_loss: 0.1308\n",
      "EPOCH: 858 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2042 - val_loss: 0.1083\n",
      "EPOCH: 859 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0595 - val_loss: 0.0812\n",
      "EPOCH: 860 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3883 - val_loss: 0.2603\n",
      "EPOCH: 861 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3797 - val_loss: 0.3028\n",
      "EPOCH: 862 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1054 - val_loss: 0.1356\n",
      "EPOCH: 863 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1055 - val_loss: 0.0148\n",
      "EPOCH: 864 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1099 - val_loss: 0.1336\n",
      "EPOCH: 865 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0712 - val_loss: 0.0010\n",
      "EPOCH: 866 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1494 - val_loss: 0.0468\n",
      "EPOCH: 867 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1840 - val_loss: 0.0053\n",
      "EPOCH: 868 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1881 - val_loss: 0.1670\n",
      "EPOCH: 869 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0726 - val_loss: 0.0035\n",
      "EPOCH: 870 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0787 - val_loss: 0.0434\n",
      "EPOCH: 871 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2203 - val_loss: 0.3130\n",
      "EPOCH: 872 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1715 - val_loss: 0.2634\n",
      "EPOCH: 873 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3376 - val_loss: 0.4730\n",
      "EPOCH: 874 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.4341 - val_loss: 0.4632\n",
      "EPOCH: 875 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2480 - val_loss: 0.2207\n",
      "EPOCH: 876 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1843 - val_loss: 0.0722\n",
      "EPOCH: 877 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2025 - val_loss: 0.0758\n",
      "EPOCH: 878 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0891 - val_loss: 0.0166\n",
      "EPOCH: 879 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2008 - val_loss: 0.1997\n",
      "EPOCH: 880 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1935 - val_loss: 0.1837\n",
      "EPOCH: 881 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0595 - val_loss: 0.0918\n",
      "EPOCH: 882 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1595 - val_loss: 0.0925\n",
      "EPOCH: 883 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1908 - val_loss: 0.2484\n",
      "EPOCH: 884 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1995 - val_loss: 0.1984\n",
      "EPOCH: 885 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1217 - val_loss: 0.1405\n",
      "EPOCH: 886 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2007 - val_loss: 0.1839\n",
      "EPOCH: 887 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1951 - val_loss: 0.0870\n",
      "EPOCH: 888 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1601 - val_loss: 0.0775\n",
      "EPOCH: 889 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2421 - val_loss: 0.1521\n",
      "EPOCH: 890 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2437 - val_loss: 0.3776\n",
      "EPOCH: 891 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1604 - val_loss: 0.1092\n",
      "EPOCH: 892 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1260 - val_loss: 0.1396\n",
      "EPOCH: 893 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1916 - val_loss: 0.2230\n",
      "EPOCH: 894 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3586 - val_loss: 0.5611\n",
      "EPOCH: 895 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1078 - val_loss: 0.1829\n",
      "EPOCH: 896 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1740 - val_loss: 0.3556\n",
      "EPOCH: 897 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1001 - val_loss: 0.0863\n",
      "EPOCH: 898 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0952 - val_loss: 0.0624\n",
      "EPOCH: 899 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2962 - val_loss: 0.3491\n",
      "EPOCH: 900 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0876 - val_loss: 0.0073\n",
      "EPOCH: 901 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3326 - val_loss: 0.4949\n",
      "EPOCH: 902 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2447 - val_loss: 0.2949\n",
      "EPOCH: 903 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0433 - val_loss: 0.1455\n",
      "EPOCH: 904 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1624 - val_loss: 0.1035\n",
      "EPOCH: 905 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1077 - val_loss: 0.2363\n",
      "EPOCH: 906 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2325 - val_loss: 0.3716\n",
      "EPOCH: 907 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2673 - val_loss: 0.1811\n",
      "EPOCH: 908 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2274 - val_loss: 0.2281\n",
      "EPOCH: 909 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2095 - val_loss: 0.1650\n",
      "EPOCH: 910 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0206 - val_loss: 0.0030\n",
      "EPOCH: 911 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0287 - val_loss: 0.0199\n",
      "EPOCH: 912 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.4017 - val_loss: 0.4493\n",
      "EPOCH: 913 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1684 - val_loss: 0.2952\n",
      "EPOCH: 914 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0244 - val_loss: 0.0171\n",
      "EPOCH: 915 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0545 - val_loss: 0.0462\n",
      "EPOCH: 916 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0846 - val_loss: 0.0723\n",
      "EPOCH: 917 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3059 - val_loss: 0.3115\n",
      "EPOCH: 918 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1346 - val_loss: 0.4708\n",
      "EPOCH: 919 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1413 - val_loss: 0.0568\n",
      "EPOCH: 920 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0908 - val_loss: 0.0312\n",
      "EPOCH: 921 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2241 - val_loss: 0.2232\n",
      "EPOCH: 922 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2131 - val_loss: 0.2074\n",
      "EPOCH: 923 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1630 - val_loss: 0.0198\n",
      "EPOCH: 924 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1161 - val_loss: 0.0441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 925 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2195 - val_loss: 0.2178\n",
      "EPOCH: 926 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1087 - val_loss: 0.0927\n",
      "EPOCH: 927 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3825 - val_loss: 0.3733\n",
      "EPOCH: 928 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0552 - val_loss: 0.0358\n",
      "EPOCH: 929 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0722 - val_loss: 0.2450\n",
      "EPOCH: 930 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1320 - val_loss: 0.1286\n",
      "EPOCH: 931 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0884 - val_loss: 0.2520\n",
      "EPOCH: 932 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0875 - val_loss: 0.0435\n",
      "EPOCH: 933 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1234 - val_loss: 0.2149\n",
      "EPOCH: 934 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0926 - val_loss: 0.0919\n",
      "EPOCH: 935 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1145 - val_loss: 0.1516\n",
      "EPOCH: 936 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1015 - val_loss: 0.0895\n",
      "EPOCH: 937 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0761 - val_loss: 0.1903\n",
      "EPOCH: 938 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1498 - val_loss: 0.4021\n",
      "EPOCH: 939 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3766 - val_loss: 0.5379\n",
      "EPOCH: 940 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1457 - val_loss: 0.1838\n",
      "EPOCH: 941 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3855 - val_loss: 0.1023\n",
      "EPOCH: 942 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3367 - val_loss: 0.3743\n",
      "EPOCH: 943 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0188 - val_loss: 0.1601\n",
      "EPOCH: 944 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1026 - val_loss: 0.1191\n",
      "EPOCH: 945 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0877 - val_loss: 0.0740\n",
      "EPOCH: 946 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1799 - val_loss: 0.1775\n",
      "EPOCH: 947 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2121 - val_loss: 0.1371\n",
      "EPOCH: 948 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1539 - val_loss: 0.2633\n",
      "EPOCH: 949 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2347 - val_loss: 0.2800\n",
      "EPOCH: 950 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1701 - val_loss: 0.1782\n",
      "EPOCH: 951 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1211 - val_loss: 0.0859\n",
      "EPOCH: 952 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2091 - val_loss: 0.2560\n",
      "EPOCH: 953 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1688 - val_loss: 0.1669\n",
      "EPOCH: 954 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1783 - val_loss: 0.1165\n",
      "EPOCH: 955 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1560 - val_loss: 0.1434\n",
      "EPOCH: 956 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1001 - val_loss: 0.0086\n",
      "EPOCH: 957 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1971 - val_loss: 0.0966\n",
      "EPOCH: 958 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1014 - val_loss: 0.0696\n",
      "EPOCH: 959 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0725 - val_loss: 0.0570\n",
      "EPOCH: 960 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0367 - val_loss: 0.0036\n",
      "EPOCH: 961 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1135 - val_loss: 0.1977\n",
      "EPOCH: 962 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1539 - val_loss: 0.1570\n",
      "EPOCH: 963 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0889 - val_loss: 0.0149\n",
      "EPOCH: 964 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0573 - val_loss: 0.1764\n",
      "EPOCH: 965 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1919 - val_loss: 0.3320\n",
      "EPOCH: 966 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0502 - val_loss: 0.0814\n",
      "EPOCH: 967 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1496 - val_loss: 0.1469\n",
      "EPOCH: 968 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0415 - val_loss: 0.0057\n",
      "EPOCH: 969 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2313 - val_loss: 0.1915\n",
      "EPOCH: 970 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1649 - val_loss: 0.0701\n",
      "EPOCH: 971 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0631 - val_loss: 0.0069\n",
      "EPOCH: 972 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0231 - val_loss: 0.0700\n",
      "EPOCH: 973 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1633 - val_loss: 0.2620\n",
      "EPOCH: 974 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0806 - val_loss: 0.1222\n",
      "EPOCH: 975 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0930 - val_loss: 0.1490\n",
      "EPOCH: 976 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0744 - val_loss: 7.4423e-07\n",
      "EPOCH: 977 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0813 - val_loss: 0.0927\n",
      "EPOCH: 978 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3446 - val_loss: 0.1739\n",
      "EPOCH: 979 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1013 - val_loss: 0.0505\n",
      "EPOCH: 980 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1433 - val_loss: 0.2128\n",
      "EPOCH: 981 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.3943 - val_loss: 0.2538\n",
      "EPOCH: 982 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0882 - val_loss: 0.0372\n",
      "EPOCH: 983 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0693 - val_loss: 0.0367\n",
      "EPOCH: 984 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0649 - val_loss: 0.0014\n",
      "EPOCH: 985 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1265 - val_loss: 0.0310\n",
      "EPOCH: 986 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2090 - val_loss: 0.2142\n",
      "EPOCH: 987 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2706 - val_loss: 0.1774\n",
      "EPOCH: 988 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1175 - val_loss: 0.0020\n",
      "EPOCH: 989 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1423 - val_loss: 0.2237\n",
      "EPOCH: 990 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1423 - val_loss: 0.2223\n",
      "EPOCH: 991 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1397 - val_loss: 0.1392\n",
      "EPOCH: 992 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1911 - val_loss: 0.1602\n",
      "EPOCH: 993 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1145 - val_loss: 0.1459\n",
      "EPOCH: 994 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1649 - val_loss: 0.2871\n",
      "EPOCH: 995 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1721 - val_loss: 0.2169\n",
      "EPOCH: 996 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.2122 - val_loss: 0.2073\n",
      "EPOCH: 997 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1253 - val_loss: 0.1196\n",
      "EPOCH: 998 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0371 - val_loss: 0.1445\n",
      "EPOCH: 999 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.1253 - val_loss: 0.1433\n",
      "EPOCH: 1000 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 0.0740 - val_loss: 0.2659\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAonklEQVR4nO3deXwV1f3/8dcnC4R9X0RUUBERFJSAWrW1LojoF7Vaq9Vqv7VFv63fLr+vttrFrZt1XyuiUlsVXECpVVAQUFRkCYgQ9oAsCUvCFgjZc8/vj5kk9yY3kOTeLEzez8cjjztzzpmZM3duPvfcM2dmzDmHiIgEV0JTV0BERBqWAr2ISMAp0IuIBJwCvYhIwCnQi4gEXFJTVyCa7t27u379+jV1NUREjhhLlizZ5ZzrES2vWQb6fv36kZaW1tTVEBE5YpjZ5pry1HUjIhJwCvQiIgGnQC8iEnDNso9eRKSuSkpKyMzMpLCwsKmr0qBSUlLo27cvycnJtV5GgV5EAiEzM5MOHTrQr18/zKypq9MgnHPs3r2bzMxM+vfvX+vl1HUjIoFQWFhIt27dAhvkAcyMbt261flXiwK9iARGkIN8ufrs42G7bsxsInA5kO2cG+KnvQEM9It0BvY554ZFWXYTcAAoA0qdc6l1rmFdZK+B/N3Q75wG3YyIyJGkNi36l4HR4QnOue8554b5wX0q8PYhlv+2X7ZhgzzA38+El8c0+GZERKrat28ff//73+u83JgxY9i3b1/8KxTmsIHeOTcP2BMtz7zfENcCk+NcLxGRI0pNgb60tPSQy02fPp3OnTs3UK08sfbRnwfsdM6tryHfATPNbImZjTvUisxsnJmlmVlaTk5OjNUSEWlcd911Fxs2bGDYsGGMGDGC8847j7Fjx3LKKacAcOWVVzJ8+HAGDx7MhAkTKpbr168fu3btYtOmTQwaNIif/OQnDB48mFGjRlFQUBCXusU6vPJ6Dt2aP9c5l2VmPYFZZrbG/4VQjXNuAjABIDU1Vc83FJF6u/8/K1m1bX9c13lKn47c+1+Da8x/8MEHSU9PZ9myZXz88cdcdtllpKenVwyDnDhxIl27dqWgoIARI0Zw9dVX061bt4h1rF+/nsmTJ/PCCy9w7bXXMnXqVG688caY617vFr2ZJQHfAd6oqYxzLst/zQbeAUbWd3siIkeSkSNHRox1f+qppxg6dChnnXUWW7duZf366h0h/fv3Z9iwYQAMHz6cTZs2xaUusbToLwLWOOcyo2WaWTsgwTl3wJ8eBTwQw/ZERGrlUC3vxtKuXbuK6Y8//piPPvqIL774grZt23L++edHHQvfunXriunExMS4dd0ctkVvZpOBL4CBZpZpZrf4WddRpdvGzPqY2XR/thfwmZl9BSwC3nfOfRCXWouINDMdOnTgwIEDUfNyc3Pp0qULbdu2Zc2aNSxYsKBR63bYFr1z7voa0n8YJW0bMMaf3ggMjbF+IiJHhG7dunHOOecwZMgQ2rRpQ69evSryRo8ezfjx4xk0aBADBw7krLPOatS66V43IiJxMmnSpKjprVu3ZsaMGVHzyvvhu3fvTnp6ekX6HXfcEbd66RYIIiIBp0AvIhJwCvQiIgGnQC8iEnAK9CIiAadALyIScAr0IiJxUN/bFAM88cQT5Ofnx7lGlRToRUTioDkHel0wJSISB+G3Kb744ovp2bMnb775JkVFRVx11VXcf//9HDx4kGuvvZbMzEzKysr4wx/+wM6dO9m2bRvf/va36d69O3Pnzo173RToRSR4ZtwFO1bEd529T4VLH6wxO/w2xTNnzmTKlCksWrQI5xxjx45l3rx55OTk0KdPH95//33AuwdOp06deOyxx5g7dy7du3ePb5196roREYmzmTNnMnPmTE4//XTOOOMM1qxZw/r16zn11FOZNWsWv/nNb/j000/p1KlTo9RHLXoRCZ5DtLwbg3OOu+++m1tvvbVa3tKlS5k+fTq///3vufDCC7nnnnsavD5q0YuIxEH4bYovueQSJk6cSF5eHgBZWVlkZ2ezbds22rZty4033sidd97J0qVLqy3bENSiFxGJg/DbFF966aV8//vf5+yzzwagffv2vPrqq2RkZHDnnXeSkJBAcnIyzz33HADjxo1j9OjR9OnTp0FOxppzze/xrKmpqS4tLa3uC97n93fdlxvfColIs7d69WoGDRrU1NVoFNH21cyWOOdSo5VX142ISMAp0IuIBJwCvYgERnPsio63+uxjbR4OPtHMss0sPSztPjPLMrNl/t+YGpYdbWZrzSzDzO6qc+1ERGopJSWF3bt3BzrYO+fYvXs3KSkpdVquNqNuXgaeAf5VJf1x59wjNS1kZonAs8DFQCaw2Mzedc6tqlMNRURqoW/fvmRmZpKTk9PUVWlQKSkp9O3bt07LHDbQO+fmmVm/etRnJJDhnNsIYGavA1cACvQiEnfJycn079+/qavRLMXSR3+7mS33u3a6RMk/GtgaNp/pp0VlZuPMLM3M0oL+jSwi0pjqG+ifA04AhgHbgUdjrYhzboJzLtU5l9qjR49YVyciIr56BXrn3E7nXJlzLgS8gNdNU1UWcEzYfF8/TUREGlG9Ar2ZHRU2exWQHqXYYmCAmfU3s1bAdcC79dmeiIjU32FPxprZZOB8oLuZZQL3Aueb2TDAAZuAW/2yfYAXnXNjnHOlZnY78CGQCEx0zq1siJ0QEZGa1WbUzfVRkl+qoew2YEzY/HRger1rJyIiMdOVsSIiAadALyIScMEM9AG+BFpEpK4U6EVEAi6YgR4FehGRcsEM9GrRi4hUCGagV4teRKRCMAO9WvQiIhWCGejVohcRqRDMQK8WvYhIhWAGerXoRUQqBDPQu1BT10BEpNkIaKBXi15EpFwwA726bkREKgQz0KtFLyJSIZiBXi16EZEKwQz0atGLiFQIZqBXi15EpEIgA71Ti15EpMJhA72ZTTSzbDNLD0t72MzWmNlyM3vHzDrXsOwmM1thZsvMLC2O9T4kF1KgFxEpV5sW/cvA6Cpps4AhzrnTgHXA3YdY/tvOuWHOudT6VbHuQrpgSkSkwmEDvXNuHrCnStpM51ypP7sA6NsAdau3kFr0IiIV4tFH/yNgRg15DphpZkvMbNyhVmJm48wszczScnJyYqqQWvQiIpViCvRm9jugFHithiLnOufOAC4FfmZm36xpXc65Cc65VOdcao8ePWKplvroRUTC1DvQm9kPgcuBG1wNw1ycc1n+azbwDjCyvturC7XoRUQq1SvQm9lo4NfAWOdcfg1l2plZh/JpYBSQHq1svCnQi4hUqs3wysnAF8BAM8s0s1uAZ4AOwCx/6OR4v2wfM5vuL9oL+MzMvgIWAe875z5okL2owpWp60ZEpFzS4Qo4566PkvxSDWW3AWP86Y3A0JhqV08hXTAlIlIhoFfGqutGRKRcoAL9wtDJgMbRi4iEC1Sgn1p2HqAWvYhIuEAFeocBGnUjIhIumIE+pEAvIlIuWIHelQd69dGLiJQLVqCvmFCgFxEpF7BA77Xod+YWNHFNRESaj0AG+pkrtzdxTUREmo9ABfr2Kd6Fvsd2a9vENRERaT4CFegTE/zdUR+9iEiFQAX6kL87umBKRKRSoAJ9eR+9WvQiIpUCFehDfqA31KIXESkXsEDv746ujBURqRCwQF/edaNALyJSLlCBvqKPHvXRi4iUC1SgV9eNiEh1AQv01adERFq6WgV6M5toZtlmlh6W1tXMZpnZev+1Sw3L3uyXWW9mN8er4tFUtOjVRy8iUqG2LfqXgdFV0u4CZjvnBgCz/fkIZtYVuBc4ExgJ3FvTF0I8hPzbFJsCvYhIhVoFeufcPGBPleQrgH/60/8Eroyy6CXALOfcHufcXmAW1b8w4iakk7EiItXE0kffyzlXfpvIHUCvKGWOBraGzWf6adWY2TgzSzOztJycnHpVqMx5u2OhsnotLyISRHE5Geucc8TYjHbOTXDOpTrnUnv06FGvdVR22KhFLyJSLpZAv9PMjgLwX7OjlMkCjgmb7+unNQidjBURqS6WQP8uUD6K5mbg31HKfAiMMrMu/knYUX5agyh/VKxOxoqIVKrt8MrJwBfAQDPLNLNbgAeBi81sPXCRP4+ZpZrZiwDOuT3AH4HF/t8DflqDKPNH3TjdvVJEpEJSbQo5566vIevCKGXTgB+HzU8EJtardnVUVnH3SgV6EZFyAbsyVjc1ExGpKliB3inQi4hUFahAX6YrY0VEqglUoNeVsSIi1QUq0Fe26HVlrIhIuUAF+nMG9PQmNLxSRKRCoAL9naMHAbAhe38T10REpPkIVKDHvN3Zuvsg2QcKm7gyIiLNQyADfQKOgmL104uIQEADvRFSN72IiC9ggd4bdZOAI6RILyICBC7QV3bdKMyLiHiCGegtpDtYioj4AhnoDVdxb3oRkZYukIE+AaeTsSIivsAGep2MFRHxBDTQh7xAv20ZbPqsaeskItLEavWEqSNGWB+9c8AL3/LS78ttujqJiDSxgLbo1W0jIlKu3oHezAaa2bKwv/1m9ssqZc43s9ywMvfEXONaqOi6ERGR+nfdOOfWAsMAzCwRyALeiVL0U+fc5fXdTp1UdN1AmcZXiogA8eu6uRDY4JzbHKf11U/YvW7UohcR8cQr0F8HTK4h72wz+8rMZpjZ4JpWYGbjzCzNzNJycnLqV4uwPvoyPTZWRASIQ6A3s1bAWOCtKNlLgeOcc0OBp4FpNa3HOTfBOZfqnEvt0aNHPSsTHujVohcRgfi06C8FljrndlbNcM7td87l+dPTgWQz6x6HbUanC6ZERKqJR6C/nhq6bcyst5l372AzG+lvb3ccthldWB+9WvQiIp6YLpgys3bAxcCtYWm3ATjnxgPXAP9jZqVAAXCda8jbSoZ33ahFLyICxBjonXMHgW5V0saHTT8DPBPLNuokvOtGLXoRESBwV8b6T5iykG5TLCLiC1ygDznDNOpGRKRCsAI9EMI06kZEJExAA71G3YiIlAtcoHckqEUvIhImcIE+hProRUTCBTLQ6xYIIiKVAhjoE0ggpEePiIj4Ahfond+ib8gLcEVEjiSBC/TlffTquRER8QQy0OtRgiIilQIY6BN0rxsRkTCBC/SO8vvRN3VNRESahwAG+gQ9M1ZEJEzgAn0I49yEdCgrbuqqiIg0CzHdj7456m17wWDkuseauioiIs1C4Fr05Trkb2nqKoiINAuBDfQhC9yPFRGReglsoC9ToBcRAeIQ6M1sk5mtMLNlZpYWJd/M7CkzyzCz5WZ2RqzbrI39OhcrIgLE72Tst51zu2rIuxQY4P+dCTznvzaor/cWc3piQ29FRKT5a4yumyuAfznPAqCzmR3V0Bstceq6ERGB+AR6B8w0syVmNi5K/tHA1rD5TD8tgpmNM7M0M0vLycmJuVKlqDkvIgLxCfTnOufOwOui+ZmZfbM+K3HOTXDOpTrnUnv06BFzpUoU6EVEgDgEeudclv+aDbwDjKxSJAs4Jmy+r5/WoCJa9Lodgoi0YDEFejNrZ2YdyqeBUUB6lWLvAjf5o2/OAnKdc9tj2W5tlIafZ1agF5EWLNYzlr2Ad8ysfF2TnHMfmNltAM658cB0YAyQAeQD/x3jNmslsutGgV5EWq6YAr1zbiMwNEr6+LBpB/wslu3UR0RoV4teRFqwwF4Zm0iocsaFai4oIhJwAQ704a14tehFpOUKbKC/Lek/lTNq0YtICxbYQB9BffQi0oK1kECvFr2ItFwtI9Crj15EWrCWEejVdSMiLVjgAv1phS9UT1TXjYi0YIEL9K/ePipKqlr0ItJyBS7Qn9a3c7U0F1KLXkRarsAF+mic+uhFpAVrEYE+pBa9iLRgCvQiIgHXIgK9Q4FeRFquQAb6UUV/i5jXyVgRackCGeg3u14R8ylPDYaV05qmMiIiTSyQgf7ZG6s+thZIn9r4FRERaQYCGegvGtyneqKujhWRFiqQgR7vGbaRQmWNXw8RkWag3oHezI4xs7lmtsrMVprZL6KUOd/Mcs1smf93T2zVjYFToBeRlimWh4OXAv/nnFtqZh2AJWY2yzm3qkq5T51zl8ewnfhQi15EWqh6t+idc9udc0v96QPAauDoeFUs7tSiF5EWKi599GbWDzgdWBgl+2wz+8rMZpjZ4EOsY5yZpZlZWk5OTuyV6jmYXR3DNqcWvYi0UDEHejNrD0wFfumc218leylwnHNuKPA0MK2m9TjnJjjnUp1zqT169Ii1WvDT+Swf8NOwDWjUjYi0TDEFejNLxgvyrznn3q6a75zb75zL86enA8lm1j2WbdatgpWnIEJlpY22WRGR5iSWUTcGvASsds49VkOZ3n45zGykv73d9d1mnSUkVkwu27KbxZv2NNqmRUSai1ha9OcAPwAuCBs+OcbMbjOz2/wy1wDpZvYV8BRwnWvEm8MnJiVXTJ+RkEFG+uLG2rSISLNR7+GVzrnPgChXJkWUeQZ4pr7biFWrVskR88fv/gS4pGkqIyLSRIJ5ZayvdatWEfMW1pUjItJStLBAH8v1YSIiR6ZgB/rWkYGeRAV6EWl5Ah3oU1q1jphXi15EWqJAB/qk5MjAbmrRi0gLFOhA37tz+8gEtehFpAUKdKDHIkfZhEyjbkSk5Ql2oA9F3vYg1HjXaomINBstKtAnlOTXarEduYX86b1VlIX0xSAiR75gB/puJ0bMjlj1FyjKg3f+Bw7uiiybv6ci7ddTl/PiZ1+z6Ota3htn+q/h4wcBKC4NUVyqO2WKSPMR7EAf5UrYskUvwleTYP7TkRkP9YdHBwJQXOrdu77Wt+VZ9Dx8/FcANv1pKFv/NITS0jIWLF5Q/7qLiMRJsAN9FB8vW+NNfP4ELBjvTZcWea9+V4/5t/CpT8fNSWzhBLL49PWHOOv9S/jy8w8B2Lx1C3kHD8ZQcxGR+mlxgX73zm2VMx/8xnvN2xlRJokSAKo16FdOgw9/V/PK7+tUMdkh50sASnLWA3DcS6ey6smr+PStJ1h+/5ns3buHT6Y+h3OOUKznAkoKYP92r0uqKC+2dYlI4AR+YHmIBBKo7DPvbNUDocvLrrwN56vX8Mq2WYy2B3GMjCz41s3e6yV/Pux2zd+mIxFXnI8BI4sXwkrvaYtfTvg+3yr4gjlrPuDU4qX0uH/roVeYvQb+fibc9C4c/63IvD/3rpxeNwPu3AgJLe47vFIo5D0jODH58GWl8ZUWQUJy/D6jzoEd8ka6LV7go4FV+QC0o7BamYK9Ya38jFkADLBMjvvyYXjjRlj4PKT9o7JMaXHl9IEdUbeb4Hf8hCyBorzqJ3UH5i8F4IKSj+lhlU9gDIUc//nDaFbedwYAO7asJ+3R71Cy1usCYuU7LHjrMRa/9QgZk+8kVFSlO6hgL6yfCe/+vMa6Nbac9Dle8G3QjayD9R950++Mgz823oPMGsy2L6P8rDyChcrg8yfhTz1Z/9J/V88vPgizH4CS6v+jNdqzEe7vDKvejU/9Gvpz2kRaQKCP3MUOVn2IZdGB6oH4xIRtHLvqeVj9H5jxa3jvlxV5c/54Kf3uep8duYWUPnNW1O0mhYrKK0DRfm80T5GrbGG2taKI8qUlXnfRitfu4r8Sv2AwGwDY8frPST0wm9z0mRVlz1p5PyNW/pET107gq7f+Un3jW+bD0n+y7/Ezmf2nsRQW1uEfJ1QGZSW1Lx+urAQy0yKS1s2fRo8pV7F8SpR6RjP7j/DEqXXf9rMj4LWrvekVb9V9+XDbl1fbjwj5e2DT53Ve7dq0ORTtz4a9mwHYumYx2VvWRC+8YQ5MOB/SXqrzduIiezXs2xKZNvXH8MjA+q9z5Tsw6x4ABmRNq54//2n49FFY8o/qeTUoyFwOQP7if0WkL0ubz8f3j4p+Xqym7s0HusIbN8Cer2Hvpsi8UCj6l0D+HvjHGO8LpxkLfKCnSqA/yqoH9eKDudXSrkn8pMZVXmBpnGBZPPDuCpKK9kYtk5Tr/TPjILRzFQAFtIpaFqCgwPvwDd0wviKtdMdq2hfneKtJ9Jet+k9wYHu1dTk/UHcO7ePC0k/YtmZhZIHCXPhbf++cwudPRuZNvj6iNZy+cDYr7k8ld+8eWDbZa2UCFOyDaT/zfkGUm3UvvHghtz0+iTU79sOXr3HSTK+767RVD1cEuMqKRmmtfvqIF2DWfQi71lfPr6roAGTMjp5Xmy8s5+DPfeCzxyvTnj8PXrwQMpdUr2PhfnhyKLw85rDr35iTR0a2d1x3bdvEwPeuovVjA+DJ0wA45vWL6DnxTHj9BnjunMiFywPHjnTKQo59+cU0qr+fVf0Ld8VbkLeDzL1eY2ljTh7pWVX+dzKXwPI3vXNG5UJl3mdt3iPVt7P9K8jzPuOUFHivxXmw6t/eZzGakgKY8RvI38OKHV4jZtP2yieUFr16HcPeu5Tz3UIy1ywi+0Bh5Qi6zCXw16PJmlGlLuX5a6fDU8O8YwyUbF1K3vOj4c0fwANdACgtC1WeV1sxBTZ/TsknUZ+mGlUo5Ni6p3bX9MRLCwj0kV03Pax6UC/Or552tB360bazW9/JhXsm1Zg/KMFvDZUVk7jFa/11tppH3ZR9/QVsiRyOmTT+LE4s9YKdhaIHldN3Tq2W9vbnyyPmu6yYCFsqg73bMBcK/C+8Wfd4QeXNm5i3cgus97qICqbeDmUl9P7gx5zq1rN13VKYdhtMOJ+9q+bC346DZa9WBkjnYOk/AdiVvZ1HZqyCf/80oh5F6e+Sk7GE9e8/waYZT1L8YH8Kdm0m/993kD7ndfbn7qEksa1XeNK18EwqC/8+jvumLPKuTcjL9v7J139E3oFc3vlgJvy1L7z6ncqNhMoqJovfvo01b/+ZFfNnULB/D6z9gHnrcsjIWAtAVuYWVmzYAiUH4aP7oKSAsrKwVtuLF+CWv0FB9kZWPXEluXOfhAePgSK/q211WHfB/u3kv3UrW7ftqOjau+DRT7josU/AORK+eCrivXClYb/o1rwHO9Mj36sSbz8OlpTx8IdrGfbALJZs3svFj33Clt2xB4n0rFzueOsrbnl5MZMWRrbcc/MrP2vPzs3gnlc+JPTISRVpNzw0maJXvsfrT9zB2KfnVS64bDK8eAG8/RN47GQKZ/7R3xn//cpZHVmJUAie/ya8fBmvLtjMht1eoN+8cy+8eROsnc6sZRvI3u//Ii3c77WgV70LC8fDQ/05acl9ACSGKt/P1hkzKqY37dzHZX+eysPvfwXA/kWvALBl0XuV9Ti4y+v+qeq+TpS8fCXtt3/hHSMA59hw/6l8+tA13nu12+seTf7qFfK2fFV9HaVFsOC5is/Evvxijv/tdM57aG5ksG/gLrrAn4yt2qKv6mD6dHbtyuGYeqz66r0TD1vm6G0z6bir5l8H5Tq/U0PrxVd6YNch8yPqlfhZxHyXDdNgwzQeHTyVrj2Oov3qZXw3LP/AW7fTYfvnfPxVR77p9y61WfEK60/4HgOc94Ww4euvGeKXz3z/QbqUL/z5k3BgJ7mFpXQq9lqvHS2fVWvXQkpkvVrP/j09gB5haaue+y6nlK1lCC+w6OOTGZkQGcTOzH6Dzjs+Z8qyk/h+0hxCSW1IKC2gPXBVlH13RQcqTqy3WjmFkwGWA37P14KS7/Hr5DfYO/x/OXrJ0xwdvvCfe7O3/1jCe/ftnVtpA5wCHJxX5ZnDU37E0rT5FLfvS59tMzl2z3zarnwdgJ3WnU0p3jErfLAbXYsiGw4rHx5V8X6Wy87aTEJyazZOf5x2e1cxGJifsYcuxU+yKWUSF45/mHyXwqInHsE676dt6g3kzp9I7mXPM3naNG7ttoLjd82hZPiPmcoFjNozia4X/JxQn+Fsm/kUbdb/h9JRf6H3wJE8PeltLtv/Bs+WXsHDazrTdf6fOLV3Ckcn7eeevddS/jvvtQ8/Z37KzyPq+Unr/wcb4LfJ8NvkyYRy15CQlOw1BMKkzH+E/HN/RevPniDaXaZCi1/yWpq71jJo+tWckOCPUFv5bEWZv74xh/wOx/NyyZ2c7LzuzLJjzq5YX+ci75fDcSUZbNu5kyc/yeRvYdvYt3kFi1Me5d3ll8Hlk+i43PtFbK6MksI8Ej9/gt2dBkd8JsO1LYtsBK5bMoeBCZkMLMyEWfewd9smysfaFcy4h6Tdy0no0ItWP3oP2nWH+U/BnD+xbk8px7QrY87XIfpbR25I/Ig357Qjaf9mfnH8Dvj4L5Sc/kOS930NP5gW98EUFsuzus1sNPAkkAi86Jx7sEp+a+BfwHBgN/A959ymw603NTXVpaUdoo+0Lh4ZCHnN46RkSzKv7FS+mbii0be7qM15jCz4tNG3Gy97XHu6ho0MW5w0nBGlS+q9vix6sjPUkTMSMirSnu7+e4bvfJtvJK6Kqa7lNiUcS3qf73J55qNxWV9VU8vO4+rEwx/T1RxPUqiIAQlZUfMnpNzCuMLGOeex23VgYtsfc2fB44cvHCbUeygJt807fMEozGyJcy41al59A72ZJQLrgIuBTGAxcL1zblVYmZ8CpznnbjOz64CrnHPfO9y64xrod2/w+t1m/j4+66uFHUlH07s0+oetXI7rFLUbqaqvQ73on7DzsOXkyJWeNJghpSubuhotxg7Xhd4W/dxaU/tn0ne5+fcv1mvZQwX6WH4fjAQynHMbnXPFwOvAFVXKXAH805+eAlxoVcc7NrRuJ8A3/hfuy4UOR1Ukj0++KaLYo93uj7r46vNfiJjPGPIrb+KcX/D1iHvZ2ebEast0++FrjO/8q0NWKzT4atZ2/MZhq//a8DfI6+T1j84ZEPllNan0Ap4vveyw6wi3rl0q/yq9uNblZ572RGVdSi+smP53SuWhvjf0E+4ruYkrix6oU11qUmgphy8EZAz6GQW05mD3obiTRse0zU3nPsz80x8ix6oPy8y7Yyv7rGPF/IERP69WJtyW1ENcVFfF9m8+yJA7Z1ZL35VyHGu7eNdLfNbxcjb3HVutzL6k+A0h3do78jNRmNyZ2a0v5P2jflbjMkUdjo2YX9mq7qOl1rUbDm27kd3rPAB2XvPvQ5Z/uvTKWq976/Vz+UPiL6ulp5x7e8X0uz1v48CpPyR00hhWXTGdjW0q9+GvXQ9/vQzArNOf5enSK1kQGsSB77zGgRMur3UdAbJSf8OkixZyWdGfuTfvSgqKyw6/UB3F0qK/BhjtnPuxP/8D4Ezn3O1hZdL9Mpn+/Aa/TLUOZzMbB4wDOPbYY4dv3ry5apHY7d4A859i/3l/oHW7TrSecx/7MhZSetQZdL/qb7BhDm7+M+T3Hk5BxxPpPmCE90WxeT4FSyZRetLldBgy2ht+1fFoSPJHwuzbCh37kLv4ddokOVoNvxGA0mVvsGfLKnqe+0NwIVxZMSV7M2mVtRDO+SWESmDnSkjp5F2d222Ad+Lq7XHQpgt871Vo29UbrfLV67hv3sH2TWvpc2AFbP8Kd97/sW7Hfgbmfkpxt4EUZa2kQ/e+0O0E8pdNIT+xM93PGEth2ivs73IqPfscC70G45xjY/Z+TnBbAIM2nWFHuvfqQpDS2RsN0a4HDLgIctZ6v4q+8XOKZv+F5L5nkDBwNOxa550g9S/gyisqpazM0SmxyDtROeRq8t//Hcm7VlF40lg4mEO7ETeS0L4HxTPvJ/HkS0k8agh5ubtoa6Xk5R0gsXt/2iWUesMbh/gnWbcvh1btYPFLMORqylI6U7BxAe1H3hBxeEvXfkjepi/pfP7t8OZNlPUdSf6ebXTocQy06uDd5G7ARQAcWP4eSZvn0WbETdA7rLc8N8s7Qd2lHwy93nv/23alcMPnhOY+SMmwm+g07AqY8wCM+DEupTOluzeRvPAZSP2Rt1z7XhAqZfvS99nZZgAntC+iQ7c+hOY9QsKJF0HPkyFrKeSsgfPv9u7JtGej92CcpDbQugMktYaCvV4/9jf+F5JTIC+Hog/vIan78SQeM9J738tvzrd2Ohw11PsrKYBFL8CZt+GK9mPtusPCCdDtBIoL8kjIWkxpu96kuEJCnzyEG/sMiUOvhawlFGxcyN7BP6BP1w4Vb8n21QtIdkV0O/lcrLTIG/rZpjP0O9cb8752OhzMgTNv9U4+zn4AWneEky+jNH0ae07+Pj03TAEzyob9wDsmVgTdT4J23byNhELeSfHWHWD1e1CSD12PpzR7HUlfz/GGO55+IyWDr2HP18vpdfxpMPsBCsscJafdAElt2PvpBI495zqKrBWtjz6tciBGcb43aibjIzjzNhj9IGQt8d7vPsOqx4nFL7L3mIvp3PMYNrz3CCVFBXQYdCF9u3f26tH7VO+YJbf1Ph/A5xm7OLFne3p19BspS/9F4b4dWFEuiYMuo3jJJLZbL47p1Y1WRw32RmxtnOuV/fZvoVU7MrLzOKFHu2rX/tRWQ3XdxDXQh4tr142ISAvQUF03WRAxWKWvnxa1jJklAZ3wTsqKiEgjiSXQLwYGmFl/M2sFXAdUvQ75XcC/QQzXAHNcLMN8RESkzuo9jt45V2pmtwMf4g2vnOicW2lmDwBpzrl3gZeAV8wsA9iD92UgIiKNKKYLppxz04HpVdLuCZsuhIhrc0REpJEF/xYIIiItnAK9iEjAKdCLiAScAr2ISMDFdFOzhmJmOUB9L43tDtT+Vo/BoH1uGbTPwRfL/h7nnIt6I85mGehjYWZpNV0dFlTa55ZB+xx8DbW/6roREQk4BXoRkYALYqCf0NQVaALa55ZB+xx8DbK/geujFxGRSEFs0YuISBgFehGRgAtMoDez0Wa21swyzOyupq5PvJjZMWY218xWmdlKM/uFn97VzGaZ2Xr/tYufbmb2lP8+LDezM5p2D+rPzBLN7Esze8+f729mC/19e8O/PTZm1tqfz/Dz+zVpxevJzDqb2RQzW2Nmq83s7KAfZzP7lf+5TjezyWaWErTjbGYTzSzbfxBTeVqdj6uZ3eyXX29mN0fbVk0CEej9B5U/C1wKnAJcb2anNG2t4qYU+D/n3CnAWcDP/H27C5jtnBsAzPbnwXsPBvh/44DnGr/KcfMLYHXY/N+Ax51zJwJ7gVv89FuAvX764365I9GTwAfOuZOBoXj7HtjjbGZHAz8HUp1zQ/Bud34dwTvOLwNVH2pcp+NqZl2Be4Ez8Z7XfW/5l0OtOOeO+D/gbODDsPm7gbubul4NtK//Bi4G1gJH+WlHAWv96eeB68PKV5Q7kv7wnlg2G7gAeA8wvCsGk6oec7xnIpztTyf55ayp96GO+9sJ+LpqvYN8nIGjga1AV/+4vQdcEsTjDPQD0ut7XIHrgefD0iPKHe4vEC16Kj8w5TL9tEDxf6qeDiwEejnntvtZO4Be/nRQ3osngF8DIX++G7DPOVfqz4fvV8U++/m5fvkjSX8gB/iH3131opm1I8DH2TmXBTwCbAG24x23JQT7OJer63GN6XgHJdAHnpm1B6YCv3TO7Q/Pc95XfGDGyZrZ5UC2c25JU9elESUBZwDPOedOBw5S+XMeCORx7gJcgfcl1wdoR/UujsBrjOMalEBfmweVH7HMLBkvyL/mnHvbT95pZkf5+UcB2X56EN6Lc4CxZrYJeB2v++ZJoLP/kHmI3K8gPIQ+E8h0zi3056fgBf4gH+eLgK+dcznOuRLgbbxjH+TjXK6uxzWm4x2UQF+bB5UfkczM8J69u9o591hYVviD12/G67svT7/JP3t/FpAb9hPxiOCcu9s519c51w/vWM5xzt0AzMV7yDxU3+cj+iH0zrkdwFYzG+gnXQisIsDHGa/L5iwza+t/zsv3ObDHOUxdj+uHwCgz6+L/Ehrlp9VOU5+kiOPJjjHAOmAD8Lumrk8c9+tcvJ91y4Fl/t8YvL7J2cB64COgq1/e8EYgbQBW4I1oaPL9iGH/zwfe86ePBxYBGcBbQGs/PcWfz/Dzj2/qetdzX4cBaf6xngZ0CfpxBu4H1gDpwCtA66AdZ2Ay3jmIErxfbrfU57gCP/L3PQP477rUQbdAEBEJuKB03YiISA0U6EVEAk6BXkQk4BToRUQCToFeRCTgFOhFRAJOgV5EJOD+P+yR8wcSxWJ0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "import random\n",
    "\n",
    "EPOCHS = 1000\n",
    "\n",
    "losses = []\n",
    "val_losses = []\n",
    "\n",
    "for a in range(EPOCHS):\n",
    "    \n",
    "    print('EPOCH: ' + str(a+1) +  ' OUT OF ' + str(EPOCHS))\n",
    "\n",
    "    rand_int = random.randint(0, 522)\n",
    "\n",
    "    values = list_of_scaled_training_df[rand_int]\n",
    "\n",
    "    n_train_hours = 21\n",
    "    train = values[:n_train_hours, :]\n",
    "    test = values[n_train_hours:, :]\n",
    "\n",
    "    train_X, train_y = train[:, :-1], train[:, -1]\n",
    "    test_X, test_y = test[:, :-1], test[:, -1]\n",
    "\n",
    "    train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "    test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "    print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "\n",
    "    # fit network\n",
    "    lstm_model.reset_states()\n",
    "    history = lstm_model.fit(train_X, train_y, epochs=1, batch_size=21, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "\n",
    "    for idx, h in enumerate(history.history['loss']):\n",
    "        losses.append(h)\n",
    "        val_losses.append(history.history['val_loss'])\n",
    "        \n",
    "# plot history\n",
    "pyplot.plot(losses, label='train')\n",
    "pyplot.plot(val_losses, label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Based on the num_predictions we choose, we predict on that many random time series and derive a resulting root mean square error\n",
    "\n",
    "# The resulting prediction is sufficiency rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import concatenate\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "num_predictions = 500\n",
    "\n",
    "summation = 0\n",
    "\n",
    "actual = []\n",
    "predicted = []\n",
    "\n",
    "for a in range(num_predictions):\n",
    "    \n",
    "    rand_int = random.randint(0, 522)\n",
    "\n",
    "    values = list_of_training_df[rand_int].values\n",
    "\n",
    "    n_train_hours = 21\n",
    "    train = values[:n_train_hours, :]\n",
    "    test = values[n_train_hours:, :]\n",
    "\n",
    "    train_X, train_y = train[:, :-1], train[:, -1]\n",
    "    test_X, test_y = test[:, :-1], test[:, -1]\n",
    "\n",
    "    train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "    test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "#     print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "\n",
    "    yhat = lstm_model.predict(test_X)\n",
    "    \n",
    "    actual.append(test_y[0])\n",
    "    predicted.append(yhat[0][0][0])\n",
    "    \n",
    "#     print(yhat[0][0][0])\n",
    "#     print(test_y[0])\n",
    "    \n",
    "#     difference = test_y[0] - yhat[0][0][0]\n",
    "#     squared_difference = difference**2\n",
    "#     summation = summation + squared_difference\n",
    "    \n",
    "mse = mean_squared_error(actual, predicted)\n",
    "rmse = math.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82.92668360875814"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Because we have individual time series for each bridge, we define an epoch number and for each epoch we train the model an a random bridge time series\n",
    "\n",
    "# At the end, we plot the loss and validation loss over time\n",
    "\n",
    "# This experiment is run without min max scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8495.0312 - val_loss: 8553.6826\n",
      "EPOCH: 2 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8928.0527 - val_loss: 10193.5762\n",
      "EPOCH: 3 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3674.9324 - val_loss: 3855.9839\n",
      "EPOCH: 4 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8629.5596 - val_loss: 9050.4902\n",
      "EPOCH: 5 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1657.6455 - val_loss: 1638.6844\n",
      "EPOCH: 6 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9591.2988 - val_loss: 9668.1504\n",
      "EPOCH: 7 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 10045.5059 - val_loss: 10142.7236\n",
      "EPOCH: 8 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6734.3252 - val_loss: 6727.3950\n",
      "EPOCH: 9 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4900.4360 - val_loss: 4895.1348\n",
      "EPOCH: 10 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6966.5288 - val_loss: 6975.5225\n",
      "EPOCH: 11 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7089.1572 - val_loss: 7084.8994\n",
      "EPOCH: 12 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1709.8380 - val_loss: 1693.2028\n",
      "EPOCH: 13 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9537.1475 - val_loss: 9753.5068\n",
      "EPOCH: 14 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2358.6045 - val_loss: 1241.8945\n",
      "EPOCH: 15 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8542.8096 - val_loss: 9684.7109\n",
      "EPOCH: 16 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1577.8440 - val_loss: 1604.2789\n",
      "EPOCH: 17 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8652.5215 - val_loss: 7161.1104\n",
      "EPOCH: 18 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5560.2295 - val_loss: 4760.7476\n",
      "EPOCH: 19 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5720.9067 - val_loss: 5715.9756\n",
      "EPOCH: 20 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9313.4697 - val_loss: 9744.3535\n",
      "EPOCH: 21 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7660.6602 - val_loss: 7960.7490\n",
      "EPOCH: 22 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6872.7061 - val_loss: 4493.7563\n",
      "EPOCH: 23 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5164.2900 - val_loss: 5267.4648\n",
      "EPOCH: 24 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8002.4048 - val_loss: 8225.2373\n",
      "EPOCH: 25 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6445.0044 - val_loss: 6530.8267\n",
      "EPOCH: 26 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8588.2949 - val_loss: 8400.6484\n",
      "EPOCH: 27 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6262.8022 - val_loss: 5668.9727\n",
      "EPOCH: 28 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9025.4658 - val_loss: 8972.2432\n",
      "EPOCH: 29 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8964.6484 - val_loss: 9230.5957\n",
      "EPOCH: 30 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6400.3193 - val_loss: 6485.6445\n",
      "EPOCH: 31 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8338.3184 - val_loss: 9490.3350\n",
      "EPOCH: 32 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7978.2695 - val_loss: 6029.2964\n",
      "EPOCH: 33 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9491.6230 - val_loss: 9501.5020\n",
      "EPOCH: 34 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8373.9219 - val_loss: 6032.1772\n",
      "EPOCH: 35 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7151.8906 - val_loss: 7318.6138\n",
      "EPOCH: 36 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5558.8994 - val_loss: 6146.7471\n",
      "EPOCH: 37 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5941.0146 - val_loss: 5649.7432\n",
      "EPOCH: 38 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8302.1768 - val_loss: 8547.5039\n",
      "EPOCH: 39 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6682.7231 - val_loss: 7119.7534\n",
      "EPOCH: 40 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5032.2505 - val_loss: 4756.7002\n",
      "EPOCH: 41 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3060.1729 - val_loss: 2987.6968\n",
      "EPOCH: 42 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5606.8564 - val_loss: 6546.0078\n",
      "EPOCH: 43 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8786.1191 - val_loss: 9087.6299\n",
      "EPOCH: 44 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8727.3643 - val_loss: 8668.1719\n",
      "EPOCH: 45 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9231.5596 - val_loss: 8872.2959\n",
      "EPOCH: 46 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4333.7969 - val_loss: 4330.4971\n",
      "EPOCH: 47 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4032.4412 - val_loss: 4340.2412\n",
      "EPOCH: 48 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3501.2683 - val_loss: 3142.0432\n",
      "EPOCH: 49 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5724.5439 - val_loss: 5749.5889\n",
      "EPOCH: 50 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5720.3252 - val_loss: 5745.1895\n",
      "EPOCH: 51 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1582.8062 - val_loss: 473.1444\n",
      "EPOCH: 52 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1914.4822 - val_loss: 1568.6439\n",
      "EPOCH: 53 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2077.2559 - val_loss: 1771.1221\n",
      "EPOCH: 54 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6911.6821 - val_loss: 6052.3789\n",
      "EPOCH: 55 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8257.0000 - val_loss: 5936.1045\n",
      "EPOCH: 56 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3887.5073 - val_loss: 3911.7297\n",
      "EPOCH: 57 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4683.8931 - val_loss: 4464.4067\n",
      "EPOCH: 58 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1804.4951 - val_loss: 56.0949\n",
      "EPOCH: 59 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6225.9014 - val_loss: 6223.0410\n",
      "EPOCH: 60 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8887.2539 - val_loss: 9208.7705\n",
      "EPOCH: 61 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8658.9824 - val_loss: 8495.9902\n",
      "EPOCH: 62 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3519.1072 - val_loss: 2535.8994\n",
      "EPOCH: 63 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5672.6318 - val_loss: 5698.9297\n",
      "EPOCH: 64 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1502.6478 - val_loss: 1495.5522\n",
      "EPOCH: 65 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8861.7070 - val_loss: 8784.6074\n",
      "EPOCH: 66 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6635.5615 - val_loss: 4308.2241\n",
      "EPOCH: 67 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9243.3975 - val_loss: 9238.7803\n",
      "EPOCH: 68 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9220.4150 - val_loss: 9190.4873\n",
      "EPOCH: 69 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8087.1675 - val_loss: 3704.7253\n",
      "EPOCH: 70 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3291.5476 - val_loss: 3489.4036\n",
      "EPOCH: 71 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6728.1680 - val_loss: 6781.8052\n",
      "EPOCH: 72 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4346.7471 - val_loss: 4399.8218\n",
      "EPOCH: 73 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6204.6494 - val_loss: 6182.2505\n",
      "EPOCH: 74 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2961.9294 - val_loss: 407.8237\n",
      "EPOCH: 75 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8722.4053 - val_loss: 8982.4033\n",
      "EPOCH: 76 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6276.4019 - val_loss: 6786.1772\n",
      "EPOCH: 77 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6391.4458 - val_loss: 6422.6860\n",
      "EPOCH: 78 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5895.4868 - val_loss: 5878.4185\n",
      "EPOCH: 79 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6419.9819 - val_loss: 6416.9805\n",
      "EPOCH: 80 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8930.7246 - val_loss: 8938.1230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 81 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9143.2881 - val_loss: 9136.7441\n",
      "EPOCH: 82 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9223.4775 - val_loss: 9217.8252\n",
      "EPOCH: 83 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8795.9658 - val_loss: 9143.8252\n",
      "EPOCH: 84 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8613.0078 - val_loss: 8299.5918\n",
      "EPOCH: 85 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7264.8789 - val_loss: 7670.3140\n",
      "EPOCH: 86 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5958.3916 - val_loss: 6155.5835\n",
      "EPOCH: 87 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9344.9512 - val_loss: 9473.7275\n",
      "EPOCH: 88 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9105.7852 - val_loss: 9100.5820\n",
      "EPOCH: 89 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5198.7100 - val_loss: 4731.8511\n",
      "EPOCH: 90 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6348.0884 - val_loss: 6378.4326\n",
      "EPOCH: 91 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7825.1035 - val_loss: 7819.0420\n",
      "EPOCH: 92 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7813.3750 - val_loss: 7812.8516\n",
      "EPOCH: 93 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9131.0830 - val_loss: 9075.0947\n",
      "EPOCH: 94 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3236.3840 - val_loss: 3432.4038\n",
      "EPOCH: 95 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6748.2568 - val_loss: 9006.5664\n",
      "EPOCH: 96 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8015.5894 - val_loss: 6589.1309\n",
      "EPOCH: 97 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6998.4727 - val_loss: 4308.1309\n",
      "EPOCH: 98 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9052.4307 - val_loss: 9046.3633\n",
      "EPOCH: 99 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8662.3984 - val_loss: 9039.8770\n",
      "EPOCH: 100 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 944.5096 - val_loss: 934.5380\n",
      "EPOCH: 101 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8848.4883 - val_loss: 9017.3301\n",
      "EPOCH: 102 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2913.2903 - val_loss: 386.5692\n",
      "EPOCH: 103 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7800.7695 - val_loss: 6486.8071\n",
      "EPOCH: 104 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8357.1875 - val_loss: 8458.9277\n",
      "EPOCH: 105 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7751.0430 - val_loss: 7763.5552\n",
      "EPOCH: 106 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8295.3408 - val_loss: 8311.3691\n",
      "EPOCH: 107 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8481.5771 - val_loss: 8321.4287\n",
      "EPOCH: 108 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7653.2886 - val_loss: 7670.8501\n",
      "EPOCH: 109 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8906.6172 - val_loss: 8895.5742\n",
      "EPOCH: 110 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8926.8301 - val_loss: 8822.5186\n",
      "EPOCH: 111 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8491.8799 - val_loss: 8883.0996\n",
      "EPOCH: 112 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8090.8896 - val_loss: 8948.2256\n",
      "EPOCH: 113 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3867.6653 - val_loss: 4170.1992\n",
      "EPOCH: 114 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8295.3545 - val_loss: 8403.9102\n",
      "EPOCH: 115 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6272.2490 - val_loss: 3976.4993\n",
      "EPOCH: 116 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8860.9434 - val_loss: 8855.1816\n",
      "EPOCH: 117 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8421.3936 - val_loss: 8261.1816\n",
      "EPOCH: 118 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6405.3848 - val_loss: 5680.4004\n",
      "EPOCH: 119 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7807.0952 - val_loss: 3414.1809\n",
      "EPOCH: 120 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8964.7891 - val_loss: 9255.0205\n",
      "EPOCH: 121 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1744.5479 - val_loss: 1556.1078\n",
      "EPOCH: 122 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5249.8804 - val_loss: 5033.0791\n",
      "EPOCH: 123 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8820.6338 - val_loss: 8814.7207\n",
      "EPOCH: 124 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6132.6050 - val_loss: 6130.1367\n",
      "EPOCH: 125 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8468.3203 - val_loss: 8448.0615\n",
      "EPOCH: 126 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8819.4268 - val_loss: 8798.9482\n",
      "EPOCH: 127 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8164.0493 - val_loss: 8174.0474\n",
      "EPOCH: 128 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7532.6118 - val_loss: 5663.8530\n",
      "EPOCH: 129 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6342.9556 - val_loss: 5628.0698\n",
      "EPOCH: 130 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4249.9658 - val_loss: 4376.3164\n",
      "EPOCH: 131 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3637.1897 - val_loss: 3442.9146\n",
      "EPOCH: 132 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8426.3457 - val_loss: 4430.6406\n",
      "EPOCH: 133 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5532.8457 - val_loss: 4891.1450\n",
      "EPOCH: 134 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8274.7246 - val_loss: 8282.6328\n",
      "EPOCH: 135 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3633.9160 - val_loss: 2459.4590\n",
      "EPOCH: 136 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8749.3232 - val_loss: 8734.4219\n",
      "EPOCH: 137 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6040.3462 - val_loss: 6127.3125\n",
      "EPOCH: 138 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 9044.4092 - val_loss: 9055.3018\n",
      "EPOCH: 139 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6179.0288 - val_loss: 3914.9324\n",
      "EPOCH: 140 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8377.5391 - val_loss: 8454.2109\n",
      "EPOCH: 141 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3069.3555 - val_loss: 3240.3748\n",
      "EPOCH: 142 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7463.2100 - val_loss: 7487.5225\n",
      "EPOCH: 143 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4640.3027 - val_loss: 4672.2114\n",
      "EPOCH: 144 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8512.0879 - val_loss: 8418.3369\n",
      "EPOCH: 145 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7007.3140 - val_loss: 6929.8916\n",
      "EPOCH: 146 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2393.0442 - val_loss: 2480.8303\n",
      "EPOCH: 147 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5159.6943 - val_loss: 2701.2585\n",
      "EPOCH: 148 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3318.2634 - val_loss: 3315.7351\n",
      "EPOCH: 149 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8636.5625 - val_loss: 8653.4834\n",
      "EPOCH: 150 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8024.7290 - val_loss: 8011.9272\n",
      "EPOCH: 151 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8649.0029 - val_loss: 8588.5938\n",
      "EPOCH: 152 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4050.7761 - val_loss: 4837.3662\n",
      "EPOCH: 153 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8665.6318 - val_loss: 8651.6172\n",
      "EPOCH: 154 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6082.3027 - val_loss: 6079.4185\n",
      "EPOCH: 155 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7364.2441 - val_loss: 3152.1235\n",
      "EPOCH: 156 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5392.8838 - val_loss: 5393.0498\n",
      "EPOCH: 157 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2041.3392 - val_loss: 1819.0760\n",
      "EPOCH: 158 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8329.2422 - val_loss: 8373.7148\n",
      "EPOCH: 159 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3842.8442 - val_loss: 2945.2734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 160 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8000.0054 - val_loss: 6683.2598\n",
      "EPOCH: 161 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8830.2480 - val_loss: 8992.6133\n",
      "EPOCH: 162 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8455.4912 - val_loss: 8428.8652\n",
      "EPOCH: 163 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4360.7539 - val_loss: 4358.9985\n",
      "EPOCH: 164 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1327.2744 - val_loss: 334.0136\n",
      "EPOCH: 165 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5076.2891 - val_loss: 4863.2681\n",
      "EPOCH: 166 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8596.6934 - val_loss: 8627.7227\n",
      "EPOCH: 167 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8627.7227 - val_loss: 8623.3096\n",
      "EPOCH: 168 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5263.8442 - val_loss: 5346.5361\n",
      "EPOCH: 169 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3709.3433 - val_loss: 2558.0469\n",
      "EPOCH: 170 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5980.0469 - val_loss: 3148.2563\n",
      "EPOCH: 171 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5295.6694 - val_loss: 5475.6973\n",
      "EPOCH: 172 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7872.1445 - val_loss: 7846.4844\n",
      "EPOCH: 173 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 814.5540 - val_loss: 6.2674\n",
      "EPOCH: 174 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6452.7041 - val_loss: 6338.6060\n",
      "EPOCH: 175 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4487.7495 - val_loss: 4604.3926\n",
      "EPOCH: 176 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5211.6958 - val_loss: 5207.2612\n",
      "EPOCH: 177 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6021.0073 - val_loss: 5851.3184\n",
      "EPOCH: 178 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3201.4075 - val_loss: 3199.2708\n",
      "EPOCH: 179 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4627.2837 - val_loss: 5284.3267\n",
      "EPOCH: 180 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 820.4235 - val_loss: 819.3619\n",
      "EPOCH: 181 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5422.6885 - val_loss: 5396.2573\n",
      "EPOCH: 182 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2467.0925 - val_loss: 2268.4272\n",
      "EPOCH: 183 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8864.5459 - val_loss: 8832.1855\n",
      "EPOCH: 184 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5487.9258 - val_loss: 4135.9517\n",
      "EPOCH: 185 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5447.3408 - val_loss: 5176.8076\n",
      "EPOCH: 186 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1237.1038 - val_loss: 1235.8495\n",
      "EPOCH: 187 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8068.2979 - val_loss: 8323.8828\n",
      "EPOCH: 188 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3134.3721 - val_loss: 3396.7014\n",
      "EPOCH: 189 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5890.1099 - val_loss: 5851.9404\n",
      "EPOCH: 190 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8067.0156 - val_loss: 8043.7954\n",
      "EPOCH: 191 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3295.3848 - val_loss: 2783.5056\n",
      "EPOCH: 192 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2744.2214 - val_loss: 314.8677\n",
      "EPOCH: 193 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7932.0898 - val_loss: 8026.5928\n",
      "EPOCH: 194 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2344.5569 - val_loss: 2342.6880\n",
      "EPOCH: 195 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8011.0000 - val_loss: 8000.6934\n",
      "EPOCH: 196 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5958.1118 - val_loss: 5791.7705\n",
      "EPOCH: 197 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4249.4834 - val_loss: 3283.1624\n",
      "EPOCH: 198 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3029.7339 - val_loss: 3027.6177\n",
      "EPOCH: 199 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6165.9854 - val_loss: 6162.8252\n",
      "EPOCH: 200 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8187.2666 - val_loss: 8159.1689\n",
      "EPOCH: 201 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1978.0487 - val_loss: 1959.2031\n",
      "EPOCH: 202 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6096.5239 - val_loss: 5391.0005\n",
      "EPOCH: 203 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8172.7305 - val_loss: 8232.4307\n",
      "EPOCH: 204 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5766.4600 - val_loss: 8028.5933\n",
      "EPOCH: 205 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5885.1401 - val_loss: 3657.9761\n",
      "EPOCH: 206 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6089.6934 - val_loss: 5821.3574\n",
      "EPOCH: 207 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7179.9585 - val_loss: 5135.1880\n",
      "EPOCH: 208 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4385.9863 - val_loss: 4417.0088\n",
      "EPOCH: 209 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2599.7231 - val_loss: 2631.3362\n",
      "EPOCH: 210 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6239.0918 - val_loss: 6252.8696\n",
      "EPOCH: 211 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5376.3271 - val_loss: 4436.0122\n",
      "EPOCH: 212 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8430.3896 - val_loss: 8444.2529\n",
      "EPOCH: 213 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8719.3359 - val_loss: 8725.2461\n",
      "EPOCH: 214 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5030.3140 - val_loss: 5920.2158\n",
      "EPOCH: 215 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4080.7344 - val_loss: 4619.1411\n",
      "EPOCH: 216 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7151.5254 - val_loss: 7576.1860\n",
      "EPOCH: 217 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2313.5569 - val_loss: 2311.5198\n",
      "EPOCH: 218 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5773.0552 - val_loss: 5760.5264\n",
      "EPOCH: 219 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6030.7314 - val_loss: 5452.4839\n",
      "EPOCH: 220 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7768.8867 - val_loss: 7657.2969\n",
      "EPOCH: 221 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6877.6743 - val_loss: 6778.8145\n",
      "EPOCH: 222 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2997.5496 - val_loss: 3244.2251\n",
      "EPOCH: 223 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7276.5010 - val_loss: 7515.4873\n",
      "EPOCH: 224 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5892.6426 - val_loss: 5889.5728\n",
      "EPOCH: 225 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7889.4072 - val_loss: 7896.9917\n",
      "EPOCH: 226 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8612.9355 - val_loss: 8612.3252\n",
      "EPOCH: 227 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2112.5361 - val_loss: 2104.0444\n",
      "EPOCH: 228 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4339.0820 - val_loss: 1458.1299\n",
      "EPOCH: 229 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5312.3179 - val_loss: 5265.6152\n",
      "EPOCH: 230 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3640.1123 - val_loss: 3436.0928\n",
      "EPOCH: 231 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8111.3936 - val_loss: 8267.1592\n",
      "EPOCH: 232 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6839.4888 - val_loss: 6740.8066\n",
      "EPOCH: 233 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5542.1211 - val_loss: 4043.8633\n",
      "EPOCH: 234 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8366.1689 - val_loss: 8362.5537\n",
      "EPOCH: 235 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6080.1519 - val_loss: 6227.9351\n",
      "EPOCH: 236 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2962.5818 - val_loss: 2960.5962\n",
      "EPOCH: 237 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6129.9893 - val_loss: 6240.9639\n",
      "EPOCH: 238 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5793.6367 - val_loss: 5848.1851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 239 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5707.6675 - val_loss: 5693.8926\n",
      "EPOCH: 240 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7797.0708 - val_loss: 8214.7646\n",
      "EPOCH: 241 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7910.3306 - val_loss: 7961.1616\n",
      "EPOCH: 242 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7132.7271 - val_loss: 5897.4399\n",
      "EPOCH: 243 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7382.2856 - val_loss: 7880.5537\n",
      "EPOCH: 244 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 727.7664 - val_loss: 721.0027\n",
      "EPOCH: 245 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3341.0227 - val_loss: 2574.3113\n",
      "EPOCH: 246 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5890.8271 - val_loss: 5932.1714\n",
      "EPOCH: 247 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8230.6816 - val_loss: 8220.6143\n",
      "EPOCH: 248 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1522.7900 - val_loss: 10.7901\n",
      "EPOCH: 249 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 999.0421 - val_loss: 938.5971\n",
      "EPOCH: 250 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2676.4331 - val_loss: 2824.2563\n",
      "EPOCH: 251 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3977.5042 - val_loss: 3974.7563\n",
      "EPOCH: 252 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8163.5669 - val_loss: 8207.7471\n",
      "EPOCH: 253 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7328.1406 - val_loss: 7847.0884\n",
      "EPOCH: 254 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1538.7053 - val_loss: 10.1784\n",
      "EPOCH: 255 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8298.0713 - val_loss: 8294.6777\n",
      "EPOCH: 256 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5052.6729 - val_loss: 5077.8921\n",
      "EPOCH: 257 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7015.9385 - val_loss: 7432.8110\n",
      "EPOCH: 258 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6742.1802 - val_loss: 6684.2612\n",
      "EPOCH: 259 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8301.2373 - val_loss: 8269.0684\n",
      "EPOCH: 260 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8281.4551 - val_loss: 8277.5537\n",
      "EPOCH: 261 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7798.3438 - val_loss: 7854.3730\n",
      "EPOCH: 262 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5563.9448 - val_loss: 5957.6216\n",
      "EPOCH: 263 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4854.5571 - val_loss: 3504.8130\n",
      "EPOCH: 264 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8101.6396 - val_loss: 8249.2119\n",
      "EPOCH: 265 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8173.8208 - val_loss: 8102.8813\n",
      "EPOCH: 266 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5869.6494 - val_loss: 3756.3538\n",
      "EPOCH: 267 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5647.9312 - val_loss: 2901.8384\n",
      "EPOCH: 268 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2616.1609 - val_loss: 418.3506\n",
      "EPOCH: 269 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8132.5112 - val_loss: 8454.4502\n",
      "EPOCH: 270 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8316.7383 - val_loss: 8475.2861\n",
      "EPOCH: 271 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8020.2217 - val_loss: 8073.9902\n",
      "EPOCH: 272 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6050.4019 - val_loss: 3834.1836\n",
      "EPOCH: 273 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7820.0552 - val_loss: 7251.6689\n",
      "EPOCH: 274 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6468.9004 - val_loss: 6336.9165\n",
      "EPOCH: 275 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7580.8369 - val_loss: 7639.1338\n",
      "EPOCH: 276 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2046.6252 - val_loss: 608.2805\n",
      "EPOCH: 277 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6592.9243 - val_loss: 5564.1958\n",
      "EPOCH: 278 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7902.6235 - val_loss: 8208.4922\n",
      "EPOCH: 279 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7537.0610 - val_loss: 7407.4160\n",
      "EPOCH: 280 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8049.5303 - val_loss: 7931.9048\n",
      "EPOCH: 281 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7448.2100 - val_loss: 8270.2158\n",
      "EPOCH: 282 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4311.2798 - val_loss: 4058.2107\n",
      "EPOCH: 283 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 942.4968 - val_loss: 892.6600\n",
      "EPOCH: 284 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7571.2539 - val_loss: 7648.3960\n",
      "EPOCH: 285 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6837.7612 - val_loss: 6834.8989\n",
      "EPOCH: 286 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4284.1743 - val_loss: 4281.1890\n",
      "EPOCH: 287 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6682.2373 - val_loss: 6194.8496\n",
      "EPOCH: 288 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3075.8823 - val_loss: 2581.6372\n",
      "EPOCH: 289 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2618.6113 - val_loss: 2469.1211\n",
      "EPOCH: 290 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3786.7175 - val_loss: 3246.0334\n",
      "EPOCH: 291 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7956.2617 - val_loss: 7991.9292\n",
      "EPOCH: 292 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3890.7202 - val_loss: 3888.3064\n",
      "EPOCH: 293 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2064.7166 - val_loss: 2095.7305\n",
      "EPOCH: 294 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7558.0640 - val_loss: 7440.3271\n",
      "EPOCH: 295 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5372.1011 - val_loss: 8026.1543\n",
      "EPOCH: 296 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7815.2041 - val_loss: 7324.9775\n",
      "EPOCH: 297 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6267.5898 - val_loss: 6379.3672\n",
      "EPOCH: 298 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2054.9751 - val_loss: 2085.8989\n",
      "EPOCH: 299 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2472.5117 - val_loss: 2074.8911\n",
      "EPOCH: 300 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5976.5444 - val_loss: 5868.2329\n",
      "EPOCH: 301 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4798.7729 - val_loss: 2810.2007\n",
      "EPOCH: 302 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4603.8042 - val_loss: 4633.5195\n",
      "EPOCH: 303 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2798.2810 - val_loss: 1478.6161\n",
      "EPOCH: 304 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6900.1606 - val_loss: 6878.1899\n",
      "EPOCH: 305 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8096.4019 - val_loss: 8123.0518\n",
      "EPOCH: 306 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7124.3696 - val_loss: 5746.4028\n",
      "EPOCH: 307 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7548.4854 - val_loss: 7500.3369\n",
      "EPOCH: 308 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7683.0312 - val_loss: 8057.2222\n",
      "EPOCH: 309 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7457.7500 - val_loss: 7577.3564\n",
      "EPOCH: 310 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2954.2542 - val_loss: 2919.4521\n",
      "EPOCH: 311 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7517.9165 - val_loss: 7379.2964\n",
      "EPOCH: 312 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4889.3086 - val_loss: 4990.4321\n",
      "EPOCH: 313 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7688.8481 - val_loss: 7583.0518\n",
      "EPOCH: 314 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1892.8470 - val_loss: 1568.4448\n",
      "EPOCH: 315 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3839.9136 - val_loss: 4362.1636\n",
      "EPOCH: 316 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3346.0234 - val_loss: 3634.3782\n",
      "EPOCH: 317 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7287.6353 - val_loss: 7176.1318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 318 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5122.1646 - val_loss: 5119.3550\n",
      "EPOCH: 319 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3582.8113 - val_loss: 3750.2986\n",
      "EPOCH: 320 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7278.8125 - val_loss: 7167.3110\n",
      "EPOCH: 321 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 650.9158 - val_loss: 650.0309\n",
      "EPOCH: 322 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7975.7686 - val_loss: 8006.0459\n",
      "EPOCH: 323 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4223.8325 - val_loss: 4838.2153\n",
      "EPOCH: 324 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2399.0403 - val_loss: 2397.6343\n",
      "EPOCH: 325 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4766.7778 - val_loss: 4622.6802\n",
      "EPOCH: 326 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2154.5369 - val_loss: 2152.7109\n",
      "EPOCH: 327 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7375.4844 - val_loss: 7653.2690\n",
      "EPOCH: 328 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4070.6831 - val_loss: 4457.2485\n",
      "EPOCH: 329 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8076.0068 - val_loss: 8284.2686\n",
      "EPOCH: 330 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7457.1475 - val_loss: 7398.3755\n",
      "EPOCH: 331 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2595.5791 - val_loss: 2765.2390\n",
      "EPOCH: 332 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4613.2769 - val_loss: 4658.6875\n",
      "EPOCH: 333 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5704.2100 - val_loss: 5823.8540\n",
      "EPOCH: 334 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6177.4102 - val_loss: 6615.6636\n",
      "EPOCH: 335 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7503.9644 - val_loss: 6850.9634\n",
      "EPOCH: 336 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7280.0073 - val_loss: 6044.5986\n",
      "EPOCH: 337 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7778.3057 - val_loss: 7712.7852\n",
      "EPOCH: 338 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5685.4531 - val_loss: 5695.7163\n",
      "EPOCH: 339 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1591.9900 - val_loss: 1419.4844\n",
      "EPOCH: 340 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4180.9761 - val_loss: 3073.3931\n",
      "EPOCH: 341 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5627.9258 - val_loss: 5718.9551\n",
      "EPOCH: 342 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 951.7153 - val_loss: 973.6614\n",
      "EPOCH: 343 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7340.6118 - val_loss: 7267.9399\n",
      "EPOCH: 344 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4216.0195 - val_loss: 1570.6945\n",
      "EPOCH: 345 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5523.8853 - val_loss: 5557.9487\n",
      "EPOCH: 346 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3745.9189 - val_loss: 3702.9080\n",
      "EPOCH: 347 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7698.6929 - val_loss: 7781.0015\n",
      "EPOCH: 348 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1035.1451 - val_loss: 184.0446\n",
      "EPOCH: 349 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6537.1250 - val_loss: 6477.4131\n",
      "EPOCH: 350 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7536.1577 - val_loss: 7244.4526\n",
      "EPOCH: 351 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6739.5352 - val_loss: 7833.8677\n",
      "EPOCH: 352 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4904.2861 - val_loss: 6075.2983\n",
      "EPOCH: 353 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5333.9619 - val_loss: 5034.0610\n",
      "EPOCH: 354 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4569.8618 - val_loss: 4615.0010\n",
      "EPOCH: 355 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7153.8052 - val_loss: 7804.3984\n",
      "EPOCH: 356 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 866.8608 - val_loss: 865.6355\n",
      "EPOCH: 357 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5470.9150 - val_loss: 5489.6172\n",
      "EPOCH: 358 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6917.4731 - val_loss: 8104.0996\n",
      "EPOCH: 359 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2589.9854 - val_loss: 2575.8491\n",
      "EPOCH: 360 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7692.7803 - val_loss: 7803.5532\n",
      "EPOCH: 361 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5464.6709 - val_loss: 7933.4487\n",
      "EPOCH: 362 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5893.2412 - val_loss: 4509.3267\n",
      "EPOCH: 363 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7202.5791 - val_loss: 7294.0840\n",
      "EPOCH: 364 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6112.8423 - val_loss: 6223.1890\n",
      "EPOCH: 365 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1538.0103 - val_loss: 1378.7715\n",
      "EPOCH: 366 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7885.9932 - val_loss: 8042.1548\n",
      "EPOCH: 367 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5659.9990 - val_loss: 5691.3262\n",
      "EPOCH: 368 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3124.1599 - val_loss: 2073.9883\n",
      "EPOCH: 369 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6809.0298 - val_loss: 5498.6763\n",
      "EPOCH: 370 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7100.9092 - val_loss: 7903.9170\n",
      "EPOCH: 371 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7259.8809 - val_loss: 7331.3623\n",
      "EPOCH: 372 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7195.3184 - val_loss: 7167.0864\n",
      "EPOCH: 373 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7376.2710 - val_loss: 7325.3237\n",
      "EPOCH: 374 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6495.3906 - val_loss: 6182.6919\n",
      "EPOCH: 375 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7671.7158 - val_loss: 7642.7563\n",
      "EPOCH: 376 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5041.3726 - val_loss: 8015.9922\n",
      "EPOCH: 377 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7691.9712 - val_loss: 7204.3486\n",
      "EPOCH: 378 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1538.5737 - val_loss: 657.9880\n",
      "EPOCH: 379 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5581.9414 - val_loss: 3891.1951\n",
      "EPOCH: 380 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2443.6230 - val_loss: 184.9275\n",
      "EPOCH: 381 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7308.5967 - val_loss: 3650.7605\n",
      "EPOCH: 382 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3587.7183 - val_loss: 3585.3162\n",
      "EPOCH: 383 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7318.3223 - val_loss: 6268.6885\n",
      "EPOCH: 384 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2203.7400 - val_loss: 2235.3604\n",
      "EPOCH: 385 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5001.8354 - val_loss: 4805.0190\n",
      "EPOCH: 386 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5359.6104 - val_loss: 5402.8535\n",
      "EPOCH: 387 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5402.8535 - val_loss: 5400.4634\n",
      "EPOCH: 388 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7666.4717 - val_loss: 7684.6709\n",
      "EPOCH: 389 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5377.3340 - val_loss: 5396.5396\n",
      "EPOCH: 390 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5950.1836 - val_loss: 6058.9072\n",
      "EPOCH: 391 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7727.0586 - val_loss: 7788.8960\n",
      "EPOCH: 392 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 8060.5996 - val_loss: 8095.8491\n",
      "EPOCH: 393 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 835.9630 - val_loss: 834.2726\n",
      "EPOCH: 394 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5187.0171 - val_loss: 5185.5010\n",
      "EPOCH: 395 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7141.5254 - val_loss: 7247.2451\n",
      "EPOCH: 396 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7642.5225 - val_loss: 7658.0366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 397 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7424.1323 - val_loss: 7328.2935\n",
      "EPOCH: 398 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7285.9229 - val_loss: 6875.5933\n",
      "EPOCH: 399 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7330.9492 - val_loss: 7399.8623\n",
      "EPOCH: 400 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5298.5156 - val_loss: 5355.1938\n",
      "EPOCH: 401 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3947.4006 - val_loss: 3888.5276\n",
      "EPOCH: 402 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 869.2807 - val_loss: 890.5027\n",
      "EPOCH: 403 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7540.2856 - val_loss: 7650.2178\n",
      "EPOCH: 404 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4402.9502 - val_loss: 3125.2417\n",
      "EPOCH: 405 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5860.1509 - val_loss: 6087.8911\n",
      "EPOCH: 406 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6432.2837 - val_loss: 4477.6938\n",
      "EPOCH: 407 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3007.4004 - val_loss: 3008.2795\n",
      "EPOCH: 408 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4851.6006 - val_loss: 5170.5942\n",
      "EPOCH: 409 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2333.3330 - val_loss: 2169.6372\n",
      "EPOCH: 410 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3619.5417 - val_loss: 3825.2180\n",
      "EPOCH: 411 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3915.6255 - val_loss: 2844.0310\n",
      "EPOCH: 412 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7172.2344 - val_loss: 7087.2065\n",
      "EPOCH: 413 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7192.9316 - val_loss: 7436.9175\n",
      "EPOCH: 414 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1042.1427 - val_loss: 790.7092\n",
      "EPOCH: 415 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3249.3687 - val_loss: 3385.7607\n",
      "EPOCH: 416 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6877.4600 - val_loss: 7414.8457\n",
      "EPOCH: 417 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6375.0312 - val_loss: 6334.4497\n",
      "EPOCH: 418 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7483.6450 - val_loss: 7516.1831\n",
      "EPOCH: 419 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6683.8711 - val_loss: 7391.8120\n",
      "EPOCH: 420 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7555.9390 - val_loss: 7573.6260\n",
      "EPOCH: 421 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3257.3472 - val_loss: 3350.3223\n",
      "EPOCH: 422 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2488.2109 - val_loss: 2486.4734\n",
      "EPOCH: 423 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7379.4517 - val_loss: 7524.9668\n",
      "EPOCH: 424 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7734.4800 - val_loss: 7643.5752\n",
      "EPOCH: 425 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4951.4761 - val_loss: 5420.6562\n",
      "EPOCH: 426 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 530.1555 - val_loss: 529.2560\n",
      "EPOCH: 427 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2443.9019 - val_loss: 2442.0618\n",
      "EPOCH: 428 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2435.8665 - val_loss: 2496.7898\n",
      "EPOCH: 429 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6478.1011 - val_loss: 2596.2776\n",
      "EPOCH: 430 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1685.2863 - val_loss: 925.9386\n",
      "EPOCH: 431 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5235.5000 - val_loss: 7559.4556\n",
      "EPOCH: 432 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4847.3398 - val_loss: 7796.3071\n",
      "EPOCH: 433 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7226.1079 - val_loss: 7388.8843\n",
      "EPOCH: 434 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5038.8066 - val_loss: 3012.8789\n",
      "EPOCH: 435 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7543.2368 - val_loss: 7539.5923\n",
      "EPOCH: 436 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7027.6069 - val_loss: 7023.9355\n",
      "EPOCH: 437 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4808.3140 - val_loss: 4793.0322\n",
      "EPOCH: 438 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4805.6055 - val_loss: 4790.3047\n",
      "EPOCH: 439 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6445.5664 - val_loss: 2575.3066\n",
      "EPOCH: 440 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4738.2310 - val_loss: 7305.4888\n",
      "EPOCH: 441 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6606.3477 - val_loss: 7682.8369\n",
      "EPOCH: 442 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3547.0398 - val_loss: 2660.6934\n",
      "EPOCH: 443 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5409.9243 - val_loss: 3307.6172\n",
      "EPOCH: 444 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1296.1611 - val_loss: 1.9814\n",
      "EPOCH: 445 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6716.0371 - val_loss: 7288.9805\n",
      "EPOCH: 446 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7183.2915 - val_loss: 7121.8447\n",
      "EPOCH: 447 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3396.2458 - val_loss: 3885.6550\n",
      "EPOCH: 448 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4718.0210 - val_loss: 4727.4907\n",
      "EPOCH: 449 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5529.4741 - val_loss: 3157.9902\n",
      "EPOCH: 450 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2060.4304 - val_loss: 2026.8025\n",
      "EPOCH: 451 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1666.2742 - val_loss: 1664.7150\n",
      "EPOCH: 452 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2230.6187 - val_loss: 3442.6047\n",
      "EPOCH: 453 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4903.5039 - val_loss: 4934.2222\n",
      "EPOCH: 454 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4489.7129 - val_loss: 4589.4658\n",
      "EPOCH: 455 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7434.2798 - val_loss: 7452.1182\n",
      "EPOCH: 456 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6966.0215 - val_loss: 6972.0234\n",
      "EPOCH: 457 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7039.2114 - val_loss: 6445.4146\n",
      "EPOCH: 458 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1655.1339 - val_loss: 1653.4323\n",
      "EPOCH: 459 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4524.8389 - val_loss: 4491.0103\n",
      "EPOCH: 460 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6323.5210 - val_loss: 6661.0015\n",
      "EPOCH: 461 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6363.7930 - val_loss: 2529.4253\n",
      "EPOCH: 462 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3583.8667 - val_loss: 3943.7771\n",
      "EPOCH: 463 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6305.4077 - val_loss: 4480.9702\n",
      "EPOCH: 464 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7033.0386 - val_loss: 7283.5894\n",
      "EPOCH: 465 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3258.9900 - val_loss: 2756.3982\n",
      "EPOCH: 466 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5952.8662 - val_loss: 5548.4414\n",
      "EPOCH: 467 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 708.3010 - val_loss: 680.0143\n",
      "EPOCH: 468 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6233.5835 - val_loss: 4309.5151\n",
      "EPOCH: 469 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4755.0962 - val_loss: 4752.3315\n",
      "EPOCH: 470 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4265.6646 - val_loss: 4277.8018\n",
      "EPOCH: 471 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4478.1274 - val_loss: 3982.2673\n",
      "EPOCH: 472 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7379.8394 - val_loss: 7408.5332\n",
      "EPOCH: 473 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3372.4546 - val_loss: 3369.9556\n",
      "EPOCH: 474 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7066.0312 - val_loss: 7059.1045\n",
      "EPOCH: 475 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4633.3481 - val_loss: 4496.7627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 476 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7369.4346 - val_loss: 7361.2427\n",
      "EPOCH: 477 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4595.2290 - val_loss: 4490.8618\n",
      "EPOCH: 478 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6608.6992 - val_loss: 6361.4805\n",
      "EPOCH: 479 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3991.1980 - val_loss: 3024.6995\n",
      "EPOCH: 480 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2070.3132 - val_loss: 3228.5908\n",
      "EPOCH: 481 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3685.2693 - val_loss: 3682.9236\n",
      "EPOCH: 482 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7398.5479 - val_loss: 7477.7510\n",
      "EPOCH: 483 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6706.1069 - val_loss: 6697.1470\n",
      "EPOCH: 484 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7205.7856 - val_loss: 7363.1909\n",
      "EPOCH: 485 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4135.5879 - val_loss: 4940.5244\n",
      "EPOCH: 486 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4111.3364 - val_loss: 4368.0571\n",
      "EPOCH: 487 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7276.6050 - val_loss: 7352.0693\n",
      "EPOCH: 488 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5468.6104 - val_loss: 4863.7505\n",
      "EPOCH: 489 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7154.7261 - val_loss: 7047.1846\n",
      "EPOCH: 490 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7161.8525 - val_loss: 7173.4741\n",
      "EPOCH: 491 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7181.7515 - val_loss: 7192.1987\n",
      "EPOCH: 492 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6289.9365 - val_loss: 6520.7573\n",
      "EPOCH: 493 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7266.5708 - val_loss: 7234.9565\n",
      "EPOCH: 494 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4505.4116 - val_loss: 4725.9077\n",
      "EPOCH: 495 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6924.6890 - val_loss: 7071.9346\n",
      "EPOCH: 496 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3967.5710 - val_loss: 3994.7468\n",
      "EPOCH: 497 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5929.0449 - val_loss: 5888.5342\n",
      "EPOCH: 498 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5180.3735 - val_loss: 5426.2759\n",
      "EPOCH: 499 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4424.6489 - val_loss: 3474.2720\n",
      "EPOCH: 500 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 768.1893 - val_loss: 763.0778\n",
      "EPOCH: 501 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6502.7671 - val_loss: 6400.6924\n",
      "EPOCH: 502 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5775.7656 - val_loss: 5515.7568\n",
      "EPOCH: 503 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3651.4346 - val_loss: 2617.8694\n",
      "EPOCH: 504 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3361.5034 - val_loss: 3356.0728\n",
      "EPOCH: 505 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5298.8159 - val_loss: 2439.4866\n",
      "EPOCH: 506 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6840.6904 - val_loss: 7001.2075\n",
      "EPOCH: 507 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1158.1182 - val_loss: 926.4131\n",
      "EPOCH: 508 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2129.4692 - val_loss: 3310.1672\n",
      "EPOCH: 509 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6025.1587 - val_loss: 5601.6484\n",
      "EPOCH: 510 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1899.1787 - val_loss: 1.3739\n",
      "EPOCH: 511 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6833.6304 - val_loss: 6767.5542\n",
      "EPOCH: 512 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2873.4824 - val_loss: 2401.1592\n",
      "EPOCH: 513 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1451.5974 - val_loss: 1543.3101\n",
      "EPOCH: 514 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6017.7793 - val_loss: 6426.8701\n",
      "EPOCH: 515 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3484.7739 - val_loss: 2475.1172\n",
      "EPOCH: 516 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5563.9902 - val_loss: 5857.2905\n",
      "EPOCH: 517 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7067.3521 - val_loss: 7000.3394\n",
      "EPOCH: 518 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6344.6963 - val_loss: 6805.5073\n",
      "EPOCH: 519 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1595.8101 - val_loss: 365.7739\n",
      "EPOCH: 520 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7095.7739 - val_loss: 7175.1572\n",
      "EPOCH: 521 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2675.7778 - val_loss: 1623.3518\n",
      "EPOCH: 522 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5098.0034 - val_loss: 5145.0708\n",
      "EPOCH: 523 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7304.6851 - val_loss: 7346.5337\n",
      "EPOCH: 524 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3943.5618 - val_loss: 3749.3608\n",
      "EPOCH: 525 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4902.7979 - val_loss: 4938.2036\n",
      "EPOCH: 526 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7071.4478 - val_loss: 7081.8325\n",
      "EPOCH: 527 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 675.6725 - val_loss: 674.7398\n",
      "EPOCH: 528 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1200.9584 - val_loss: 12.0566\n",
      "EPOCH: 529 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7218.0479 - val_loss: 7215.0073\n",
      "EPOCH: 530 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4907.9272 - val_loss: 4940.1030\n",
      "EPOCH: 531 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4754.7305 - val_loss: 2816.2783\n",
      "EPOCH: 532 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6853.8125 - val_loss: 6840.4014\n",
      "EPOCH: 533 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6879.4390 - val_loss: 7213.3706\n",
      "EPOCH: 534 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4250.2617 - val_loss: 4375.5361\n",
      "EPOCH: 535 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 668.1104 - val_loss: 667.1512\n",
      "EPOCH: 536 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6770.1035 - val_loss: 5208.9756\n",
      "EPOCH: 537 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4745.3379 - val_loss: 4714.7085\n",
      "EPOCH: 538 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3622.5083 - val_loss: 2595.5303\n",
      "EPOCH: 539 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2233.9070 - val_loss: 2232.3936\n",
      "EPOCH: 540 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5592.5244 - val_loss: 1351.2192\n",
      "EPOCH: 541 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4672.4248 - val_loss: 5023.7856\n",
      "EPOCH: 542 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3614.2856 - val_loss: 2588.5598\n",
      "EPOCH: 543 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3999.3162 - val_loss: 2783.6799\n",
      "EPOCH: 544 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7056.0513 - val_loss: 7167.8018\n",
      "EPOCH: 545 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6377.7612 - val_loss: 6276.5845\n",
      "EPOCH: 546 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5714.9087 - val_loss: 5670.8027\n",
      "EPOCH: 547 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7129.4302 - val_loss: 7157.8232\n",
      "EPOCH: 548 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7115.2524 - val_loss: 7066.2925\n",
      "EPOCH: 549 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2804.7319 - val_loss: 2337.8452\n",
      "EPOCH: 550 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4680.9565 - val_loss: 4683.0522\n",
      "EPOCH: 551 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5091.1567 - val_loss: 3081.8440\n",
      "EPOCH: 552 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6843.1636 - val_loss: 6806.4854\n",
      "EPOCH: 553 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 776.0284 - val_loss: 74.1482\n",
      "EPOCH: 554 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6965.0186 - val_loss: 7045.1079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 555 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4437.8682 - val_loss: 4553.4272\n",
      "EPOCH: 556 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4697.3394 - val_loss: 2304.1074\n",
      "EPOCH: 557 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3248.1067 - val_loss: 2359.3333\n",
      "EPOCH: 558 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4691.5068 - val_loss: 4636.2788\n",
      "EPOCH: 559 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 770.5377 - val_loss: 72.2145\n",
      "EPOCH: 560 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2198.9807 - val_loss: 1053.4971\n",
      "EPOCH: 561 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5651.0908 - val_loss: 5333.7661\n",
      "EPOCH: 562 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2335.2124 - val_loss: 2507.6689\n",
      "EPOCH: 563 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3940.5684 - val_loss: 1811.1407\n",
      "EPOCH: 564 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5024.8750 - val_loss: 6995.2910\n",
      "EPOCH: 565 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6211.2646 - val_loss: 6934.9229\n",
      "EPOCH: 566 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4033.8411 - val_loss: 4096.8457\n",
      "EPOCH: 567 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3569.5808 - val_loss: 1195.2698\n",
      "EPOCH: 568 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4843.5498 - val_loss: 4882.5137\n",
      "EPOCH: 569 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5340.5327 - val_loss: 5359.4985\n",
      "EPOCH: 570 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1849.0223 - val_loss: 1713.2867\n",
      "EPOCH: 571 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7083.6367 - val_loss: 7080.5410\n",
      "EPOCH: 572 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4117.7969 - val_loss: 4209.8823\n",
      "EPOCH: 573 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2895.5950 - val_loss: 2893.8892\n",
      "EPOCH: 574 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2304.8853 - val_loss: 2303.1724\n",
      "EPOCH: 575 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6962.8125 - val_loss: 6959.9360\n",
      "EPOCH: 576 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 7177.5327 - val_loss: 7291.5928\n",
      "EPOCH: 577 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4294.5068 - val_loss: 4288.4302\n",
      "EPOCH: 578 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6145.0918 - val_loss: 4825.4292\n",
      "EPOCH: 579 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6769.1548 - val_loss: 6698.3970\n",
      "EPOCH: 580 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3120.4880 - val_loss: 2939.8813\n",
      "EPOCH: 581 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 707.4691 - val_loss: 660.6063\n",
      "EPOCH: 582 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6855.4854 - val_loss: 6786.9453\n",
      "EPOCH: 583 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2466.9500 - val_loss: 2487.0769\n",
      "EPOCH: 584 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1905.8412 - val_loss: 3019.9875\n",
      "EPOCH: 585 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3973.6152 - val_loss: 4045.4343\n",
      "EPOCH: 586 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5507.9727 - val_loss: 4047.6946\n",
      "EPOCH: 587 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5794.1987 - val_loss: 5791.8706\n",
      "EPOCH: 588 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6905.3379 - val_loss: 6918.8809\n",
      "EPOCH: 589 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4263.6509 - val_loss: 4257.6084\n",
      "EPOCH: 590 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4443.6802 - val_loss: 4441.2231\n",
      "EPOCH: 591 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6140.9165 - val_loss: 6157.8130\n",
      "EPOCH: 592 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1054.0912 - val_loss: 832.5104\n",
      "EPOCH: 593 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6724.2158 - val_loss: 6653.8081\n",
      "EPOCH: 594 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3940.6548 - val_loss: 1837.7338\n",
      "EPOCH: 595 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6834.4756 - val_loss: 6734.9790\n",
      "EPOCH: 596 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6431.7598 - val_loss: 5277.8950\n",
      "EPOCH: 597 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6441.1367 - val_loss: 6318.5444\n",
      "EPOCH: 598 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4721.2568 - val_loss: 4718.5542\n",
      "EPOCH: 599 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6631.8413 - val_loss: 7139.3784\n",
      "EPOCH: 600 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 605.9493 - val_loss: 605.0143\n",
      "EPOCH: 601 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 516.5159 - val_loss: 515.6626\n",
      "EPOCH: 602 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5810.3120 - val_loss: 5947.1206\n",
      "EPOCH: 603 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3076.4451 - val_loss: 3073.8933\n",
      "EPOCH: 604 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3145.6472 - val_loss: 2270.6018\n",
      "EPOCH: 605 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3098.3647 - val_loss: 3091.1558\n",
      "EPOCH: 606 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4295.2075 - val_loss: 4308.0444\n",
      "EPOCH: 607 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6299.9756 - val_loss: 6114.2539\n",
      "EPOCH: 608 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1742.9060 - val_loss: 1711.8486\n",
      "EPOCH: 609 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2515.1953 - val_loss: 2759.9202\n",
      "EPOCH: 610 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4285.5454 - val_loss: 4298.4214\n",
      "EPOCH: 611 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4079.9128 - val_loss: 4134.9399\n",
      "EPOCH: 612 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3387.0872 - val_loss: 3385.0198\n",
      "EPOCH: 613 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6621.5640 - val_loss: 6840.5908\n",
      "EPOCH: 614 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4884.9736 - val_loss: 4949.8877\n",
      "EPOCH: 615 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5197.9507 - val_loss: 5247.3662\n",
      "EPOCH: 616 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3874.6458 - val_loss: 3797.3970\n",
      "EPOCH: 617 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 317.5417 - val_loss: 311.6688\n",
      "EPOCH: 618 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3745.0852 - val_loss: 2015.2120\n",
      "EPOCH: 619 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1779.4283 - val_loss: 1215.0409\n",
      "EPOCH: 620 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5416.9429 - val_loss: 5349.4863\n",
      "EPOCH: 621 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1388.5521 - val_loss: 683.0475\n",
      "EPOCH: 622 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6619.2075 - val_loss: 6612.3296\n",
      "EPOCH: 623 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6941.1592 - val_loss: 6941.4355\n",
      "EPOCH: 624 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2785.7834 - val_loss: 2887.7556\n",
      "EPOCH: 625 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6696.7412 - val_loss: 7086.8198\n",
      "EPOCH: 626 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3404.7117 - val_loss: 2407.5615\n",
      "EPOCH: 627 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5701.0674 - val_loss: 5688.6987\n",
      "EPOCH: 628 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6384.9336 - val_loss: 6331.0049\n",
      "EPOCH: 629 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4416.6885 - val_loss: 6902.3730\n",
      "EPOCH: 630 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6771.4272 - val_loss: 6789.7061\n",
      "EPOCH: 631 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3018.2090 - val_loss: 2353.2729\n",
      "EPOCH: 632 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5385.4575 - val_loss: 5317.6421\n",
      "EPOCH: 633 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1193.2755 - val_loss: 1186.7886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 634 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6685.3677 - val_loss: 6607.7627\n",
      "EPOCH: 635 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3046.8989 - val_loss: 3122.1206\n",
      "EPOCH: 636 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2655.3748 - val_loss: 2505.1318\n",
      "EPOCH: 637 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6346.3696 - val_loss: 6514.7124\n",
      "EPOCH: 638 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5345.9180 - val_loss: 3964.9934\n",
      "EPOCH: 639 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2121.2949 - val_loss: 2322.8147\n",
      "EPOCH: 640 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4857.9883 - val_loss: 6373.7524\n",
      "EPOCH: 641 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3011.5391 - val_loss: 3009.5557\n",
      "EPOCH: 642 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6787.1123 - val_loss: 6926.3965\n",
      "EPOCH: 643 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6569.3604 - val_loss: 6870.1387\n",
      "EPOCH: 644 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3100.0059 - val_loss: 2051.6033\n",
      "EPOCH: 645 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3373.2188 - val_loss: 2389.7146\n",
      "EPOCH: 646 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5966.8955 - val_loss: 6000.9771\n",
      "EPOCH: 647 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4142.0947 - val_loss: 4253.5850\n",
      "EPOCH: 648 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4696.5098 - val_loss: 4733.7837\n",
      "EPOCH: 649 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4085.5647 - val_loss: 5190.9785\n",
      "EPOCH: 650 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4268.7959 - val_loss: 4593.1729\n",
      "EPOCH: 651 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5241.5127 - val_loss: 5122.7891\n",
      "EPOCH: 652 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6698.7056 - val_loss: 6730.3188\n",
      "EPOCH: 653 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5187.8555 - val_loss: 5523.1006\n",
      "EPOCH: 654 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3314.4050 - val_loss: 3312.1201\n",
      "EPOCH: 655 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6294.2271 - val_loss: 6221.4629\n",
      "EPOCH: 656 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2970.1458 - val_loss: 2967.4443\n",
      "EPOCH: 657 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6596.6138 - val_loss: 6647.8027\n",
      "EPOCH: 658 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3823.4512 - val_loss: 3820.8059\n",
      "EPOCH: 659 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4183.7319 - val_loss: 6070.8862\n",
      "EPOCH: 660 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5167.6050 - val_loss: 5505.4741\n",
      "EPOCH: 661 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1489.8737 - val_loss: 1488.6096\n",
      "EPOCH: 662 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6812.8706 - val_loss: 6913.2339\n",
      "EPOCH: 663 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2712.2654 - val_loss: 2750.9182\n",
      "EPOCH: 664 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2129.4050 - val_loss: 2073.2649\n",
      "EPOCH: 665 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5351.7144 - val_loss: 4989.2344\n",
      "EPOCH: 666 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2894.1350 - val_loss: 3088.5085\n",
      "EPOCH: 667 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4167.0234 - val_loss: 6050.4722\n",
      "EPOCH: 668 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6462.4229 - val_loss: 6786.2666\n",
      "EPOCH: 669 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6285.3667 - val_loss: 6403.2061\n",
      "EPOCH: 670 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2477.3635 - val_loss: 1925.0994\n",
      "EPOCH: 671 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4251.2744 - val_loss: 4248.8857\n",
      "EPOCH: 672 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6672.8618 - val_loss: 6664.6348\n",
      "EPOCH: 673 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4645.3638 - val_loss: 4690.2539\n",
      "EPOCH: 674 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5269.2490 - val_loss: 3864.8967\n",
      "EPOCH: 675 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 997.7563 - val_loss: 1016.6570\n",
      "EPOCH: 676 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2977.2678 - val_loss: 2211.2976\n",
      "EPOCH: 677 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5844.9634 - val_loss: 6259.9312\n",
      "EPOCH: 678 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4030.1633 - val_loss: 2832.5886\n",
      "EPOCH: 679 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6125.2334 - val_loss: 6144.4575\n",
      "EPOCH: 680 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4025.6160 - val_loss: 2828.5981\n",
      "EPOCH: 681 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6341.0835 - val_loss: 6298.8066\n",
      "EPOCH: 682 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6689.4360 - val_loss: 6616.9731\n",
      "EPOCH: 683 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6612.3271 - val_loss: 6613.5664\n",
      "EPOCH: 684 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3557.7434 - val_loss: 3375.9565\n",
      "EPOCH: 685 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6140.6533 - val_loss: 6249.5264\n",
      "EPOCH: 686 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3616.4104 - val_loss: 1612.8911\n",
      "EPOCH: 687 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6868.8818 - val_loss: 6980.4243\n",
      "EPOCH: 688 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4435.3237 - val_loss: 4466.4155\n",
      "EPOCH: 689 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5549.6250 - val_loss: 5582.0801\n",
      "EPOCH: 690 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4001.0815 - val_loss: 2806.7903\n",
      "EPOCH: 691 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1986.4911 - val_loss: 1712.1842\n",
      "EPOCH: 692 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6382.0186 - val_loss: 6576.2163\n",
      "EPOCH: 693 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6624.7759 - val_loss: 6638.1367\n",
      "EPOCH: 694 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1272.5436 - val_loss: 610.1269\n",
      "EPOCH: 695 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5178.8711 - val_loss: 1151.8005\n",
      "EPOCH: 696 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 657.6093 - val_loss: 36.2523\n",
      "EPOCH: 697 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5554.9385 - val_loss: 5925.7246\n",
      "EPOCH: 698 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6279.4429 - val_loss: 6574.9155\n",
      "EPOCH: 699 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 293.3321 - val_loss: 292.7271\n",
      "EPOCH: 700 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2305.9888 - val_loss: 1713.2698\n",
      "EPOCH: 701 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5006.8110 - val_loss: 2206.5374\n",
      "EPOCH: 702 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1819.2028 - val_loss: 1817.7545\n",
      "EPOCH: 703 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1125.8210 - val_loss: 1081.6763\n",
      "EPOCH: 704 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4313.2642 - val_loss: 4339.4424\n",
      "EPOCH: 705 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3510.2202 - val_loss: 3330.0547\n",
      "EPOCH: 706 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1813.6193 - val_loss: 1812.2543\n",
      "EPOCH: 707 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4448.4487 - val_loss: 3947.8125\n",
      "EPOCH: 708 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2411.7498 - val_loss: 1499.0311\n",
      "EPOCH: 709 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5092.2617 - val_loss: 4173.4902\n",
      "EPOCH: 710 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1747.2368 - val_loss: 1737.8998\n",
      "EPOCH: 711 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6549.0552 - val_loss: 6546.3594\n",
      "EPOCH: 712 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4126.3652 - val_loss: 6766.3906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 713 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6527.2588 - val_loss: 6635.5142\n",
      "EPOCH: 714 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1237.3203 - val_loss: 1236.1277\n",
      "EPOCH: 715 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5401.6924 - val_loss: 5000.2329\n",
      "EPOCH: 716 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2264.5952 - val_loss: 2883.3950\n",
      "EPOCH: 717 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1337.2159 - val_loss: 1393.4470\n",
      "EPOCH: 718 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1362.6373 - val_loss: 1361.1338\n",
      "EPOCH: 719 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6310.4302 - val_loss: 6505.6572\n",
      "EPOCH: 720 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5341.0288 - val_loss: 5585.9922\n",
      "EPOCH: 721 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6500.5635 - val_loss: 6403.8213\n",
      "EPOCH: 722 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6527.9448 - val_loss: 6546.0474\n",
      "EPOCH: 723 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6279.1260 - val_loss: 6430.8232\n",
      "EPOCH: 724 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6276.4556 - val_loss: 6428.0215\n",
      "EPOCH: 725 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5698.9424 - val_loss: 6030.6021\n",
      "EPOCH: 726 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6460.1406 - val_loss: 6014.4800\n",
      "EPOCH: 727 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4295.4287 - val_loss: 4293.1401\n",
      "EPOCH: 728 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3302.9231 - val_loss: 2959.8857\n",
      "EPOCH: 729 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3114.4121 - val_loss: 783.3195\n",
      "EPOCH: 730 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4581.2388 - val_loss: 4234.0342\n",
      "EPOCH: 731 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6407.5171 - val_loss: 6425.8486\n",
      "EPOCH: 732 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3797.8337 - val_loss: 3787.4641\n",
      "EPOCH: 733 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4574.0566 - val_loss: 4227.0337\n",
      "EPOCH: 734 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6495.0386 - val_loss: 6512.9170\n",
      "EPOCH: 735 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 532.6252 - val_loss: 551.6115\n",
      "EPOCH: 736 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2538.7908 - val_loss: 2537.1816\n",
      "EPOCH: 737 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6049.8008 - val_loss: 6154.5874\n",
      "EPOCH: 738 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5601.5713 - val_loss: 3688.0925\n",
      "EPOCH: 739 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2937.8191 - val_loss: 3114.7273\n",
      "EPOCH: 740 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1365.2955 - val_loss: 1390.2515\n",
      "EPOCH: 741 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6170.0435 - val_loss: 6412.6040\n",
      "EPOCH: 742 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5863.7388 - val_loss: 5772.0879\n",
      "EPOCH: 743 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6340.0923 - val_loss: 6295.2515\n",
      "EPOCH: 744 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4275.0688 - val_loss: 4150.3872\n",
      "EPOCH: 745 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5970.1523 - val_loss: 6022.9023\n",
      "EPOCH: 746 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 453.8643 - val_loss: 453.0896\n",
      "EPOCH: 747 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5089.8916 - val_loss: 3744.6206\n",
      "EPOCH: 748 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1267.0819 - val_loss: 1330.6493\n",
      "EPOCH: 749 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5269.9307 - val_loss: 5514.9126\n",
      "EPOCH: 750 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6232.1050 - val_loss: 6419.7456\n",
      "EPOCH: 751 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1379.8635 - val_loss: 1378.7236\n",
      "EPOCH: 752 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2736.6843 - val_loss: 2925.8259\n",
      "EPOCH: 753 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1979.0312 - val_loss: 1977.1271\n",
      "EPOCH: 754 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4053.5044 - val_loss: 4081.4934\n",
      "EPOCH: 755 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5533.7065 - val_loss: 5951.0469\n",
      "EPOCH: 756 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1059.7677 - val_loss: 1099.3761\n",
      "EPOCH: 757 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6276.8594 - val_loss: 6351.8076\n",
      "EPOCH: 758 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1963.2699 - val_loss: 1905.6816\n",
      "EPOCH: 759 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3357.4382 - val_loss: 3601.5071\n",
      "EPOCH: 760 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6132.5981 - val_loss: 6000.6460\n",
      "EPOCH: 761 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 517.9573 - val_loss: 0.0045\n",
      "EPOCH: 762 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4555.9976 - val_loss: 4525.1548\n",
      "EPOCH: 763 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3410.2886 - val_loss: 3875.6694\n",
      "EPOCH: 764 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6247.5166 - val_loss: 5911.2168\n",
      "EPOCH: 765 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6397.5098 - val_loss: 6394.6777\n",
      "EPOCH: 766 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6291.0288 - val_loss: 6391.7104\n",
      "EPOCH: 767 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4125.2441 - val_loss: 4453.4990\n",
      "EPOCH: 768 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3674.4170 - val_loss: 3589.2971\n",
      "EPOCH: 769 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5937.8491 - val_loss: 5820.3608\n",
      "EPOCH: 770 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4204.7305 - val_loss: 4179.1475\n",
      "EPOCH: 771 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4696.3008 - val_loss: 4792.8218\n",
      "EPOCH: 772 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4311.6504 - val_loss: 4331.4761\n",
      "EPOCH: 773 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3791.9224 - val_loss: 4875.5674\n",
      "EPOCH: 774 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5840.7612 - val_loss: 5837.9824\n",
      "EPOCH: 775 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6080.2446 - val_loss: 6321.9482\n",
      "EPOCH: 776 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5722.3345 - val_loss: 6350.8394\n",
      "EPOCH: 777 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6346.1323 - val_loss: 6342.1323\n",
      "EPOCH: 778 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6149.6655 - val_loss: 6344.7510\n",
      "EPOCH: 779 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6354.7788 - val_loss: 6351.4014\n",
      "EPOCH: 780 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2704.1243 - val_loss: 2032.9316\n",
      "EPOCH: 781 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2670.3123 - val_loss: 2668.2188\n",
      "EPOCH: 782 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5480.0117 - val_loss: 4307.8423\n",
      "EPOCH: 783 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4179.3032 - val_loss: 4177.1665\n",
      "EPOCH: 784 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6353.5820 - val_loss: 6386.2515\n",
      "EPOCH: 785 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6232.0254 - val_loss: 6331.9277\n",
      "EPOCH: 786 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 221.1918 - val_loss: 216.2105\n",
      "EPOCH: 787 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6293.4307 - val_loss: 6309.8823\n",
      "EPOCH: 788 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6325.7773 - val_loss: 6322.5503\n",
      "EPOCH: 789 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6039.8306 - val_loss: 6005.2676\n",
      "EPOCH: 790 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1161.0189 - val_loss: 527.7997\n",
      "EPOCH: 791 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5916.0024 - val_loss: 5787.4863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 792 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6110.1465 - val_loss: 6421.7715\n",
      "EPOCH: 793 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4266.0742 - val_loss: 4286.0454\n",
      "EPOCH: 794 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6190.5635 - val_loss: 6259.4761\n",
      "EPOCH: 795 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5837.7100 - val_loss: 5857.5283\n",
      "EPOCH: 796 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4381.0078 - val_loss: 4424.5850\n",
      "EPOCH: 797 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3850.4971 - val_loss: 3863.7371\n",
      "EPOCH: 798 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2625.3533 - val_loss: 2622.8821\n",
      "EPOCH: 799 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5195.4067 - val_loss: 5222.6733\n",
      "EPOCH: 800 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2649.1167 - val_loss: 2195.0967\n",
      "EPOCH: 801 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6205.9175 - val_loss: 6092.9224\n",
      "EPOCH: 802 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5244.1548 - val_loss: 5375.6333\n",
      "EPOCH: 803 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3053.8420 - val_loss: 3569.8474\n",
      "EPOCH: 804 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 496.1725 - val_loss: 0.8062\n",
      "EPOCH: 805 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6248.5742 - val_loss: 6252.3569\n",
      "EPOCH: 806 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4403.9487 - val_loss: 4063.7026\n",
      "EPOCH: 807 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1821.8229 - val_loss: 2020.4946\n",
      "EPOCH: 808 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2568.4189 - val_loss: 2532.7419\n",
      "EPOCH: 809 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3922.9021 - val_loss: 5214.4810\n",
      "EPOCH: 810 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6169.6226 - val_loss: 6083.9014\n",
      "EPOCH: 811 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6226.9575 - val_loss: 6253.8276\n",
      "EPOCH: 812 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4347.4282 - val_loss: 4390.9824\n",
      "EPOCH: 813 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5384.5571 - val_loss: 5796.2051\n",
      "EPOCH: 814 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4268.7046 - val_loss: 4307.6108\n",
      "EPOCH: 815 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4341.1084 - val_loss: 4384.5806\n",
      "EPOCH: 816 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5884.9727 - val_loss: 6003.4238\n",
      "EPOCH: 817 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2554.1003 - val_loss: 2518.3984\n",
      "EPOCH: 818 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4041.9587 - val_loss: 3781.2151\n",
      "EPOCH: 819 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2474.7075 - val_loss: 2515.2170\n",
      "EPOCH: 820 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4274.0771 - val_loss: 4398.5215\n",
      "EPOCH: 821 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2795.6050 - val_loss: 2883.5667\n",
      "EPOCH: 822 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2884.1294 - val_loss: 2882.2732\n",
      "EPOCH: 823 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5115.3638 - val_loss: 5079.2603\n",
      "EPOCH: 824 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6130.7529 - val_loss: 6045.1099\n",
      "EPOCH: 825 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2446.4226 - val_loss: 3088.1545\n",
      "EPOCH: 826 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5251.9644 - val_loss: 5463.1724\n",
      "EPOCH: 827 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1073.6925 - val_loss: 1164.8359\n",
      "EPOCH: 828 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5829.8447 - val_loss: 5839.7935\n",
      "EPOCH: 829 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5123.3223 - val_loss: 5120.6431\n",
      "EPOCH: 830 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1902.2638 - val_loss: 122.8741\n",
      "EPOCH: 831 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4013.3333 - val_loss: 3753.5618\n",
      "EPOCH: 832 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4295.8511 - val_loss: 4328.3794\n",
      "EPOCH: 833 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4165.2378 - val_loss: 4113.9902\n",
      "EPOCH: 834 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4211.1289 - val_loss: 2413.2910\n",
      "EPOCH: 835 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5519.5537 - val_loss: 4811.6860\n",
      "EPOCH: 836 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2093.1980 - val_loss: 2682.7112\n",
      "EPOCH: 837 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5331.3384 - val_loss: 4967.3579\n",
      "EPOCH: 838 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5604.7163 - val_loss: 5229.8457\n",
      "EPOCH: 839 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5737.8535 - val_loss: 5622.5957\n",
      "EPOCH: 840 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1182.0248 - val_loss: 1205.0396\n",
      "EPOCH: 841 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1617.1400 - val_loss: 1615.8358\n",
      "EPOCH: 842 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3877.4419 - val_loss: 3875.4729\n",
      "EPOCH: 843 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5705.3315 - val_loss: 5702.6973\n",
      "EPOCH: 844 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6135.2642 - val_loss: 6161.9312\n",
      "EPOCH: 845 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4125.7485 - val_loss: 4147.7544\n",
      "EPOCH: 846 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4216.2573 - val_loss: 3949.1230\n",
      "EPOCH: 847 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6156.2539 - val_loss: 6153.3237\n",
      "EPOCH: 848 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5897.5239 - val_loss: 6158.2920\n",
      "EPOCH: 849 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 339.4445 - val_loss: 338.7891\n",
      "EPOCH: 850 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1394.7682 - val_loss: 899.3398\n",
      "EPOCH: 851 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5716.2114 - val_loss: 5685.5239\n",
      "EPOCH: 852 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1638.1130 - val_loss: 1793.7399\n",
      "EPOCH: 853 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6037.8931 - val_loss: 6136.6733\n",
      "EPOCH: 854 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3852.7302 - val_loss: 3850.6914\n",
      "EPOCH: 855 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5526.3628 - val_loss: 6115.4067\n",
      "EPOCH: 856 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3462.4348 - val_loss: 3550.1030\n",
      "EPOCH: 857 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5868.4854 - val_loss: 5916.7002\n",
      "EPOCH: 858 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6494.7554 - val_loss: 6538.8408\n",
      "EPOCH: 859 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6107.4136 - val_loss: 6103.6338\n",
      "EPOCH: 860 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2163.3147 - val_loss: 1319.9888\n",
      "EPOCH: 861 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2660.5803 - val_loss: 2653.9307\n",
      "EPOCH: 862 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5827.1484 - val_loss: 5887.5015\n",
      "EPOCH: 863 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6115.7603 - val_loss: 6159.8438\n",
      "EPOCH: 864 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2341.0767 - val_loss: 2339.5554\n",
      "EPOCH: 865 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6148.1572 - val_loss: 6086.5674\n",
      "EPOCH: 866 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6000.9463 - val_loss: 6099.2129\n",
      "EPOCH: 867 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6002.7119 - val_loss: 5925.6001\n",
      "EPOCH: 868 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5144.1553 - val_loss: 6101.4751\n",
      "EPOCH: 869 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4249.1475 - val_loss: 4287.8828\n",
      "EPOCH: 870 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2930.5408 - val_loss: 3432.0923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 871 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3816.3567 - val_loss: 3814.2017\n",
      "EPOCH: 872 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1232.1277 - val_loss: 1230.8710\n",
      "EPOCH: 873 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1815.7195 - val_loss: 628.3199\n",
      "EPOCH: 874 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3997.5222 - val_loss: 3995.6545\n",
      "EPOCH: 875 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4733.7578 - val_loss: 3843.5212\n",
      "EPOCH: 876 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1114.6978 - val_loss: 1100.8433\n",
      "EPOCH: 877 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5757.3569 - val_loss: 6068.2070\n",
      "EPOCH: 878 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3937.6086 - val_loss: 3988.2131\n",
      "EPOCH: 879 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 976.9135 - val_loss: 97.2477\n",
      "EPOCH: 880 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2106.2776 - val_loss: 2325.6519\n",
      "EPOCH: 881 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5707.3667 - val_loss: 5776.5405\n",
      "EPOCH: 882 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4302.1406 - val_loss: 2370.5569\n",
      "EPOCH: 883 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3537.2693 - val_loss: 3705.5283\n",
      "EPOCH: 884 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1693.3079 - val_loss: 9.4220\n",
      "EPOCH: 885 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3379.9050 - val_loss: 3382.1143\n",
      "EPOCH: 886 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5648.4712 - val_loss: 5588.7559\n",
      "EPOCH: 887 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5770.2041 - val_loss: 5823.5708\n",
      "EPOCH: 888 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4016.4658 - val_loss: 4031.9700\n",
      "EPOCH: 889 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4545.5479 - val_loss: 1901.6459\n",
      "EPOCH: 890 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2338.5859 - val_loss: 2966.2114\n",
      "EPOCH: 891 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 459.6144 - val_loss: 5.8779\n",
      "EPOCH: 892 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5895.4712 - val_loss: 6131.5933\n",
      "EPOCH: 893 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6181.7261 - val_loss: 6246.2305\n",
      "EPOCH: 894 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4176.0312 - val_loss: 5582.7617\n",
      "EPOCH: 895 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4276.5479 - val_loss: 2351.1882\n",
      "EPOCH: 896 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2746.7668 - val_loss: 2745.0203\n",
      "EPOCH: 897 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5013.2056 - val_loss: 3393.9026\n",
      "EPOCH: 898 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5000.5186 - val_loss: 5293.4927\n",
      "EPOCH: 899 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2456.0950 - val_loss: 2454.4226\n",
      "EPOCH: 900 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5737.2007 - val_loss: 5703.9531\n",
      "EPOCH: 901 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2153.1453 - val_loss: 1989.8010\n",
      "EPOCH: 902 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4822.0898 - val_loss: 1528.3649\n",
      "EPOCH: 903 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3597.2847 - val_loss: 3269.3901\n",
      "EPOCH: 904 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4816.4326 - val_loss: 4783.4546\n",
      "EPOCH: 905 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4265.6743 - val_loss: 4191.0083\n",
      "EPOCH: 906 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5907.0503 - val_loss: 5916.6499\n",
      "EPOCH: 907 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3820.6116 - val_loss: 4132.4795\n",
      "EPOCH: 908 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4680.7539 - val_loss: 868.0546\n",
      "EPOCH: 909 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2527.9558 - val_loss: 1769.4783\n",
      "EPOCH: 910 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1471.3000 - val_loss: 1573.3965\n",
      "EPOCH: 911 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1030.7153 - val_loss: 433.9511\n",
      "EPOCH: 912 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5575.7046 - val_loss: 5507.7627\n",
      "EPOCH: 913 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3502.3792 - val_loss: 3748.0493\n",
      "EPOCH: 914 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3499.6504 - val_loss: 2399.0801\n",
      "EPOCH: 915 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3783.0186 - val_loss: 3781.1409\n",
      "EPOCH: 916 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 333.5590 - val_loss: 332.9850\n",
      "EPOCH: 917 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3819.5229 - val_loss: 3777.6157\n",
      "EPOCH: 918 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5026.4312 - val_loss: 5024.1221\n",
      "EPOCH: 919 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6027.7920 - val_loss: 5959.8384\n",
      "EPOCH: 920 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4980.0049 - val_loss: 1752.9771\n",
      "EPOCH: 921 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3741.7649 - val_loss: 5531.5044\n",
      "EPOCH: 922 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5866.9868 - val_loss: 5783.3545\n",
      "EPOCH: 923 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3351.7231 - val_loss: 3395.2937\n",
      "EPOCH: 924 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5872.5142 - val_loss: 5762.7837\n",
      "EPOCH: 925 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2550.4133 - val_loss: 2574.2300\n",
      "EPOCH: 926 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1568.8447 - val_loss: 1567.5986\n",
      "EPOCH: 927 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5853.6104 - val_loss: 5770.0825\n",
      "EPOCH: 928 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5113.1685 - val_loss: 5514.5537\n",
      "EPOCH: 929 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 6089.4961 - val_loss: 6121.9580\n",
      "EPOCH: 930 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 336.3282 - val_loss: 335.8805\n",
      "EPOCH: 931 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3570.5945 - val_loss: 3527.0276\n",
      "EPOCH: 932 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2428.4778 - val_loss: 2610.7869\n",
      "EPOCH: 933 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 664.7885 - val_loss: 486.6356\n",
      "EPOCH: 934 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5922.8145 - val_loss: 5920.2925\n",
      "EPOCH: 935 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3842.1414 - val_loss: 3724.2603\n",
      "EPOCH: 936 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3757.6418 - val_loss: 3960.7898\n",
      "EPOCH: 937 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5883.0088 - val_loss: 5897.0767\n",
      "EPOCH: 938 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3019.5427 - val_loss: 3018.4026\n",
      "EPOCH: 939 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4986.2061 - val_loss: 5177.8965\n",
      "EPOCH: 940 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5829.5166 - val_loss: 5838.2881\n",
      "EPOCH: 941 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5791.6855 - val_loss: 5748.8804\n",
      "EPOCH: 942 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2956.4368 - val_loss: 2975.3540\n",
      "EPOCH: 943 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3676.7642 - val_loss: 3674.7500\n",
      "EPOCH: 944 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5796.5400 - val_loss: 5893.2061\n",
      "EPOCH: 945 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4090.4675 - val_loss: 4132.7695\n",
      "EPOCH: 946 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3737.2649 - val_loss: 1562.6986\n",
      "EPOCH: 947 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5100.2358 - val_loss: 6114.5166\n",
      "EPOCH: 948 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2945.9531 - val_loss: 2946.2354\n",
      "EPOCH: 949 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5517.8867 - val_loss: 2413.4451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 950 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4765.6396 - val_loss: 5876.5093\n",
      "EPOCH: 951 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4661.3306 - val_loss: 3351.7087\n",
      "EPOCH: 952 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5422.8999 - val_loss: 5420.1641\n",
      "EPOCH: 953 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5879.6216 - val_loss: 5952.0239\n",
      "EPOCH: 954 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4201.2319 - val_loss: 3670.3752\n",
      "EPOCH: 955 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1552.1851 - val_loss: 1393.5769\n",
      "EPOCH: 956 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4567.7925 - val_loss: 3698.4775\n",
      "EPOCH: 957 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5772.6167 - val_loss: 5689.5298\n",
      "EPOCH: 958 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 713.9528 - val_loss: 676.5945\n",
      "EPOCH: 959 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1112.5271 - val_loss: 973.1028\n",
      "EPOCH: 960 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5552.2485 - val_loss: 5531.9507\n",
      "EPOCH: 961 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2409.2456 - val_loss: 2495.9778\n",
      "EPOCH: 962 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3333.2729 - val_loss: 2948.7141\n",
      "EPOCH: 963 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5275.7075 - val_loss: 5245.3403\n",
      "EPOCH: 964 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5110.6582 - val_loss: 5158.5542\n",
      "EPOCH: 965 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4928.2988 - val_loss: 4925.7944\n",
      "EPOCH: 966 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5863.6538 - val_loss: 5865.4258\n",
      "EPOCH: 967 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5727.1094 - val_loss: 5636.1694\n",
      "EPOCH: 968 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5359.0264 - val_loss: 5363.2612\n",
      "EPOCH: 969 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5794.2026 - val_loss: 6059.1445\n",
      "EPOCH: 970 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 478.7504 - val_loss: 296.6833\n",
      "EPOCH: 971 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5776.2036 - val_loss: 5355.3472\n",
      "EPOCH: 972 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5732.0781 - val_loss: 5649.2729\n",
      "EPOCH: 973 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5815.8379 - val_loss: 5812.9189\n",
      "EPOCH: 974 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 278.0673 - val_loss: 260.0073\n",
      "EPOCH: 975 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5585.0283 - val_loss: 5728.2349\n",
      "EPOCH: 976 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2201.2161 - val_loss: 2810.1594\n",
      "EPOCH: 977 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3211.4824 - val_loss: 3364.1248\n",
      "EPOCH: 978 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1605.7607 - val_loss: 1604.4222\n",
      "EPOCH: 979 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1575.2842 - val_loss: 1758.8755\n",
      "EPOCH: 980 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5858.6885 - val_loss: 5794.5625\n",
      "EPOCH: 981 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1504.2512 - val_loss: 864.6878\n",
      "EPOCH: 982 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4930.0210 - val_loss: 4769.1201\n",
      "EPOCH: 983 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5341.9648 - val_loss: 5339.4121\n",
      "EPOCH: 984 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3385.5591 - val_loss: 3370.2378\n",
      "EPOCH: 985 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1635.5212 - val_loss: 2246.4304\n",
      "EPOCH: 986 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4640.1323 - val_loss: 4607.9229\n",
      "EPOCH: 987 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2582.6953 - val_loss: 2580.9985\n",
      "EPOCH: 988 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1563.3455 - val_loss: 1746.1747\n",
      "EPOCH: 989 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 946.6053 - val_loss: 1007.2941\n",
      "EPOCH: 990 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2987.1401 - val_loss: 2940.3550\n",
      "EPOCH: 991 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3789.1035 - val_loss: 5869.4219\n",
      "EPOCH: 992 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2328.9497 - val_loss: 2171.4185\n",
      "EPOCH: 993 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 3972.3850 - val_loss: 4068.4556\n",
      "EPOCH: 994 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5436.6875 - val_loss: 5387.4316\n",
      "EPOCH: 995 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5899.5234 - val_loss: 6003.7432\n",
      "EPOCH: 996 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2270.5503 - val_loss: 2269.5962\n",
      "EPOCH: 997 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 2880.6431 - val_loss: 3309.1851\n",
      "EPOCH: 998 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 5517.9136 - val_loss: 5770.9541\n",
      "EPOCH: 999 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 4650.0083 - val_loss: 4809.5078\n",
      "EPOCH: 1000 OUT OF 1000\n",
      "(21, 1, 6) (21,) (1, 1, 6) (1,)\n",
      "1/1 - 0s - loss: 1364.6414 - val_loss: 1259.3927\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "import random\n",
    "\n",
    "EPOCHS = 1000\n",
    "\n",
    "losses = []\n",
    "val_losses = []\n",
    "\n",
    "for a in range(EPOCHS):\n",
    "    \n",
    "    print('EPOCH: ' + str(a+1) +  ' OUT OF ' + str(EPOCHS))\n",
    "\n",
    "    rand_int = random.randint(0, 522)\n",
    "\n",
    "    values = list_of_training_df[rand_int].values\n",
    "\n",
    "    n_train_hours = 21\n",
    "    train = values[:n_train_hours, :]\n",
    "    test = values[n_train_hours:, :]\n",
    "\n",
    "    train_X, train_y = train[:, :-1], train[:, -1]\n",
    "    test_X, test_y = test[:, :-1], test[:, -1]\n",
    "\n",
    "    train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "    test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "    print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "\n",
    "    # fit network\n",
    "    history = lstm_model.fit(train_X, train_y, epochs=1, batch_size=21, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "\n",
    "    for idx, h in enumerate(history.history['loss']):\n",
    "        losses.append(h)\n",
    "        val_losses.append(history.history['val_loss'])\n",
    "        \n",
    "# plot history\n",
    "pyplot.plot(losses, label='train')\n",
    "pyplot.plot(val_losses, label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Based on the num_predictions we choose, we predict on that many random time series and derive a resulting root mean square error\n",
    "\n",
    "# The resulting prediction is sufficiency rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import concatenate\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "num_predictions = 500\n",
    "\n",
    "summation = 0\n",
    "\n",
    "actual = []\n",
    "predicted = []\n",
    "\n",
    "for a in range(num_predictions):\n",
    "    \n",
    "    rand_int = random.randint(0, 522)\n",
    "\n",
    "    values = list_of_training_df[rand_int].values\n",
    "\n",
    "    n_train_hours = 21\n",
    "    train = values[:n_train_hours, :]\n",
    "    test = values[n_train_hours:, :]\n",
    "\n",
    "    train_X, train_y = train[:, :-1], train[:, -1]\n",
    "    test_X, test_y = test[:, :-1], test[:, -1]\n",
    "\n",
    "    train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "    test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "#     print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "\n",
    "    yhat = lstm_model.predict(test_X)\n",
    "    \n",
    "    actual.append(test_y[0])\n",
    "    predicted.append(yhat[0][0][0])\n",
    "    \n",
    "#     print(yhat[0][0][0])\n",
    "#     print(test_y[0])\n",
    "    \n",
    "#     difference = test_y[0] - yhat[0][0][0]\n",
    "#     squared_difference = difference**2\n",
    "#     summation = summation + squared_difference\n",
    "    \n",
    "mse = mean_squared_error(actual, predicted)\n",
    "rmse = math.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59.564423514983666"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20.612076,\n",
       " 20.612076,\n",
       " 24.199451,\n",
       " 22.291847,\n",
       " 21.819641,\n",
       " 20.612076,\n",
       " 20.612076,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 20.612076,\n",
       " 20.612076,\n",
       " 24.199451,\n",
       " 21.819641,\n",
       " 21.819641,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 23.264862,\n",
       " 21.819641,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 22.291847,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 23.264862,\n",
       " 20.612076,\n",
       " 20.612076,\n",
       " 24.199451,\n",
       " 22.291847,\n",
       " 22.291847,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 22.291847,\n",
       " 22.291847,\n",
       " 22.291847,\n",
       " 20.612076,\n",
       " 22.291847,\n",
       " 20.612076,\n",
       " 20.612076,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 21.819641,\n",
       " 21.819641,\n",
       " 20.612076,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 20.612076,\n",
       " 22.291847,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 20.612076,\n",
       " 23.264862,\n",
       " 24.199451,\n",
       " 21.819569,\n",
       " 24.199451,\n",
       " 21.819641,\n",
       " 24.199451,\n",
       " 22.291847,\n",
       " 21.819641,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 21.819641,\n",
       " 20.612076,\n",
       " 24.199451,\n",
       " 22.291847,\n",
       " 20.612076,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 21.819641,\n",
       " 23.264862,\n",
       " 21.819641,\n",
       " 24.199451,\n",
       " 22.291847,\n",
       " 24.199451,\n",
       " 21.819641,\n",
       " 24.199451,\n",
       " 20.612076,\n",
       " 22.291847,\n",
       " 24.199451,\n",
       " 20.612076,\n",
       " 21.819641,\n",
       " 21.819641,\n",
       " 21.819641,\n",
       " 21.819641,\n",
       " 21.819641,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 21.819641,\n",
       " 22.291847,\n",
       " 22.291847,\n",
       " 24.199451,\n",
       " 21.819641,\n",
       " 20.612076,\n",
       " 21.819641,\n",
       " 21.819641,\n",
       " 21.819641,\n",
       " 20.612076,\n",
       " 22.291847,\n",
       " 22.291847,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 21.819641,\n",
       " 21.819641,\n",
       " 20.612076,\n",
       " 22.291847,\n",
       " 24.199451,\n",
       " 22.291847,\n",
       " 21.819641,\n",
       " 23.264862,\n",
       " 22.291847,\n",
       " 24.199451,\n",
       " 21.819641,\n",
       " 22.291847,\n",
       " 21.819641,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 21.819641,\n",
       " 21.819641,\n",
       " 24.199451,\n",
       " 22.291847,\n",
       " 24.199451,\n",
       " 21.819641,\n",
       " 21.819641,\n",
       " 20.670689,\n",
       " 23.292877,\n",
       " 21.819641,\n",
       " 20.612076,\n",
       " 22.291847,\n",
       " 23.264862,\n",
       " 21.819641,\n",
       " 24.199451,\n",
       " 20.670689,\n",
       " 23.264862,\n",
       " 23.264862,\n",
       " 23.264862,\n",
       " 21.819641,\n",
       " 22.291847,\n",
       " 21.819641,\n",
       " 24.199451,\n",
       " 22.291847,\n",
       " 20.612076,\n",
       " 22.291847,\n",
       " 24.199451,\n",
       " 24.165699,\n",
       " 24.199451,\n",
       " 21.819641,\n",
       " 22.291847,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 20.612076,\n",
       " 22.291847,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 21.819641,\n",
       " 24.199451,\n",
       " 21.819641,\n",
       " 22.291847,\n",
       " 21.819641,\n",
       " 22.291847,\n",
       " 22.291847,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 21.819641,\n",
       " 24.199451,\n",
       " 21.819641,\n",
       " 21.819641,\n",
       " 24.199451,\n",
       " 23.264862,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 22.291847,\n",
       " 23.264862,\n",
       " 24.199451,\n",
       " 23.264862,\n",
       " 22.291847,\n",
       " 20.612076,\n",
       " 24.199451,\n",
       " 21.819641,\n",
       " 21.819641,\n",
       " 22.291847,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 21.819641,\n",
       " 20.612076,\n",
       " 22.291847,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 21.819641,\n",
       " 20.612076,\n",
       " 21.819641,\n",
       " 20.612076,\n",
       " 23.264862,\n",
       " 22.291847,\n",
       " 22.291847,\n",
       " 21.819641,\n",
       " 21.819641,\n",
       " 24.199451,\n",
       " 21.819641,\n",
       " 22.291847,\n",
       " 24.199451,\n",
       " 21.819641,\n",
       " 20.612076,\n",
       " 21.819641,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 22.291847,\n",
       " 22.291847,\n",
       " 20.612076,\n",
       " 20.612076,\n",
       " 22.291847,\n",
       " 21.819233,\n",
       " 21.819641,\n",
       " 22.291847,\n",
       " 21.819641,\n",
       " 21.819641,\n",
       " 20.612076,\n",
       " 22.291847,\n",
       " 24.199451,\n",
       " 21.819641,\n",
       " 21.819641,\n",
       " 22.291847,\n",
       " 21.819641,\n",
       " 20.612076,\n",
       " 21.819641,\n",
       " 21.819641,\n",
       " 21.819641,\n",
       " 21.819641,\n",
       " 22.291847,\n",
       " 21.819641,\n",
       " 21.819641,\n",
       " 21.819641,\n",
       " 21.819641,\n",
       " 21.819641,\n",
       " 21.819641,\n",
       " 20.612076,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 22.291847,\n",
       " 24.199451,\n",
       " 21.819641,\n",
       " 24.199451,\n",
       " 23.264862,\n",
       " 20.612076,\n",
       " 23.264862,\n",
       " 21.819641,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 21.819641,\n",
       " 24.199451,\n",
       " 21.819641,\n",
       " 21.819641,\n",
       " 23.264862,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 22.291847,\n",
       " 24.199451,\n",
       " 20.612076,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 20.612076,\n",
       " 22.291847,\n",
       " 21.819641,\n",
       " 23.264862,\n",
       " 21.819641,\n",
       " 21.819641,\n",
       " 20.612076,\n",
       " 21.819641,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 21.819641,\n",
       " 22.291847,\n",
       " 22.291847,\n",
       " 20.612076,\n",
       " 22.291847,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 21.819641,\n",
       " 21.819641,\n",
       " 22.291847,\n",
       " 22.291847,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 21.819641,\n",
       " 24.199451,\n",
       " 23.264862,\n",
       " 20.612076,\n",
       " 21.819641,\n",
       " 22.291847,\n",
       " 21.819641,\n",
       " 24.199451,\n",
       " 21.819641,\n",
       " 21.819641,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 21.819641,\n",
       " 23.264862,\n",
       " 24.199451,\n",
       " 21.819641,\n",
       " 20.612076,\n",
       " 21.819641,\n",
       " 21.819641,\n",
       " 24.199451,\n",
       " 21.819641,\n",
       " 22.291847,\n",
       " 20.612076,\n",
       " 23.264862,\n",
       " 21.819641,\n",
       " 21.819641,\n",
       " 22.291847,\n",
       " 23.264862,\n",
       " 21.819641,\n",
       " 24.199451,\n",
       " 22.291847,\n",
       " 20.612076,\n",
       " 21.819641,\n",
       " 20.612076,\n",
       " 21.819641,\n",
       " 21.819641,\n",
       " 22.291847,\n",
       " 24.199451,\n",
       " 22.291847,\n",
       " 21.819641,\n",
       " 20.612076,\n",
       " 24.199451,\n",
       " 21.819641,\n",
       " 22.291847,\n",
       " 20.612076,\n",
       " 22.291847,\n",
       " 23.264862,\n",
       " 20.612076,\n",
       " 24.199451,\n",
       " 22.291847,\n",
       " 22.291847,\n",
       " 22.291847,\n",
       " 20.612076,\n",
       " 24.199451,\n",
       " 21.819641,\n",
       " 23.292877,\n",
       " 22.291847,\n",
       " 22.291847,\n",
       " 22.291847,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 20.612076,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 22.291847,\n",
       " 22.291847,\n",
       " 21.819641,\n",
       " 24.199451,\n",
       " 20.612076,\n",
       " 24.199451,\n",
       " 23.264862,\n",
       " 20.612076,\n",
       " 20.612076,\n",
       " 23.264862,\n",
       " 21.819641,\n",
       " 21.819641,\n",
       " 21.819641,\n",
       " 21.819641,\n",
       " 24.199451,\n",
       " 21.819641,\n",
       " 21.819641,\n",
       " 22.291847,\n",
       " 24.199451,\n",
       " 22.291847,\n",
       " 20.615517,\n",
       " 20.612076,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 22.291847,\n",
       " 24.199451,\n",
       " 22.291847,\n",
       " 21.819641,\n",
       " 22.291847,\n",
       " 22.291847,\n",
       " 22.291847,\n",
       " 24.199451,\n",
       " 23.264862,\n",
       " 20.612076,\n",
       " 24.199451,\n",
       " 21.819641,\n",
       " 24.199451,\n",
       " 20.612076,\n",
       " 21.819641,\n",
       " 21.819641,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 21.819641,\n",
       " 23.264862,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 20.612076,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 22.291847,\n",
       " 21.819641,\n",
       " 21.819641,\n",
       " 22.291847,\n",
       " 23.264862,\n",
       " 21.819641,\n",
       " 22.291847,\n",
       " 21.819233,\n",
       " 21.795422,\n",
       " 24.199451,\n",
       " 21.819641,\n",
       " 23.341892,\n",
       " 22.291847,\n",
       " 24.199451,\n",
       " 22.291847,\n",
       " 20.612076,\n",
       " 20.612076,\n",
       " 22.291847,\n",
       " 24.199451,\n",
       " 20.612076,\n",
       " 22.291847,\n",
       " 24.199451,\n",
       " 20.612076,\n",
       " 21.819641,\n",
       " 20.612076,\n",
       " 20.612076,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 21.819641,\n",
       " 22.291847,\n",
       " 22.291847,\n",
       " 21.819641,\n",
       " 21.819641,\n",
       " 22.291847,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 22.291847,\n",
       " 21.819641,\n",
       " 21.819641,\n",
       " 24.199451,\n",
       " 22.291847,\n",
       " 24.199451,\n",
       " 21.819641,\n",
       " 22.291847,\n",
       " 24.199451,\n",
       " 20.612076,\n",
       " 21.819641,\n",
       " 23.25991,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 20.612076,\n",
       " 21.819641,\n",
       " 23.264862,\n",
       " 21.819641,\n",
       " 24.199451,\n",
       " 22.291847,\n",
       " 24.199451,\n",
       " 22.291847,\n",
       " 20.612076,\n",
       " 20.612076,\n",
       " 22.291847,\n",
       " 21.819641,\n",
       " 24.199451,\n",
       " 20.612076,\n",
       " 23.264862,\n",
       " 21.819641,\n",
       " 21.819641,\n",
       " 24.191216,\n",
       " 20.612076,\n",
       " 21.819641,\n",
       " 24.199451,\n",
       " 21.819641,\n",
       " 20.612076,\n",
       " 21.819641,\n",
       " 22.291847,\n",
       " 24.199451,\n",
       " 21.819569,\n",
       " 21.819641,\n",
       " 21.819641,\n",
       " 21.819641,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 24.199451,\n",
       " 24.199451]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "\n",
    "df = read_csv('Time_Series_For_Clustering_El_Paso_Final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "non_decimal = re.compile(r'[^\\d.]+')\n",
    "\n",
    "list_of_training_df = []\n",
    "list_of_row_components = []\n",
    "\n",
    "for i in range(1, 524):\n",
    "    \n",
    "#     list_of_row_components = []\n",
    "    \n",
    "    current_row = df.iloc[i]\n",
    "    \n",
    "    bridge_id = current_row.iloc[0]\n",
    "    \n",
    "    current_row = current_row.iloc[1:]\n",
    "    \n",
    "#     print(bridge_id)\n",
    "#     print(current_row)\n",
    "    \n",
    "    for j, row in current_row.iteritems():\n",
    "        \n",
    "        current_row_components = row.split(', ')\n",
    "        current_row_components_replaced = []\n",
    "        \n",
    "#         current_row_components_replaced.append(bridge_id)\n",
    "\n",
    "        for idx, component in enumerate(current_row_components):\n",
    "\n",
    "            result = non_decimal.sub('', current_row_components[idx])\n",
    "#             print(result)\n",
    "            current_row_components_replaced.append(float(result))\n",
    "\n",
    "        list_of_row_components.append(current_row_components_replaced)\n",
    "\n",
    "# bridge_ids = []\n",
    "# var1 = []\n",
    "# var2 = []\n",
    "# var3 = []\n",
    "# var4 = []\n",
    "# var5 = []\n",
    "# var6 = []\n",
    "# varout = []\n",
    "\n",
    "# for element in list_of_row_components:\n",
    "\n",
    "#     bridge_ids.append(element[0])\n",
    "#     var1.append(float(element[1]))\n",
    "#     var2.append(float(element[2]))\n",
    "#     var3.append(float(element[3]))\n",
    "#     var4.append(float(element[5]))\n",
    "#     var5.append(float(element[6]))\n",
    "#     var6.append(float(element[7]))\n",
    "#     varout.append(float(element[2]))\n",
    "\n",
    "# # dict_temp = {'bridge_id':bridge_ids, 'var1': var1, 'var2': var2, 'var3': var3, 'var4': var4, 'var5': var5, 'var6': var6, 'varout': varout}\n",
    "# dict_temp = {'var1': var1, 'var2': var2, 'var3': var3, 'var4': var4, 'var5': var5, 'var6': var6, 'varout': varout}\n",
    "\n",
    "# df_temp = pd.DataFrame(dict_temp)\n",
    "\n",
    "# list_of_training_df.append(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, element in enumerate(list_of_row_components):\n",
    "    for i in range(1, len(element)):\n",
    "        list_of_row_components[idx][i] = float( list_of_row_components[idx][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[36.0, 97.0, 428.0, 1949.0, 2.0, 10.9, 7.3],\n",
       " [36.0, 96.9, 955.0, 1949.0, 2.0, 10.9, 7.3],\n",
       " [36.0, 96.9, 955.0, 1949.0, 2.0, 10.9, 7.3],\n",
       " [36.0, 96.9, 955.0, 1949.0, 2.0, 10.9, 7.3],\n",
       " [36.0, 96.9, 955.0, 1949.0, 2.0, 10.9, 7.3],\n",
       " [36.3, 97.0, 955.0, 1949.0, 2.0, 11.0, 7.0],\n",
       " [36.3, 96.9, 955.0, 1949.0, 2.0, 11.0, 7.3],\n",
       " [36.3, 96.9, 983.0, 1949.0, 2.0, 11.0, 7.3],\n",
       " [36.3, 96.9, 983.0, 1949.0, 2.0, 11.0, 7.3],\n",
       " [36.3, 96.9, 983.0, 1949.0, 2.0, 11.0, 7.3],\n",
       " [36.3, 96.9, 983.0, 1949.0, 2.0, 11.0, 7.3],\n",
       " [36.3, 97.0, 422.0, 1949.0, 2.0, 11.0, 7.3],\n",
       " [36.3, 97.0, 422.0, 1949.0, 2.0, 11.0, 7.3],\n",
       " [36.3, 97.0, 422.0, 1949.0, 2.0, 11.0, 7.3],\n",
       " [36.3, 97.0, 422.0, 1949.0, 2.0, 11.0, 7.3],\n",
       " [36.3, 97.0, 422.0, 1949.0, 2.0, 9.7, 7.3],\n",
       " [36.3, 97.0, 369.0, 1949.0, 2.0, 9.7, 7.3],\n",
       " [36.3, 86.0, 369.0, 1949.0, 2.0, 9.7, 7.3],\n",
       " [36.3, 86.0, 369.0, 1949.0, 2.0, 9.7, 7.3],\n",
       " [36.3, 86.0, 369.0, 1949.0, 2.0, 9.7, 7.3],\n",
       " [36.3, 86.0, 369.0, 1949.0, 2.0, 9.7, 7.3],\n",
       " [36.3, 86.0, 522.0, 1949.0, 2.0, 9.7, 7.3],\n",
       " [36.0, 83.9, 417.0, 1970.0, 2.0, 6.6, 6.4],\n",
       " [36.0, 70.9, 351.0, 1970.0, 2.0, 6.6, 3.0],\n",
       " [36.0, 70.9, 351.0, 1970.0, 2.0, 6.6, 3.0],\n",
       " [36.0, 70.9, 351.0, 1970.0, 2.0, 6.6, 3.0],\n",
       " [36.0, 70.9, 351.0, 1970.0, 2.0, 6.6, 3.0],\n",
       " [36.3, 76.0, 351.0, 1970.0, 2.0, 6.6, 3.0],\n",
       " [36.3, 69.0, 351.0, 1970.0, 2.0, 6.6, 3.0],\n",
       " [36.3, 66.9, 478.0, 1970.0, 2.0, 6.6, 2.9],\n",
       " [36.3, 66.9, 478.0, 1970.0, 2.0, 6.6, 2.9],\n",
       " [36.3, 66.9, 478.0, 1970.0, 2.0, 6.6, 2.9],\n",
       " [36.3, 66.9, 478.0, 1970.0, 2.0, 6.6, 2.9],\n",
       " [36.3, 62.9, 478.0, 1970.0, 2.0, 6.6, 2.9],\n",
       " [36.3, 62.9, 478.0, 1970.0, 2.0, 6.6, 2.9],\n",
       " [36.3, 62.9, 777.0, 1970.0, 2.0, 6.6, 2.9],\n",
       " [36.3, 62.9, 777.0, 1970.0, 2.0, 6.6, 2.9],\n",
       " [36.3, 62.9, 777.0, 1970.0, 2.0, 6.6, 2.9],\n",
       " [36.3, 62.9, 623.0, 1970.0, 2.0, 6.6, 2.9],\n",
       " [36.3, 62.9, 623.0, 1970.0, 2.0, 6.6, 2.9],\n",
       " [36.3, 62.9, 623.0, 1970.0, 2.0, 6.6, 2.9],\n",
       " [32.7, 55.7, 623.0, 1970.0, 2.0, 6.6, 2.9],\n",
       " [32.7, 55.7, 623.0, 1970.0, 2.0, 6.6, 2.9],\n",
       " [32.7, 55.7, 717.0, 1970.0, 2.0, 6.6, 2.9],\n",
       " [36.0, 82.0, 1836.0, 1955.0, 2.0, 7.6, 4.0],\n",
       " [36.0, 84.3, 1459.0, 1955.0, 2.0, 7.7, 4.0],\n",
       " [36.0, 84.3, 1459.0, 1955.0, 2.0, 7.7, 4.0],\n",
       " [36.0, 84.3, 1459.0, 1955.0, 2.0, 7.7, 4.0],\n",
       " [36.0, 84.3, 1459.0, 1955.0, 2.0, 7.7, 3.4],\n",
       " [36.3, 83.4, 1459.0, 1955.0, 2.0, 7.7, 3.0],\n",
       " [36.3, 84.3, 1459.0, 1955.0, 2.0, 7.7, 3.4],\n",
       " [36.3, 84.4, 1295.0, 1955.0, 2.0, 7.7, 3.4],\n",
       " [36.3, 84.4, 1295.0, 1955.0, 2.0, 7.7, 3.4],\n",
       " [36.3, 72.3, 1295.0, 1955.0, 2.0, 7.7, 3.4],\n",
       " [36.3, 72.3, 1295.0, 1955.0, 2.0, 7.7, 3.4],\n",
       " [36.3, 72.3, 1295.0, 1955.0, 2.0, 7.7, 3.4],\n",
       " [36.3, 72.3, 1295.0, 1955.0, 2.0, 7.7, 3.4],\n",
       " [36.3, 72.3, 1329.0, 1955.0, 2.0, 7.7, 3.4],\n",
       " [36.3, 72.3, 1329.0, 1955.0, 2.0, 7.7, 3.4],\n",
       " [36.3, 72.3, 1329.0, 1955.0, 2.0, 7.7, 3.4],\n",
       " [36.3, 72.3, 1446.0, 1955.0, 2.0, 7.7, 3.4],\n",
       " [36.3, 72.3, 1446.0, 1955.0, 2.0, 7.7, 3.4],\n",
       " [36.3, 72.3, 1446.0, 1955.0, 2.0, 7.7, 3.4],\n",
       " [27.2, 50.2, 1446.0, 1955.0, 2.0, 7.7, 3.4],\n",
       " [27.2, 50.2, 1446.0, 1955.0, 2.0, 7.7, 3.4],\n",
       " [27.2, 50.2, 2696.0, 1955.0, 2.0, 7.7, 3.4],\n",
       " [36.0, 97.0, 87.0, 1984.0, 2.0, 12.8, 3.0],\n",
       " [36.0, 97.0, 305.0, 1984.0, 2.0, 12.8, 3.0],\n",
       " [36.0, 97.0, 305.0, 1984.0, 2.0, 12.8, 3.0],\n",
       " [36.0, 97.0, 305.0, 1984.0, 2.0, 12.8, 3.0],\n",
       " [36.0, 97.0, 305.0, 1984.0, 2.0, 12.8, 3.0],\n",
       " [36.3, 97.0, 305.0, 1984.0, 2.0, 12.8, 3.0],\n",
       " [36.3, 97.0, 305.0, 1984.0, 2.0, 12.8, 3.0],\n",
       " [36.3, 97.0, 397.0, 1984.0, 2.0, 12.8, 3.0],\n",
       " [36.3, 97.0, 397.0, 1984.0, 2.0, 12.8, 3.0],\n",
       " [36.3, 97.0, 397.0, 1984.0, 2.0, 12.8, 3.0],\n",
       " [36.3, 97.0, 397.0, 1984.0, 2.0, 12.8, 3.0],\n",
       " [36.3, 98.0, 397.0, 1984.0, 2.0, 13.3, 3.0],\n",
       " [36.3, 98.0, 397.0, 1984.0, 2.0, 13.3, 3.0],\n",
       " [36.3, 98.0, 287.0, 1984.0, 2.0, 13.3, 3.0],\n",
       " [36.3, 98.0, 287.0, 1984.0, 2.0, 13.3, 3.0],\n",
       " [36.3, 99.0, 287.0, 1984.0, 2.0, 12.8, 3.0],\n",
       " [36.3, 99.0, 302.0, 1984.0, 2.0, 12.8, 3.0],\n",
       " [36.3, 100.0, 302.0, 1984.0, 2.0, 12.8, 3.0],\n",
       " [36.3, 100.0, 302.0, 1984.0, 2.0, 12.8, 3.0],\n",
       " [36.3, 100.0, 302.0, 1984.0, 2.0, 12.8, 3.0],\n",
       " [36.3, 100.0, 302.0, 1984.0, 2.0, 12.8, 3.0],\n",
       " [36.3, 100.0, 268.0, 1984.0, 2.0, 12.8, 3.0],\n",
       " [67.5, 80.1, 16737.0, 1960.0, 12.0, 18.5, 7.6],\n",
       " [36.0, 80.5, 13460.0, 1960.0, 12.0, 18.5, 7.6],\n",
       " [36.0, 80.5, 13460.0, 1960.0, 12.0, 18.5, 7.6],\n",
       " [36.0, 80.5, 13460.0, 1960.0, 12.0, 18.5, 7.6],\n",
       " [36.0, 80.5, 13460.0, 1960.0, 12.0, 18.5, 7.6],\n",
       " [36.3, 81.2, 13460.0, 1960.0, 12.0, 18.6, 7.6],\n",
       " [36.3, 80.5, 13460.0, 1960.0, 12.0, 18.6, 7.6],\n",
       " [36.3, 80.3, 15229.0, 1960.0, 12.0, 18.6, 7.6],\n",
       " [36.3, 80.3, 15229.0, 1960.0, 12.0, 18.6, 7.6],\n",
       " [36.3, 68.9, 15229.0, 1960.0, 12.0, 18.6, 7.6],\n",
       " [36.3, 68.9, 15229.0, 1960.0, 12.0, 18.6, 7.6],\n",
       " [36.3, 68.9, 15229.0, 1960.0, 12.0, 18.6, 7.6],\n",
       " [36.3, 68.9, 15229.0, 1960.0, 12.0, 18.6, 7.6],\n",
       " [36.3, 68.8, 16000.0, 1960.0, 12.0, 18.6, 7.6],\n",
       " [36.3, 68.8, 16000.0, 1960.0, 12.0, 18.6, 7.6],\n",
       " [36.3, 68.8, 16000.0, 1960.0, 12.0, 18.6, 7.6],\n",
       " [36.3, 70.9, 664.0, 1960.0, 12.0, 18.6, 7.6],\n",
       " [36.3, 70.9, 664.0, 1960.0, 12.0, 18.6, 7.6],\n",
       " [36.3, 70.9, 664.0, 1960.0, 12.0, 18.6, 7.6],\n",
       " [36.3, 70.9, 664.0, 1960.0, 12.0, 18.6, 7.6],\n",
       " [36.3, 70.9, 664.0, 1960.0, 12.0, 18.6, 7.6],\n",
       " [99.9, 70.9, 14775.0, 1960.0, 12.0, 18.6, 7.6],\n",
       " [36.0, 96.8, 2289.0, 1955.0, 2.0, 12.1, 3.7],\n",
       " [36.0, 85.7, 3236.0, 1955.0, 2.0, 12.1, 3.7],\n",
       " [36.0, 85.7, 3236.0, 1955.0, 2.0, 12.1, 3.7],\n",
       " [36.0, 85.7, 3236.0, 1955.0, 2.0, 12.1, 3.7],\n",
       " [36.0, 85.7, 3236.0, 1955.0, 2.0, 12.1, 2.7],\n",
       " [36.3, 96.9, 3236.0, 1955.0, 2.0, 12.2, 3.0],\n",
       " [36.3, 85.7, 3236.0, 1955.0, 2.0, 12.2, 3.4],\n",
       " [36.3, 69.6, 2810.0, 1955.0, 2.0, 12.2, 3.4],\n",
       " [36.3, 69.6, 2810.0, 1955.0, 2.0, 12.2, 3.4],\n",
       " [36.3, 87.7, 2810.0, 1955.0, 2.0, 12.2, 3.4],\n",
       " [36.3, 87.7, 2810.0, 1955.0, 2.0, 12.2, 3.4],\n",
       " [36.3, 87.7, 2810.0, 1955.0, 2.0, 12.2, 3.4],\n",
       " [36.3, 87.7, 2810.0, 1955.0, 2.0, 12.2, 3.4],\n",
       " [36.3, 71.7, 2355.0, 1955.0, 2.0, 12.2, 3.4],\n",
       " [36.3, 71.7, 2355.0, 1955.0, 2.0, 12.2, 3.4],\n",
       " [36.3, 71.7, 2355.0, 1955.0, 2.0, 12.2, 3.4],\n",
       " [36.3, 71.7, 2019.0, 1955.0, 2.0, 12.2, 3.4],\n",
       " [36.3, 71.7, 2019.0, 1955.0, 2.0, 12.2, 3.4],\n",
       " [36.3, 71.7, 2019.0, 1955.0, 2.0, 12.2, 3.4],\n",
       " [36.3, 71.7, 2019.0, 1955.0, 2.0, 12.2, 3.4],\n",
       " [36.3, 71.7, 2019.0, 1955.0, 2.0, 12.2, 3.4],\n",
       " [39.1, 71.7, 727.0, 1955.0, 2.0, 12.2, 3.4],\n",
       " [36.0, 81.1, 8323.0, 1955.0, 4.0, 20.4, 2.7],\n",
       " [36.0, 96.3, 7809.0, 1955.0, 2.0, 20.4, 2.7],\n",
       " [36.0, 96.3, 7809.0, 1955.0, 2.0, 20.4, 2.7],\n",
       " [36.0, 96.3, 7809.0, 1955.0, 2.0, 20.4, 2.7],\n",
       " [36.0, 96.3, 7809.0, 1955.0, 2.0, 20.4, 2.7],\n",
       " [36.3, 96.6, 7809.0, 1955.0, 2.0, 20.4, 3.0],\n",
       " [36.3, 96.3, 7809.0, 1955.0, 2.0, 20.4, 2.7],\n",
       " [36.3, 95.9, 11303.0, 1955.0, 2.0, 20.4, 2.7],\n",
       " [36.3, 95.9, 11303.0, 1955.0, 2.0, 20.4, 2.7],\n",
       " [36.3, 97.9, 11303.0, 1955.0, 2.0, 20.4, 2.7],\n",
       " [36.3, 97.9, 11303.0, 1955.0, 2.0, 20.4, 2.7],\n",
       " [36.3, 97.9, 11303.0, 1955.0, 2.0, 20.4, 2.7],\n",
       " [36.3, 97.9, 11303.0, 1955.0, 2.0, 20.4, 2.7],\n",
       " [36.3, 98.0, 10629.0, 1955.0, 2.0, 20.4, 2.7],\n",
       " [36.3, 98.0, 10629.0, 1955.0, 2.0, 20.4, 2.7],\n",
       " [36.3, 98.0, 10629.0, 1955.0, 2.0, 20.4, 2.7],\n",
       " [36.3, 98.9, 954.0, 1955.0, 2.0, 20.4, 2.7],\n",
       " [36.3, 98.9, 954.0, 1955.0, 2.0, 20.4, 2.7],\n",
       " [36.3, 98.9, 954.0, 1955.0, 2.0, 20.4, 2.7],\n",
       " [36.3, 98.9, 954.0, 1955.0, 2.0, 20.4, 2.7],\n",
       " [36.3, 98.9, 954.0, 1955.0, 2.0, 20.4, 2.7],\n",
       " [99.9, 98.9, 16371.0, 1955.0, 2.0, 20.4, 2.7],\n",
       " [36.0, 96.9, 660.0, 1970.0, 2.0, 11.2, 2.4],\n",
       " [36.0, 96.9, 950.0, 1970.0, 2.0, 11.1, 2.4],\n",
       " [36.0, 96.9, 950.0, 1970.0, 2.0, 11.1, 2.4],\n",
       " [36.0, 96.9, 950.0, 1970.0, 2.0, 11.1, 2.4],\n",
       " [36.0, 96.9, 950.0, 1970.0, 2.0, 11.1, 2.4],\n",
       " [36.3, 97.0, 950.0, 1970.0, 2.0, 11.1, 2.0],\n",
       " [36.3, 96.9, 950.0, 1970.0, 2.0, 11.1, 2.4],\n",
       " [36.3, 96.9, 700.0, 1970.0, 2.0, 11.1, 2.0],\n",
       " [36.3, 96.9, 700.0, 1970.0, 2.0, 11.1, 2.0],\n",
       " [36.3, 85.9, 700.0, 1970.0, 2.0, 11.1, 2.6],\n",
       " [36.3, 85.9, 700.0, 1970.0, 2.0, 11.1, 2.6],\n",
       " [36.3, 85.9, 700.0, 1970.0, 2.0, 11.1, 2.6],\n",
       " [36.3, 85.9, 700.0, 1970.0, 2.0, 11.1, 2.6],\n",
       " [36.3, 85.9, 780.0, 1970.0, 2.0, 11.1, 2.6],\n",
       " [36.3, 85.9, 780.0, 1970.0, 2.0, 11.1, 2.6],\n",
       " [36.3, 87.9, 780.0, 1970.0, 2.0, 11.1, 2.6],\n",
       " [36.3, 87.9, 771.0, 1970.0, 2.0, 11.1, 2.6],\n",
       " [36.3, 87.9, 771.0, 1970.0, 2.0, 11.1, 2.6],\n",
       " [36.3, 87.9, 771.0, 1970.0, 2.0, 11.1, 2.6],\n",
       " [27.2, 65.9, 771.0, 1970.0, 2.0, 11.1, 2.6],\n",
       " [27.2, 65.9, 771.0, 1970.0, 2.0, 11.1, 2.6],\n",
       " [27.2, 65.9, 391.0, 1970.0, 2.0, 11.1, 2.6],\n",
       " [36.0, 79.6, 3698.0, 1964.0, 2.0, 8.5, 9.4],\n",
       " [36.0, 79.4, 4746.0, 1964.0, 2.0, 8.5, 9.4],\n",
       " [36.0, 79.4, 4746.0, 1964.0, 2.0, 8.5, 9.4],\n",
       " [36.0, 79.4, 4746.0, 1964.0, 2.0, 8.5, 9.4],\n",
       " [36.0, 79.4, 4746.0, 1964.0, 2.0, 8.5, 8.8],\n",
       " [36.3, 79.7, 4746.0, 1964.0, 2.0, 8.5, 9.0],\n",
       " [36.3, 79.4, 4746.0, 1964.0, 2.0, 8.5, 8.8],\n",
       " [36.3, 79.5, 4701.0, 1964.0, 2.0, 8.5, 8.9],\n",
       " [36.3, 79.5, 4701.0, 1964.0, 2.0, 8.5, 8.9],\n",
       " [36.3, 68.3, 4701.0, 1964.0, 2.0, 8.5, 8.9],\n",
       " [36.3, 68.3, 4701.0, 1964.0, 2.0, 8.5, 8.9],\n",
       " [36.3, 68.3, 4701.0, 1964.0, 2.0, 8.5, 8.9],\n",
       " [36.3, 68.3, 4701.0, 1964.0, 2.0, 8.5, 8.9],\n",
       " [36.3, 79.5, 4409.0, 1964.0, 2.0, 8.5, 8.9],\n",
       " [36.3, 79.5, 4409.0, 1964.0, 2.0, 8.5, 8.9],\n",
       " [36.3, 79.5, 4409.0, 1964.0, 2.0, 8.5, 8.9],\n",
       " [36.3, 79.5, 4240.0, 1964.0, 2.0, 8.5, 8.9],\n",
       " [36.3, 79.5, 4240.0, 1964.0, 2.0, 8.5, 8.9],\n",
       " [36.3, 79.5, 4240.0, 1964.0, 2.0, 8.5, 8.9],\n",
       " [36.3, 79.5, 4240.0, 1964.0, 2.0, 8.5, 8.9],\n",
       " [36.3, 79.5, 4240.0, 1964.0, 2.0, 8.5, 8.9],\n",
       " [36.3, 79.5, 4811.0, 1964.0, 2.0, 8.5, 8.9],\n",
       " [36.0, 83.3, 1927.0, 1984.0, 5.0, 18.2, 3.7],\n",
       " [36.0, 98.5, 5329.0, 1984.0, 3.0, 18.2, 3.7],\n",
       " [36.0, 98.5, 5329.0, 1984.0, 3.0, 18.2, 3.7],\n",
       " [36.0, 98.5, 5329.0, 1984.0, 3.0, 18.2, 3.7],\n",
       " [36.0, 95.5, 5329.0, 1984.0, 3.0, 18.2, 3.7],\n",
       " [36.3, 98.8, 5329.0, 1984.0, 3.0, 18.3, 4.0],\n",
       " [36.3, 96.5, 5329.0, 1984.0, 3.0, 18.3, 3.7],\n",
       " [36.3, 98.6, 4606.0, 1984.0, 3.0, 18.3, 4.0],\n",
       " [36.3, 98.6, 4606.0, 1984.0, 3.0, 18.3, 4.0],\n",
       " [36.3, 96.6, 4606.0, 1984.0, 3.0, 18.3, 3.7],\n",
       " [36.3, 96.6, 4606.0, 1984.0, 3.0, 18.3, 3.7],\n",
       " [36.3, 96.6, 4606.0, 1984.0, 3.0, 18.3, 3.7],\n",
       " [36.3, 96.6, 4606.0, 1984.0, 3.0, 18.3, 3.7],\n",
       " [36.3, 96.4, 6021.0, 1984.0, 3.0, 18.3, 3.7],\n",
       " [36.3, 96.4, 6021.0, 1984.0, 3.0, 18.3, 3.7],\n",
       " [36.3, 96.4, 6021.0, 1984.0, 3.0, 18.3, 3.7],\n",
       " [36.3, 96.6, 4478.0, 1984.0, 3.0, 18.3, 3.7],\n",
       " [36.3, 97.6, 4478.0, 1984.0, 3.0, 18.3, 3.7],\n",
       " [36.3, 97.6, 4478.0, 1984.0, 3.0, 18.3, 3.7],\n",
       " [36.3, 97.6, 4478.0, 1984.0, 3.0, 18.3, 3.7],\n",
       " [36.3, 97.6, 4478.0, 1984.0, 3.0, 18.3, 3.7],\n",
       " [36.3, 97.6, 3890.0, 1984.0, 3.0, 18.3, 3.7],\n",
       " [31.5, 49.7, 560.0, 1915.0, 2.0, 5.9, 9.8],\n",
       " [31.5, 48.8, 147.0, 1915.0, 2.0, 5.9, 9.8],\n",
       " [31.5, 48.8, 147.0, 1915.0, 2.0, 5.9, 9.8],\n",
       " [31.5, 48.8, 147.0, 1915.0, 2.0, 5.9, 9.8],\n",
       " [31.5, 48.8, 147.0, 1915.0, 2.0, 5.9, 9.1],\n",
       " [31.7, 47.0, 147.0, 1915.0, 2.0, 5.9, 9.0],\n",
       " [31.8, 49.0, 147.0, 1915.0, 2.0, 5.9, 9.1],\n",
       " [32.3, 49.4, 988.0, 1915.0, 2.0, 5.9, 9.0],\n",
       " [32.3, 49.4, 988.0, 1915.0, 2.0, 5.9, 9.0],\n",
       " [32.3, 51.4, 988.0, 1915.0, 2.0, 5.9, 9.0],\n",
       " [32.3, 51.4, 988.0, 1915.0, 2.0, 5.9, 9.0],\n",
       " [32.3, 51.4, 988.0, 1915.0, 2.0, 5.9, 9.0],\n",
       " [32.3, 51.4, 988.0, 1915.0, 2.0, 5.9, 9.0],\n",
       " [32.3, 51.5, 385.0, 1915.0, 2.0, 5.9, 9.0],\n",
       " [32.3, 51.5, 385.0, 1915.0, 2.0, 5.9, 9.0],\n",
       " [32.3, 51.5, 385.0, 1915.0, 2.0, 5.9, 9.0],\n",
       " [32.3, 51.5, 349.0, 1915.0, 2.0, 5.9, 9.0],\n",
       " [32.3, 51.5, 349.0, 1915.0, 2.0, 5.9, 9.0],\n",
       " [32.3, 51.5, 349.0, 1915.0, 2.0, 5.9, 9.0],\n",
       " [32.3, 49.5, 349.0, 1915.0, 2.0, 5.9, 9.0],\n",
       " [32.3, 49.5, 349.0, 1915.0, 2.0, 5.9, 9.0],\n",
       " [32.3, 49.5, 433.0, 1915.0, 2.0, 5.9, 9.0],\n",
       " [46.8, 77.7, 10205.0, 1984.0, 5.0, 29.4, 3.0],\n",
       " [46.8, 77.0, 15983.0, 1984.0, 5.0, 99.9, 3.0],\n",
       " [46.8, 77.0, 15983.0, 1984.0, 5.0, 99.9, 3.0],\n",
       " [46.8, 77.0, 15983.0, 1984.0, 5.0, 99.9, 3.0],\n",
       " [46.8, 77.0, 15983.0, 1984.0, 5.0, 99.9, 3.0],\n",
       " [47.2, 78.2, 15983.0, 1984.0, 5.0, 30.5, 3.0],\n",
       " [47.2, 77.2, 15983.0, 1984.0, 5.0, 30.5, 3.0],\n",
       " [47.4, 77.8, 13807.0, 1984.0, 5.0, 30.5, 3.0],\n",
       " [47.4, 77.8, 13807.0, 1984.0, 5.0, 30.5, 3.0],\n",
       " [47.4, 77.8, 13807.0, 1984.0, 5.0, 18.0, 3.0],\n",
       " [47.4, 77.8, 13807.0, 1984.0, 5.0, 18.0, 3.0],\n",
       " [47.4, 78.1, 11436.0, 1984.0, 5.0, 18.0, 3.0],\n",
       " [47.4, 78.1, 11436.0, 1984.0, 5.0, 18.0, 3.0],\n",
       " [47.4, 78.1, 11436.0, 1984.0, 5.0, 18.0, 3.0],\n",
       " [47.4, 78.1, 11436.0, 1984.0, 5.0, 18.0, 3.0],\n",
       " [47.4, 78.1, 11436.0, 1984.0, 5.0, 18.0, 3.0],\n",
       " [47.4, 77.6, 15597.0, 1984.0, 5.0, 18.0, 3.0],\n",
       " [47.4, 77.6, 15597.0, 1984.0, 5.0, 18.0, 3.0],\n",
       " [47.4, 77.6, 15597.0, 1984.0, 5.0, 18.0, 3.0],\n",
       " [47.4, 66.2, 15597.0, 1984.0, 5.0, 18.0, 3.0],\n",
       " [47.4, 66.2, 15597.0, 1984.0, 5.0, 18.0, 3.0],\n",
       " [47.4, 66.2, 15009.0, 1984.0, 5.0, 18.0, 3.0],\n",
       " [36.0, 65.5, 567.0, 1925.0, 2.0, 5.9, 4.9],\n",
       " [36.0, 65.5, 691.0, 1925.0, 2.0, 6.0, 4.9],\n",
       " [36.0, 65.5, 691.0, 1925.0, 2.0, 6.0, 4.9],\n",
       " [36.0, 65.5, 691.0, 1925.0, 2.0, 6.0, 4.9],\n",
       " [36.0, 65.5, 691.0, 1925.0, 2.0, 6.0, 4.6],\n",
       " [16.3, 30.2, 691.0, 1925.0, 2.0, 6.0, 5.0],\n",
       " [16.3, 30.0, 691.0, 1925.0, 2.0, 6.0, 4.6],\n",
       " [16.4, 31.8, 574.0, 1925.0, 2.0, 6.0, 4.5],\n",
       " [16.4, 31.8, 574.0, 1925.0, 2.0, 6.0, 4.5],\n",
       " [16.4, 21.4, 574.0, 1925.0, 2.0, 6.0, 4.5],\n",
       " [16.4, 21.4, 574.0, 1925.0, 2.0, 6.0, 4.5],\n",
       " [16.4, 21.4, 574.0, 1925.0, 2.0, 6.0, 4.5],\n",
       " [16.4, 21.4, 574.0, 1925.0, 2.0, 6.0, 4.5],\n",
       " [16.4, 21.2, 710.0, 1925.0, 2.0, 6.0, 4.5],\n",
       " [16.4, 21.2, 710.0, 1925.0, 2.0, 6.0, 4.5],\n",
       " [16.4, 21.2, 710.0, 1925.0, 2.0, 6.0, 4.5],\n",
       " [16.4, 21.1, 830.0, 1925.0, 2.0, 6.0, 4.5],\n",
       " [16.4, 21.1, 830.0, 1925.0, 2.0, 6.0, 4.7],\n",
       " [16.4, 21.1, 830.0, 1925.0, 2.0, 6.0, 4.7],\n",
       " [16.4, 19.9, 830.0, 1925.0, 2.0, 6.0, 4.7],\n",
       " [16.4, 19.9, 830.0, 1925.0, 2.0, 6.0, 4.7],\n",
       " [16.4, 19.9, 830.0, 1925.0, 2.0, 6.0, 4.7],\n",
       " [36.0, 95.2, 7543.0, 1984.0, 2.0, 29.8, 4.0],\n",
       " [36.0, 97.6, 10181.0, 1984.0, 2.0, 10.2, 4.0],\n",
       " [36.0, 97.6, 10181.0, 1984.0, 2.0, 10.2, 4.0],\n",
       " [36.0, 97.6, 10181.0, 1984.0, 2.0, 10.2, 4.0],\n",
       " [36.0, 97.6, 10181.0, 1984.0, 4.0, 10.5, 4.0],\n",
       " [36.3, 96.5, 10181.0, 1984.0, 4.0, 10.5, 4.0],\n",
       " [36.3, 99.1, 10181.0, 1984.0, 4.0, 10.5, 4.0],\n",
       " [36.3, 95.8, 12723.0, 1984.0, 4.0, 10.5, 4.0],\n",
       " [36.3, 95.8, 12723.0, 1984.0, 4.0, 10.5, 4.0],\n",
       " [36.3, 98.8, 12723.0, 1984.0, 4.0, 10.2, 4.1],\n",
       " [36.3, 98.8, 12723.0, 1984.0, 4.0, 10.2, 4.1],\n",
       " [36.3, 98.8, 12723.0, 1984.0, 4.0, 10.2, 4.1],\n",
       " [36.3, 98.8, 12723.0, 1984.0, 4.0, 10.2, 4.1],\n",
       " [36.3, 99.1, 10146.0, 1984.0, 4.0, 10.2, 4.1],\n",
       " [36.3, 99.1, 10146.0, 1984.0, 4.0, 10.2, 4.1],\n",
       " [36.3, 99.1, 10146.0, 1984.0, 4.0, 10.2, 4.1],\n",
       " [36.3, 99.0, 10431.0, 1984.0, 4.0, 10.2, 4.1],\n",
       " [36.3, 99.0, 10431.0, 1984.0, 4.0, 10.2, 4.1],\n",
       " [36.3, 99.0, 10431.0, 1984.0, 4.0, 10.2, 4.1],\n",
       " [36.3, 99.0, 10431.0, 1984.0, 4.0, 10.2, 4.1],\n",
       " [36.3, 99.0, 10431.0, 1984.0, 4.0, 10.2, 4.1],\n",
       " [36.3, 99.0, 9717.0, 1984.0, 4.0, 10.2, 4.1],\n",
       " [31.5, 79.9, 10.0, 1984.0, 2.0, 10.6, 4.6],\n",
       " [31.5, 79.8, 626.0, 1984.0, 2.0, 10.6, 4.6],\n",
       " [31.5, 79.8, 626.0, 1984.0, 2.0, 10.6, 4.6],\n",
       " [31.5, 79.8, 626.0, 1984.0, 2.0, 10.6, 4.6],\n",
       " [31.5, 79.8, 626.0, 1984.0, 2.0, 10.6, 4.6],\n",
       " [31.7, 80.0, 626.0, 1984.0, 2.0, 10.6, 5.0],\n",
       " [31.8, 80.0, 626.0, 1984.0, 2.0, 10.6, 4.6],\n",
       " [32.1, 80.3, 537.0, 1984.0, 2.0, 10.6, 4.5],\n",
       " [32.1, 80.3, 537.0, 1984.0, 2.0, 10.6, 4.5],\n",
       " [32.1, 80.3, 537.0, 1984.0, 2.0, 10.6, 4.5],\n",
       " [32.1, 80.3, 537.0, 1984.0, 2.0, 10.6, 4.5],\n",
       " [32.1, 80.3, 537.0, 1984.0, 2.0, 10.6, 4.5],\n",
       " [32.1, 80.3, 537.0, 1984.0, 2.0, 10.6, 4.5],\n",
       " [32.1, 81.3, 532.0, 1984.0, 2.0, 10.6, 4.5],\n",
       " [32.1, 81.3, 532.0, 1984.0, 2.0, 10.6, 4.5],\n",
       " [32.1, 81.3, 532.0, 1984.0, 2.0, 10.6, 4.5],\n",
       " [32.1, 81.3, 481.0, 1984.0, 2.0, 10.6, 4.5],\n",
       " [32.1, 81.3, 481.0, 1984.0, 2.0, 10.6, 4.5],\n",
       " [32.1, 81.3, 481.0, 1984.0, 2.0, 10.6, 4.5],\n",
       " [32.1, 81.3, 481.0, 1984.0, 2.0, 10.6, 4.5],\n",
       " [32.1, 81.3, 481.0, 1984.0, 2.0, 10.6, 4.5],\n",
       " [32.1, 81.3, 424.0, 1984.0, 2.0, 10.6, 4.5],\n",
       " [37.8, 86.9, 10.0, 1984.0, 2.0, 10.3, 4.6],\n",
       " [37.8, 86.8, 304.0, 1984.0, 2.0, 10.3, 4.3],\n",
       " [37.8, 86.8, 304.0, 1984.0, 2.0, 10.3, 4.3],\n",
       " [37.8, 86.8, 304.0, 1984.0, 2.0, 10.3, 4.3],\n",
       " [37.8, 86.8, 304.0, 1984.0, 2.0, 10.3, 4.3],\n",
       " [38.1, 87.2, 304.0, 1984.0, 2.0, 10.4, 4.0],\n",
       " [38.1, 87.1, 304.0, 1984.0, 2.0, 10.4, 4.3],\n",
       " [38.4, 87.6, 287.0, 1984.0, 2.0, 10.4, 4.3],\n",
       " [38.4, 87.6, 287.0, 1984.0, 2.0, 10.4, 4.3],\n",
       " [38.4, 90.6, 287.0, 1984.0, 2.0, 10.4, 4.3],\n",
       " [38.4, 90.6, 287.0, 1984.0, 2.0, 10.4, 4.3],\n",
       " [38.4, 90.6, 287.0, 1984.0, 2.0, 10.4, 4.3],\n",
       " [38.4, 90.6, 287.0, 1984.0, 2.0, 10.4, 4.3],\n",
       " [38.4, 90.6, 283.0, 1984.0, 2.0, 10.4, 4.3],\n",
       " [38.4, 90.6, 283.0, 1984.0, 2.0, 10.4, 4.3],\n",
       " [38.4, 90.6, 283.0, 1984.0, 2.0, 10.4, 4.3],\n",
       " [38.4, 90.6, 329.0, 1984.0, 2.0, 10.4, 4.3],\n",
       " [38.4, 90.6, 329.0, 1984.0, 2.0, 10.4, 4.3],\n",
       " [38.4, 90.6, 329.0, 1984.0, 2.0, 10.4, 4.3],\n",
       " [38.4, 90.6, 329.0, 1984.0, 2.0, 10.4, 4.3],\n",
       " [38.4, 90.6, 329.0, 1984.0, 2.0, 10.4, 4.3],\n",
       " [38.4, 90.6, 260.0, 1984.0, 2.0, 10.4, 4.3],\n",
       " [36.0, 91.1, 100.0, 1984.0, 2.0, 14.6, 3.7],\n",
       " [36.0, 77.0, 1842.0, 1984.0, 2.0, 14.6, 3.7],\n",
       " [36.0, 77.0, 1842.0, 1984.0, 2.0, 14.6, 3.7],\n",
       " [36.0, 77.0, 1842.0, 1984.0, 2.0, 14.6, 3.7],\n",
       " [36.0, 77.0, 1842.0, 1984.0, 2.0, 14.6, 3.7],\n",
       " [36.3, 87.6, 1842.0, 1984.0, 2.0, 14.6, 4.0],\n",
       " [36.3, 78.3, 1842.0, 1984.0, 2.0, 14.6, 3.7],\n",
       " [36.3, 79.6, 1670.0, 1984.0, 2.0, 14.6, 3.7],\n",
       " [36.3, 79.6, 1670.0, 1984.0, 2.0, 14.6, 3.7],\n",
       " [36.3, 79.6, 1670.0, 1984.0, 2.0, 14.6, 3.7],\n",
       " [36.3, 79.6, 1670.0, 1984.0, 2.0, 14.6, 3.7],\n",
       " [36.3, 79.6, 1670.0, 1984.0, 2.0, 14.6, 3.7],\n",
       " [36.3, 79.6, 1670.0, 1984.0, 2.0, 14.6, 3.7],\n",
       " [36.3, 79.6, 1670.0, 1984.0, 2.0, 14.6, 3.7],\n",
       " [36.3, 79.6, 1670.0, 1984.0, 2.0, 14.6, 3.7],\n",
       " [36.3, 79.6, 1670.0, 1984.0, 2.0, 14.6, 3.7],\n",
       " [36.3, 77.0, 2209.0, 1984.0, 2.0, 14.6, 3.7],\n",
       " [36.3, 77.0, 2209.0, 1984.0, 2.0, 14.6, 3.7],\n",
       " [36.3, 77.0, 2209.0, 1984.0, 2.0, 14.6, 3.7],\n",
       " [32.7, 58.8, 2209.0, 1984.0, 2.0, 14.6, 3.7],\n",
       " [32.7, 58.8, 2209.0, 1984.0, 2.0, 14.6, 3.7],\n",
       " [32.7, 58.8, 411.0, 1984.0, 2.0, 14.6, 3.7],\n",
       " [36.0, 96.9, 582.0, 1984.0, 2.0, 10.3, 3.0],\n",
       " [36.0, 96.9, 741.0, 1984.0, 2.0, 10.3, 3.0],\n",
       " [36.0, 96.9, 741.0, 1984.0, 2.0, 10.3, 3.0],\n",
       " [36.0, 96.9, 741.0, 1984.0, 2.0, 10.3, 3.0],\n",
       " [36.0, 96.9, 741.0, 1984.0, 2.0, 10.3, 3.0],\n",
       " [36.3, 97.0, 741.0, 1984.0, 2.0, 10.4, 3.0],\n",
       " [36.3, 96.9, 741.0, 1984.0, 2.0, 10.4, 3.0],\n",
       " [36.3, 96.9, 710.0, 1984.0, 2.0, 10.4, 3.0],\n",
       " [36.3, 96.9, 710.0, 1984.0, 2.0, 10.4, 3.0],\n",
       " [36.3, 96.9, 710.0, 1984.0, 2.0, 10.4, 3.0],\n",
       " [36.3, 96.9, 710.0, 1984.0, 2.0, 10.4, 3.0],\n",
       " [36.3, 96.9, 710.0, 1984.0, 2.0, 10.4, 3.0],\n",
       " [36.3, 96.9, 710.0, 1984.0, 2.0, 10.4, 3.0],\n",
       " [36.3, 97.9, 775.0, 1984.0, 2.0, 10.4, 3.0],\n",
       " [36.3, 97.9, 775.0, 1984.0, 2.0, 10.4, 3.0],\n",
       " [36.3, 97.9, 775.0, 1984.0, 2.0, 10.4, 3.0],\n",
       " [36.3, 98.0, 501.0, 1984.0, 2.0, 10.4, 3.0],\n",
       " [36.3, 98.0, 501.0, 1984.0, 2.0, 10.4, 3.0],\n",
       " [36.3, 98.0, 501.0, 1984.0, 2.0, 10.4, 3.0],\n",
       " [36.3, 98.0, 501.0, 1984.0, 2.0, 10.4, 3.0],\n",
       " [36.3, 98.0, 501.0, 1984.0, 2.0, 10.4, 3.0],\n",
       " [36.3, 98.0, 467.0, 1984.0, 2.0, 10.4, 3.0],\n",
       " [29.7, 88.0, 7602.0, 1958.0, 2.0, 13.4, 14.3],\n",
       " [29.7, 87.5, 12275.0, 1958.0, 2.0, 13.4, 14.3],\n",
       " [29.7, 87.5, 12275.0, 1958.0, 2.0, 13.4, 14.3],\n",
       " [29.7, 87.5, 12275.0, 1958.0, 2.0, 13.4, 14.3],\n",
       " [29.7, 87.5, 12275.0, 1958.0, 2.0, 13.4, 13.7],\n",
       " [29.9, 88.5, 12275.0, 1958.0, 2.0, 13.4, 14.0],\n",
       " [29.9, 87.9, 12275.0, 1958.0, 2.0, 13.4, 13.7],\n",
       " [30.2, 88.7, 11508.0, 1958.0, 2.0, 13.4, 13.7],\n",
       " [30.2, 88.7, 11508.0, 1958.0, 2.0, 13.4, 13.7],\n",
       " [30.2, 86.7, 11508.0, 1958.0, 2.0, 13.4, 13.7],\n",
       " [30.2, 86.7, 11508.0, 1958.0, 2.0, 13.4, 13.7],\n",
       " [30.2, 86.7, 11508.0, 1958.0, 2.0, 13.4, 13.7],\n",
       " [30.2, 86.7, 11508.0, 1958.0, 2.0, 13.4, 13.7],\n",
       " [30.2, 86.8, 11006.0, 1958.0, 2.0, 13.4, 13.7],\n",
       " [30.2, 86.8, 11006.0, 1958.0, 2.0, 13.4, 13.7],\n",
       " [30.2, 86.8, 11006.0, 1958.0, 2.0, 13.4, 13.7],\n",
       " [30.2, 88.5, 4394.0, 1958.0, 2.0, 13.4, 13.7],\n",
       " [30.2, 88.5, 4394.0, 1958.0, 2.0, 13.4, 13.7],\n",
       " [30.2, 88.5, 4394.0, 1958.0, 2.0, 13.4, 13.7],\n",
       " [30.2, 89.5, 4394.0, 1958.0, 2.0, 13.4, 13.7],\n",
       " [30.2, 89.5, 4394.0, 1958.0, 2.0, 13.4, 13.7],\n",
       " [30.2, 89.5, 11399.0, 1958.0, 2.0, 13.4, 13.7],\n",
       " [36.0, 91.6, 10455.0, 1957.0, 2.0, 12.1, 3.0],\n",
       " [36.0, 91.0, 11690.0, 1957.0, 2.0, 12.1, 3.0],\n",
       " [36.0, 91.0, 11690.0, 1957.0, 2.0, 12.1, 3.0],\n",
       " [36.0, 91.0, 11690.0, 1957.0, 2.0, 12.1, 3.0],\n",
       " [36.0, 91.0, 11690.0, 1957.0, 2.0, 12.1, 3.0],\n",
       " [36.3, 78.7, 11690.0, 1957.0, 3.0, 12.2, 3.0],\n",
       " [36.3, 67.1, 11690.0, 1957.0, 3.0, 12.2, 3.0],\n",
       " [36.3, 68.4, 7594.0, 1957.0, 3.0, 12.2, 3.2],\n",
       " [36.3, 68.4, 7594.0, 1957.0, 3.0, 12.2, 3.2],\n",
       " [36.3, 71.4, 7594.0, 1957.0, 3.0, 12.2, 3.2],\n",
       " [36.3, 71.4, 7594.0, 1957.0, 3.0, 12.2, 3.2],\n",
       " [36.3, 71.4, 7594.0, 1957.0, 3.0, 12.2, 3.2],\n",
       " [36.3, 71.4, 7594.0, 1957.0, 3.0, 12.2, 3.2],\n",
       " [36.3, 81.9, 10811.0, 1957.0, 3.0, 12.2, 3.2],\n",
       " [36.3, 81.9, 10811.0, 1957.0, 3.0, 12.2, 3.2],\n",
       " [36.3, 81.9, 10811.0, 1957.0, 3.0, 12.2, 3.2],\n",
       " [36.3, 81.9, 10838.0, 1957.0, 3.0, 12.2, 3.2],\n",
       " [36.3, 80.9, 10838.0, 1957.0, 3.0, 12.2, 3.2],\n",
       " [36.3, 80.9, 10838.0, 1957.0, 3.0, 12.2, 3.2],\n",
       " [36.3, 95.4, 10838.0, 1957.0, 2.0, 12.2, 3.2],\n",
       " [36.3, 95.4, 10838.0, 1957.0, 2.0, 12.2, 3.2],\n",
       " [36.3, 95.4, 8296.0, 1957.0, 2.0, 12.2, 3.2],\n",
       " [36.0, 95.0, 193.0, 1968.0, 2.0, 9.2, 8.2],\n",
       " [36.0, 97.0, 447.0, 1968.0, 2.0, 9.2, 8.2],\n",
       " [36.0, 97.0, 447.0, 1968.0, 2.0, 9.2, 8.2],\n",
       " [36.0, 97.0, 447.0, 1968.0, 2.0, 9.2, 8.2],\n",
       " [36.0, 96.0, 447.0, 1968.0, 2.0, 9.2, 7.6],\n",
       " [36.3, 95.0, 447.0, 1968.0, 2.0, 9.2, 8.0],\n",
       " [36.3, 83.0, 447.0, 1968.0, 2.0, 9.2, 7.9],\n",
       " [36.3, 83.0, 410.0, 1968.0, 2.0, 9.2, 7.9],\n",
       " [36.3, 83.0, 410.0, 1968.0, 2.0, 9.2, 7.9],\n",
       " [36.3, 86.0, 410.0, 1968.0, 2.0, 9.2, 7.9],\n",
       " [36.3, 86.0, 410.0, 1968.0, 2.0, 9.2, 7.9],\n",
       " [36.3, 85.0, 410.0, 1968.0, 2.0, 9.2, 7.9],\n",
       " [36.3, 85.0, 410.0, 1968.0, 2.0, 9.2, 7.9],\n",
       " [36.3, 85.0, 384.0, 1968.0, 2.0, 9.2, 7.9],\n",
       " [36.3, 85.0, 384.0, 1968.0, 2.0, 9.2, 7.9],\n",
       " [36.3, 85.0, 384.0, 1968.0, 2.0, 9.2, 7.9],\n",
       " [36.3, 85.0, 363.0, 1968.0, 2.0, 9.2, 7.9],\n",
       " [36.3, 86.0, 363.0, 1968.0, 2.0, 9.2, 8.0],\n",
       " [36.3, 86.0, 363.0, 1968.0, 2.0, 9.2, 8.0],\n",
       " [36.3, 84.0, 363.0, 1968.0, 2.0, 9.2, 8.0],\n",
       " [36.3, 84.0, 363.0, 1968.0, 2.0, 9.2, 8.0],\n",
       " [36.3, 84.0, 383.0, 1968.0, 2.0, 9.2, 8.0],\n",
       " [81.9, 99.0, 207.0, 1986.0, 2.0, 12.2, 15.5],\n",
       " [81.9, 99.9, 664.0, 1986.0, 2.0, 12.2, 15.5],\n",
       " [81.9, 99.9, 664.0, 1986.0, 2.0, 12.2, 15.5],\n",
       " [81.9, 99.9, 664.0, 1986.0, 2.0, 12.2, 15.5],\n",
       " [81.9, 99.9, 664.0, 1986.0, 2.0, 12.2, 14.9],\n",
       " [82.5, 99.0, 664.0, 1986.0, 2.0, 12.3, 15.0],\n",
       " [82.6, 99.9, 664.0, 1986.0, 2.0, 12.3, 14.9],\n",
       " [82.6, 99.0, 540.0, 1986.0, 2.0, 12.3, 15.0],\n",
       " [82.6, 99.0, 540.0, 1986.0, 2.0, 12.3, 15.0],\n",
       " [83.2, 100.0, 540.0, 1986.0, 2.0, 12.3, 15.0],\n",
       " [83.2, 100.0, 540.0, 1986.0, 2.0, 12.3, 15.0],\n",
       " [83.2, 100.0, 540.0, 1986.0, 2.0, 12.3, 15.0],\n",
       " [83.2, 100.0, 540.0, 1986.0, 2.0, 12.3, 15.0],\n",
       " [83.2, 100.0, 419.0, 1986.0, 2.0, 12.3, 15.0],\n",
       " [83.2, 100.0, 419.0, 1986.0, 2.0, 12.3, 15.0],\n",
       " [83.2, 100.0, 419.0, 1986.0, 2.0, 12.3, 15.0],\n",
       " [83.2, 100.0, 461.0, 1986.0, 2.0, 12.3, 15.0],\n",
       " [83.2, 100.0, 461.0, 1986.0, 2.0, 12.3, 15.0],\n",
       " [83.2, 100.0, 461.0, 1986.0, 2.0, 12.3, 15.0],\n",
       " [83.2, 100.0, 461.0, 1986.0, 2.0, 12.3, 15.0],\n",
       " [83.2, 100.0, 461.0, 1986.0, 2.0, 12.3, 15.0],\n",
       " [83.2, 100.0, 392.0, 1986.0, 2.0, 12.3, 15.0],\n",
       " [36.0, 97.5, 5102.0, 1970.0, 2.0, 12.1, 3.4],\n",
       " [36.0, 95.1, 9942.0, 1970.0, 3.0, 12.1, 3.4],\n",
       " [36.0, 95.1, 9942.0, 1970.0, 3.0, 12.1, 3.4],\n",
       " [36.0, 95.1, 9942.0, 1970.0, 3.0, 12.1, 3.4],\n",
       " [36.0, 95.1, 9942.0, 1970.0, 3.0, 12.1, 3.4],\n",
       " [36.3, 96.5, 9942.0, 1970.0, 3.0, 12.2, 3.0],\n",
       " [36.3, 95.1, 9942.0, 1970.0, 3.0, 12.2, 3.4],\n",
       " [36.3, 95.1, 9746.0, 1970.0, 3.0, 12.2, 3.2],\n",
       " [36.3, 95.1, 9746.0, 1970.0, 3.0, 12.2, 3.2],\n",
       " [36.3, 96.1, 9746.0, 1970.0, 3.0, 12.2, 3.2],\n",
       " [36.3, 96.1, 9746.0, 1970.0, 3.0, 12.2, 3.2],\n",
       " [36.3, 96.1, 9746.0, 1970.0, 3.0, 12.2, 3.2],\n",
       " [36.3, 96.1, 9746.0, 1970.0, 3.0, 12.2, 3.2],\n",
       " [36.3, 96.1, 9726.0, 1970.0, 3.0, 12.2, 3.2],\n",
       " [36.3, 96.1, 9726.0, 1970.0, 3.0, 12.2, 3.2],\n",
       " [36.3, 79.9, 9726.0, 1970.0, 3.0, 12.2, 3.2],\n",
       " [36.3, 79.9, 9125.0, 1970.0, 3.0, 12.2, 3.2],\n",
       " [36.3, 78.9, 9125.0, 1970.0, 3.0, 12.2, 3.2],\n",
       " [36.3, 78.9, 9125.0, 1970.0, 3.0, 12.2, 3.2],\n",
       " [36.3, 78.9, 9125.0, 1970.0, 3.0, 12.2, 3.2],\n",
       " [36.3, 78.9, 9125.0, 1970.0, 3.0, 12.2, 3.2],\n",
       " [36.3, 78.9, 7680.0, 1970.0, 3.0, 12.2, 3.2],\n",
       " [36.0, 82.5, 5089.0, 1984.0, 4.0, 20.1, 4.6],\n",
       " [36.0, 82.4, 8990.0, 1984.0, 4.0, 25.2, 4.6],\n",
       " [36.0, 82.4, 8990.0, 1984.0, 4.0, 25.2, 4.6],\n",
       " [36.0, 82.4, 8990.0, 1984.0, 4.0, 25.2, 4.6],\n",
       " [36.0, 82.4, 8990.0, 1984.0, 4.0, 25.2, 4.6],\n",
       " [36.3, 82.4, 8990.0, 1984.0, 4.0, 25.3, 5.0],\n",
       " [36.3, 83.5, 8990.0, 1984.0, 4.0, 25.3, 4.6],\n",
       " [36.3, 83.5, 13588.0, 1984.0, 4.0, 10.2, 4.4],\n",
       " [36.3, 83.5, 13588.0, 1984.0, 4.0, 10.2, 4.4],\n",
       " [36.3, 83.5, 13588.0, 1984.0, 4.0, 10.2, 4.4],\n",
       " [36.3, 83.5, 13588.0, 1984.0, 4.0, 10.2, 4.4],\n",
       " [36.3, 83.5, 13588.0, 1984.0, 4.0, 10.2, 4.4],\n",
       " [36.3, 83.5, 13588.0, 1984.0, 4.0, 10.2, 4.4],\n",
       " [36.3, 83.5, 13588.0, 1984.0, 4.0, 10.2, 4.4],\n",
       " [36.3, 83.5, 13588.0, 1984.0, 4.0, 10.2, 4.4],\n",
       " [36.3, 83.5, 13588.0, 1984.0, 4.0, 10.2, 4.4],\n",
       " [36.3, 83.4, 14264.0, 1984.0, 4.0, 10.2, 4.4],\n",
       " [36.3, 83.4, 14264.0, 1984.0, 4.0, 10.2, 4.4],\n",
       " [36.3, 83.4, 14264.0, 1984.0, 4.0, 10.2, 4.4],\n",
       " [36.3, 83.4, 14264.0, 1984.0, 4.0, 10.2, 4.4],\n",
       " [36.3, 83.4, 14264.0, 1984.0, 4.0, 10.2, 4.4],\n",
       " [36.3, 83.4, 14206.0, 1984.0, 4.0, 10.2, 4.4],\n",
       " [36.0, 96.8, 1637.0, 1975.0, 2.0, 16.1, 3.0],\n",
       " [36.0, 96.7, 2243.0, 1975.0, 2.0, 16.1, 3.0],\n",
       " [36.0, 96.7, 2243.0, 1975.0, 2.0, 16.1, 3.0],\n",
       " [36.0, 96.7, 2243.0, 1975.0, 2.0, 16.1, 3.0],\n",
       " [36.0, 96.7, 2243.0, 1975.0, 2.0, 16.1, 3.0],\n",
       " [36.3, 96.9, 2243.0, 1975.0, 2.0, 16.2, 3.0],\n",
       " [36.3, 96.8, 2243.0, 1975.0, 2.0, 16.2, 3.0],\n",
       " [36.3, 96.8, 2076.0, 1975.0, 2.0, 16.2, 3.0],\n",
       " [36.3, 96.8, 2076.0, 1975.0, 2.0, 16.2, 3.0],\n",
       " [36.3, 96.8, 2076.0, 1975.0, 2.0, 16.2, 3.1],\n",
       " [36.3, 96.8, 2076.0, 1975.0, 2.0, 16.2, 3.1],\n",
       " [36.3, 96.9, 1577.0, 1975.0, 2.0, 16.2, 3.1],\n",
       " [36.3, 96.9, 1577.0, 1975.0, 2.0, 16.2, 3.1],\n",
       " [36.3, 96.9, 1577.0, 1975.0, 2.0, 4.0, 3.1],\n",
       " [36.3, 96.9, 1577.0, 1975.0, 2.0, 4.0, 3.1],\n",
       " [36.3, 96.9, 1577.0, 1975.0, 2.0, 4.0, 3.1],\n",
       " [36.3, 96.8, 2128.0, 1975.0, 2.0, 4.0, 3.1],\n",
       " [36.3, 95.8, 2128.0, 1975.0, 2.0, 4.0, 3.1],\n",
       " [36.3, 95.8, 2128.0, 1975.0, 2.0, 4.0, 3.1],\n",
       " [36.3, 95.8, 2128.0, 1975.0, 2.0, 4.0, 3.1],\n",
       " [36.3, 95.8, 2128.0, 1975.0, 2.0, 4.0, 3.1],\n",
       " [36.3, 95.8, 1899.0, 1975.0, 2.0, 4.0, 3.1],\n",
       " [99.9, 82.9, 18848.0, 1986.0, 5.0, 22.8, 13.1],\n",
       " [99.9, 97.2, 30281.0, 1986.0, 7.0, 22.8, 13.1],\n",
       " [99.9, 97.2, 30281.0, 1986.0, 7.0, 22.8, 13.1],\n",
       " [99.9, 97.2, 30281.0, 1986.0, 7.0, 22.8, 13.1],\n",
       " [99.9, 95.2, 30281.0, 1986.0, 7.0, 27.2, 13.1],\n",
       " [89.8, 98.6, 30281.0, 1986.0, 7.0, 27.3, 13.0],\n",
       " [89.8, 95.2, 30281.0, 1986.0, 7.0, 27.3, 13.1],\n",
       " [10.5, 94.2, 40588.0, 1986.0, 7.0, 14.5, 13.0],\n",
       " [10.5, 94.2, 40588.0, 1986.0, 7.0, 14.5, 13.0],\n",
       " [10.5, 96.2, 40588.0, 1986.0, 7.0, 14.5, 13.0],\n",
       " [81.6, 96.2, 40588.0, 1986.0, 7.0, 14.5, 13.0],\n",
       " [81.6, 96.7, 34840.0, 1986.0, 7.0, 14.5, 13.0],\n",
       " [81.6, 96.7, 34840.0, 1986.0, 7.0, 14.5, 13.0],\n",
       " [81.6, 96.7, 34840.0, 1986.0, 7.0, 14.5, 13.0],\n",
       " [81.6, 96.7, 34840.0, 1986.0, 7.0, 14.5, 13.0],\n",
       " [81.6, 96.7, 34840.0, 1986.0, 7.0, 14.5, 13.0],\n",
       " [81.6, 98.0, 21836.0, 1986.0, 7.0, 14.5, 13.0],\n",
       " [81.6, 98.0, 21836.0, 1986.0, 7.0, 14.5, 13.0],\n",
       " [81.6, 98.0, 21836.0, 1986.0, 7.0, 14.5, 13.0],\n",
       " [81.6, 98.0, 21836.0, 1986.0, 7.0, 14.5, 13.0],\n",
       " [81.6, 98.0, 21836.0, 1986.0, 7.0, 14.5, 13.0],\n",
       " [81.6, 98.0, 16382.0, 1986.0, 7.0, 14.5, 13.0],\n",
       " [79.2, 99.9, 726.0, 1984.0, 2.0, 12.1, 12.2],\n",
       " [79.2, 99.8, 1979.0, 1984.0, 2.0, 12.1, 12.2],\n",
       " [79.2, 99.8, 1979.0, 1984.0, 2.0, 12.1, 12.2],\n",
       " [79.2, 99.8, 1979.0, 1984.0, 2.0, 12.1, 12.2],\n",
       " [79.2, 99.8, 1979.0, 1984.0, 2.0, 12.1, 11.9],\n",
       " [79.8, 99.9, 1979.0, 1984.0, 2.0, 12.2, 12.0],\n",
       " [79.8, 99.8, 1979.0, 1984.0, 2.0, 12.2, 11.9],\n",
       " [79.8, 99.9, 1561.0, 1984.0, 2.0, 12.2, 12.0],\n",
       " [79.8, 99.9, 1561.0, 1984.0, 2.0, 12.2, 12.0],\n",
       " [80.5, 99.9, 1561.0, 1984.0, 2.0, 12.2, 11.6],\n",
       " [80.5, 99.9, 1561.0, 1984.0, 2.0, 12.2, 11.6],\n",
       " [80.5, 99.9, 1561.0, 1984.0, 2.0, 12.2, 11.6],\n",
       " [80.5, 99.9, 1561.0, 1984.0, 2.0, 12.2, 11.6],\n",
       " [80.5, 99.9, 929.0, 1984.0, 2.0, 12.2, 11.6],\n",
       " [80.5, 99.9, 929.0, 1984.0, 2.0, 12.2, 11.6],\n",
       " [80.5, 99.9, 929.0, 1984.0, 2.0, 12.2, 11.6],\n",
       " [80.5, 99.9, 1360.0, 1984.0, 2.0, 12.2, 11.6],\n",
       " [80.5, 99.9, 1360.0, 1984.0, 2.0, 12.2, 11.6],\n",
       " [80.5, 99.9, 1360.0, 1984.0, 2.0, 12.2, 11.6],\n",
       " [80.5, 99.9, 1360.0, 1984.0, 2.0, 12.2, 11.6],\n",
       " [80.5, 99.9, 1360.0, 1984.0, 2.0, 12.2, 11.6],\n",
       " [80.5, 99.9, 1048.0, 1984.0, 2.0, 12.2, 11.6],\n",
       " [32.4, 77.3, 24032.0, 1951.0, 4.0, 18.8, 19.5],\n",
       " [32.4, 75.0, 24875.0, 1951.0, 5.0, 18.8, 19.5],\n",
       " [32.4, 75.0, 24875.0, 1951.0, 5.0, 18.8, 19.5],\n",
       " [32.4, 75.0, 24875.0, 1951.0, 5.0, 18.8, 19.5],\n",
       " [32.4, 75.0, 24875.0, 1951.0, 5.0, 18.8, 18.9],\n",
       " [32.7, 75.4, 24875.0, 1951.0, 5.0, 18.8, 19.0],\n",
       " [32.7, 75.4, 24875.0, 1951.0, 5.0, 18.8, 18.9],\n",
       " [33.4, 74.0, 32792.0, 1951.0, 5.0, 18.8, 18.7],\n",
       " [33.4, 74.0, 32792.0, 1951.0, 5.0, 18.8, 18.7],\n",
       " [33.4, 74.0, 32792.0, 1951.0, 5.0, 18.8, 18.7],\n",
       " [33.4, 74.0, 32792.0, 1951.0, 5.0, 18.8, 18.7],\n",
       " [33.4, 74.0, 32792.0, 1951.0, 5.0, 18.8, 18.7],\n",
       " [33.4, 74.0, 32792.0, 1951.0, 5.0, 18.8, 18.7],\n",
       " [33.4, 75.1, 26528.0, 1951.0, 5.0, 18.8, 18.7],\n",
       " [33.4, 75.1, 26528.0, 1951.0, 5.0, 18.8, 18.7],\n",
       " [33.4, 75.1, 26528.0, 1951.0, 5.0, 18.8, 18.7],\n",
       " [33.4, 75.3, 25700.0, 1951.0, 5.0, 18.8, 18.7],\n",
       " [33.4, 75.3, 25700.0, 1951.0, 5.0, 18.8, 18.7],\n",
       " [33.4, 75.3, 25700.0, 1951.0, 5.0, 18.8, 18.7],\n",
       " [33.4, 75.3, 25700.0, 1951.0, 5.0, 18.8, 18.7],\n",
       " [33.4, 75.3, 25700.0, 1951.0, 5.0, 18.8, 18.7],\n",
       " [28.8, 75.3, 26829.0, 1951.0, 5.0, 18.8, 18.7],\n",
       " [36.0, 82.3, 16059.0, 1970.0, 4.0, 24.2, 4.0],\n",
       " [36.0, 81.8, 18642.0, 1970.0, 4.0, 24.2, 4.0],\n",
       " [36.0, 81.8, 18642.0, 1970.0, 4.0, 24.2, 4.0],\n",
       " [36.0, 81.8, 18642.0, 1970.0, 4.0, 24.2, 4.0],\n",
       " [36.0, 81.8, 18642.0, 1970.0, 5.0, 24.2, 6.1],\n",
       " [36.3, 81.8, 18642.0, 1970.0, 5.0, 24.2, 6.0],\n",
       " [36.3, 81.8, 18642.0, 1970.0, 5.0, 24.2, 6.1],\n",
       " [36.3, 81.3, 21731.0, 1970.0, 5.0, 24.2, 6.2],\n",
       " [36.3, 81.3, 21731.0, 1970.0, 5.0, 24.2, 6.2],\n",
       " [36.3, 81.3, 21731.0, 1970.0, 5.0, 24.2, 6.2],\n",
       " [36.3, 81.3, 21731.0, 1970.0, 5.0, 24.2, 6.2],\n",
       " [36.3, 81.3, 21731.0, 1970.0, 5.0, 24.2, 6.2],\n",
       " [36.3, 81.3, 21731.0, 1970.0, 5.0, 24.2, 6.2],\n",
       " [36.3, 82.2, 16509.0, 1970.0, 5.0, 24.2, 6.2],\n",
       " [36.3, 82.2, 16509.0, 1970.0, 5.0, 24.2, 6.2],\n",
       " [36.3, 82.2, 16509.0, 1970.0, 6.0, 24.2, 6.2],\n",
       " [36.3, 82.0, 17336.0, 1970.0, 6.0, 24.2, 6.2],\n",
       " [36.3, 82.0, 17336.0, 1970.0, 6.0, 24.2, 6.2],\n",
       " [36.3, 82.0, 17336.0, 1970.0, 6.0, 24.2, 6.2],\n",
       " [36.3, 82.0, 17336.0, 1970.0, 5.0, 24.2, 6.2],\n",
       " [36.3, 82.0, 17336.0, 1970.0, 5.0, 24.2, 6.2],\n",
       " [36.3, 82.0, 17088.0, 1970.0, 5.0, 24.2, 6.2],\n",
       " [53.1, 73.4, 3314.0, 1973.0, 2.0, 18.2, 2.4],\n",
       " [53.1, 72.7, 8391.0, 1973.0, 3.0, 18.2, 2.4],\n",
       " [53.1, 72.7, 8391.0, 1973.0, 3.0, 18.2, 2.4],\n",
       " [53.1, 72.7, 8391.0, 1973.0, 3.0, 18.2, 2.4],\n",
       " [53.1, 72.7, 8391.0, 1973.0, 3.0, 18.2, 2.4],\n",
       " [53.5, 73.4, 8391.0, 1973.0, 3.0, 18.3, 2.0],\n",
       " [53.5, 72.9, 8391.0, 1973.0, 3.0, 18.3, 2.4],\n",
       " [53.6, 72.9, 8652.0, 1973.0, 3.0, 18.3, 2.4],\n",
       " [53.6, 72.9, 8652.0, 1973.0, 3.0, 18.3, 2.4],\n",
       " [53.6, 72.9, 8652.0, 1973.0, 3.0, 18.3, 2.4],\n",
       " [53.6, 72.9, 8652.0, 1973.0, 3.0, 18.3, 2.4],\n",
       " [53.6, 72.9, 8590.0, 1973.0, 3.0, 18.3, 2.4],\n",
       " [53.6, 72.9, 8590.0, 1973.0, 3.0, 18.3, 2.4],\n",
       " [53.6, 72.9, 8590.0, 1973.0, 3.0, 18.3, 2.4],\n",
       " [53.6, 72.9, 8590.0, 1973.0, 3.0, 18.3, 2.4],\n",
       " [53.6, 72.9, 8590.0, 1973.0, 3.0, 18.3, 2.4],\n",
       " [53.6, 72.9, 8145.0, 1973.0, 3.0, 18.3, 2.4],\n",
       " [53.6, 72.9, 8145.0, 1973.0, 3.0, 18.3, 2.4],\n",
       " [53.6, 72.9, 8145.0, 1973.0, 3.0, 18.3, 2.4],\n",
       " [53.6, 62.7, 8145.0, 1973.0, 3.0, 18.3, 2.4],\n",
       " [53.6, 62.7, 8145.0, 1973.0, 3.0, 18.3, 2.4],\n",
       " [53.6, 62.7, 9149.0, 1973.0, 3.0, 18.3, 2.4],\n",
       " [60.3, 88.2, 850.0, 1995.0, 2.0, 9.1, 10.1],\n",
       " [60.3, 86.0, 2556.0, 1995.0, 2.0, 9.1, 10.1],\n",
       " [60.3, 86.0, 2556.0, 1995.0, 2.0, 9.1, 10.1],\n",
       " [60.3, 86.0, 2556.0, 1995.0, 2.0, 9.1, 10.1],\n",
       " [60.3, 86.0, 2556.0, 1995.0, 2.0, 9.1, 9.8],\n",
       " [60.8, 86.1, 2556.0, 1995.0, 2.0, 9.1, 10.0],\n",
       " [60.8, 86.0, 2556.0, 1995.0, 2.0, 9.1, 9.8],\n",
       " [61.2, 79.6, 3061.0, 1995.0, 2.0, 9.1, 9.8],\n",
       " [61.2, 79.6, 3061.0, 1995.0, 2.0, 9.1, 9.8],\n",
       " [61.2, 79.6, 3061.0, 1995.0, 2.0, 9.1, 9.8],\n",
       " [61.2, 79.6, 3061.0, 1995.0, 2.0, 9.1, 9.8],\n",
       " [61.2, 81.6, 3061.0, 1995.0, 2.0, 9.1, 9.8],\n",
       " [61.2, 81.6, 3061.0, 1995.0, 2.0, 9.1, 9.8],\n",
       " [61.2, 88.0, 2445.0, 1995.0, 2.0, 9.1, 9.8],\n",
       " [61.2, 88.0, 2445.0, 1995.0, 2.0, 9.1, 9.8],\n",
       " [61.2, 88.0, 2445.0, 1995.0, 2.0, 9.1, 9.8],\n",
       " [61.2, 81.7, 2738.0, 1995.0, 2.0, 9.1, 9.8],\n",
       " [61.2, 81.7, 2738.0, 1995.0, 2.0, 9.1, 9.8],\n",
       " [61.2, 81.7, 2738.0, 1995.0, 2.0, 9.1, 9.8],\n",
       " [61.2, 81.7, 2738.0, 1995.0, 2.0, 9.1, 9.8],\n",
       " [61.2, 81.7, 2738.0, 1995.0, 2.0, 9.1, 9.8],\n",
       " [61.2, 81.7, 3198.0, 1995.0, 2.0, 9.1, 9.8],\n",
       " [48.6, 96.5, 3274.0, 1989.0, 2.0, 13.4, 9.1],\n",
       " [48.6, 90.4, 3621.0, 1989.0, 3.0, 13.4, 9.1],\n",
       " [48.6, 90.4, 3621.0, 1989.0, 3.0, 13.4, 9.1],\n",
       " [48.6, 90.4, 3621.0, 1989.0, 3.0, 13.4, 9.1],\n",
       " [48.6, 90.4, 3621.0, 1989.0, 3.0, 13.4, 9.4],\n",
       " [38.1, 83.0, 3621.0, 1989.0, 3.0, 13.5, 9.0],\n",
       " [38.1, 82.8, 3621.0, 1989.0, 3.0, 13.5, 9.5],\n",
       " [38.4, 83.4, 1844.0, 1989.0, 3.0, 13.5, 9.4],\n",
       " [38.4, 83.4, 1844.0, 1989.0, 3.0, 13.5, 9.4],\n",
       " [38.4, 83.4, 1844.0, 1989.0, 3.0, 13.5, 9.4],\n",
       " [38.4, 83.4, 1844.0, 1989.0, 3.0, 13.5, 9.4],\n",
       " [38.4, 83.4, 1844.0, 1989.0, 3.0, 13.5, 9.4],\n",
       " [38.4, 83.4, 1844.0, 1989.0, 3.0, 13.5, 9.4],\n",
       " [38.4, 83.3, 2429.0, 1989.0, 3.0, 13.5, 9.4],\n",
       " [38.4, 83.3, 2429.0, 1989.0, 3.0, 13.5, 9.4],\n",
       " [38.4, 71.3, 2429.0, 1989.0, 3.0, 13.5, 9.4],\n",
       " [38.4, 71.2, 3029.0, 1989.0, 3.0, 13.5, 9.4],\n",
       " [38.4, 71.2, 3029.0, 1989.0, 3.0, 13.5, 9.4],\n",
       " [38.4, 71.2, 3029.0, 1989.0, 3.0, 13.5, 9.4],\n",
       " [38.4, 71.2, 3029.0, 1989.0, 3.0, 13.5, 9.4],\n",
       " [38.4, 71.2, 3029.0, 1989.0, 3.0, 13.5, 9.4],\n",
       " [38.4, 71.2, 2768.0, 1989.0, 3.0, 13.5, 9.4],\n",
       " [55.8, 73.2, 23300.0, 1959.0, 6.0, 24.3, 22.3],\n",
       " [55.8, 78.6, 23504.0, 1959.0, 6.0, 25.6, 22.3],\n",
       " [55.8, 78.6, 23504.0, 1959.0, 6.0, 25.6, 22.3],\n",
       " [55.8, 78.6, 23504.0, 1959.0, 6.0, 25.6, 22.3],\n",
       " [55.8, 78.6, 23504.0, 1959.0, 6.0, 25.6, 21.3],\n",
       " [56.2, 84.7, 23504.0, 1959.0, 5.0, 25.6, 21.0],\n",
       " [56.3, 83.5, 23504.0, 1959.0, 5.0, 25.6, 21.3],\n",
       " [57.0, 84.0, 18994.0, 1959.0, 5.0, 25.6, 21.2],\n",
       " [57.0, 84.0, 18994.0, 1959.0, 5.0, 25.6, 21.2],\n",
       " [57.0, 84.0, 18994.0, 1959.0, 5.0, 25.6, 21.2],\n",
       " [57.0, 84.0, 18994.0, 1959.0, 5.0, 25.6, 21.2],\n",
       " [57.0, 84.0, 18994.0, 1959.0, 5.0, 25.6, 21.2],\n",
       " [57.0, 84.0, 18994.0, 1959.0, 5.0, 25.6, 21.2],\n",
       " [57.0, 95.3, 18326.0, 1959.0, 5.0, 25.6, 21.2],\n",
       " [57.0, 95.3, 18326.0, 1959.0, 5.0, 25.6, 21.2],\n",
       " [57.0, 84.0, 18326.0, 1959.0, 5.0, 25.6, 21.2],\n",
       " [57.0, 84.0, 18933.0, 1959.0, 5.0, 25.6, 21.2],\n",
       " [57.0, 84.0, 18933.0, 1959.0, 5.0, 25.6, 21.2],\n",
       " [57.0, 84.0, 18933.0, 1959.0, 5.0, 25.6, 21.2],\n",
       " [57.0, 84.0, 18933.0, 1959.0, 5.0, 25.6, 21.2],\n",
       " [57.0, 84.0, 18933.0, 1959.0, 5.0, 25.6, 21.2],\n",
       " [57.0, 84.0, 18933.0, 1959.0, 5.0, 25.6, 21.2],\n",
       " [53.1, 99.9, 753.0, 1987.0, 2.0, 11.2, 15.2],\n",
       " [53.1, 98.9, 848.0, 1987.0, 2.0, 11.2, 15.2],\n",
       " [53.1, 98.9, 848.0, 1987.0, 2.0, 11.2, 15.2],\n",
       " [53.1, 98.9, 848.0, 1987.0, 2.0, 11.2, 15.2],\n",
       " [53.1, 98.9, 848.0, 1987.0, 2.0, 11.2, 14.6],\n",
       " [53.5, 100.0, 848.0, 1987.0, 2.0, 11.3, 15.0],\n",
       " [53.5, 99.9, 848.0, 1987.0, 2.0, 11.3, 14.6],\n",
       " [53.7, 99.9, 725.0, 1987.0, 2.0, 11.3, 14.5],\n",
       " [53.7, 99.9, 725.0, 1987.0, 2.0, 11.3, 14.5],\n",
       " [53.7, 99.9, 725.0, 1987.0, 2.0, 11.3, 14.5],\n",
       " [53.7, 99.9, 725.0, 1987.0, 2.0, 11.3, 14.5],\n",
       " [53.7, 98.9, 725.0, 1987.0, 2.0, 11.3, 14.5],\n",
       " [53.7, 98.9, 725.0, 1987.0, 2.0, 11.3, 14.5],\n",
       " [53.7, 98.9, 733.0, 1987.0, 2.0, 11.3, 14.5],\n",
       " [53.7, 98.9, 733.0, 1987.0, 2.0, 11.3, 14.5],\n",
       " [53.7, 98.9, 733.0, 1987.0, 2.0, 11.3, 14.5],\n",
       " [53.7, 99.0, 81.0, 1987.0, 2.0, 11.3, 14.5],\n",
       " [53.7, 99.0, 81.0, 1987.0, 2.0, 11.3, 14.5],\n",
       " [53.7, 99.0, 81.0, 1987.0, 2.0, 11.3, 14.5],\n",
       " [53.7, 99.0, 81.0, 1987.0, 2.0, 11.3, 14.5],\n",
       " [53.7, 99.0, 81.0, 1987.0, 2.0, 11.3, 14.5],\n",
       " [53.7, 99.0, 589.0, 1987.0, 2.0, 11.3, 14.5],\n",
       " [30.6, 40.6, 17972.0, 1935.0, 4.0, 16.1, 35.1],\n",
       " [30.6, 40.6, 17972.0, 1935.0, 4.0, 16.1, 35.1],\n",
       " [30.6, 40.6, 17972.0, 1935.0, 4.0, 16.1, 35.1],\n",
       " [30.6, 40.6, 17972.0, 1935.0, 4.0, 16.1, 35.1],\n",
       " [30.6, 40.6, 17972.0, 1935.0, 4.0, 16.1, 35.1],\n",
       " [30.6, 40.6, 17972.0, 1935.0, 4.0, 16.1, 35.1],\n",
       " [30.6, 40.6, 17972.0, 1935.0, 4.0, 16.1, 35.1],\n",
       " [30.6, 40.6, 17972.0, 1935.0, 4.0, 16.1, 35.1],\n",
       " [30.6, 40.6, 17972.0, 1935.0, 4.0, 16.1, 35.1],\n",
       " [30.6, 40.6, 17972.0, 1935.0, 4.0, 16.1, 35.1],\n",
       " [30.6, 40.6, 17972.0, 1935.0, 4.0, 16.1, 35.1],\n",
       " [30.6, 40.6, 17972.0, 1935.0, 4.0, 16.1, 35.1],\n",
       " [30.6, 40.6, 17972.0, 1935.0, 4.0, 16.1, 35.1],\n",
       " [30.6, 40.6, 17972.0, 1935.0, 4.0, 16.1, 35.1],\n",
       " [30.6, 40.6, 17972.0, 1935.0, 4.0, 16.1, 35.1],\n",
       " [30.6, 40.6, 17972.0, 1935.0, 4.0, 16.1, 35.1],\n",
       " [30.6, 40.6, 17972.0, 1935.0, 4.0, 16.1, 35.1],\n",
       " [30.6, 40.6, 17972.0, 1935.0, 4.0, 16.1, 35.1],\n",
       " [30.6, 40.6, 17972.0, 1935.0, 4.0, 16.1, 35.1],\n",
       " [30.6, 40.6, 17972.0, 1935.0, 4.0, 16.1, 35.1],\n",
       " [30.6, 40.6, 17972.0, 1935.0, 4.0, 16.1, 35.1],\n",
       " [30.6, 40.6, 17972.0, 1935.0, 4.0, 16.1, 35.1],\n",
       " [76.5, 83.6, 1218.0, 1986.0, 2.0, 10.9, 33.5],\n",
       " [76.5, 81.9, 1409.0, 1986.0, 2.0, 10.9, 33.5],\n",
       " [76.5, 81.9, 1409.0, 1986.0, 2.0, 10.9, 33.5],\n",
       " [76.5, 81.9, 1409.0, 1986.0, 2.0, 10.9, 33.5],\n",
       " [76.5, 81.9, 1409.0, 1986.0, 2.0, 10.9, 32.9],\n",
       " [77.1, 99.9, 1409.0, 1986.0, 2.0, 11.0, 33.0],\n",
       " [77.1, 99.9, 1409.0, 1986.0, 2.0, 11.0, 32.9],\n",
       " [77.3, 99.9, 871.0, 1986.0, 2.0, 11.0, 32.5],\n",
       " [77.3, 99.9, 871.0, 1986.0, 2.0, 11.0, 32.5],\n",
       " [77.3, 99.9, 871.0, 1986.0, 2.0, 11.0, 32.5],\n",
       " [77.3, 99.9, 871.0, 1986.0, 2.0, 11.0, 32.5],\n",
       " [77.3, 99.9, 871.0, 1986.0, 2.0, 11.0, 32.5],\n",
       " [77.3, 99.9, 871.0, 1986.0, 2.0, 11.0, 32.5],\n",
       " [77.3, 98.9, 633.0, 1986.0, 2.0, 11.0, 32.5],\n",
       " [77.3, 98.9, 633.0, 1986.0, 2.0, 11.0, 32.5],\n",
       " [77.3, 98.9, 633.0, 1986.0, 2.0, 11.0, 32.5],\n",
       " [77.3, 98.9, 614.0, 1986.0, 2.0, 11.0, 32.5],\n",
       " [77.3, 98.9, 614.0, 1986.0, 2.0, 11.0, 32.5],\n",
       " [77.3, 98.9, 614.0, 1986.0, 2.0, 11.0, 32.5],\n",
       " [77.3, 98.9, 614.0, 1986.0, 2.0, 11.0, 32.5],\n",
       " [77.3, 98.9, 614.0, 1986.0, 2.0, 11.0, 32.5],\n",
       " [77.3, 98.9, 978.0, 1986.0, 2.0, 11.0, 32.5],\n",
       " [36.0, 96.7, 1827.0, 1975.0, 2.0, 12.1, 3.7],\n",
       " [36.0, 96.6, 2586.0, 1975.0, 2.0, 12.1, 3.7],\n",
       " [36.0, 96.6, 2586.0, 1975.0, 2.0, 12.1, 3.7],\n",
       " [36.0, 96.6, 2586.0, 1975.0, 2.0, 12.1, 3.7],\n",
       " [36.0, 96.6, 2586.0, 1975.0, 2.0, 12.1, 3.7],\n",
       " [36.3, 96.9, 2586.0, 1975.0, 2.0, 12.2, 4.0],\n",
       " [36.3, 96.8, 2586.0, 1975.0, 2.0, 12.2, 3.7],\n",
       " [36.3, 96.5, 5180.0, 1975.0, 2.0, 12.2, 4.0],\n",
       " [36.3, 96.5, 5180.0, 1975.0, 2.0, 12.2, 4.0],\n",
       " [36.3, 96.5, 5180.0, 1975.0, 2.0, 12.2, 3.7],\n",
       " [36.3, 96.5, 5180.0, 1975.0, 2.0, 12.2, 3.7],\n",
       " [36.3, 96.5, 5180.0, 1975.0, 2.0, 12.2, 3.7],\n",
       " [36.3, 96.5, 5180.0, 1975.0, 2.0, 12.2, 3.7],\n",
       " [36.3, 97.8, 2657.0, 1975.0, 2.0, 12.2, 3.7],\n",
       " [36.3, 97.8, 2657.0, 1975.0, 2.0, 12.2, 3.7],\n",
       " [36.3, 97.8, 2657.0, 1975.0, 2.0, 12.2, 3.7],\n",
       " [36.3, 97.7, 3620.0, 1975.0, 2.0, 12.2, 3.7],\n",
       " [36.3, 97.7, 3620.0, 1975.0, 2.0, 12.2, 3.7],\n",
       " [36.3, 97.7, 3620.0, 1975.0, 2.0, 12.2, 3.7],\n",
       " [36.3, 97.7, 3620.0, 1975.0, 2.0, 12.2, 3.7],\n",
       " [36.3, 97.7, 3620.0, 1975.0, 2.0, 12.2, 3.7],\n",
       " [36.3, 97.7, 3099.0, 1975.0, 2.0, 12.2, 3.7],\n",
       " [36.0, 85.0, 2092.0, 1940.0, 2.0, 9.1, 23.8],\n",
       " [36.0, 74.0, 2025.0, 1940.0, 2.0, 9.1, 23.8],\n",
       " [36.0, 74.0, 2025.0, 1940.0, 2.0, 9.1, 23.8],\n",
       " [36.0, 74.0, 2025.0, 1940.0, 2.0, 9.1, 23.8],\n",
       " [36.0, 74.0, 2025.0, 1940.0, 2.0, 9.1, 22.6],\n",
       " [36.3, 85.1, 2025.0, 1940.0, 2.0, 9.1, 23.0],\n",
       " [36.3, 85.0, 2025.0, 1940.0, 2.0, 9.1, 22.6],\n",
       " [36.3, 71.9, 2348.0, 1940.0, 2.0, 9.1, 22.6],\n",
       " [36.3, 71.9, 2348.0, 1940.0, 2.0, 9.1, 22.6],\n",
       " [36.3, 74.0, 2348.0, 1940.0, 2.0, 9.1, 22.6],\n",
       " [36.3, 74.0, 2348.0, 1940.0, 2.0, 9.1, 22.6],\n",
       " [36.3, 74.0, 2348.0, 1940.0, 2.0, 9.1, 22.6],\n",
       " [36.3, 74.0, 2348.0, 1940.0, 2.0, 9.1, 22.6],\n",
       " [36.3, 75.0, 1924.0, 1940.0, 2.0, 9.1, 22.6],\n",
       " [36.3, 75.0, 1924.0, 1940.0, 2.0, 9.1, 22.6],\n",
       " [36.3, 73.0, 1924.0, 1940.0, 2.0, 9.1, 22.6],\n",
       " [36.3, 73.0, 1926.0, 1940.0, 2.0, 9.1, 22.6],\n",
       " [36.3, 73.0, 1926.0, 1940.0, 2.0, 9.1, 22.6],\n",
       " [36.3, 73.0, 1926.0, 1940.0, 2.0, 9.1, 22.6],\n",
       " [36.3, 73.0, 1926.0, 1940.0, 2.0, 9.1, 22.6],\n",
       " [36.3, 73.0, 1926.0, 1940.0, 2.0, 9.1, 22.6],\n",
       " [63.8, 73.0, 2651.0, 1940.0, 2.0, 9.1, 22.6],\n",
       " [36.0, 69.3, 26968.0, 1940.0, 4.0, 13.4, 23.5],\n",
       " [36.0, 69.4, 26219.0, 1940.0, 4.0, 13.4, 23.5],\n",
       " [36.0, 69.4, 26219.0, 1940.0, 4.0, 13.4, 23.5],\n",
       " [36.0, 69.4, 26219.0, 1940.0, 4.0, 13.4, 23.5],\n",
       " [36.0, 69.4, 26219.0, 1940.0, 4.0, 13.4, 23.5],\n",
       " [36.0, 69.4, 26219.0, 1940.0, 4.0, 13.4, 23.5],\n",
       " [36.0, 69.4, 26219.0, 1940.0, 4.0, 13.4, 23.5],\n",
       " [36.0, 69.4, 26219.0, 1940.0, 4.0, 13.4, 23.5],\n",
       " [36.0, 69.4, 26219.0, 1940.0, 4.0, 13.4, 23.5],\n",
       " [36.0, 69.4, 26219.0, 1940.0, 4.0, 13.4, 23.5],\n",
       " [36.0, 69.4, 26219.0, 1940.0, 4.0, 13.4, 23.5],\n",
       " [36.0, 69.4, 26219.0, 1940.0, 4.0, 13.4, 23.5],\n",
       " [36.0, 69.4, 26219.0, 1940.0, 4.0, 13.4, 23.5],\n",
       " [36.0, 69.4, 26219.0, 1940.0, 4.0, 13.4, 23.5],\n",
       " [36.0, 69.4, 26219.0, 1940.0, 4.0, 13.4, 23.5],\n",
       " [36.0, 69.4, 26219.0, 1940.0, 4.0, 13.4, 23.5],\n",
       " [36.0, 69.4, 26219.0, 1940.0, 4.0, 13.4, 23.5],\n",
       " [36.0, 69.4, 26219.0, 1940.0, 4.0, 13.4, 23.5],\n",
       " [36.0, 69.4, 26219.0, 1940.0, 4.0, 13.4, 23.5],\n",
       " [36.0, 69.4, 26219.0, 1940.0, 4.0, 13.4, 23.5],\n",
       " [36.0, 69.4, 26219.0, 1940.0, 4.0, 13.4, 23.5],\n",
       " [36.0, 69.4, 26219.0, 1940.0, 4.0, 13.4, 23.5],\n",
       " [36.0, 73.0, 13631.0, 1937.0, 2.0, 9.1, 30.2],\n",
       " [36.0, 61.8, 12655.0, 1937.0, 2.0, 9.1, 30.2],\n",
       " [36.0, 61.8, 12655.0, 1937.0, 2.0, 9.1, 30.2],\n",
       " [36.0, 61.8, 12655.0, 1937.0, 2.0, 9.1, 30.2],\n",
       " [36.0, 59.8, 12655.0, 1937.0, 2.0, 9.1, 27.1],\n",
       " [36.3, 74.2, 12655.0, 1937.0, 2.0, 9.1, 27.0],\n",
       " [36.3, 59.9, 12655.0, 1937.0, 2.0, 9.1, 27.1],\n",
       " [36.3, 60.6, 12924.0, 1937.0, 2.0, 9.1, 27.1],\n",
       " [36.3, 60.6, 12924.0, 1937.0, 2.0, 9.1, 27.1],\n",
       " [36.3, 74.0, 12924.0, 1937.0, 2.0, 9.1, 27.1],\n",
       " [36.3, 74.0, 12924.0, 1937.0, 2.0, 9.1, 27.1],\n",
       " [36.3, 74.0, 12924.0, 1937.0, 2.0, 9.1, 27.1],\n",
       " [36.3, 74.0, 12924.0, 1937.0, 2.0, 9.1, 27.1],\n",
       " [36.3, 74.0, 12924.0, 1937.0, 2.0, 9.1, 27.1],\n",
       " [36.3, 74.0, 12924.0, 1937.0, 2.0, 9.1, 27.1],\n",
       " [36.3, 74.0, 12924.0, 1937.0, 2.0, 9.1, 27.1],\n",
       " [36.3, 74.0, 12924.0, 1937.0, 2.0, 9.1, 27.1],\n",
       " [36.3, 74.0, 12924.0, 1937.0, 2.0, 9.1, 27.1],\n",
       " [36.3, 74.0, 12924.0, 1937.0, 2.0, 9.1, 27.1],\n",
       " [36.3, 74.0, 12924.0, 1937.0, 2.0, 9.1, 27.1],\n",
       " [36.3, 74.0, 12924.0, 1937.0, 2.0, 9.1, 27.1],\n",
       " [36.3, 74.0, 12924.0, 1937.0, 2.0, 9.1, 27.1],\n",
       " [36.0, 75.8, 10051.0, 1958.0, 2.0, 9.1, 29.9],\n",
       " [36.0, 74.5, 12109.0, 1958.0, 3.0, 9.1, 29.9],\n",
       " [36.0, 74.5, 12109.0, 1958.0, 3.0, 9.1, 29.9],\n",
       " [36.0, 74.5, 12109.0, 1958.0, 3.0, 9.1, 29.9],\n",
       " [36.0, 74.5, 12109.0, 1958.0, 3.0, 9.1, 28.0],\n",
       " [36.3, 74.2, 12109.0, 1958.0, 3.0, 9.1, 29.0],\n",
       " [36.3, 74.5, 12109.0, 1958.0, 3.0, 9.1, 28.7],\n",
       " [36.3, 61.9, 13774.0, 1958.0, 3.0, 9.1, 28.7],\n",
       " [36.3, 61.9, 13774.0, 1958.0, 3.0, 9.1, 28.7],\n",
       " [36.3, 61.9, 13774.0, 1958.0, 3.0, 9.1, 28.7],\n",
       " [36.3, 61.9, 13774.0, 1958.0, 3.0, 9.1, 28.7],\n",
       " [36.3, 61.9, 13774.0, 1958.0, 3.0, 9.1, 28.7],\n",
       " [36.3, 61.9, 13774.0, 1958.0, 3.0, 9.1, 28.7],\n",
       " [36.3, 61.9, 13774.0, 1958.0, 3.0, 9.1, 28.7],\n",
       " [36.3, 61.9, 13774.0, 1958.0, 3.0, 9.1, 28.7],\n",
       " [36.3, 61.9, 13774.0, 1958.0, 3.0, 9.1, 28.7],\n",
       " [36.3, 61.9, 13774.0, 1958.0, 3.0, 9.1, 28.7],\n",
       " [36.3, 61.9, 13774.0, 1958.0, 3.0, 9.1, 28.7],\n",
       " [36.3, 61.9, 13774.0, 1958.0, 3.0, 9.1, 28.7],\n",
       " [36.3, 61.9, 13774.0, 1958.0, 3.0, 9.1, 28.7],\n",
       " [36.3, 61.9, 13774.0, 1958.0, 3.0, 9.1, 28.7],\n",
       " [36.3, 61.9, 13774.0, 1958.0, 3.0, 9.1, 28.7],\n",
       " [36.0, 69.7, 190.0, 1929.0, 1.0, 3.6, 7.9],\n",
       " [36.0, 74.3, 59.0, 1929.0, 1.0, 3.6, 7.9],\n",
       " [36.0, 74.3, 59.0, 1929.0, 1.0, 3.6, 7.9],\n",
       " [36.0, 74.3, 59.0, 1929.0, 1.0, 3.6, 7.9],\n",
       " [36.0, 63.2, 59.0, 1929.0, 1.0, 3.6, 7.9],\n",
       " [36.3, 77.9, 59.0, 1929.0, 1.0, 3.7, 7.9],\n",
       " [36.3, 48.1, 59.0, 1929.0, 1.0, 3.7, 7.9],\n",
       " [36.3, 43.5, 215.0, 1929.0, 1.0, 3.7, 7.9],\n",
       " [36.3, 43.5, 215.0, 1929.0, 1.0, 3.7, 7.9],\n",
       " [36.3, 43.5, 215.0, 1929.0, 1.0, 3.7, 7.9],\n",
       " [36.3, 43.5, 215.0, 1929.0, 1.0, 3.7, 7.9],\n",
       " [36.3, 43.5, 215.0, 1929.0, 1.0, 3.7, 7.9],\n",
       " [36.3, 43.5, 215.0, 1929.0, 1.0, 3.7, 7.9],\n",
       " [36.3, 43.5, 215.0, 1929.0, 1.0, 3.7, 7.9],\n",
       " [36.3, 43.5, 215.0, 1929.0, 1.0, 3.7, 7.9],\n",
       " [36.3, 43.5, 215.0, 1929.0, 1.0, 3.7, 7.9],\n",
       " [36.3, 43.5, 215.0, 1929.0, 1.0, 3.7, 7.9],\n",
       " [36.3, 43.5, 215.0, 1929.0, 1.0, 3.7, 7.9],\n",
       " [36.3, 43.5, 215.0, 1929.0, 1.0, 3.7, 7.9],\n",
       " [36.3, 43.5, 215.0, 1929.0, 1.0, 3.7, 7.9],\n",
       " [36.3, 43.5, 215.0, 1929.0, 1.0, 3.7, 7.9],\n",
       " [36.3, 43.5, 215.0, 1929.0, 1.0, 3.7, 7.9],\n",
       " [54.0, 86.3, 860.0, 1984.0, 3.0, 13.4, 4.9],\n",
       " [54.0, 96.6, 1768.0, 1984.0, 3.0, 13.4, 4.9],\n",
       " [54.0, 96.6, 1768.0, 1984.0, 3.0, 13.4, 4.9],\n",
       " [54.0, 96.6, 1768.0, 1984.0, 3.0, 13.4, 4.9],\n",
       " [54.0, 85.5, 1768.0, 1984.0, 3.0, 13.4, 4.9],\n",
       " [54.4, 96.9, 1768.0, 1984.0, 3.0, 13.5, 5.0],\n",
       " [54.4, 86.8, 1768.0, 1984.0, 3.0, 13.5, 4.9],\n",
       " [50.6, 85.8, 2584.0, 1984.0, 3.0, 13.5, 4.8],\n",
       " [50.6, 85.8, 2584.0, 1984.0, 3.0, 13.5, 4.8],\n",
       " [50.6, 98.8, 2584.0, 1984.0, 3.0, 13.5, 4.8],\n",
       " [50.6, 98.8, 2584.0, 1984.0, 3.0, 13.5, 4.8],\n",
       " [50.6, 98.8, 2584.0, 1984.0, 3.0, 13.5, 4.8],\n",
       " [50.6, 98.8, 2584.0, 1984.0, 3.0, 13.5, 4.8],\n",
       " [50.6, 98.9, 1554.0, 1984.0, 3.0, 13.5, 4.8],\n",
       " [50.6, 98.9, 1554.0, 1984.0, 3.0, 13.5, 4.8],\n",
       " [50.6, 98.9, 1554.0, 1984.0, 3.0, 13.5, 4.8],\n",
       " [50.6, 98.9, 1566.0, 1984.0, 3.0, 13.5, 4.8],\n",
       " [50.6, 98.9, 1566.0, 1984.0, 3.0, 13.5, 4.8],\n",
       " [50.6, 98.9, 1566.0, 1984.0, 3.0, 13.5, 4.8],\n",
       " [50.6, 98.9, 1566.0, 1984.0, 3.0, 13.5, 4.8],\n",
       " [50.6, 98.9, 1566.0, 1984.0, 3.0, 13.5, 4.8],\n",
       " [50.6, 98.9, 2281.0, 1984.0, 3.0, 13.5, 4.8],\n",
       " [36.0, 82.6, 2501.0, 1975.0, 3.0, 12.1, 3.7],\n",
       " [36.0, 94.3, 4370.0, 1975.0, 3.0, 12.1, 3.7],\n",
       " [36.0, 94.3, 4370.0, 1975.0, 3.0, 12.1, 3.7],\n",
       " [36.0, 94.3, 4370.0, 1975.0, 3.0, 12.1, 3.7],\n",
       " [36.0, 94.3, 4370.0, 1975.0, 3.0, 12.1, 3.7],\n",
       " [36.3, 95.4, 4370.0, 1975.0, 3.0, 12.2, 4.0],\n",
       " [36.3, 95.4, 4370.0, 1975.0, 3.0, 12.2, 3.7],\n",
       " [36.3, 95.4, 3936.0, 1975.0, 3.0, 12.2, 4.0],\n",
       " [36.3, 95.4, 3936.0, 1975.0, 3.0, 12.2, 4.0],\n",
       " [36.3, 95.4, 3936.0, 1975.0, 3.0, 12.2, 3.7],\n",
       " [36.3, 95.4, 3936.0, 1975.0, 3.0, 12.2, 3.7],\n",
       " [36.3, 95.4, 3936.0, 1975.0, 3.0, 12.2, 3.7],\n",
       " [36.3, 95.4, 3936.0, 1975.0, 3.0, 12.2, 3.7],\n",
       " [36.3, 95.6, 2576.0, 1975.0, 3.0, 12.2, 3.7],\n",
       " [36.3, 95.6, 2576.0, 1975.0, 3.0, 12.2, 3.7],\n",
       " [36.3, 84.6, 2576.0, 1975.0, 3.0, 12.2, 3.7],\n",
       " [36.3, 84.6, 2634.0, 1975.0, 3.0, 12.2, 3.7],\n",
       " [36.3, 84.6, 2634.0, 1975.0, 3.0, 12.2, 3.7],\n",
       " [36.3, 84.6, 2634.0, 1975.0, 3.0, 12.2, 3.7],\n",
       " [27.2, 51.2, 2634.0, 1975.0, 3.0, 12.2, 3.7],\n",
       " [27.2, 51.2, 2634.0, 1975.0, 3.0, 12.2, 3.7],\n",
       " [27.2, 51.2, 3204.0, 1975.0, 3.0, 12.2, 3.7],\n",
       " [47.7, 96.4, 4202.0, 1987.0, 2.0, 8.5, 3.7],\n",
       " [47.7, 96.2, 5564.0, 1987.0, 2.0, 8.5, 3.7],\n",
       " [47.7, 96.2, 5564.0, 1987.0, 2.0, 8.5, 3.7],\n",
       " [47.7, 96.2, 5564.0, 1987.0, 2.0, 8.5, 3.7],\n",
       " [47.7, 96.2, 5564.0, 1987.0, 2.0, 8.5, 3.7],\n",
       " [48.1, 96.7, 5564.0, 1987.0, 2.0, 10.4, 4.0],\n",
       " [48.1, 96.4, 5564.0, 1987.0, 2.0, 10.4, 3.7],\n",
       " [48.1, 96.4, 5518.0, 1987.0, 2.0, 10.4, 4.0],\n",
       " [48.1, 96.4, 5518.0, 1987.0, 2.0, 10.4, 4.0],\n",
       " [48.6, 95.6, 5518.0, 1987.0, 2.0, 10.4, 3.7],\n",
       " [48.6, 95.6, 5518.0, 1987.0, 2.0, 10.4, 3.7],\n",
       " [48.6, 95.6, 5518.0, 1987.0, 2.0, 10.4, 3.7],\n",
       " [48.6, 95.6, 5518.0, 1987.0, 2.0, 10.4, 3.7],\n",
       " [48.6, 95.6, 5306.0, 1987.0, 2.0, 10.4, 3.7],\n",
       " [48.6, 95.6, 5306.0, 1987.0, 2.0, 10.4, 3.7],\n",
       " [48.6, 95.6, 5306.0, 1987.0, 2.0, 10.4, 3.7],\n",
       " [48.6, 95.6, 5413.0, 1987.0, 2.0, 10.4, 3.7],\n",
       " [48.6, 95.6, 5413.0, 1987.0, 2.0, 10.4, 3.7],\n",
       " [48.6, 95.6, 5413.0, 1987.0, 2.0, 10.4, 3.7],\n",
       " [48.6, 95.6, 5413.0, 1987.0, 2.0, 10.4, 3.7],\n",
       " [48.6, 95.6, 5413.0, 1987.0, 2.0, 10.4, 3.7],\n",
       " [48.6, 95.6, 5666.0, 1987.0, 2.0, 10.4, 3.7],\n",
       " [36.0, 92.1, 1272.0, 1955.0, 2.0, 9.1, 14.3],\n",
       " [36.0, 92.1, 1931.0, 1955.0, 2.0, 9.1, 14.3],\n",
       " [36.0, 92.1, 1931.0, 1955.0, 2.0, 9.1, 14.3],\n",
       " [36.0, 92.1, 1931.0, 1955.0, 2.0, 9.1, 14.3],\n",
       " [36.0, 92.1, 1931.0, 1955.0, 2.0, 9.1, 14.0],\n",
       " [36.3, 92.2, 1931.0, 1955.0, 2.0, 9.1, 14.0],\n",
       " [36.3, 92.1, 1931.0, 1955.0, 2.0, 9.1, 14.0],\n",
       " [36.3, 96.9, 696.0, 1955.0, 2.0, 9.1, 14.0],\n",
       " [36.3, 96.9, 696.0, 1955.0, 2.0, 9.1, 14.0],\n",
       " [36.3, 96.9, 696.0, 1955.0, 2.0, 9.1, 13.7],\n",
       " ...]"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# list_of_row_components = np.array(list_of_row_components)\n",
    "\n",
    "list_of_row_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36.0, 97.0, 428.0, 1949.0, 2.0, 10.9, 7.3]\n",
      "[36.0, 96.9, 955.0, 1949.0, 2.0, 10.9, 7.3]\n",
      "[36.0, 96.9, 955.0, 1949.0, 2.0, 10.9, 7.3]\n",
      "[36.0, 96.9, 955.0, 1949.0, 2.0, 10.9, 7.3]\n",
      "[36.0, 96.9, 955.0, 1949.0, 2.0, 10.9, 7.3]\n",
      "[36.3, 97.0, 955.0, 1949.0, 2.0, 11.0, 7.0]\n",
      "[36.3, 96.9, 955.0, 1949.0, 2.0, 11.0, 7.3]\n",
      "[36.3, 96.9, 983.0, 1949.0, 2.0, 11.0, 7.3]\n",
      "[36.3, 96.9, 983.0, 1949.0, 2.0, 11.0, 7.3]\n",
      "[36.3, 96.9, 983.0, 1949.0, 2.0, 11.0, 7.3]\n",
      "[36.3, 96.9, 983.0, 1949.0, 2.0, 11.0, 7.3]\n",
      "[36.3, 97.0, 422.0, 1949.0, 2.0, 11.0, 7.3]\n",
      "[36.3, 97.0, 422.0, 1949.0, 2.0, 11.0, 7.3]\n",
      "[36.3, 97.0, 422.0, 1949.0, 2.0, 11.0, 7.3]\n",
      "[36.3, 97.0, 422.0, 1949.0, 2.0, 11.0, 7.3]\n",
      "[36.3, 97.0, 422.0, 1949.0, 2.0, 9.7, 7.3]\n",
      "[36.3, 97.0, 369.0, 1949.0, 2.0, 9.7, 7.3]\n",
      "[36.3, 86.0, 369.0, 1949.0, 2.0, 9.7, 7.3]\n",
      "[36.3, 86.0, 369.0, 1949.0, 2.0, 9.7, 7.3]\n",
      "[36.3, 86.0, 369.0, 1949.0, 2.0, 9.7, 7.3]\n",
      "[36.3, 86.0, 369.0, 1949.0, 2.0, 9.7, 7.3]\n",
      "[36.3, 86.0, 522.0, 1949.0, 2.0, 9.7, 7.3]\n"
     ]
    }
   ],
   "source": [
    "for i in range(22):\n",
    "    print(list_of_row_components[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11506"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_of_row_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, component in enumerate(list_of_row_components):\n",
    "    temp = component[6]\n",
    "    list_of_row_components[idx][6] = list_of_row_components[idx][1]\n",
    "    list_of_row_components[idx][1] = temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = tf.keras.models.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "    tf.keras.layers.LSTM(50, return_sequences=True),\n",
    "#     tf.keras.layers.LSTM(30, return_sequences=True),\n",
    "#     tf.keras.layers.LSTM(100, return_sequences=True),\n",
    "#     tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "#     tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "#     tf.keras.layers.Dense(units=16, activation='relu'),\n",
    "#     tf.keras.layers.Dense(units=8, activation='relu'),\n",
    "#     tf.keras.layers.Dense(units=4, activation='relu'),\n",
    "#     tf.keras.layers.Dense(units=2, activation='relu'),\n",
    "#     Shape => [batch, time, features]\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_examples = []\n",
    "temp_list = []\n",
    "\n",
    "max_num = 22\n",
    "iter = 0;\n",
    "\n",
    "for row_component in list_of_row_components:\n",
    "    if iter == max_num:\n",
    "        list_of_examples.append(np.array(temp_list))\n",
    "        temp_list = []\n",
    "        iter = 0\n",
    "        \n",
    "    temp_list.append(np.array(row_component))\n",
    "    iter += 1\n",
    "\n",
    "list_of_examples = np.array(list_of_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "522"
      ]
     },
     "execution_count": 627,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_of_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  36. ,    7.3,  428. , 1949. ,    2. ,   10.9,   97. ],\n",
       "       [  36. ,    7.3,  955. , 1949. ,    2. ,   10.9,   96.9],\n",
       "       [  36. ,    7.3,  955. , 1949. ,    2. ,   10.9,   96.9],\n",
       "       [  36. ,    7.3,  955. , 1949. ,    2. ,   10.9,   96.9],\n",
       "       [  36. ,    7.3,  955. , 1949. ,    2. ,   10.9,   96.9],\n",
       "       [  36.3,    7. ,  955. , 1949. ,    2. ,   11. ,   97. ],\n",
       "       [  36.3,    7.3,  955. , 1949. ,    2. ,   11. ,   96.9],\n",
       "       [  36.3,    7.3,  983. , 1949. ,    2. ,   11. ,   96.9],\n",
       "       [  36.3,    7.3,  983. , 1949. ,    2. ,   11. ,   96.9],\n",
       "       [  36.3,    7.3,  983. , 1949. ,    2. ,   11. ,   96.9],\n",
       "       [  36.3,    7.3,  983. , 1949. ,    2. ,   11. ,   96.9],\n",
       "       [  36.3,    7.3,  422. , 1949. ,    2. ,   11. ,   97. ],\n",
       "       [  36.3,    7.3,  422. , 1949. ,    2. ,   11. ,   97. ],\n",
       "       [  36.3,    7.3,  422. , 1949. ,    2. ,   11. ,   97. ],\n",
       "       [  36.3,    7.3,  422. , 1949. ,    2. ,   11. ,   97. ],\n",
       "       [  36.3,    7.3,  422. , 1949. ,    2. ,    9.7,   97. ],\n",
       "       [  36.3,    7.3,  369. , 1949. ,    2. ,    9.7,   97. ],\n",
       "       [  36.3,    7.3,  369. , 1949. ,    2. ,    9.7,   86. ],\n",
       "       [  36.3,    7.3,  369. , 1949. ,    2. ,    9.7,   86. ],\n",
       "       [  36.3,    7.3,  369. , 1949. ,    2. ,    9.7,   86. ],\n",
       "       [  36.3,    7.3,  369. , 1949. ,    2. ,    9.7,   86. ],\n",
       "       [  36.3,    7.3,  522. , 1949. ,    2. ,    9.7,   86. ]])"
      ]
     },
     "execution_count": 628,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_examples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.0\n",
      "55.7\n",
      "50.2\n",
      "100.0\n",
      "70.9\n",
      "71.7\n",
      "98.9\n",
      "65.9\n",
      "79.5\n",
      "97.6\n",
      "49.5\n",
      "66.2\n",
      "19.9\n",
      "99.0\n",
      "81.3\n",
      "90.6\n",
      "58.8\n",
      "98.0\n",
      "89.5\n",
      "95.4\n",
      "84.0\n",
      "100.0\n",
      "78.9\n",
      "83.4\n",
      "95.8\n",
      "98.0\n",
      "99.9\n",
      "75.3\n",
      "82.0\n",
      "62.7\n",
      "81.7\n",
      "71.2\n",
      "84.0\n",
      "99.0\n",
      "40.6\n",
      "98.9\n",
      "97.7\n",
      "73.0\n",
      "69.4\n",
      "74.0\n",
      "61.9\n",
      "43.5\n",
      "98.9\n",
      "51.2\n",
      "95.6\n",
      "92.0\n",
      "91.9\n",
      "47.8\n",
      "83.4\n",
      "97.8\n",
      "99.9\n",
      "96.7\n",
      "47.9\n",
      "79.7\n",
      "95.8\n",
      "96.8\n",
      "87.6\n",
      "92.0\n",
      "63.9\n",
      "97.4\n",
      "71.4\n",
      "92.0\n",
      "99.9\n",
      "98.9\n",
      "78.4\n",
      "84.2\n",
      "91.7\n",
      "55.2\n",
      "95.3\n",
      "34.0\n",
      "93.4\n",
      "63.1\n",
      "95.1\n",
      "39.5\n",
      "97.3\n",
      "63.9\n",
      "87.3\n",
      "71.4\n",
      "87.6\n",
      "58.3\n",
      "71.6\n",
      "97.0\n",
      "63.7\n",
      "78.7\n",
      "23.3\n",
      "79.2\n",
      "97.9\n",
      "89.6\n",
      "89.6\n",
      "78.0\n",
      "11.0\n",
      "96.0\n",
      "93.1\n",
      "94.1\n",
      "94.8\n",
      "63.2\n",
      "97.3\n",
      "90.0\n",
      "96.7\n",
      "80.9\n",
      "97.0\n",
      "90.7\n",
      "94.9\n",
      "95.4\n",
      "76.4\n",
      "83.5\n",
      "75.8\n",
      "95.8\n",
      "87.0\n",
      "91.1\n",
      "63.8\n",
      "96.9\n",
      "44.5\n",
      "81.5\n",
      "96.9\n",
      "81.8\n",
      "49.4\n",
      "81.3\n",
      "96.8\n",
      "96.7\n",
      "95.0\n",
      "97.9\n",
      "57.3\n",
      "56.1\n",
      "93.1\n",
      "88.1\n",
      "97.0\n",
      "59.4\n",
      "93.8\n",
      "90.5\n",
      "84.0\n",
      "69.1\n",
      "66.3\n",
      "98.8\n",
      "99.8\n",
      "99.0\n",
      "98.7\n",
      "97.0\n",
      "85.9\n",
      "98.3\n",
      "99.2\n",
      "62.2\n",
      "73.5\n",
      "99.9\n",
      "95.8\n",
      "97.2\n",
      "84.1\n",
      "100.0\n",
      "74.8\n",
      "77.4\n",
      "100.0\n",
      "88.9\n",
      "100.0\n",
      "100.0\n",
      "98.1\n",
      "98.3\n",
      "92.8\n",
      "96.9\n",
      "78.9\n",
      "55.3\n",
      "54.3\n",
      "98.1\n",
      "91.2\n",
      "95.1\n",
      "67.1\n",
      "98.0\n",
      "97.0\n",
      "100.0\n",
      "99.6\n",
      "74.8\n",
      "98.9\n",
      "100.0\n",
      "100.0\n",
      "79.3\n",
      "87.2\n",
      "96.4\n",
      "74.8\n",
      "99.1\n",
      "99.3\n",
      "91.6\n",
      "99.8\n",
      "58.5\n",
      "92.9\n",
      "55.3\n",
      "100.0\n",
      "88.9\n",
      "47.1\n",
      "81.4\n",
      "100.0\n",
      "100.0\n",
      "96.9\n",
      "95.4\n",
      "99.9\n",
      "99.9\n",
      "99.8\n",
      "100.0\n",
      "96.8\n",
      "92.4\n",
      "73.8\n",
      "57.1\n",
      "99.3\n",
      "98.4\n",
      "99.4\n",
      "82.9\n",
      "98.9\n",
      "56.1\n",
      "100.0\n",
      "97.5\n",
      "60.3\n",
      "99.4\n",
      "98.3\n",
      "100.0\n",
      "95.1\n",
      "96.9\n",
      "100.0\n",
      "86.0\n",
      "100.0\n",
      "89.9\n",
      "39.7\n",
      "98.0\n",
      "72.0\n",
      "100.0\n",
      "100.0\n",
      "97.0\n",
      "99.9\n",
      "99.9\n",
      "100.0\n",
      "100.0\n",
      "57.1\n",
      "74.8\n",
      "64.3\n",
      "65.5\n",
      "95.3\n",
      "93.8\n",
      "93.9\n",
      "99.4\n",
      "98.4\n",
      "72.0\n",
      "64.7\n",
      "98.8\n",
      "81.0\n",
      "80.0\n",
      "100.0\n",
      "65.3\n",
      "72.0\n",
      "100.0\n",
      "99.6\n",
      "99.5\n",
      "99.6\n",
      "75.5\n",
      "36.2\n",
      "100.0\n",
      "65.8\n",
      "40.0\n",
      "94.0\n",
      "71.9\n",
      "100.0\n",
      "41.0\n",
      "41.0\n",
      "51.6\n",
      "36.0\n",
      "48.9\n",
      "100.0\n",
      "55.0\n",
      "53.3\n",
      "34.0\n",
      "87.4\n",
      "42.6\n",
      "63.0\n",
      "100.0\n",
      "63.6\n",
      "94.7\n",
      "48.9\n",
      "84.2\n",
      "97.1\n",
      "96.9\n",
      "98.3\n",
      "93.2\n",
      "86.0\n",
      "99.9\n",
      "45.1\n",
      "64.3\n",
      "92.7\n",
      "60.8\n",
      "45.5\n",
      "88.9\n",
      "100.0\n",
      "95.8\n",
      "99.9\n",
      "86.6\n",
      "54.7\n",
      "48.9\n",
      "77.8\n",
      "85.0\n",
      "80.8\n",
      "67.1\n",
      "68.1\n",
      "63.5\n",
      "59.6\n",
      "80.8\n",
      "80.8\n",
      "66.6\n",
      "76.1\n",
      "70.0\n",
      "80.5\n",
      "43.3\n",
      "72.3\n",
      "60.7\n",
      "48.7\n",
      "96.4\n",
      "96.4\n",
      "95.7\n",
      "58.6\n",
      "73.8\n",
      "65.5\n",
      "95.7\n",
      "65.5\n",
      "73.1\n",
      "89.6\n",
      "99.2\n",
      "99.2\n",
      "74.6\n",
      "75.9\n",
      "74.6\n",
      "64.6\n",
      "76.7\n",
      "76.7\n",
      "65.2\n",
      "52.2\n",
      "78.3\n",
      "69.1\n",
      "99.4\n",
      "66.7\n",
      "50.1\n",
      "65.2\n",
      "67.9\n",
      "67.9\n",
      "74.7\n",
      "61.0\n",
      "79.0\n",
      "26.5\n",
      "9.0\n",
      "73.5\n",
      "29.2\n",
      "9.0\n",
      "22.0\n",
      "93.3\n",
      "81.2\n",
      "55.9\n",
      "55.9\n",
      "59.9\n",
      "57.9\n",
      "78.9\n",
      "70.0\n",
      "78.9\n",
      "70.1\n",
      "68.1\n",
      "75.8\n",
      "64.5\n",
      "62.8\n",
      "64.0\n",
      "89.9\n",
      "67.9\n",
      "86.4\n",
      "77.0\n",
      "82.0\n",
      "90.7\n",
      "88.5\n",
      "89.5\n",
      "79.3\n",
      "88.7\n",
      "76.0\n",
      "92.1\n",
      "86.3\n",
      "93.0\n",
      "55.3\n",
      "81.7\n",
      "99.0\n",
      "77.5\n",
      "77.5\n",
      "71.1\n",
      "68.1\n",
      "80.4\n",
      "79.5\n",
      "90.3\n",
      "99.2\n",
      "99.2\n",
      "49.0\n",
      "87.1\n",
      "99.4\n",
      "69.0\n",
      "83.1\n",
      "70.0\n",
      "72.3\n",
      "94.1\n",
      "99.2\n",
      "99.7\n",
      "90.6\n",
      "95.8\n",
      "92.7\n",
      "99.8\n",
      "100.0\n",
      "96.8\n",
      "92.7\n",
      "87.0\n",
      "70.0\n",
      "83.0\n",
      "82.3\n",
      "81.0\n",
      "71.4\n",
      "84.1\n",
      "83.8\n",
      "61.5\n",
      "53.3\n",
      "46.3\n",
      "84.1\n",
      "64.3\n",
      "67.0\n",
      "54.0\n",
      "99.4\n",
      "71.0\n",
      "79.3\n",
      "93.1\n",
      "93.1\n",
      "72.8\n",
      "84.3\n",
      "84.0\n",
      "85.0\n",
      "89.0\n",
      "98.1\n",
      "67.3\n",
      "82.7\n",
      "98.1\n",
      "82.8\n",
      "97.8\n",
      "40.1\n",
      "40.3\n",
      "40.9\n",
      "33.5\n",
      "6.9\n",
      "46.2\n",
      "69.7\n",
      "89.2\n",
      "99.4\n",
      "97.0\n",
      "84.2\n",
      "75.7\n",
      "99.5\n",
      "99.6\n",
      "99.5\n",
      "98.7\n",
      "96.9\n",
      "76.7\n",
      "65.2\n",
      "58.4\n",
      "53.5\n",
      "50.0\n",
      "57.2\n",
      "84.2\n",
      "60.7\n",
      "59.7\n",
      "49.1\n",
      "80.7\n",
      "96.4\n",
      "60.1\n",
      "60.8\n",
      "96.4\n",
      "95.0\n",
      "97.1\n",
      "97.1\n",
      "54.9\n",
      "81.2\n",
      "84.7\n",
      "55.8\n",
      "97.2\n",
      "79.0\n",
      "97.3\n",
      "92.9\n",
      "86.3\n",
      "85.5\n",
      "97.3\n",
      "91.0\n",
      "58.3\n",
      "77.1\n",
      "77.1\n",
      "68.3\n",
      "35.2\n",
      "38.6\n",
      "52.2\n",
      "77.0\n",
      "55.3\n",
      "98.5\n",
      "79.9\n",
      "62.8\n",
      "92.6\n",
      "39.9\n",
      "66.3\n",
      "79.1\n",
      "95.9\n",
      "82.0\n",
      "82.0\n",
      "82.0\n",
      "82.0\n",
      "82.0\n",
      "82.0\n",
      "82.0\n",
      "82.0\n",
      "82.0\n",
      "82.0\n",
      "82.0\n",
      "82.0\n",
      "82.0\n",
      "82.0\n",
      "82.0\n",
      "82.0\n",
      "82.0\n",
      "82.0\n",
      "82.0\n",
      "82.0\n",
      "82.0\n",
      "82.0\n",
      "82.0\n"
     ]
    }
   ],
   "source": [
    "for idx, example in enumerate(list_of_examples):\n",
    "#     print('here')\n",
    "    print(list_of_examples[idx][21][6])\n",
    "    list_of_examples[idx][21] = [list_of_examples[idx][21][6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(522, 22, 7)"
      ]
     },
     "execution_count": 630,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_examples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[3.6000e+01, 7.3000e+00, 4.2800e+02, ..., 2.0000e+00,\n",
       "         1.0900e+01, 9.7000e+01],\n",
       "        [3.6000e+01, 7.3000e+00, 9.5500e+02, ..., 2.0000e+00,\n",
       "         1.0900e+01, 9.6900e+01],\n",
       "        [3.6000e+01, 7.3000e+00, 9.5500e+02, ..., 2.0000e+00,\n",
       "         1.0900e+01, 9.6900e+01],\n",
       "        ...,\n",
       "        [3.6300e+01, 7.3000e+00, 3.6900e+02, ..., 2.0000e+00,\n",
       "         9.7000e+00, 8.6000e+01],\n",
       "        [3.6300e+01, 7.3000e+00, 3.6900e+02, ..., 2.0000e+00,\n",
       "         9.7000e+00, 8.6000e+01],\n",
       "        [8.6000e+01, 8.6000e+01, 8.6000e+01, ..., 8.6000e+01,\n",
       "         8.6000e+01, 8.6000e+01]],\n",
       "\n",
       "       [[3.6000e+01, 6.4000e+00, 4.1700e+02, ..., 2.0000e+00,\n",
       "         6.6000e+00, 8.3900e+01],\n",
       "        [3.6000e+01, 3.0000e+00, 3.5100e+02, ..., 2.0000e+00,\n",
       "         6.6000e+00, 7.0900e+01],\n",
       "        [3.6000e+01, 3.0000e+00, 3.5100e+02, ..., 2.0000e+00,\n",
       "         6.6000e+00, 7.0900e+01],\n",
       "        ...,\n",
       "        [3.2700e+01, 2.9000e+00, 6.2300e+02, ..., 2.0000e+00,\n",
       "         6.6000e+00, 5.5700e+01],\n",
       "        [3.2700e+01, 2.9000e+00, 6.2300e+02, ..., 2.0000e+00,\n",
       "         6.6000e+00, 5.5700e+01],\n",
       "        [5.5700e+01, 5.5700e+01, 5.5700e+01, ..., 5.5700e+01,\n",
       "         5.5700e+01, 5.5700e+01]],\n",
       "\n",
       "       [[3.6000e+01, 4.0000e+00, 1.8360e+03, ..., 2.0000e+00,\n",
       "         7.6000e+00, 8.2000e+01],\n",
       "        [3.6000e+01, 4.0000e+00, 1.4590e+03, ..., 2.0000e+00,\n",
       "         7.7000e+00, 8.4300e+01],\n",
       "        [3.6000e+01, 4.0000e+00, 1.4590e+03, ..., 2.0000e+00,\n",
       "         7.7000e+00, 8.4300e+01],\n",
       "        ...,\n",
       "        [2.7200e+01, 3.4000e+00, 1.4460e+03, ..., 2.0000e+00,\n",
       "         7.7000e+00, 5.0200e+01],\n",
       "        [2.7200e+01, 3.4000e+00, 1.4460e+03, ..., 2.0000e+00,\n",
       "         7.7000e+00, 5.0200e+01],\n",
       "        [5.0200e+01, 5.0200e+01, 5.0200e+01, ..., 5.0200e+01,\n",
       "         5.0200e+01, 5.0200e+01]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[8.7300e+01, 3.5100e+01, 3.8400e+04, ..., 0.0000e+00,\n",
       "         2.2500e+01, 8.2000e+01],\n",
       "        [8.7300e+01, 3.5100e+01, 3.8000e+04, ..., 0.0000e+00,\n",
       "         2.2500e+01, 8.2000e+01],\n",
       "        [8.7300e+01, 3.5100e+01, 3.8000e+04, ..., 0.0000e+00,\n",
       "         2.2500e+01, 8.2000e+01],\n",
       "        ...,\n",
       "        [8.7300e+01, 3.5100e+01, 3.8000e+04, ..., 0.0000e+00,\n",
       "         2.2500e+01, 8.2000e+01],\n",
       "        [8.7300e+01, 3.5100e+01, 3.8000e+04, ..., 0.0000e+00,\n",
       "         2.2500e+01, 8.2000e+01],\n",
       "        [8.2000e+01, 8.2000e+01, 8.2000e+01, ..., 8.2000e+01,\n",
       "         8.2000e+01, 8.2000e+01]],\n",
       "\n",
       "       [[8.7300e+01, 2.0700e+01, 1.0500e+04, ..., 0.0000e+00,\n",
       "         1.2900e+01, 8.2000e+01],\n",
       "        [8.7300e+01, 2.0700e+01, 3.2904e+04, ..., 0.0000e+00,\n",
       "         1.2900e+01, 8.2000e+01],\n",
       "        [8.7300e+01, 2.0700e+01, 3.2904e+04, ..., 0.0000e+00,\n",
       "         1.2900e+01, 8.2000e+01],\n",
       "        ...,\n",
       "        [8.7300e+01, 2.1300e+01, 3.5800e+04, ..., 0.0000e+00,\n",
       "         1.2200e+01, 8.2000e+01],\n",
       "        [8.7300e+01, 2.1300e+01, 3.5800e+04, ..., 0.0000e+00,\n",
       "         1.2200e+01, 8.2000e+01],\n",
       "        [8.2000e+01, 8.2000e+01, 8.2000e+01, ..., 8.2000e+01,\n",
       "         8.2000e+01, 8.2000e+01]],\n",
       "\n",
       "       [[8.7300e+01, 2.8000e+01, 2.1800e+04, ..., 0.0000e+00,\n",
       "         1.1500e+01, 8.2000e+01],\n",
       "        [8.7300e+01, 2.8000e+01, 2.5600e+04, ..., 0.0000e+00,\n",
       "         1.1500e+01, 8.2000e+01],\n",
       "        [8.7300e+01, 2.8000e+01, 2.5600e+04, ..., 0.0000e+00,\n",
       "         1.1500e+01, 8.2000e+01],\n",
       "        ...,\n",
       "        [8.7300e+01, 2.8000e+01, 3.2300e+04, ..., 0.0000e+00,\n",
       "         1.1600e+01, 8.2000e+01],\n",
       "        [8.7300e+01, 2.8000e+01, 3.2300e+04, ..., 0.0000e+00,\n",
       "         1.1600e+01, 8.2000e+01],\n",
       "        [8.2000e+01, 8.2000e+01, 8.2000e+01, ..., 8.2000e+01,\n",
       "         8.2000e+01, 8.2000e+01]]])"
      ]
     },
     "execution_count": 631,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_examples.astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([86., 86., 86., 86., 86., 86., 86.])"
      ]
     },
     "execution_count": 632,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_examples[0][21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "n_train_periods = 300\n",
    "train = list_of_examples[:n_train_periods, :]\n",
    "test = list_of_examples[n_train_periods:, :]\n",
    "\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1, 1:], train[:, -1, 0]\n",
    "test_X, test_y = test[:, :-1, 1:], test[:, -1, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_X: (300, 21, 6)\n",
      "Shape of train_y: (300,)\n",
      "Shape of test_X: (222, 21, 6)\n",
      "Shape of test_y: (222,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of train_X: \" + str(train_X.shape))\n",
    "print(\"Shape of train_y: \" + str(train_y.shape))\n",
    "print(\"Shape of test_X: \" + str(test_X.shape))\n",
    "print(\"Shape of test_y: \" + str(test_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.0"
      ]
     },
     "execution_count": 635,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   7.3,  428. , 1949. ,    2. ,   10.9,   97. ],\n",
       "       [   7.3,  955. , 1949. ,    2. ,   10.9,   96.9],\n",
       "       [   7.3,  955. , 1949. ,    2. ,   10.9,   96.9],\n",
       "       [   7.3,  955. , 1949. ,    2. ,   10.9,   96.9],\n",
       "       [   7.3,  955. , 1949. ,    2. ,   10.9,   96.9],\n",
       "       [   7. ,  955. , 1949. ,    2. ,   11. ,   97. ],\n",
       "       [   7.3,  955. , 1949. ,    2. ,   11. ,   96.9],\n",
       "       [   7.3,  983. , 1949. ,    2. ,   11. ,   96.9],\n",
       "       [   7.3,  983. , 1949. ,    2. ,   11. ,   96.9],\n",
       "       [   7.3,  983. , 1949. ,    2. ,   11. ,   96.9],\n",
       "       [   7.3,  983. , 1949. ,    2. ,   11. ,   96.9],\n",
       "       [   7.3,  422. , 1949. ,    2. ,   11. ,   97. ],\n",
       "       [   7.3,  422. , 1949. ,    2. ,   11. ,   97. ],\n",
       "       [   7.3,  422. , 1949. ,    2. ,   11. ,   97. ],\n",
       "       [   7.3,  422. , 1949. ,    2. ,   11. ,   97. ],\n",
       "       [   7.3,  422. , 1949. ,    2. ,    9.7,   97. ],\n",
       "       [   7.3,  369. , 1949. ,    2. ,    9.7,   97. ],\n",
       "       [   7.3,  369. , 1949. ,    2. ,    9.7,   86. ],\n",
       "       [   7.3,  369. , 1949. ,    2. ,    9.7,   86. ],\n",
       "       [   7.3,  369. , 1949. ,    2. ,    9.7,   86. ],\n",
       "       [   7.3,  369. , 1949. ,    2. ,    9.7,   86. ]])"
      ]
     },
     "execution_count": 636,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,)"
      ]
     },
     "execution_count": 637,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "lstm_model = tf.keras.models.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "    tf.keras.layers.LSTM(50, dropout=0.2, recurrent_dropout=0.2, return_sequences=True, input_shape=(train_X.shape[1], train_X.shape[2])),\n",
    "#     tf.keras.layers.LSTM(50, return_sequences=True),\n",
    "#     tf.keras.layers.LSTM(25, return_sequences=True),\n",
    "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "#     tf.keras.layers.Dense(units=16, activation='relu'),\n",
    "#     tf.keras.layers.Dense(units=8, activation='relu'),\n",
    "#     tf.keras.layers.Dense(units=4, activation='relu'),\n",
    "#     tf.keras.layers.Dense(units=2, activation='relu'),\n",
    "#     Shape => [batch, time, features]\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "5/5 - 0s - loss: 776.6276 - val_loss: 466.1786\n",
      "Epoch 2/1000\n",
      "5/5 - 0s - loss: 666.5452 - val_loss: 401.8412\n",
      "Epoch 3/1000\n",
      "5/5 - 0s - loss: 586.9301 - val_loss: 378.2432\n",
      "Epoch 4/1000\n",
      "5/5 - 0s - loss: 513.1487 - val_loss: 360.8959\n",
      "Epoch 5/1000\n",
      "5/5 - 0s - loss: 485.1230 - val_loss: 355.5756\n",
      "Epoch 6/1000\n",
      "5/5 - 0s - loss: 446.4182 - val_loss: 354.9412\n",
      "Epoch 7/1000\n",
      "5/5 - 0s - loss: 422.7479 - val_loss: 354.8810\n",
      "Epoch 8/1000\n",
      "5/5 - 0s - loss: 410.6182 - val_loss: 356.2977\n",
      "Epoch 9/1000\n",
      "5/5 - 0s - loss: 409.8529 - val_loss: 358.4290\n",
      "Epoch 10/1000\n",
      "5/5 - 0s - loss: 400.3551 - val_loss: 359.8032\n",
      "Epoch 11/1000\n",
      "5/5 - 0s - loss: 401.0134 - val_loss: 362.1145\n",
      "Epoch 12/1000\n",
      "5/5 - 0s - loss: 393.8828 - val_loss: 363.2304\n",
      "Epoch 13/1000\n",
      "5/5 - 0s - loss: 390.7591 - val_loss: 362.8516\n",
      "Epoch 14/1000\n",
      "5/5 - 0s - loss: 387.3022 - val_loss: 363.5946\n",
      "Epoch 15/1000\n",
      "5/5 - 0s - loss: 394.2895 - val_loss: 364.6305\n",
      "Epoch 16/1000\n",
      "5/5 - 0s - loss: 392.8170 - val_loss: 364.7746\n",
      "Epoch 17/1000\n",
      "5/5 - 0s - loss: 386.7476 - val_loss: 364.8834\n",
      "Epoch 18/1000\n",
      "5/5 - 0s - loss: 390.5209 - val_loss: 364.0395\n",
      "Epoch 19/1000\n",
      "5/5 - 0s - loss: 380.5665 - val_loss: 363.4359\n",
      "Epoch 20/1000\n",
      "5/5 - 0s - loss: 383.2340 - val_loss: 363.3687\n",
      "Epoch 21/1000\n",
      "5/5 - 0s - loss: 386.1361 - val_loss: 362.8330\n",
      "Epoch 22/1000\n",
      "5/5 - 0s - loss: 383.0122 - val_loss: 362.3134\n",
      "Epoch 23/1000\n",
      "5/5 - 0s - loss: 389.9307 - val_loss: 361.7940\n",
      "Epoch 24/1000\n",
      "5/5 - 0s - loss: 388.7909 - val_loss: 361.8453\n",
      "Epoch 25/1000\n",
      "5/5 - 0s - loss: 390.3677 - val_loss: 361.7890\n",
      "Epoch 26/1000\n",
      "5/5 - 0s - loss: 382.2016 - val_loss: 361.0013\n",
      "Epoch 27/1000\n",
      "5/5 - 0s - loss: 386.4315 - val_loss: 361.4612\n",
      "Epoch 28/1000\n",
      "5/5 - 0s - loss: 390.5775 - val_loss: 361.3303\n",
      "Epoch 29/1000\n",
      "5/5 - 0s - loss: 380.9351 - val_loss: 361.0494\n",
      "Epoch 30/1000\n",
      "5/5 - 0s - loss: 382.7188 - val_loss: 359.8660\n",
      "Epoch 31/1000\n",
      "5/5 - 0s - loss: 380.4238 - val_loss: 358.8897\n",
      "Epoch 32/1000\n",
      "5/5 - 0s - loss: 383.2280 - val_loss: 357.9291\n",
      "Epoch 33/1000\n",
      "5/5 - 0s - loss: 386.5089 - val_loss: 356.9668\n",
      "Epoch 34/1000\n",
      "5/5 - 0s - loss: 380.9305 - val_loss: 356.3237\n",
      "Epoch 35/1000\n",
      "5/5 - 0s - loss: 377.5446 - val_loss: 356.6537\n",
      "Epoch 36/1000\n",
      "5/5 - 0s - loss: 375.8755 - val_loss: 358.1717\n",
      "Epoch 37/1000\n",
      "5/5 - 0s - loss: 378.9998 - val_loss: 356.2634\n",
      "Epoch 38/1000\n",
      "5/5 - 0s - loss: 377.3501 - val_loss: 357.9025\n",
      "Epoch 39/1000\n",
      "5/5 - 0s - loss: 384.2179 - val_loss: 357.6426\n",
      "Epoch 40/1000\n",
      "5/5 - 0s - loss: 380.2297 - val_loss: 358.1847\n",
      "Epoch 41/1000\n",
      "5/5 - 0s - loss: 382.7087 - val_loss: 358.1852\n",
      "Epoch 42/1000\n",
      "5/5 - 0s - loss: 382.0800 - val_loss: 359.0083\n",
      "Epoch 43/1000\n",
      "5/5 - 0s - loss: 377.1782 - val_loss: 357.6509\n",
      "Epoch 44/1000\n",
      "5/5 - 0s - loss: 382.7962 - val_loss: 357.8520\n",
      "Epoch 45/1000\n",
      "5/5 - 0s - loss: 380.1682 - val_loss: 356.9108\n",
      "Epoch 46/1000\n",
      "5/5 - 0s - loss: 379.6750 - val_loss: 357.1159\n",
      "Epoch 47/1000\n",
      "5/5 - 0s - loss: 372.7084 - val_loss: 357.0213\n",
      "Epoch 48/1000\n",
      "5/5 - 0s - loss: 378.2787 - val_loss: 356.9636\n",
      "Epoch 49/1000\n",
      "5/5 - 0s - loss: 377.1448 - val_loss: 356.3802\n",
      "Epoch 50/1000\n",
      "5/5 - 0s - loss: 378.2034 - val_loss: 356.3164\n",
      "Epoch 51/1000\n",
      "5/5 - 0s - loss: 380.5605 - val_loss: 356.0520\n",
      "Epoch 52/1000\n",
      "5/5 - 0s - loss: 380.7423 - val_loss: 356.0823\n",
      "Epoch 53/1000\n",
      "5/5 - 0s - loss: 380.5595 - val_loss: 355.9459\n",
      "Epoch 54/1000\n",
      "5/5 - 0s - loss: 377.2445 - val_loss: 356.5591\n",
      "Epoch 55/1000\n",
      "5/5 - 0s - loss: 383.8784 - val_loss: 355.6611\n",
      "Epoch 56/1000\n",
      "5/5 - 0s - loss: 373.3068 - val_loss: 355.4489\n",
      "Epoch 57/1000\n",
      "5/5 - 0s - loss: 373.3662 - val_loss: 355.6384\n",
      "Epoch 58/1000\n",
      "5/5 - 0s - loss: 376.1357 - val_loss: 355.7833\n",
      "Epoch 59/1000\n",
      "5/5 - 0s - loss: 381.2278 - val_loss: 356.2026\n",
      "Epoch 60/1000\n",
      "5/5 - 0s - loss: 380.8149 - val_loss: 356.2467\n",
      "Epoch 61/1000\n",
      "5/5 - 0s - loss: 373.4460 - val_loss: 356.4457\n",
      "Epoch 62/1000\n",
      "5/5 - 0s - loss: 377.6267 - val_loss: 356.2524\n",
      "Epoch 63/1000\n",
      "5/5 - 0s - loss: 368.0662 - val_loss: 349.7507\n",
      "Epoch 64/1000\n",
      "5/5 - 0s - loss: 373.7481 - val_loss: 356.3275\n",
      "Epoch 65/1000\n",
      "5/5 - 0s - loss: 373.8061 - val_loss: 356.3507\n",
      "Epoch 66/1000\n",
      "5/5 - 0s - loss: 371.0558 - val_loss: 356.4323\n",
      "Epoch 67/1000\n",
      "5/5 - 0s - loss: 369.8365 - val_loss: 356.0981\n",
      "Epoch 68/1000\n",
      "5/5 - 0s - loss: 364.4128 - val_loss: 355.8113\n",
      "Epoch 69/1000\n",
      "5/5 - 0s - loss: 371.0100 - val_loss: 355.0454\n",
      "Epoch 70/1000\n",
      "5/5 - 0s - loss: 368.4663 - val_loss: 355.8372\n",
      "Epoch 71/1000\n",
      "5/5 - 0s - loss: 372.7745 - val_loss: 356.8318\n",
      "Epoch 72/1000\n",
      "5/5 - 0s - loss: 369.4426 - val_loss: 356.8565\n",
      "Epoch 73/1000\n",
      "5/5 - 0s - loss: 369.1797 - val_loss: 355.8495\n",
      "Epoch 74/1000\n",
      "5/5 - 0s - loss: 366.3590 - val_loss: 354.8732\n",
      "Epoch 75/1000\n",
      "5/5 - 0s - loss: 372.6048 - val_loss: 354.8026\n",
      "Epoch 76/1000\n",
      "5/5 - 0s - loss: 364.4336 - val_loss: 354.7130\n",
      "Epoch 77/1000\n",
      "5/5 - 0s - loss: 369.6325 - val_loss: 355.5174\n",
      "Epoch 78/1000\n",
      "5/5 - 0s - loss: 372.2616 - val_loss: 355.2951\n",
      "Epoch 79/1000\n",
      "5/5 - 0s - loss: 367.2674 - val_loss: 354.6486\n",
      "Epoch 80/1000\n",
      "5/5 - 0s - loss: 362.2356 - val_loss: 354.2039\n",
      "Epoch 81/1000\n",
      "5/5 - 0s - loss: 375.9187 - val_loss: 354.3269\n",
      "Epoch 82/1000\n",
      "5/5 - 0s - loss: 359.7489 - val_loss: 354.2720\n",
      "Epoch 83/1000\n",
      "5/5 - 0s - loss: 368.5731 - val_loss: 354.4370\n",
      "Epoch 84/1000\n",
      "5/5 - 0s - loss: 367.2682 - val_loss: 355.1698\n",
      "Epoch 85/1000\n",
      "5/5 - 0s - loss: 364.7669 - val_loss: 355.6366\n",
      "Epoch 86/1000\n",
      "5/5 - 0s - loss: 363.4935 - val_loss: 355.2605\n",
      "Epoch 87/1000\n",
      "5/5 - 0s - loss: 370.3985 - val_loss: 354.7209\n",
      "Epoch 88/1000\n",
      "5/5 - 0s - loss: 366.3071 - val_loss: 354.8814\n",
      "Epoch 89/1000\n",
      "5/5 - 0s - loss: 365.2081 - val_loss: 354.9377\n",
      "Epoch 90/1000\n",
      "5/5 - 0s - loss: 366.7634 - val_loss: 350.4483\n",
      "Epoch 91/1000\n",
      "5/5 - 0s - loss: 365.5890 - val_loss: 355.7157\n",
      "Epoch 92/1000\n",
      "5/5 - 0s - loss: 364.3741 - val_loss: 355.1198\n",
      "Epoch 93/1000\n",
      "5/5 - 0s - loss: 361.4701 - val_loss: 354.7714\n",
      "Epoch 94/1000\n",
      "5/5 - 0s - loss: 362.7427 - val_loss: 355.1310\n",
      "Epoch 95/1000\n",
      "5/5 - 0s - loss: 364.2075 - val_loss: 355.6427\n",
      "Epoch 96/1000\n",
      "5/5 - 0s - loss: 353.6526 - val_loss: 356.9609\n",
      "Epoch 97/1000\n",
      "5/5 - 0s - loss: 355.3423 - val_loss: 356.6683\n",
      "Epoch 98/1000\n",
      "5/5 - 0s - loss: 360.5049 - val_loss: 357.5186\n",
      "Epoch 99/1000\n",
      "5/5 - 0s - loss: 362.2811 - val_loss: 355.5679\n",
      "Epoch 100/1000\n",
      "5/5 - 0s - loss: 358.3467 - val_loss: 353.3734\n",
      "Epoch 101/1000\n",
      "5/5 - 0s - loss: 359.7375 - val_loss: 353.7937\n",
      "Epoch 102/1000\n",
      "5/5 - 0s - loss: 358.1409 - val_loss: 354.6100\n",
      "Epoch 103/1000\n",
      "5/5 - 0s - loss: 353.5368 - val_loss: 353.9034\n",
      "Epoch 104/1000\n",
      "5/5 - 0s - loss: 356.9523 - val_loss: 353.6808\n",
      "Epoch 105/1000\n",
      "5/5 - 0s - loss: 354.6643 - val_loss: 354.9759\n",
      "Epoch 106/1000\n",
      "5/5 - 0s - loss: 351.2423 - val_loss: 357.4569\n",
      "Epoch 107/1000\n",
      "5/5 - 0s - loss: 354.1479 - val_loss: 361.5221\n",
      "Epoch 108/1000\n",
      "5/5 - 0s - loss: 359.3532 - val_loss: 362.3795\n",
      "Epoch 109/1000\n",
      "5/5 - 0s - loss: 356.4909 - val_loss: 366.5048\n",
      "Epoch 110/1000\n",
      "5/5 - 0s - loss: 355.1958 - val_loss: 370.9708\n",
      "Epoch 111/1000\n",
      "5/5 - 0s - loss: 349.1554 - val_loss: 378.3817\n",
      "Epoch 112/1000\n",
      "5/5 - 0s - loss: 354.5724 - val_loss: 370.9854\n",
      "Epoch 113/1000\n",
      "5/5 - 0s - loss: 353.4890 - val_loss: 363.0090\n",
      "Epoch 114/1000\n",
      "5/5 - 0s - loss: 355.3089 - val_loss: 361.1383\n",
      "Epoch 115/1000\n",
      "5/5 - 0s - loss: 358.3597 - val_loss: 361.7993\n",
      "Epoch 116/1000\n",
      "5/5 - 0s - loss: 354.7234 - val_loss: 362.0560\n",
      "Epoch 117/1000\n",
      "5/5 - 0s - loss: 350.8648 - val_loss: 366.3072\n",
      "Epoch 118/1000\n",
      "5/5 - 0s - loss: 358.0124 - val_loss: 374.9970\n",
      "Epoch 119/1000\n",
      "5/5 - 0s - loss: 351.0692 - val_loss: 380.1708\n",
      "Epoch 120/1000\n",
      "5/5 - 0s - loss: 349.6963 - val_loss: 372.4637\n",
      "Epoch 121/1000\n",
      "5/5 - 0s - loss: 341.3363 - val_loss: 362.9822\n",
      "Epoch 122/1000\n",
      "5/5 - 0s - loss: 340.1773 - val_loss: 360.9549\n",
      "Epoch 123/1000\n",
      "5/5 - 0s - loss: 344.8637 - val_loss: 358.7339\n",
      "Epoch 124/1000\n",
      "5/5 - 0s - loss: 345.3675 - val_loss: 356.4599\n",
      "Epoch 125/1000\n",
      "5/5 - 0s - loss: 344.6333 - val_loss: 356.0467\n",
      "Epoch 126/1000\n",
      "5/5 - 0s - loss: 342.7532 - val_loss: 358.2845\n",
      "Epoch 127/1000\n",
      "5/5 - 0s - loss: 351.4791 - val_loss: 354.7262\n",
      "Epoch 128/1000\n",
      "5/5 - 0s - loss: 342.8804 - val_loss: 351.5696\n",
      "Epoch 129/1000\n",
      "5/5 - 0s - loss: 349.7721 - val_loss: 356.2576\n",
      "Epoch 130/1000\n",
      "5/5 - 0s - loss: 341.7371 - val_loss: 355.4950\n",
      "Epoch 131/1000\n",
      "5/5 - 0s - loss: 341.9329 - val_loss: 356.2308\n",
      "Epoch 132/1000\n",
      "5/5 - 0s - loss: 344.7834 - val_loss: 356.9023\n",
      "Epoch 133/1000\n",
      "5/5 - 0s - loss: 339.9749 - val_loss: 356.9426\n",
      "Epoch 134/1000\n",
      "5/5 - 0s - loss: 338.2108 - val_loss: 357.1744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/1000\n",
      "5/5 - 0s - loss: 337.7613 - val_loss: 357.5776\n",
      "Epoch 136/1000\n",
      "5/5 - 0s - loss: 339.5834 - val_loss: 357.1800\n",
      "Epoch 137/1000\n",
      "5/5 - 0s - loss: 338.4344 - val_loss: 356.2032\n",
      "Epoch 138/1000\n",
      "5/5 - 0s - loss: 337.0596 - val_loss: 355.2157\n",
      "Epoch 139/1000\n",
      "5/5 - 0s - loss: 333.3559 - val_loss: 353.8389\n",
      "Epoch 140/1000\n",
      "5/5 - 0s - loss: 320.6289 - val_loss: 339.2695\n",
      "Epoch 141/1000\n",
      "5/5 - 0s - loss: 323.3517 - val_loss: 356.5707\n",
      "Epoch 142/1000\n",
      "5/5 - 0s - loss: 331.8399 - val_loss: 353.6920\n",
      "Epoch 143/1000\n",
      "5/5 - 0s - loss: 344.8238 - val_loss: 358.0179\n",
      "Epoch 144/1000\n",
      "5/5 - 0s - loss: 340.4207 - val_loss: 311.3771\n",
      "Epoch 145/1000\n",
      "5/5 - 0s - loss: 307.0847 - val_loss: 352.0023\n",
      "Epoch 146/1000\n",
      "5/5 - 0s - loss: 330.8617 - val_loss: 347.6089\n",
      "Epoch 147/1000\n",
      "5/5 - 0s - loss: 324.8808 - val_loss: 301.9772\n",
      "Epoch 148/1000\n",
      "5/5 - 0s - loss: 311.7111 - val_loss: 365.2801\n",
      "Epoch 149/1000\n",
      "5/5 - 0s - loss: 319.1666 - val_loss: 357.1793\n",
      "Epoch 150/1000\n",
      "5/5 - 0s - loss: 317.0511 - val_loss: 353.0449\n",
      "Epoch 151/1000\n",
      "5/5 - 0s - loss: 312.5266 - val_loss: 340.6104\n",
      "Epoch 152/1000\n",
      "5/5 - 0s - loss: 311.2628 - val_loss: 341.0620\n",
      "Epoch 153/1000\n",
      "5/5 - 0s - loss: 314.6499 - val_loss: 323.2713\n",
      "Epoch 154/1000\n",
      "5/5 - 0s - loss: 307.8695 - val_loss: 321.0158\n",
      "Epoch 155/1000\n",
      "5/5 - 0s - loss: 319.9529 - val_loss: 357.3298\n",
      "Epoch 156/1000\n",
      "5/5 - 0s - loss: 334.2472 - val_loss: 351.7823\n",
      "Epoch 157/1000\n",
      "5/5 - 0s - loss: 322.2429 - val_loss: 348.1542\n",
      "Epoch 158/1000\n",
      "5/5 - 0s - loss: 329.2620 - val_loss: 345.3444\n",
      "Epoch 159/1000\n",
      "5/5 - 0s - loss: 312.9212 - val_loss: 341.2993\n",
      "Epoch 160/1000\n",
      "5/5 - 0s - loss: 311.5602 - val_loss: 335.0084\n",
      "Epoch 161/1000\n",
      "5/5 - 0s - loss: 303.8445 - val_loss: 343.5956\n",
      "Epoch 162/1000\n",
      "5/5 - 0s - loss: 314.1004 - val_loss: 357.7990\n",
      "Epoch 163/1000\n",
      "5/5 - 0s - loss: 302.1686 - val_loss: 381.8027\n",
      "Epoch 164/1000\n",
      "5/5 - 0s - loss: 307.8626 - val_loss: 381.1715\n",
      "Epoch 165/1000\n",
      "5/5 - 0s - loss: 309.9464 - val_loss: 372.4555\n",
      "Epoch 166/1000\n",
      "5/5 - 0s - loss: 305.9673 - val_loss: 361.1156\n",
      "Epoch 167/1000\n",
      "5/5 - 0s - loss: 299.9387 - val_loss: 349.7101\n",
      "Epoch 168/1000\n",
      "5/5 - 0s - loss: 298.2009 - val_loss: 336.7291\n",
      "Epoch 169/1000\n",
      "5/5 - 0s - loss: 302.0043 - val_loss: 284.1987\n",
      "Epoch 170/1000\n",
      "5/5 - 0s - loss: 298.1799 - val_loss: 345.3829\n",
      "Epoch 171/1000\n",
      "5/5 - 0s - loss: 303.6198 - val_loss: 354.6991\n",
      "Epoch 172/1000\n",
      "5/5 - 0s - loss: 312.3622 - val_loss: 351.6407\n",
      "Epoch 173/1000\n",
      "5/5 - 0s - loss: 298.7502 - val_loss: 346.8471\n",
      "Epoch 174/1000\n",
      "5/5 - 0s - loss: 299.3200 - val_loss: 325.4111\n",
      "Epoch 175/1000\n",
      "5/5 - 0s - loss: 296.4814 - val_loss: 295.3336\n",
      "Epoch 176/1000\n",
      "5/5 - 0s - loss: 285.5395 - val_loss: 331.4906\n",
      "Epoch 177/1000\n",
      "5/5 - 0s - loss: 308.5003 - val_loss: 333.9266\n",
      "Epoch 178/1000\n",
      "5/5 - 0s - loss: 302.0717 - val_loss: 339.2284\n",
      "Epoch 179/1000\n",
      "5/5 - 0s - loss: 302.7586 - val_loss: 349.7194\n",
      "Epoch 180/1000\n",
      "5/5 - 0s - loss: 300.8546 - val_loss: 297.9493\n",
      "Epoch 181/1000\n",
      "5/5 - 0s - loss: 280.0402 - val_loss: 365.3692\n",
      "Epoch 182/1000\n",
      "5/5 - 0s - loss: 327.1084 - val_loss: 328.7319\n",
      "Epoch 183/1000\n",
      "5/5 - 0s - loss: 301.3949 - val_loss: 320.9528\n",
      "Epoch 184/1000\n",
      "5/5 - 0s - loss: 304.8506 - val_loss: 333.3613\n",
      "Epoch 185/1000\n",
      "5/5 - 0s - loss: 293.9796 - val_loss: 347.8536\n",
      "Epoch 186/1000\n",
      "5/5 - 0s - loss: 289.5695 - val_loss: 359.7500\n",
      "Epoch 187/1000\n",
      "5/5 - 0s - loss: 291.8692 - val_loss: 348.8521\n",
      "Epoch 188/1000\n",
      "5/5 - 0s - loss: 280.0023 - val_loss: 340.8805\n",
      "Epoch 189/1000\n",
      "5/5 - 0s - loss: 279.8836 - val_loss: 296.7747\n",
      "Epoch 190/1000\n",
      "5/5 - 0s - loss: 268.6878 - val_loss: 356.0850\n",
      "Epoch 191/1000\n",
      "5/5 - 0s - loss: 286.6501 - val_loss: 352.1510\n",
      "Epoch 192/1000\n",
      "5/5 - 0s - loss: 283.7506 - val_loss: 353.8541\n",
      "Epoch 193/1000\n",
      "5/5 - 0s - loss: 283.4637 - val_loss: 331.6314\n",
      "Epoch 194/1000\n",
      "5/5 - 0s - loss: 280.0047 - val_loss: 368.7592\n",
      "Epoch 195/1000\n",
      "5/5 - 0s - loss: 272.5747 - val_loss: 338.2760\n",
      "Epoch 196/1000\n",
      "5/5 - 0s - loss: 279.5411 - val_loss: 354.1793\n",
      "Epoch 197/1000\n",
      "5/5 - 0s - loss: 275.5564 - val_loss: 316.5549\n",
      "Epoch 198/1000\n",
      "5/5 - 0s - loss: 269.8939 - val_loss: 352.7252\n",
      "Epoch 199/1000\n",
      "5/5 - 0s - loss: 274.6205 - val_loss: 358.1388\n",
      "Epoch 200/1000\n",
      "5/5 - 0s - loss: 267.9207 - val_loss: 376.0367\n",
      "Epoch 201/1000\n",
      "5/5 - 0s - loss: 266.1063 - val_loss: 369.5497\n",
      "Epoch 202/1000\n",
      "5/5 - 0s - loss: 266.6833 - val_loss: 343.0724\n",
      "Epoch 203/1000\n",
      "5/5 - 0s - loss: 272.8596 - val_loss: 334.4189\n",
      "Epoch 204/1000\n",
      "5/5 - 0s - loss: 268.7038 - val_loss: 324.7523\n",
      "Epoch 205/1000\n",
      "5/5 - 0s - loss: 262.5051 - val_loss: 298.7449\n",
      "Epoch 206/1000\n",
      "5/5 - 0s - loss: 258.4435 - val_loss: 342.2512\n",
      "Epoch 207/1000\n",
      "5/5 - 0s - loss: 268.1120 - val_loss: 368.1132\n",
      "Epoch 208/1000\n",
      "5/5 - 0s - loss: 275.4349 - val_loss: 369.6681\n",
      "Epoch 209/1000\n",
      "5/5 - 0s - loss: 277.8193 - val_loss: 368.1037\n",
      "Epoch 210/1000\n",
      "5/5 - 0s - loss: 276.1831 - val_loss: 365.9091\n",
      "Epoch 211/1000\n",
      "5/5 - 0s - loss: 265.9980 - val_loss: 332.7620\n",
      "Epoch 212/1000\n",
      "5/5 - 0s - loss: 266.8547 - val_loss: 312.2902\n",
      "Epoch 213/1000\n",
      "5/5 - 0s - loss: 262.9500 - val_loss: 310.4549\n",
      "Epoch 214/1000\n",
      "5/5 - 0s - loss: 261.3383 - val_loss: 337.3366\n",
      "Epoch 215/1000\n",
      "5/5 - 0s - loss: 264.8924 - val_loss: 371.7126\n",
      "Epoch 216/1000\n",
      "5/5 - 0s - loss: 274.2734 - val_loss: 363.8980\n",
      "Epoch 217/1000\n",
      "5/5 - 0s - loss: 269.0763 - val_loss: 344.3968\n",
      "Epoch 218/1000\n",
      "5/5 - 0s - loss: 264.0197 - val_loss: 394.1001\n",
      "Epoch 219/1000\n",
      "5/5 - 0s - loss: 322.2240 - val_loss: 377.5494\n",
      "Epoch 220/1000\n",
      "5/5 - 0s - loss: 306.0880 - val_loss: 399.4802\n",
      "Epoch 221/1000\n",
      "5/5 - 0s - loss: 317.9253 - val_loss: 390.6517\n",
      "Epoch 222/1000\n",
      "5/5 - 0s - loss: 316.4139 - val_loss: 373.2388\n",
      "Epoch 223/1000\n",
      "5/5 - 0s - loss: 326.4617 - val_loss: 342.3081\n",
      "Epoch 224/1000\n",
      "5/5 - 0s - loss: 310.7889 - val_loss: 337.0108\n",
      "Epoch 225/1000\n",
      "5/5 - 0s - loss: 290.5627 - val_loss: 350.1627\n",
      "Epoch 226/1000\n",
      "5/5 - 0s - loss: 283.6140 - val_loss: 349.4511\n",
      "Epoch 227/1000\n",
      "5/5 - 0s - loss: 282.0363 - val_loss: 340.0294\n",
      "Epoch 228/1000\n",
      "5/5 - 0s - loss: 278.2360 - val_loss: 345.9279\n",
      "Epoch 229/1000\n",
      "5/5 - 0s - loss: 273.3898 - val_loss: 334.2509\n",
      "Epoch 230/1000\n",
      "5/5 - 0s - loss: 273.1549 - val_loss: 368.7753\n",
      "Epoch 231/1000\n",
      "5/5 - 0s - loss: 279.9739 - val_loss: 359.5231\n",
      "Epoch 232/1000\n",
      "5/5 - 0s - loss: 282.6157 - val_loss: 324.8460\n",
      "Epoch 233/1000\n",
      "5/5 - 0s - loss: 280.6184 - val_loss: 338.4669\n",
      "Epoch 234/1000\n",
      "5/5 - 0s - loss: 269.3269 - val_loss: 336.2111\n",
      "Epoch 235/1000\n",
      "5/5 - 0s - loss: 271.7612 - val_loss: 342.0788\n",
      "Epoch 236/1000\n",
      "5/5 - 0s - loss: 277.1139 - val_loss: 337.5821\n",
      "Epoch 237/1000\n",
      "5/5 - 0s - loss: 269.6454 - val_loss: 315.7530\n",
      "Epoch 238/1000\n",
      "5/5 - 0s - loss: 264.6693 - val_loss: 337.4056\n",
      "Epoch 239/1000\n",
      "5/5 - 0s - loss: 267.0381 - val_loss: 339.3564\n",
      "Epoch 240/1000\n",
      "5/5 - 0s - loss: 265.2965 - val_loss: 323.9894\n",
      "Epoch 241/1000\n",
      "5/5 - 0s - loss: 267.8400 - val_loss: 339.5135\n",
      "Epoch 242/1000\n",
      "5/5 - 0s - loss: 264.8453 - val_loss: 337.5312\n",
      "Epoch 243/1000\n",
      "5/5 - 0s - loss: 264.3759 - val_loss: 333.6671\n",
      "Epoch 244/1000\n",
      "5/5 - 0s - loss: 266.7820 - val_loss: 322.5668\n",
      "Epoch 245/1000\n",
      "5/5 - 0s - loss: 262.9042 - val_loss: 345.2799\n",
      "Epoch 246/1000\n",
      "5/5 - 0s - loss: 263.4400 - val_loss: 338.6882\n",
      "Epoch 247/1000\n",
      "5/5 - 0s - loss: 267.5258 - val_loss: 328.9421\n",
      "Epoch 248/1000\n",
      "5/5 - 0s - loss: 262.6118 - val_loss: 323.9451\n",
      "Epoch 249/1000\n",
      "5/5 - 0s - loss: 238.8099 - val_loss: 310.7389\n",
      "Epoch 250/1000\n",
      "5/5 - 0s - loss: 247.8522 - val_loss: 345.4081\n",
      "Epoch 251/1000\n",
      "5/5 - 0s - loss: 287.9136 - val_loss: 328.7245\n",
      "Epoch 252/1000\n",
      "5/5 - 0s - loss: 247.8958 - val_loss: 321.6385\n",
      "Epoch 253/1000\n",
      "5/5 - 0s - loss: 259.3449 - val_loss: 307.2920\n",
      "Epoch 254/1000\n",
      "5/5 - 0s - loss: 254.9353 - val_loss: 268.5518\n",
      "Epoch 255/1000\n",
      "5/5 - 0s - loss: 247.8734 - val_loss: 326.8969\n",
      "Epoch 256/1000\n",
      "5/5 - 0s - loss: 252.9093 - val_loss: 328.7693\n",
      "Epoch 257/1000\n",
      "5/5 - 0s - loss: 241.4520 - val_loss: 393.6582\n",
      "Epoch 258/1000\n",
      "5/5 - 0s - loss: 271.0147 - val_loss: 384.8215\n",
      "Epoch 259/1000\n",
      "5/5 - 0s - loss: 270.9953 - val_loss: 367.4812\n",
      "Epoch 260/1000\n",
      "5/5 - 0s - loss: 268.7695 - val_loss: 364.5581\n",
      "Epoch 261/1000\n",
      "5/5 - 0s - loss: 293.2821 - val_loss: 355.7380\n",
      "Epoch 262/1000\n",
      "5/5 - 0s - loss: 253.2994 - val_loss: 348.6388\n",
      "Epoch 263/1000\n",
      "5/5 - 0s - loss: 259.0975 - val_loss: 350.6695\n",
      "Epoch 264/1000\n",
      "5/5 - 0s - loss: 256.5750 - val_loss: 379.4050\n",
      "Epoch 265/1000\n",
      "5/5 - 0s - loss: 262.0794 - val_loss: 361.5454\n",
      "Epoch 266/1000\n",
      "5/5 - 0s - loss: 252.1078 - val_loss: 332.6410\n",
      "Epoch 267/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 - 0s - loss: 246.2022 - val_loss: 295.7081\n",
      "Epoch 268/1000\n",
      "5/5 - 0s - loss: 241.4649 - val_loss: 223.4706\n",
      "Epoch 269/1000\n",
      "5/5 - 0s - loss: 220.4735 - val_loss: 277.1010\n",
      "Epoch 270/1000\n",
      "5/5 - 0s - loss: 244.0447 - val_loss: 263.9562\n",
      "Epoch 271/1000\n",
      "5/5 - 0s - loss: 233.0784 - val_loss: 262.1953\n",
      "Epoch 272/1000\n",
      "5/5 - 0s - loss: 234.0263 - val_loss: 380.1194\n",
      "Epoch 273/1000\n",
      "5/5 - 0s - loss: 255.2796 - val_loss: 385.6829\n",
      "Epoch 274/1000\n",
      "5/5 - 0s - loss: 255.6257 - val_loss: 381.4283\n",
      "Epoch 275/1000\n",
      "5/5 - 0s - loss: 258.3795 - val_loss: 363.3306\n",
      "Epoch 276/1000\n",
      "5/5 - 0s - loss: 260.9924 - val_loss: 336.4650\n",
      "Epoch 277/1000\n",
      "5/5 - 0s - loss: 248.4417 - val_loss: 336.4759\n",
      "Epoch 278/1000\n",
      "5/5 - 0s - loss: 246.6142 - val_loss: 333.0085\n",
      "Epoch 279/1000\n",
      "5/5 - 0s - loss: 251.0774 - val_loss: 346.1597\n",
      "Epoch 280/1000\n",
      "5/5 - 0s - loss: 252.9276 - val_loss: 346.7333\n",
      "Epoch 281/1000\n",
      "5/5 - 0s - loss: 242.6037 - val_loss: 332.3050\n",
      "Epoch 282/1000\n",
      "5/5 - 0s - loss: 243.1306 - val_loss: 318.9273\n",
      "Epoch 283/1000\n",
      "5/5 - 0s - loss: 246.0486 - val_loss: 284.7345\n",
      "Epoch 284/1000\n",
      "5/5 - 0s - loss: 226.3032 - val_loss: 268.1982\n",
      "Epoch 285/1000\n",
      "5/5 - 0s - loss: 224.8029 - val_loss: 373.2426\n",
      "Epoch 286/1000\n",
      "5/5 - 0s - loss: 241.7589 - val_loss: 365.4444\n",
      "Epoch 287/1000\n",
      "5/5 - 0s - loss: 249.1007 - val_loss: 354.1699\n",
      "Epoch 288/1000\n",
      "5/5 - 0s - loss: 255.1089 - val_loss: 340.4671\n",
      "Epoch 289/1000\n",
      "5/5 - 0s - loss: 243.9306 - val_loss: 269.4102\n",
      "Epoch 290/1000\n",
      "5/5 - 0s - loss: 236.0440 - val_loss: 317.2336\n",
      "Epoch 291/1000\n",
      "5/5 - 0s - loss: 228.0413 - val_loss: 265.1606\n",
      "Epoch 292/1000\n",
      "5/5 - 0s - loss: 221.7044 - val_loss: 283.1815\n",
      "Epoch 293/1000\n",
      "5/5 - 0s - loss: 216.0652 - val_loss: 345.9345\n",
      "Epoch 294/1000\n",
      "5/5 - 0s - loss: 246.0420 - val_loss: 352.8543\n",
      "Epoch 295/1000\n",
      "5/5 - 0s - loss: 238.9273 - val_loss: 351.5224\n",
      "Epoch 296/1000\n",
      "5/5 - 0s - loss: 284.5640 - val_loss: 347.8453\n",
      "Epoch 297/1000\n",
      "5/5 - 0s - loss: 253.4632 - val_loss: 348.0656\n",
      "Epoch 298/1000\n",
      "5/5 - 0s - loss: 266.6837 - val_loss: 351.8288\n",
      "Epoch 299/1000\n",
      "5/5 - 0s - loss: 268.5203 - val_loss: 355.5403\n",
      "Epoch 300/1000\n",
      "5/5 - 0s - loss: 260.0507 - val_loss: 351.5578\n",
      "Epoch 301/1000\n",
      "5/5 - 0s - loss: 248.8217 - val_loss: 347.9954\n",
      "Epoch 302/1000\n",
      "5/5 - 0s - loss: 242.7408 - val_loss: 345.5955\n",
      "Epoch 303/1000\n",
      "5/5 - 0s - loss: 258.3920 - val_loss: 344.0093\n",
      "Epoch 304/1000\n",
      "5/5 - 0s - loss: 238.4926 - val_loss: 342.0240\n",
      "Epoch 305/1000\n",
      "5/5 - 0s - loss: 245.9977 - val_loss: 343.3730\n",
      "Epoch 306/1000\n",
      "5/5 - 0s - loss: 236.6021 - val_loss: 327.2340\n",
      "Epoch 307/1000\n",
      "5/5 - 0s - loss: 233.7332 - val_loss: 306.8212\n",
      "Epoch 308/1000\n",
      "5/5 - 0s - loss: 227.0945 - val_loss: 241.6265\n",
      "Epoch 309/1000\n",
      "5/5 - 0s - loss: 221.8238 - val_loss: 392.8850\n",
      "Epoch 310/1000\n",
      "5/5 - 0s - loss: 225.7221 - val_loss: 337.2029\n",
      "Epoch 311/1000\n",
      "5/5 - 0s - loss: 239.7690 - val_loss: 350.5613\n",
      "Epoch 312/1000\n",
      "5/5 - 0s - loss: 234.6179 - val_loss: 341.8579\n",
      "Epoch 313/1000\n",
      "5/5 - 0s - loss: 229.6921 - val_loss: 330.8794\n",
      "Epoch 314/1000\n",
      "5/5 - 0s - loss: 222.2017 - val_loss: 320.5238\n",
      "Epoch 315/1000\n",
      "5/5 - 0s - loss: 227.1421 - val_loss: 311.0724\n",
      "Epoch 316/1000\n",
      "5/5 - 0s - loss: 224.8789 - val_loss: 300.5447\n",
      "Epoch 317/1000\n",
      "5/5 - 0s - loss: 223.4402 - val_loss: 287.8067\n",
      "Epoch 318/1000\n",
      "5/5 - 0s - loss: 220.6784 - val_loss: 253.6416\n",
      "Epoch 319/1000\n",
      "5/5 - 0s - loss: 224.4954 - val_loss: 430.9343\n",
      "Epoch 320/1000\n",
      "5/5 - 0s - loss: 270.6234 - val_loss: 316.4333\n",
      "Epoch 321/1000\n",
      "5/5 - 0s - loss: 245.8867 - val_loss: 336.0165\n",
      "Epoch 322/1000\n",
      "5/5 - 0s - loss: 247.9930 - val_loss: 348.9523\n",
      "Epoch 323/1000\n",
      "5/5 - 0s - loss: 244.8758 - val_loss: 345.3785\n",
      "Epoch 324/1000\n",
      "5/5 - 0s - loss: 245.2190 - val_loss: 350.5694\n",
      "Epoch 325/1000\n",
      "5/5 - 0s - loss: 241.3152 - val_loss: 355.3239\n",
      "Epoch 326/1000\n",
      "5/5 - 0s - loss: 235.4061 - val_loss: 345.6597\n",
      "Epoch 327/1000\n",
      "5/5 - 0s - loss: 225.0940 - val_loss: 348.0511\n",
      "Epoch 328/1000\n",
      "5/5 - 0s - loss: 224.5234 - val_loss: 329.1328\n",
      "Epoch 329/1000\n",
      "5/5 - 0s - loss: 220.6432 - val_loss: 366.6221\n",
      "Epoch 330/1000\n",
      "5/5 - 0s - loss: 235.7025 - val_loss: 385.7677\n",
      "Epoch 331/1000\n",
      "5/5 - 0s - loss: 247.1773 - val_loss: 372.7304\n",
      "Epoch 332/1000\n",
      "5/5 - 0s - loss: 252.1651 - val_loss: 353.7958\n",
      "Epoch 333/1000\n",
      "5/5 - 0s - loss: 246.7933 - val_loss: 345.9789\n",
      "Epoch 334/1000\n",
      "5/5 - 0s - loss: 237.4045 - val_loss: 330.7144\n",
      "Epoch 335/1000\n",
      "5/5 - 0s - loss: 236.3722 - val_loss: 325.6756\n",
      "Epoch 336/1000\n",
      "5/5 - 0s - loss: 230.2916 - val_loss: 308.4289\n",
      "Epoch 337/1000\n",
      "5/5 - 0s - loss: 226.9493 - val_loss: 382.0945\n",
      "Epoch 338/1000\n",
      "5/5 - 0s - loss: 224.2443 - val_loss: 359.0069\n",
      "Epoch 339/1000\n",
      "5/5 - 0s - loss: 227.4911 - val_loss: 349.7732\n",
      "Epoch 340/1000\n",
      "5/5 - 0s - loss: 223.7898 - val_loss: 339.4276\n",
      "Epoch 341/1000\n",
      "5/5 - 0s - loss: 234.1326 - val_loss: 321.3186\n",
      "Epoch 342/1000\n",
      "5/5 - 0s - loss: 213.5023 - val_loss: 256.7085\n",
      "Epoch 343/1000\n",
      "5/5 - 0s - loss: 204.3369 - val_loss: 282.9348\n",
      "Epoch 344/1000\n",
      "5/5 - 0s - loss: 208.4009 - val_loss: 298.0107\n",
      "Epoch 345/1000\n",
      "5/5 - 0s - loss: 216.0324 - val_loss: 270.8069\n",
      "Epoch 346/1000\n",
      "5/5 - 0s - loss: 204.5268 - val_loss: 421.4626\n",
      "Epoch 347/1000\n",
      "5/5 - 0s - loss: 236.6186 - val_loss: 394.7821\n",
      "Epoch 348/1000\n",
      "5/5 - 0s - loss: 223.5558 - val_loss: 324.6524\n",
      "Epoch 349/1000\n",
      "5/5 - 0s - loss: 231.5391 - val_loss: 313.3226\n",
      "Epoch 350/1000\n",
      "5/5 - 0s - loss: 237.8958 - val_loss: 332.8264\n",
      "Epoch 351/1000\n",
      "5/5 - 0s - loss: 231.9295 - val_loss: 289.6664\n",
      "Epoch 352/1000\n",
      "5/5 - 0s - loss: 213.1477 - val_loss: 264.8231\n",
      "Epoch 353/1000\n",
      "5/5 - 0s - loss: 216.3406 - val_loss: 329.9640\n",
      "Epoch 354/1000\n",
      "5/5 - 0s - loss: 197.2682 - val_loss: 303.2240\n",
      "Epoch 355/1000\n",
      "5/5 - 0s - loss: 225.2651 - val_loss: 324.7775\n",
      "Epoch 356/1000\n",
      "5/5 - 0s - loss: 226.9317 - val_loss: 327.5836\n",
      "Epoch 357/1000\n",
      "5/5 - 0s - loss: 220.5798 - val_loss: 326.0505\n",
      "Epoch 358/1000\n",
      "5/5 - 0s - loss: 220.5405 - val_loss: 293.8905\n",
      "Epoch 359/1000\n",
      "5/5 - 0s - loss: 217.8982 - val_loss: 316.2321\n",
      "Epoch 360/1000\n",
      "5/5 - 0s - loss: 216.8103 - val_loss: 308.1457\n",
      "Epoch 361/1000\n",
      "5/5 - 0s - loss: 217.7296 - val_loss: 301.0788\n",
      "Epoch 362/1000\n",
      "5/5 - 0s - loss: 216.3011 - val_loss: 248.9074\n",
      "Epoch 363/1000\n",
      "5/5 - 0s - loss: 204.4125 - val_loss: 252.0656\n",
      "Epoch 364/1000\n",
      "5/5 - 0s - loss: 205.4444 - val_loss: 278.4677\n",
      "Epoch 365/1000\n",
      "5/5 - 0s - loss: 213.7525 - val_loss: 284.5954\n",
      "Epoch 366/1000\n",
      "5/5 - 0s - loss: 217.4792 - val_loss: 243.8148\n",
      "Epoch 367/1000\n",
      "5/5 - 0s - loss: 210.7450 - val_loss: 435.2615\n",
      "Epoch 368/1000\n",
      "5/5 - 0s - loss: 235.1561 - val_loss: 323.8000\n",
      "Epoch 369/1000\n",
      "5/5 - 0s - loss: 207.0972 - val_loss: 304.7205\n",
      "Epoch 370/1000\n",
      "5/5 - 0s - loss: 224.8791 - val_loss: 268.0643\n",
      "Epoch 371/1000\n",
      "5/5 - 0s - loss: 211.1616 - val_loss: 411.9908\n",
      "Epoch 372/1000\n",
      "5/5 - 0s - loss: 240.9536 - val_loss: 254.1410\n",
      "Epoch 373/1000\n",
      "5/5 - 0s - loss: 202.7243 - val_loss: 309.4791\n",
      "Epoch 374/1000\n",
      "5/5 - 0s - loss: 222.2320 - val_loss: 278.7635\n",
      "Epoch 375/1000\n",
      "5/5 - 0s - loss: 208.6719 - val_loss: 342.0151\n",
      "Epoch 376/1000\n",
      "5/5 - 0s - loss: 225.4776 - val_loss: 369.4652\n",
      "Epoch 377/1000\n",
      "5/5 - 0s - loss: 245.3849 - val_loss: 360.8260\n",
      "Epoch 378/1000\n",
      "5/5 - 0s - loss: 247.4310 - val_loss: 355.7372\n",
      "Epoch 379/1000\n",
      "5/5 - 0s - loss: 250.3628 - val_loss: 351.9896\n",
      "Epoch 380/1000\n",
      "5/5 - 0s - loss: 252.6602 - val_loss: 349.1512\n",
      "Epoch 381/1000\n",
      "5/5 - 0s - loss: 237.9565 - val_loss: 348.7877\n",
      "Epoch 382/1000\n",
      "5/5 - 0s - loss: 241.5784 - val_loss: 349.1041\n",
      "Epoch 383/1000\n",
      "5/5 - 0s - loss: 242.5572 - val_loss: 349.2973\n",
      "Epoch 384/1000\n",
      "5/5 - 0s - loss: 239.2065 - val_loss: 350.8840\n",
      "Epoch 385/1000\n",
      "5/5 - 0s - loss: 251.4414 - val_loss: 351.4812\n",
      "Epoch 386/1000\n",
      "5/5 - 0s - loss: 242.2912 - val_loss: 351.9347\n",
      "Epoch 387/1000\n",
      "5/5 - 0s - loss: 241.7691 - val_loss: 349.7539\n",
      "Epoch 388/1000\n",
      "5/5 - 0s - loss: 237.2284 - val_loss: 350.5774\n",
      "Epoch 389/1000\n",
      "5/5 - 0s - loss: 248.8180 - val_loss: 350.1562\n",
      "Epoch 390/1000\n",
      "5/5 - 0s - loss: 248.6431 - val_loss: 364.8980\n",
      "Epoch 391/1000\n",
      "5/5 - 0s - loss: 250.5921 - val_loss: 351.3428\n",
      "Epoch 392/1000\n",
      "5/5 - 0s - loss: 239.8079 - val_loss: 347.9347\n",
      "Epoch 393/1000\n",
      "5/5 - 0s - loss: 243.9041 - val_loss: 358.7903\n",
      "Epoch 394/1000\n",
      "5/5 - 0s - loss: 232.2511 - val_loss: 359.2098\n",
      "Epoch 395/1000\n",
      "5/5 - 0s - loss: 246.2068 - val_loss: 355.9801\n",
      "Epoch 396/1000\n",
      "5/5 - 0s - loss: 247.9725 - val_loss: 354.9144\n",
      "Epoch 397/1000\n",
      "5/5 - 0s - loss: 236.7310 - val_loss: 353.3628\n",
      "Epoch 398/1000\n",
      "5/5 - 0s - loss: 248.1887 - val_loss: 353.3647\n",
      "Epoch 399/1000\n",
      "5/5 - 0s - loss: 246.0574 - val_loss: 353.9490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1000\n",
      "5/5 - 0s - loss: 244.5842 - val_loss: 352.5726\n",
      "Epoch 401/1000\n",
      "5/5 - 0s - loss: 241.4844 - val_loss: 350.2851\n",
      "Epoch 402/1000\n",
      "5/5 - 0s - loss: 237.1295 - val_loss: 346.9987\n",
      "Epoch 403/1000\n",
      "5/5 - 0s - loss: 236.6300 - val_loss: 341.6294\n",
      "Epoch 404/1000\n",
      "5/5 - 0s - loss: 243.4535 - val_loss: 349.2514\n",
      "Epoch 405/1000\n",
      "5/5 - 0s - loss: 235.8768 - val_loss: 346.2806\n",
      "Epoch 406/1000\n",
      "5/5 - 0s - loss: 239.2074 - val_loss: 348.9733\n",
      "Epoch 407/1000\n",
      "5/5 - 0s - loss: 222.2729 - val_loss: 348.1174\n",
      "Epoch 408/1000\n",
      "5/5 - 0s - loss: 235.8785 - val_loss: 348.5461\n",
      "Epoch 409/1000\n",
      "5/5 - 0s - loss: 236.3966 - val_loss: 354.1634\n",
      "Epoch 410/1000\n",
      "5/5 - 0s - loss: 229.1569 - val_loss: 347.0077\n",
      "Epoch 411/1000\n",
      "5/5 - 0s - loss: 231.6001 - val_loss: 351.1565\n",
      "Epoch 412/1000\n",
      "5/5 - 0s - loss: 227.6830 - val_loss: 355.4644\n",
      "Epoch 413/1000\n",
      "5/5 - 0s - loss: 228.9398 - val_loss: 354.4055\n",
      "Epoch 414/1000\n",
      "5/5 - 0s - loss: 231.5406 - val_loss: 351.8067\n",
      "Epoch 415/1000\n",
      "5/5 - 0s - loss: 240.9812 - val_loss: 337.0905\n",
      "Epoch 416/1000\n",
      "5/5 - 0s - loss: 229.7713 - val_loss: 346.9984\n",
      "Epoch 417/1000\n",
      "5/5 - 0s - loss: 225.3153 - val_loss: 339.5358\n",
      "Epoch 418/1000\n",
      "5/5 - 0s - loss: 223.1376 - val_loss: 343.8569\n",
      "Epoch 419/1000\n",
      "5/5 - 0s - loss: 231.8591 - val_loss: 343.4605\n",
      "Epoch 420/1000\n",
      "5/5 - 0s - loss: 229.9268 - val_loss: 339.0528\n",
      "Epoch 421/1000\n",
      "5/5 - 0s - loss: 229.1747 - val_loss: 336.0700\n",
      "Epoch 422/1000\n",
      "5/5 - 0s - loss: 222.5997 - val_loss: 334.0482\n",
      "Epoch 423/1000\n",
      "5/5 - 0s - loss: 228.8354 - val_loss: 339.5822\n",
      "Epoch 424/1000\n",
      "5/5 - 0s - loss: 231.8944 - val_loss: 337.7254\n",
      "Epoch 425/1000\n",
      "5/5 - 0s - loss: 226.2197 - val_loss: 338.7744\n",
      "Epoch 426/1000\n",
      "5/5 - 0s - loss: 226.3858 - val_loss: 335.1744\n",
      "Epoch 427/1000\n",
      "5/5 - 0s - loss: 227.8186 - val_loss: 336.7259\n",
      "Epoch 428/1000\n",
      "5/5 - 0s - loss: 224.8877 - val_loss: 323.8448\n",
      "Epoch 429/1000\n",
      "5/5 - 0s - loss: 227.9805 - val_loss: 340.4762\n",
      "Epoch 430/1000\n",
      "5/5 - 0s - loss: 230.8083 - val_loss: 337.5674\n",
      "Epoch 431/1000\n",
      "5/5 - 0s - loss: 227.2112 - val_loss: 322.0032\n",
      "Epoch 432/1000\n",
      "5/5 - 0s - loss: 220.4382 - val_loss: 310.5174\n",
      "Epoch 433/1000\n",
      "5/5 - 0s - loss: 222.0769 - val_loss: 341.0511\n",
      "Epoch 434/1000\n",
      "5/5 - 0s - loss: 230.9900 - val_loss: 343.0775\n",
      "Epoch 435/1000\n",
      "5/5 - 0s - loss: 227.0572 - val_loss: 344.0559\n",
      "Epoch 436/1000\n",
      "5/5 - 0s - loss: 237.2501 - val_loss: 341.8466\n",
      "Epoch 437/1000\n",
      "5/5 - 0s - loss: 233.8186 - val_loss: 338.9419\n",
      "Epoch 438/1000\n",
      "5/5 - 0s - loss: 233.4893 - val_loss: 336.3854\n",
      "Epoch 439/1000\n",
      "5/5 - 0s - loss: 230.3295 - val_loss: 334.6356\n",
      "Epoch 440/1000\n",
      "5/5 - 0s - loss: 235.7241 - val_loss: 311.3003\n",
      "Epoch 441/1000\n",
      "5/5 - 0s - loss: 223.2843 - val_loss: 311.9641\n",
      "Epoch 442/1000\n",
      "5/5 - 0s - loss: 223.1545 - val_loss: 319.4523\n",
      "Epoch 443/1000\n",
      "5/5 - 0s - loss: 229.6756 - val_loss: 326.3245\n",
      "Epoch 444/1000\n",
      "5/5 - 0s - loss: 219.5390 - val_loss: 339.3931\n",
      "Epoch 445/1000\n",
      "5/5 - 0s - loss: 231.1028 - val_loss: 348.1834\n",
      "Epoch 446/1000\n",
      "5/5 - 0s - loss: 224.7697 - val_loss: 352.5253\n",
      "Epoch 447/1000\n",
      "5/5 - 0s - loss: 236.9304 - val_loss: 348.6597\n",
      "Epoch 448/1000\n",
      "5/5 - 0s - loss: 227.8492 - val_loss: 349.8889\n",
      "Epoch 449/1000\n",
      "5/5 - 0s - loss: 223.9841 - val_loss: 368.7433\n",
      "Epoch 450/1000\n",
      "5/5 - 0s - loss: 226.6114 - val_loss: 337.5170\n",
      "Epoch 451/1000\n",
      "5/5 - 0s - loss: 225.4511 - val_loss: 337.8091\n",
      "Epoch 452/1000\n",
      "5/5 - 0s - loss: 220.1970 - val_loss: 323.9396\n",
      "Epoch 453/1000\n",
      "5/5 - 0s - loss: 225.2066 - val_loss: 359.9554\n",
      "Epoch 454/1000\n",
      "5/5 - 0s - loss: 225.8101 - val_loss: 345.3119\n",
      "Epoch 455/1000\n",
      "5/5 - 0s - loss: 222.1777 - val_loss: 342.9143\n",
      "Epoch 456/1000\n",
      "5/5 - 0s - loss: 225.9779 - val_loss: 338.8530\n",
      "Epoch 457/1000\n",
      "5/5 - 0s - loss: 225.2228 - val_loss: 321.7039\n",
      "Epoch 458/1000\n",
      "5/5 - 0s - loss: 221.3900 - val_loss: 325.2911\n",
      "Epoch 459/1000\n",
      "5/5 - 0s - loss: 222.3800 - val_loss: 330.4155\n",
      "Epoch 460/1000\n",
      "5/5 - 0s - loss: 220.1437 - val_loss: 362.8877\n",
      "Epoch 461/1000\n",
      "5/5 - 0s - loss: 228.3517 - val_loss: 363.9235\n",
      "Epoch 462/1000\n",
      "5/5 - 0s - loss: 222.4328 - val_loss: 359.5512\n",
      "Epoch 463/1000\n",
      "5/5 - 0s - loss: 227.3214 - val_loss: 359.5450\n",
      "Epoch 464/1000\n",
      "5/5 - 0s - loss: 223.7123 - val_loss: 330.0424\n",
      "Epoch 465/1000\n",
      "5/5 - 0s - loss: 226.9176 - val_loss: 355.6214\n",
      "Epoch 466/1000\n",
      "5/5 - 0s - loss: 220.1958 - val_loss: 338.5908\n",
      "Epoch 467/1000\n",
      "5/5 - 0s - loss: 214.0506 - val_loss: 333.8906\n",
      "Epoch 468/1000\n",
      "5/5 - 0s - loss: 223.5377 - val_loss: 317.4065\n",
      "Epoch 469/1000\n",
      "5/5 - 0s - loss: 226.1479 - val_loss: 349.7173\n",
      "Epoch 470/1000\n",
      "5/5 - 0s - loss: 225.6400 - val_loss: 338.9697\n",
      "Epoch 471/1000\n",
      "5/5 - 0s - loss: 225.8374 - val_loss: 347.9511\n",
      "Epoch 472/1000\n",
      "5/5 - 0s - loss: 226.6354 - val_loss: 346.9675\n",
      "Epoch 473/1000\n",
      "5/5 - 0s - loss: 225.4966 - val_loss: 335.7622\n",
      "Epoch 474/1000\n",
      "5/5 - 0s - loss: 224.6095 - val_loss: 321.5113\n",
      "Epoch 475/1000\n",
      "5/5 - 0s - loss: 224.1002 - val_loss: 349.0083\n",
      "Epoch 476/1000\n",
      "5/5 - 0s - loss: 221.3328 - val_loss: 344.7675\n",
      "Epoch 477/1000\n",
      "5/5 - 0s - loss: 225.1045 - val_loss: 346.5925\n",
      "Epoch 478/1000\n",
      "5/5 - 0s - loss: 227.1339 - val_loss: 347.5765\n",
      "Epoch 479/1000\n",
      "5/5 - 0s - loss: 221.1844 - val_loss: 348.7095\n",
      "Epoch 480/1000\n",
      "5/5 - 0s - loss: 219.6535 - val_loss: 346.6820\n",
      "Epoch 481/1000\n",
      "5/5 - 0s - loss: 212.8474 - val_loss: 344.2022\n",
      "Epoch 482/1000\n",
      "5/5 - 0s - loss: 222.3235 - val_loss: 336.5434\n",
      "Epoch 483/1000\n",
      "5/5 - 0s - loss: 220.5090 - val_loss: 345.7026\n",
      "Epoch 484/1000\n",
      "5/5 - 0s - loss: 219.1560 - val_loss: 332.6087\n",
      "Epoch 485/1000\n",
      "5/5 - 0s - loss: 215.5118 - val_loss: 350.5224\n",
      "Epoch 486/1000\n",
      "5/5 - 0s - loss: 219.5308 - val_loss: 351.9062\n",
      "Epoch 487/1000\n",
      "5/5 - 0s - loss: 208.0449 - val_loss: 347.8329\n",
      "Epoch 488/1000\n",
      "5/5 - 0s - loss: 218.4104 - val_loss: 346.3847\n",
      "Epoch 489/1000\n",
      "5/5 - 0s - loss: 216.6349 - val_loss: 344.3736\n",
      "Epoch 490/1000\n",
      "5/5 - 0s - loss: 214.9328 - val_loss: 340.8088\n",
      "Epoch 491/1000\n",
      "5/5 - 0s - loss: 220.4824 - val_loss: 336.6324\n",
      "Epoch 492/1000\n",
      "5/5 - 0s - loss: 213.4163 - val_loss: 326.9193\n",
      "Epoch 493/1000\n",
      "5/5 - 0s - loss: 209.7203 - val_loss: 311.1129\n",
      "Epoch 494/1000\n",
      "5/5 - 0s - loss: 209.8572 - val_loss: 319.0691\n",
      "Epoch 495/1000\n",
      "5/5 - 0s - loss: 210.4841 - val_loss: 339.1599\n",
      "Epoch 496/1000\n",
      "5/5 - 0s - loss: 215.4866 - val_loss: 344.6556\n",
      "Epoch 497/1000\n",
      "5/5 - 0s - loss: 216.6777 - val_loss: 340.9534\n",
      "Epoch 498/1000\n",
      "5/5 - 0s - loss: 215.1223 - val_loss: 339.9086\n",
      "Epoch 499/1000\n",
      "5/5 - 0s - loss: 215.5464 - val_loss: 338.4133\n",
      "Epoch 500/1000\n",
      "5/5 - 0s - loss: 216.1250 - val_loss: 332.2562\n",
      "Epoch 501/1000\n",
      "5/5 - 0s - loss: 221.9550 - val_loss: 323.5395\n",
      "Epoch 502/1000\n",
      "5/5 - 0s - loss: 211.4788 - val_loss: 319.4033\n",
      "Epoch 503/1000\n",
      "5/5 - 0s - loss: 209.2908 - val_loss: 348.3187\n",
      "Epoch 504/1000\n",
      "5/5 - 0s - loss: 213.6976 - val_loss: 332.5114\n",
      "Epoch 505/1000\n",
      "5/5 - 0s - loss: 215.7332 - val_loss: 353.0172\n",
      "Epoch 506/1000\n",
      "5/5 - 0s - loss: 212.0850 - val_loss: 352.8819\n",
      "Epoch 507/1000\n",
      "5/5 - 0s - loss: 216.4141 - val_loss: 344.8056\n",
      "Epoch 508/1000\n",
      "5/5 - 0s - loss: 212.6218 - val_loss: 343.0855\n",
      "Epoch 509/1000\n",
      "5/5 - 0s - loss: 216.2327 - val_loss: 337.8427\n",
      "Epoch 510/1000\n",
      "5/5 - 0s - loss: 210.9982 - val_loss: 331.3453\n",
      "Epoch 511/1000\n",
      "5/5 - 0s - loss: 211.6829 - val_loss: 311.7632\n",
      "Epoch 512/1000\n",
      "5/5 - 0s - loss: 227.4193 - val_loss: 348.1077\n",
      "Epoch 513/1000\n",
      "5/5 - 0s - loss: 213.0670 - val_loss: 328.1186\n",
      "Epoch 514/1000\n",
      "5/5 - 0s - loss: 212.5203 - val_loss: 320.7307\n",
      "Epoch 515/1000\n",
      "5/5 - 0s - loss: 217.7352 - val_loss: 330.4694\n",
      "Epoch 516/1000\n",
      "5/5 - 0s - loss: 216.1892 - val_loss: 336.7943\n",
      "Epoch 517/1000\n",
      "5/5 - 0s - loss: 208.1281 - val_loss: 318.0291\n",
      "Epoch 518/1000\n",
      "5/5 - 0s - loss: 205.6145 - val_loss: 363.9789\n",
      "Epoch 519/1000\n",
      "5/5 - 0s - loss: 206.6941 - val_loss: 357.9052\n",
      "Epoch 520/1000\n",
      "5/5 - 0s - loss: 210.7108 - val_loss: 360.5631\n",
      "Epoch 521/1000\n",
      "5/5 - 0s - loss: 202.1943 - val_loss: 354.0184\n",
      "Epoch 522/1000\n",
      "5/5 - 0s - loss: 209.9189 - val_loss: 341.6096\n",
      "Epoch 523/1000\n",
      "5/5 - 0s - loss: 204.6859 - val_loss: 361.3484\n",
      "Epoch 524/1000\n",
      "5/5 - 0s - loss: 199.1851 - val_loss: 348.6725\n",
      "Epoch 525/1000\n",
      "5/5 - 0s - loss: 192.5159 - val_loss: 340.6207\n",
      "Epoch 526/1000\n",
      "5/5 - 0s - loss: 204.5598 - val_loss: 357.5729\n",
      "Epoch 527/1000\n",
      "5/5 - 0s - loss: 206.3470 - val_loss: 351.0067\n",
      "Epoch 528/1000\n",
      "5/5 - 0s - loss: 200.6102 - val_loss: 340.8329\n",
      "Epoch 529/1000\n",
      "5/5 - 0s - loss: 184.9829 - val_loss: 334.1104\n",
      "Epoch 530/1000\n",
      "5/5 - 0s - loss: 191.6035 - val_loss: 331.5121\n",
      "Epoch 531/1000\n",
      "5/5 - 0s - loss: 186.5700 - val_loss: 312.2180\n",
      "Epoch 532/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 - 0s - loss: 189.7436 - val_loss: 295.4947\n",
      "Epoch 533/1000\n",
      "5/5 - 0s - loss: 189.8540 - val_loss: 332.9811\n",
      "Epoch 534/1000\n",
      "5/5 - 0s - loss: 197.0186 - val_loss: 352.8944\n",
      "Epoch 535/1000\n",
      "5/5 - 0s - loss: 202.0098 - val_loss: 349.7079\n",
      "Epoch 536/1000\n",
      "5/5 - 0s - loss: 196.4103 - val_loss: 343.4403\n",
      "Epoch 537/1000\n",
      "5/5 - 0s - loss: 197.7135 - val_loss: 341.9809\n",
      "Epoch 538/1000\n",
      "5/5 - 0s - loss: 193.3255 - val_loss: 343.4661\n",
      "Epoch 539/1000\n",
      "5/5 - 0s - loss: 195.6401 - val_loss: 340.4627\n",
      "Epoch 540/1000\n",
      "5/5 - 0s - loss: 198.1973 - val_loss: 325.4696\n",
      "Epoch 541/1000\n",
      "5/5 - 0s - loss: 194.9546 - val_loss: 325.5616\n",
      "Epoch 542/1000\n",
      "5/5 - 0s - loss: 196.3789 - val_loss: 316.7280\n",
      "Epoch 543/1000\n",
      "5/5 - 0s - loss: 203.5005 - val_loss: 305.7335\n",
      "Epoch 544/1000\n",
      "5/5 - 0s - loss: 187.4406 - val_loss: 286.6931\n",
      "Epoch 545/1000\n",
      "5/5 - 0s - loss: 190.0900 - val_loss: 304.8276\n",
      "Epoch 546/1000\n",
      "5/5 - 0s - loss: 193.0308 - val_loss: 292.7053\n",
      "Epoch 547/1000\n",
      "5/5 - 0s - loss: 193.1032 - val_loss: 281.5536\n",
      "Epoch 548/1000\n",
      "5/5 - 0s - loss: 193.6892 - val_loss: 265.3799\n",
      "Epoch 549/1000\n",
      "5/5 - 0s - loss: 194.3462 - val_loss: 266.4813\n",
      "Epoch 550/1000\n",
      "5/5 - 0s - loss: 184.3257 - val_loss: 418.3730\n",
      "Epoch 551/1000\n",
      "5/5 - 0s - loss: 176.0374 - val_loss: 258.1526\n",
      "Epoch 552/1000\n",
      "5/5 - 0s - loss: 192.9233 - val_loss: 275.5146\n",
      "Epoch 553/1000\n",
      "5/5 - 0s - loss: 198.7313 - val_loss: 279.2503\n",
      "Epoch 554/1000\n",
      "5/5 - 0s - loss: 195.5568 - val_loss: 280.3474\n",
      "Epoch 555/1000\n",
      "5/5 - 0s - loss: 189.4829 - val_loss: 275.4713\n",
      "Epoch 556/1000\n",
      "5/5 - 0s - loss: 192.3708 - val_loss: 259.3306\n",
      "Epoch 557/1000\n",
      "5/5 - 0s - loss: 198.6115 - val_loss: 568.2584\n",
      "Epoch 558/1000\n",
      "5/5 - 0s - loss: 266.9161 - val_loss: 515.6577\n",
      "Epoch 559/1000\n",
      "5/5 - 0s - loss: 231.2297 - val_loss: 380.4131\n",
      "Epoch 560/1000\n",
      "5/5 - 0s - loss: 212.6058 - val_loss: 356.6773\n",
      "Epoch 561/1000\n",
      "5/5 - 0s - loss: 193.3815 - val_loss: 316.6028\n",
      "Epoch 562/1000\n",
      "5/5 - 0s - loss: 195.7217 - val_loss: 268.1900\n",
      "Epoch 563/1000\n",
      "5/5 - 0s - loss: 211.8649 - val_loss: 262.9085\n",
      "Epoch 564/1000\n",
      "5/5 - 0s - loss: 185.3097 - val_loss: 235.9654\n",
      "Epoch 565/1000\n",
      "5/5 - 0s - loss: 184.0215 - val_loss: 284.6292\n",
      "Epoch 566/1000\n",
      "5/5 - 0s - loss: 189.6410 - val_loss: 263.7900\n",
      "Epoch 567/1000\n",
      "5/5 - 0s - loss: 186.8070 - val_loss: 348.7603\n",
      "Epoch 568/1000\n",
      "5/5 - 0s - loss: 189.5720 - val_loss: 295.8080\n",
      "Epoch 569/1000\n",
      "5/5 - 0s - loss: 197.2910 - val_loss: 347.4927\n",
      "Epoch 570/1000\n",
      "5/5 - 0s - loss: 211.6549 - val_loss: 348.7493\n",
      "Epoch 571/1000\n",
      "5/5 - 0s - loss: 204.3437 - val_loss: 347.8914\n",
      "Epoch 572/1000\n",
      "5/5 - 0s - loss: 205.9315 - val_loss: 344.6199\n",
      "Epoch 573/1000\n",
      "5/5 - 0s - loss: 200.8535 - val_loss: 337.7015\n",
      "Epoch 574/1000\n",
      "5/5 - 0s - loss: 200.5385 - val_loss: 342.8281\n",
      "Epoch 575/1000\n",
      "5/5 - 0s - loss: 198.8499 - val_loss: 340.0165\n",
      "Epoch 576/1000\n",
      "5/5 - 0s - loss: 198.0000 - val_loss: 309.1275\n",
      "Epoch 577/1000\n",
      "5/5 - 0s - loss: 192.6041 - val_loss: 311.7630\n",
      "Epoch 578/1000\n",
      "5/5 - 0s - loss: 194.6068 - val_loss: 302.0695\n",
      "Epoch 579/1000\n",
      "5/5 - 0s - loss: 202.9883 - val_loss: 321.0625\n",
      "Epoch 580/1000\n",
      "5/5 - 0s - loss: 194.4317 - val_loss: 318.4163\n",
      "Epoch 581/1000\n",
      "5/5 - 0s - loss: 194.9369 - val_loss: 303.5535\n",
      "Epoch 582/1000\n",
      "5/5 - 0s - loss: 190.9992 - val_loss: 297.1245\n",
      "Epoch 583/1000\n",
      "5/5 - 0s - loss: 183.5972 - val_loss: 312.3528\n",
      "Epoch 584/1000\n",
      "5/5 - 0s - loss: 188.2072 - val_loss: 281.9007\n",
      "Epoch 585/1000\n",
      "5/5 - 0s - loss: 191.5984 - val_loss: 303.5797\n",
      "Epoch 586/1000\n",
      "5/5 - 0s - loss: 183.6300 - val_loss: 292.4950\n",
      "Epoch 587/1000\n",
      "5/5 - 0s - loss: 189.9380 - val_loss: 273.8803\n",
      "Epoch 588/1000\n",
      "5/5 - 0s - loss: 186.6675 - val_loss: 249.3185\n",
      "Epoch 589/1000\n",
      "5/5 - 0s - loss: 170.5467 - val_loss: 249.0424\n",
      "Epoch 590/1000\n",
      "5/5 - 0s - loss: 180.3977 - val_loss: 283.7173\n",
      "Epoch 591/1000\n",
      "5/5 - 0s - loss: 173.8724 - val_loss: 293.5188\n",
      "Epoch 592/1000\n",
      "5/5 - 0s - loss: 187.2761 - val_loss: 337.1610\n",
      "Epoch 593/1000\n",
      "5/5 - 0s - loss: 195.3853 - val_loss: 337.2985\n",
      "Epoch 594/1000\n",
      "5/5 - 0s - loss: 198.9166 - val_loss: 339.1034\n",
      "Epoch 595/1000\n",
      "5/5 - 0s - loss: 189.6005 - val_loss: 332.2348\n",
      "Epoch 596/1000\n",
      "5/5 - 0s - loss: 200.5463 - val_loss: 324.4053\n",
      "Epoch 597/1000\n",
      "5/5 - 0s - loss: 191.8702 - val_loss: 320.3654\n",
      "Epoch 598/1000\n",
      "5/5 - 0s - loss: 192.9828 - val_loss: 318.8835\n",
      "Epoch 599/1000\n",
      "5/5 - 0s - loss: 183.1839 - val_loss: 315.1688\n",
      "Epoch 600/1000\n",
      "5/5 - 0s - loss: 189.7234 - val_loss: 299.6807\n",
      "Epoch 601/1000\n",
      "5/5 - 0s - loss: 186.9612 - val_loss: 280.0404\n",
      "Epoch 602/1000\n",
      "5/5 - 0s - loss: 182.9049 - val_loss: 263.8533\n",
      "Epoch 603/1000\n",
      "5/5 - 0s - loss: 181.3179 - val_loss: 260.5646\n",
      "Epoch 604/1000\n",
      "5/5 - 0s - loss: 173.9051 - val_loss: 238.4810\n",
      "Epoch 605/1000\n",
      "5/5 - 0s - loss: 189.1530 - val_loss: 237.3417\n",
      "Epoch 606/1000\n",
      "5/5 - 0s - loss: 179.9763 - val_loss: 303.9539\n",
      "Epoch 607/1000\n",
      "5/5 - 0s - loss: 196.4257 - val_loss: 311.3706\n",
      "Epoch 608/1000\n",
      "5/5 - 0s - loss: 188.8960 - val_loss: 302.0173\n",
      "Epoch 609/1000\n",
      "5/5 - 0s - loss: 183.9619 - val_loss: 243.3947\n",
      "Epoch 610/1000\n",
      "5/5 - 0s - loss: 174.5024 - val_loss: 246.0857\n",
      "Epoch 611/1000\n",
      "5/5 - 0s - loss: 169.7301 - val_loss: 242.0843\n",
      "Epoch 612/1000\n",
      "5/5 - 0s - loss: 175.4654 - val_loss: 253.2082\n",
      "Epoch 613/1000\n",
      "5/5 - 0s - loss: 179.7443 - val_loss: 304.1801\n",
      "Epoch 614/1000\n",
      "5/5 - 0s - loss: 190.8184 - val_loss: 396.8063\n",
      "Epoch 615/1000\n",
      "5/5 - 0s - loss: 170.1709 - val_loss: 254.1005\n",
      "Epoch 616/1000\n",
      "5/5 - 0s - loss: 191.2558 - val_loss: 199.0048\n",
      "Epoch 617/1000\n",
      "5/5 - 0s - loss: 173.1208 - val_loss: 233.7021\n",
      "Epoch 618/1000\n",
      "5/5 - 0s - loss: 175.5316 - val_loss: 237.8327\n",
      "Epoch 619/1000\n",
      "5/5 - 0s - loss: 172.1296 - val_loss: 249.5664\n",
      "Epoch 620/1000\n",
      "5/5 - 0s - loss: 178.4218 - val_loss: 319.6856\n",
      "Epoch 621/1000\n",
      "5/5 - 0s - loss: 186.8991 - val_loss: 226.9370\n",
      "Epoch 622/1000\n",
      "5/5 - 0s - loss: 179.7861 - val_loss: 223.5296\n",
      "Epoch 623/1000\n",
      "5/5 - 0s - loss: 176.3206 - val_loss: 265.4908\n",
      "Epoch 624/1000\n",
      "5/5 - 0s - loss: 185.6610 - val_loss: 202.1834\n",
      "Epoch 625/1000\n",
      "5/5 - 0s - loss: 204.5630 - val_loss: 478.9768\n",
      "Epoch 626/1000\n",
      "5/5 - 0s - loss: 218.1858 - val_loss: 443.3351\n",
      "Epoch 627/1000\n",
      "5/5 - 0s - loss: 206.9416 - val_loss: 223.7915\n",
      "Epoch 628/1000\n",
      "5/5 - 0s - loss: 197.7824 - val_loss: 399.3690\n",
      "Epoch 629/1000\n",
      "5/5 - 0s - loss: 194.5240 - val_loss: 257.9765\n",
      "Epoch 630/1000\n",
      "5/5 - 0s - loss: 185.9931 - val_loss: 217.6640\n",
      "Epoch 631/1000\n",
      "5/5 - 0s - loss: 179.5722 - val_loss: 400.6886\n",
      "Epoch 632/1000\n",
      "5/5 - 0s - loss: 189.0771 - val_loss: 249.4341\n",
      "Epoch 633/1000\n",
      "5/5 - 0s - loss: 188.0345 - val_loss: 267.7947\n",
      "Epoch 634/1000\n",
      "5/5 - 0s - loss: 187.0286 - val_loss: 254.2610\n",
      "Epoch 635/1000\n",
      "5/5 - 0s - loss: 167.5431 - val_loss: 251.4095\n",
      "Epoch 636/1000\n",
      "5/5 - 0s - loss: 183.8289 - val_loss: 252.8854\n",
      "Epoch 637/1000\n",
      "5/5 - 0s - loss: 189.8133 - val_loss: 481.0648\n",
      "Epoch 638/1000\n",
      "5/5 - 0s - loss: 253.2057 - val_loss: 461.5150\n",
      "Epoch 639/1000\n",
      "5/5 - 0s - loss: 237.0164 - val_loss: 421.0069\n",
      "Epoch 640/1000\n",
      "5/5 - 0s - loss: 230.9795 - val_loss: 387.8551\n",
      "Epoch 641/1000\n",
      "5/5 - 0s - loss: 213.5688 - val_loss: 371.7791\n",
      "Epoch 642/1000\n",
      "5/5 - 0s - loss: 204.8367 - val_loss: 361.9227\n",
      "Epoch 643/1000\n",
      "5/5 - 0s - loss: 200.0521 - val_loss: 306.7971\n",
      "Epoch 644/1000\n",
      "5/5 - 0s - loss: 183.7307 - val_loss: 244.1194\n",
      "Epoch 645/1000\n",
      "5/5 - 0s - loss: 177.1477 - val_loss: 270.9991\n",
      "Epoch 646/1000\n",
      "5/5 - 0s - loss: 194.5859 - val_loss: 343.2309\n",
      "Epoch 647/1000\n",
      "5/5 - 0s - loss: 203.1707 - val_loss: 331.0257\n",
      "Epoch 648/1000\n",
      "5/5 - 0s - loss: 205.4698 - val_loss: 316.1071\n",
      "Epoch 649/1000\n",
      "5/5 - 0s - loss: 203.9610 - val_loss: 315.7757\n",
      "Epoch 650/1000\n",
      "5/5 - 0s - loss: 202.9648 - val_loss: 308.2104\n",
      "Epoch 651/1000\n",
      "5/5 - 0s - loss: 190.7877 - val_loss: 293.6629\n",
      "Epoch 652/1000\n",
      "5/5 - 0s - loss: 176.2293 - val_loss: 313.6983\n",
      "Epoch 653/1000\n",
      "5/5 - 0s - loss: 186.1242 - val_loss: 323.1592\n",
      "Epoch 654/1000\n",
      "5/5 - 0s - loss: 191.3008 - val_loss: 323.7270\n",
      "Epoch 655/1000\n",
      "5/5 - 0s - loss: 192.5473 - val_loss: 314.0647\n",
      "Epoch 656/1000\n",
      "5/5 - 0s - loss: 198.6612 - val_loss: 300.7418\n",
      "Epoch 657/1000\n",
      "5/5 - 0s - loss: 183.2732 - val_loss: 289.1205\n",
      "Epoch 658/1000\n",
      "5/5 - 0s - loss: 178.1031 - val_loss: 285.5826\n",
      "Epoch 659/1000\n",
      "5/5 - 0s - loss: 184.2300 - val_loss: 254.8381\n",
      "Epoch 660/1000\n",
      "5/5 - 0s - loss: 169.4790 - val_loss: 422.6216\n",
      "Epoch 661/1000\n",
      "5/5 - 0s - loss: 179.3700 - val_loss: 270.6370\n",
      "Epoch 662/1000\n",
      "5/5 - 0s - loss: 194.2023 - val_loss: 299.2875\n",
      "Epoch 663/1000\n",
      "5/5 - 0s - loss: 185.9261 - val_loss: 282.3700\n",
      "Epoch 664/1000\n",
      "5/5 - 0s - loss: 182.8305 - val_loss: 233.7583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 665/1000\n",
      "5/5 - 0s - loss: 174.9231 - val_loss: 249.4161\n",
      "Epoch 666/1000\n",
      "5/5 - 0s - loss: 178.3364 - val_loss: 417.4099\n",
      "Epoch 667/1000\n",
      "5/5 - 0s - loss: 201.1174 - val_loss: 258.7542\n",
      "Epoch 668/1000\n",
      "5/5 - 0s - loss: 190.7473 - val_loss: 228.3467\n",
      "Epoch 669/1000\n",
      "5/5 - 0s - loss: 178.2442 - val_loss: 273.5468\n",
      "Epoch 670/1000\n",
      "5/5 - 0s - loss: 183.3168 - val_loss: 294.7043\n",
      "Epoch 671/1000\n",
      "5/5 - 0s - loss: 180.3708 - val_loss: 332.2860\n",
      "Epoch 672/1000\n",
      "5/5 - 0s - loss: 187.0030 - val_loss: 330.7284\n",
      "Epoch 673/1000\n",
      "5/5 - 0s - loss: 190.8019 - val_loss: 292.4797\n",
      "Epoch 674/1000\n",
      "5/5 - 0s - loss: 183.8093 - val_loss: 334.4319\n",
      "Epoch 675/1000\n",
      "5/5 - 0s - loss: 197.9344 - val_loss: 349.0012\n",
      "Epoch 676/1000\n",
      "5/5 - 0s - loss: 185.7332 - val_loss: 347.4632\n",
      "Epoch 677/1000\n",
      "5/5 - 0s - loss: 189.0674 - val_loss: 334.7187\n",
      "Epoch 678/1000\n",
      "5/5 - 0s - loss: 189.5473 - val_loss: 325.4329\n",
      "Epoch 679/1000\n",
      "5/5 - 0s - loss: 191.2974 - val_loss: 293.9455\n",
      "Epoch 680/1000\n",
      "5/5 - 0s - loss: 180.6863 - val_loss: 356.7705\n",
      "Epoch 681/1000\n",
      "5/5 - 0s - loss: 197.5065 - val_loss: 355.4180\n",
      "Epoch 682/1000\n",
      "5/5 - 0s - loss: 193.5855 - val_loss: 351.3245\n",
      "Epoch 683/1000\n",
      "5/5 - 0s - loss: 194.6353 - val_loss: 339.4447\n",
      "Epoch 684/1000\n",
      "5/5 - 0s - loss: 196.6100 - val_loss: 302.6427\n",
      "Epoch 685/1000\n",
      "5/5 - 0s - loss: 180.5987 - val_loss: 321.1018\n",
      "Epoch 686/1000\n",
      "5/5 - 0s - loss: 189.0740 - val_loss: 290.8365\n",
      "Epoch 687/1000\n",
      "5/5 - 0s - loss: 177.7575 - val_loss: 264.1956\n",
      "Epoch 688/1000\n",
      "5/5 - 0s - loss: 178.7518 - val_loss: 244.3581\n",
      "Epoch 689/1000\n",
      "5/5 - 0s - loss: 171.3557 - val_loss: 247.8188\n",
      "Epoch 690/1000\n",
      "5/5 - 0s - loss: 177.7755 - val_loss: 269.1606\n",
      "Epoch 691/1000\n",
      "5/5 - 0s - loss: 179.6110 - val_loss: 266.7928\n",
      "Epoch 692/1000\n",
      "5/5 - 0s - loss: 178.2729 - val_loss: 244.5746\n",
      "Epoch 693/1000\n",
      "5/5 - 0s - loss: 176.5524 - val_loss: 243.1213\n",
      "Epoch 694/1000\n",
      "5/5 - 0s - loss: 166.5337 - val_loss: 295.3878\n",
      "Epoch 695/1000\n",
      "5/5 - 0s - loss: 178.6269 - val_loss: 364.4299\n",
      "Epoch 696/1000\n",
      "5/5 - 0s - loss: 207.7477 - val_loss: 364.1342\n",
      "Epoch 697/1000\n",
      "5/5 - 0s - loss: 208.0166 - val_loss: 358.4474\n",
      "Epoch 698/1000\n",
      "5/5 - 0s - loss: 209.1056 - val_loss: 340.6986\n",
      "Epoch 699/1000\n",
      "5/5 - 0s - loss: 207.2241 - val_loss: 308.8297\n",
      "Epoch 700/1000\n",
      "5/5 - 0s - loss: 214.6764 - val_loss: 313.9845\n",
      "Epoch 701/1000\n",
      "5/5 - 0s - loss: 207.0645 - val_loss: 313.7475\n",
      "Epoch 702/1000\n",
      "5/5 - 0s - loss: 203.6393 - val_loss: 293.4979\n",
      "Epoch 703/1000\n",
      "5/5 - 0s - loss: 206.4487 - val_loss: 301.5840\n",
      "Epoch 704/1000\n",
      "5/5 - 0s - loss: 189.3991 - val_loss: 326.1920\n",
      "Epoch 705/1000\n",
      "5/5 - 0s - loss: 205.2738 - val_loss: 314.7240\n",
      "Epoch 706/1000\n",
      "5/5 - 0s - loss: 207.8412 - val_loss: 305.1624\n",
      "Epoch 707/1000\n",
      "5/5 - 0s - loss: 199.8450 - val_loss: 318.2219\n",
      "Epoch 708/1000\n",
      "5/5 - 0s - loss: 200.0930 - val_loss: 299.4593\n",
      "Epoch 709/1000\n",
      "5/5 - 0s - loss: 197.1312 - val_loss: 366.8807\n",
      "Epoch 710/1000\n",
      "5/5 - 0s - loss: 211.8629 - val_loss: 312.7202\n",
      "Epoch 711/1000\n",
      "5/5 - 0s - loss: 200.6691 - val_loss: 298.7181\n",
      "Epoch 712/1000\n",
      "5/5 - 0s - loss: 201.2980 - val_loss: 316.5276\n",
      "Epoch 713/1000\n",
      "5/5 - 0s - loss: 193.2918 - val_loss: 280.0632\n",
      "Epoch 714/1000\n",
      "5/5 - 0s - loss: 205.3058 - val_loss: 371.5872\n",
      "Epoch 715/1000\n",
      "5/5 - 0s - loss: 201.4854 - val_loss: 343.5049\n",
      "Epoch 716/1000\n",
      "5/5 - 0s - loss: 204.2487 - val_loss: 340.8256\n",
      "Epoch 717/1000\n",
      "5/5 - 0s - loss: 212.9694 - val_loss: 341.8748\n",
      "Epoch 718/1000\n",
      "5/5 - 0s - loss: 211.8266 - val_loss: 338.4680\n",
      "Epoch 719/1000\n",
      "5/5 - 0s - loss: 200.6308 - val_loss: 328.6852\n",
      "Epoch 720/1000\n",
      "5/5 - 0s - loss: 190.5696 - val_loss: 323.5107\n",
      "Epoch 721/1000\n",
      "5/5 - 0s - loss: 209.7528 - val_loss: 278.9409\n",
      "Epoch 722/1000\n",
      "5/5 - 0s - loss: 202.8003 - val_loss: 308.3134\n",
      "Epoch 723/1000\n",
      "5/5 - 0s - loss: 202.8264 - val_loss: 297.3694\n",
      "Epoch 724/1000\n",
      "5/5 - 0s - loss: 201.1913 - val_loss: 324.5891\n",
      "Epoch 725/1000\n",
      "5/5 - 0s - loss: 204.4633 - val_loss: 326.9662\n",
      "Epoch 726/1000\n",
      "5/5 - 0s - loss: 201.3920 - val_loss: 326.3498\n",
      "Epoch 727/1000\n",
      "5/5 - 0s - loss: 199.6478 - val_loss: 320.7453\n",
      "Epoch 728/1000\n",
      "5/5 - 0s - loss: 204.6924 - val_loss: 316.5783\n",
      "Epoch 729/1000\n",
      "5/5 - 0s - loss: 200.1165 - val_loss: 312.2588\n",
      "Epoch 730/1000\n",
      "5/5 - 0s - loss: 202.7266 - val_loss: 303.9418\n",
      "Epoch 731/1000\n",
      "5/5 - 0s - loss: 191.0258 - val_loss: 348.4907\n",
      "Epoch 732/1000\n",
      "5/5 - 0s - loss: 198.5022 - val_loss: 346.3074\n",
      "Epoch 733/1000\n",
      "5/5 - 0s - loss: 205.1560 - val_loss: 328.0698\n",
      "Epoch 734/1000\n",
      "5/5 - 0s - loss: 201.2698 - val_loss: 292.6487\n",
      "Epoch 735/1000\n",
      "5/5 - 0s - loss: 201.2177 - val_loss: 297.0090\n",
      "Epoch 736/1000\n",
      "5/5 - 0s - loss: 198.7010 - val_loss: 278.9395\n",
      "Epoch 737/1000\n",
      "5/5 - 0s - loss: 195.0983 - val_loss: 301.5533\n",
      "Epoch 738/1000\n",
      "5/5 - 0s - loss: 195.8559 - val_loss: 336.0968\n",
      "Epoch 739/1000\n",
      "5/5 - 0s - loss: 200.0958 - val_loss: 334.8784\n",
      "Epoch 740/1000\n",
      "5/5 - 0s - loss: 199.2980 - val_loss: 341.2426\n",
      "Epoch 741/1000\n",
      "5/5 - 0s - loss: 215.7856 - val_loss: 342.6317\n",
      "Epoch 742/1000\n",
      "5/5 - 0s - loss: 197.3149 - val_loss: 338.7604\n",
      "Epoch 743/1000\n",
      "5/5 - 0s - loss: 193.1009 - val_loss: 332.2657\n",
      "Epoch 744/1000\n",
      "5/5 - 0s - loss: 196.1706 - val_loss: 322.3693\n",
      "Epoch 745/1000\n",
      "5/5 - 0s - loss: 200.3329 - val_loss: 309.8051\n",
      "Epoch 746/1000\n",
      "5/5 - 0s - loss: 196.6695 - val_loss: 296.9717\n",
      "Epoch 747/1000\n",
      "5/5 - 0s - loss: 194.5249 - val_loss: 320.4585\n",
      "Epoch 748/1000\n",
      "5/5 - 0s - loss: 195.5035 - val_loss: 313.4358\n",
      "Epoch 749/1000\n",
      "5/5 - 0s - loss: 204.0170 - val_loss: 303.0131\n",
      "Epoch 750/1000\n",
      "5/5 - 0s - loss: 204.4336 - val_loss: 287.4608\n",
      "Epoch 751/1000\n",
      "5/5 - 0s - loss: 194.5248 - val_loss: 290.8369\n",
      "Epoch 752/1000\n",
      "5/5 - 0s - loss: 204.0944 - val_loss: 290.7812\n",
      "Epoch 753/1000\n",
      "5/5 - 0s - loss: 189.9454 - val_loss: 296.7702\n",
      "Epoch 754/1000\n",
      "5/5 - 0s - loss: 192.0637 - val_loss: 287.1730\n",
      "Epoch 755/1000\n",
      "5/5 - 0s - loss: 189.9003 - val_loss: 284.3853\n",
      "Epoch 756/1000\n",
      "5/5 - 0s - loss: 195.8159 - val_loss: 349.5533\n",
      "Epoch 757/1000\n",
      "5/5 - 0s - loss: 197.9532 - val_loss: 331.2248\n",
      "Epoch 758/1000\n",
      "5/5 - 0s - loss: 202.6626 - val_loss: 341.9701\n",
      "Epoch 759/1000\n",
      "5/5 - 0s - loss: 202.0779 - val_loss: 342.8405\n",
      "Epoch 760/1000\n",
      "5/5 - 0s - loss: 194.8936 - val_loss: 346.6856\n",
      "Epoch 761/1000\n",
      "5/5 - 0s - loss: 195.4050 - val_loss: 345.6881\n",
      "Epoch 762/1000\n",
      "5/5 - 0s - loss: 202.7976 - val_loss: 339.0917\n",
      "Epoch 763/1000\n",
      "5/5 - 0s - loss: 203.3611 - val_loss: 327.1206\n",
      "Epoch 764/1000\n",
      "5/5 - 0s - loss: 191.1495 - val_loss: 326.2471\n",
      "Epoch 765/1000\n",
      "5/5 - 0s - loss: 203.0302 - val_loss: 318.2753\n",
      "Epoch 766/1000\n",
      "5/5 - 0s - loss: 196.9935 - val_loss: 312.0997\n",
      "Epoch 767/1000\n",
      "5/5 - 0s - loss: 191.1929 - val_loss: 294.0497\n",
      "Epoch 768/1000\n",
      "5/5 - 0s - loss: 192.9456 - val_loss: 287.0105\n",
      "Epoch 769/1000\n",
      "5/5 - 0s - loss: 197.5329 - val_loss: 328.5783\n",
      "Epoch 770/1000\n",
      "5/5 - 0s - loss: 190.3929 - val_loss: 305.6910\n",
      "Epoch 771/1000\n",
      "5/5 - 0s - loss: 199.6986 - val_loss: 305.5480\n",
      "Epoch 772/1000\n",
      "5/5 - 0s - loss: 200.7780 - val_loss: 309.6974\n",
      "Epoch 773/1000\n",
      "5/5 - 0s - loss: 195.9954 - val_loss: 318.2006\n",
      "Epoch 774/1000\n",
      "5/5 - 0s - loss: 204.2251 - val_loss: 310.9173\n",
      "Epoch 775/1000\n",
      "5/5 - 0s - loss: 205.3919 - val_loss: 319.6349\n",
      "Epoch 776/1000\n",
      "5/5 - 0s - loss: 202.5587 - val_loss: 322.0787\n",
      "Epoch 777/1000\n",
      "5/5 - 0s - loss: 198.8655 - val_loss: 312.4044\n",
      "Epoch 778/1000\n",
      "5/5 - 0s - loss: 197.9553 - val_loss: 291.4169\n",
      "Epoch 779/1000\n",
      "5/5 - 0s - loss: 194.0775 - val_loss: 291.3763\n",
      "Epoch 780/1000\n",
      "5/5 - 0s - loss: 187.3679 - val_loss: 311.7882\n",
      "Epoch 781/1000\n",
      "5/5 - 0s - loss: 206.3902 - val_loss: 315.2635\n",
      "Epoch 782/1000\n",
      "5/5 - 0s - loss: 199.6428 - val_loss: 309.2719\n",
      "Epoch 783/1000\n",
      "5/5 - 0s - loss: 193.8768 - val_loss: 306.9412\n",
      "Epoch 784/1000\n",
      "5/5 - 0s - loss: 192.8870 - val_loss: 307.5235\n",
      "Epoch 785/1000\n",
      "5/5 - 0s - loss: 191.3382 - val_loss: 308.3364\n",
      "Epoch 786/1000\n",
      "5/5 - 0s - loss: 188.0196 - val_loss: 293.6896\n",
      "Epoch 787/1000\n",
      "5/5 - 0s - loss: 190.6210 - val_loss: 324.7504\n",
      "Epoch 788/1000\n",
      "5/5 - 0s - loss: 195.6015 - val_loss: 311.9247\n",
      "Epoch 789/1000\n",
      "5/5 - 0s - loss: 193.1742 - val_loss: 325.0850\n",
      "Epoch 790/1000\n",
      "5/5 - 0s - loss: 196.8537 - val_loss: 317.7155\n",
      "Epoch 791/1000\n",
      "5/5 - 0s - loss: 192.2795 - val_loss: 314.0869\n",
      "Epoch 792/1000\n",
      "5/5 - 0s - loss: 185.7658 - val_loss: 311.2405\n",
      "Epoch 793/1000\n",
      "5/5 - 0s - loss: 190.1558 - val_loss: 302.5197\n",
      "Epoch 794/1000\n",
      "5/5 - 0s - loss: 197.7941 - val_loss: 286.6910\n",
      "Epoch 795/1000\n",
      "5/5 - 0s - loss: 191.2560 - val_loss: 294.7700\n",
      "Epoch 796/1000\n",
      "5/5 - 0s - loss: 192.2295 - val_loss: 284.7764\n",
      "Epoch 797/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 - 0s - loss: 192.5202 - val_loss: 280.3287\n",
      "Epoch 798/1000\n",
      "5/5 - 0s - loss: 189.6722 - val_loss: 286.6276\n",
      "Epoch 799/1000\n",
      "5/5 - 0s - loss: 183.2129 - val_loss: 289.6028\n",
      "Epoch 800/1000\n",
      "5/5 - 0s - loss: 194.6889 - val_loss: 280.1107\n",
      "Epoch 801/1000\n",
      "5/5 - 0s - loss: 190.4210 - val_loss: 280.8503\n",
      "Epoch 802/1000\n",
      "5/5 - 0s - loss: 184.6098 - val_loss: 320.4891\n",
      "Epoch 803/1000\n",
      "5/5 - 0s - loss: 190.0430 - val_loss: 327.2531\n",
      "Epoch 804/1000\n",
      "5/5 - 0s - loss: 204.5674 - val_loss: 328.6202\n",
      "Epoch 805/1000\n",
      "5/5 - 0s - loss: 198.9901 - val_loss: 330.0345\n",
      "Epoch 806/1000\n",
      "5/5 - 0s - loss: 205.0609 - val_loss: 328.4703\n",
      "Epoch 807/1000\n",
      "5/5 - 0s - loss: 199.8700 - val_loss: 327.7911\n",
      "Epoch 808/1000\n",
      "5/5 - 0s - loss: 201.0185 - val_loss: 322.4509\n",
      "Epoch 809/1000\n",
      "5/5 - 0s - loss: 197.0941 - val_loss: 319.9766\n",
      "Epoch 810/1000\n",
      "5/5 - 0s - loss: 195.8734 - val_loss: 315.6710\n",
      "Epoch 811/1000\n",
      "5/5 - 0s - loss: 189.7114 - val_loss: 305.6325\n",
      "Epoch 812/1000\n",
      "5/5 - 0s - loss: 189.4731 - val_loss: 289.5267\n",
      "Epoch 813/1000\n",
      "5/5 - 0s - loss: 186.4196 - val_loss: 358.5726\n",
      "Epoch 814/1000\n",
      "5/5 - 0s - loss: 186.2714 - val_loss: 302.8103\n",
      "Epoch 815/1000\n",
      "5/5 - 0s - loss: 196.5468 - val_loss: 327.1729\n",
      "Epoch 816/1000\n",
      "5/5 - 0s - loss: 195.2288 - val_loss: 324.1708\n",
      "Epoch 817/1000\n",
      "5/5 - 0s - loss: 190.1259 - val_loss: 320.1934\n",
      "Epoch 818/1000\n",
      "5/5 - 0s - loss: 189.8094 - val_loss: 315.8520\n",
      "Epoch 819/1000\n",
      "5/5 - 0s - loss: 188.2608 - val_loss: 315.6610\n",
      "Epoch 820/1000\n",
      "5/5 - 0s - loss: 196.7170 - val_loss: 316.0791\n",
      "Epoch 821/1000\n",
      "5/5 - 0s - loss: 189.8318 - val_loss: 312.5121\n",
      "Epoch 822/1000\n",
      "5/5 - 0s - loss: 191.9957 - val_loss: 291.5428\n",
      "Epoch 823/1000\n",
      "5/5 - 0s - loss: 189.0506 - val_loss: 283.6952\n",
      "Epoch 824/1000\n",
      "5/5 - 0s - loss: 192.9375 - val_loss: 297.0031\n",
      "Epoch 825/1000\n",
      "5/5 - 0s - loss: 187.4950 - val_loss: 295.9316\n",
      "Epoch 826/1000\n",
      "5/5 - 0s - loss: 202.2151 - val_loss: 290.2013\n",
      "Epoch 827/1000\n",
      "5/5 - 0s - loss: 193.8669 - val_loss: 289.1861\n",
      "Epoch 828/1000\n",
      "5/5 - 0s - loss: 184.6833 - val_loss: 327.9913\n",
      "Epoch 829/1000\n",
      "5/5 - 0s - loss: 192.6102 - val_loss: 301.2279\n",
      "Epoch 830/1000\n",
      "5/5 - 0s - loss: 190.3797 - val_loss: 281.5382\n",
      "Epoch 831/1000\n",
      "5/5 - 0s - loss: 185.2745 - val_loss: 348.2451\n",
      "Epoch 832/1000\n",
      "5/5 - 0s - loss: 190.5218 - val_loss: 281.3633\n",
      "Epoch 833/1000\n",
      "5/5 - 0s - loss: 192.5556 - val_loss: 325.4175\n",
      "Epoch 834/1000\n",
      "5/5 - 0s - loss: 215.5269 - val_loss: 274.0980\n",
      "Epoch 835/1000\n",
      "5/5 - 0s - loss: 187.3034 - val_loss: 272.5565\n",
      "Epoch 836/1000\n",
      "5/5 - 0s - loss: 188.4665 - val_loss: 292.1389\n",
      "Epoch 837/1000\n",
      "5/5 - 0s - loss: 183.9373 - val_loss: 278.4893\n",
      "Epoch 838/1000\n",
      "5/5 - 0s - loss: 178.1750 - val_loss: 310.8434\n",
      "Epoch 839/1000\n",
      "5/5 - 0s - loss: 181.5059 - val_loss: 328.1029\n",
      "Epoch 840/1000\n",
      "5/5 - 0s - loss: 192.9761 - val_loss: 332.4898\n",
      "Epoch 841/1000\n",
      "5/5 - 0s - loss: 190.3240 - val_loss: 323.7179\n",
      "Epoch 842/1000\n",
      "5/5 - 0s - loss: 196.4490 - val_loss: 324.7082\n",
      "Epoch 843/1000\n",
      "5/5 - 0s - loss: 198.4282 - val_loss: 328.1880\n",
      "Epoch 844/1000\n",
      "5/5 - 0s - loss: 191.5351 - val_loss: 326.7433\n",
      "Epoch 845/1000\n",
      "5/5 - 0s - loss: 194.7957 - val_loss: 332.9579\n",
      "Epoch 846/1000\n",
      "5/5 - 0s - loss: 190.9564 - val_loss: 333.3796\n",
      "Epoch 847/1000\n",
      "5/5 - 0s - loss: 193.4467 - val_loss: 330.3871\n",
      "Epoch 848/1000\n",
      "5/5 - 0s - loss: 191.4910 - val_loss: 336.0592\n",
      "Epoch 849/1000\n",
      "5/5 - 0s - loss: 195.8962 - val_loss: 337.4132\n",
      "Epoch 850/1000\n",
      "5/5 - 0s - loss: 183.6603 - val_loss: 334.5019\n",
      "Epoch 851/1000\n",
      "5/5 - 0s - loss: 187.7081 - val_loss: 339.9531\n",
      "Epoch 852/1000\n",
      "5/5 - 0s - loss: 185.0387 - val_loss: 338.0164\n",
      "Epoch 853/1000\n",
      "5/5 - 0s - loss: 179.9740 - val_loss: 340.8727\n",
      "Epoch 854/1000\n",
      "5/5 - 0s - loss: 189.6116 - val_loss: 344.7932\n",
      "Epoch 855/1000\n",
      "5/5 - 0s - loss: 193.1730 - val_loss: 347.0056\n",
      "Epoch 856/1000\n",
      "5/5 - 0s - loss: 186.3779 - val_loss: 345.9025\n",
      "Epoch 857/1000\n",
      "5/5 - 0s - loss: 188.1059 - val_loss: 345.3618\n",
      "Epoch 858/1000\n",
      "5/5 - 0s - loss: 191.2148 - val_loss: 344.6871\n",
      "Epoch 859/1000\n",
      "5/5 - 0s - loss: 186.8913 - val_loss: 344.0023\n",
      "Epoch 860/1000\n",
      "5/5 - 0s - loss: 189.5388 - val_loss: 343.9617\n",
      "Epoch 861/1000\n",
      "5/5 - 0s - loss: 191.8572 - val_loss: 341.1035\n",
      "Epoch 862/1000\n",
      "5/5 - 0s - loss: 177.9067 - val_loss: 335.4399\n",
      "Epoch 863/1000\n",
      "5/5 - 0s - loss: 176.6416 - val_loss: 321.2804\n",
      "Epoch 864/1000\n",
      "5/5 - 0s - loss: 184.1529 - val_loss: 303.4839\n",
      "Epoch 865/1000\n",
      "5/5 - 0s - loss: 180.9088 - val_loss: 304.2741\n",
      "Epoch 866/1000\n",
      "5/5 - 0s - loss: 181.2260 - val_loss: 323.3558\n",
      "Epoch 867/1000\n",
      "5/5 - 0s - loss: 187.8900 - val_loss: 323.2668\n",
      "Epoch 868/1000\n",
      "5/5 - 0s - loss: 192.9007 - val_loss: 324.4428\n",
      "Epoch 869/1000\n",
      "5/5 - 0s - loss: 184.1505 - val_loss: 300.0406\n",
      "Epoch 870/1000\n",
      "5/5 - 0s - loss: 184.6712 - val_loss: 272.5361\n",
      "Epoch 871/1000\n",
      "5/5 - 0s - loss: 180.4550 - val_loss: 262.4307\n",
      "Epoch 872/1000\n",
      "5/5 - 0s - loss: 172.0202 - val_loss: 249.4023\n",
      "Epoch 873/1000\n",
      "5/5 - 0s - loss: 171.2346 - val_loss: 252.9603\n",
      "Epoch 874/1000\n",
      "5/5 - 0s - loss: 179.3714 - val_loss: 250.9431\n",
      "Epoch 875/1000\n",
      "5/5 - 0s - loss: 166.4245 - val_loss: 249.4648\n",
      "Epoch 876/1000\n",
      "5/5 - 0s - loss: 168.0881 - val_loss: 250.8576\n",
      "Epoch 877/1000\n",
      "5/5 - 0s - loss: 171.8537 - val_loss: 261.1641\n",
      "Epoch 878/1000\n",
      "5/5 - 0s - loss: 173.8360 - val_loss: 253.6353\n",
      "Epoch 879/1000\n",
      "5/5 - 0s - loss: 174.0443 - val_loss: 259.2098\n",
      "Epoch 880/1000\n",
      "5/5 - 0s - loss: 165.6847 - val_loss: 260.5583\n",
      "Epoch 881/1000\n",
      "5/5 - 0s - loss: 161.4964 - val_loss: 244.6744\n",
      "Epoch 882/1000\n",
      "5/5 - 0s - loss: 162.7548 - val_loss: 253.5984\n",
      "Epoch 883/1000\n",
      "5/5 - 0s - loss: 177.8902 - val_loss: 284.8253\n",
      "Epoch 884/1000\n",
      "5/5 - 0s - loss: 175.1992 - val_loss: 283.9938\n",
      "Epoch 885/1000\n",
      "5/5 - 0s - loss: 182.6970 - val_loss: 281.5378\n",
      "Epoch 886/1000\n",
      "5/5 - 0s - loss: 173.9557 - val_loss: 281.1740\n",
      "Epoch 887/1000\n",
      "5/5 - 0s - loss: 170.1252 - val_loss: 296.8915\n",
      "Epoch 888/1000\n",
      "5/5 - 0s - loss: 183.8992 - val_loss: 276.5156\n",
      "Epoch 889/1000\n",
      "5/5 - 0s - loss: 175.2587 - val_loss: 277.6664\n",
      "Epoch 890/1000\n",
      "5/5 - 0s - loss: 177.2021 - val_loss: 282.7345\n",
      "Epoch 891/1000\n",
      "5/5 - 0s - loss: 172.3723 - val_loss: 281.5344\n",
      "Epoch 892/1000\n",
      "5/5 - 0s - loss: 174.8598 - val_loss: 279.4706\n",
      "Epoch 893/1000\n",
      "5/5 - 0s - loss: 171.2417 - val_loss: 285.1879\n",
      "Epoch 894/1000\n",
      "5/5 - 0s - loss: 174.5670 - val_loss: 242.1945\n",
      "Epoch 895/1000\n",
      "5/5 - 0s - loss: 187.7479 - val_loss: 543.7020\n",
      "Epoch 896/1000\n",
      "5/5 - 0s - loss: 240.0863 - val_loss: 392.0551\n",
      "Epoch 897/1000\n",
      "5/5 - 0s - loss: 231.4596 - val_loss: 371.4683\n",
      "Epoch 898/1000\n",
      "5/5 - 0s - loss: 241.0039 - val_loss: 355.3514\n",
      "Epoch 899/1000\n",
      "5/5 - 0s - loss: 217.4536 - val_loss: 349.2319\n",
      "Epoch 900/1000\n",
      "5/5 - 0s - loss: 220.5835 - val_loss: 346.4801\n",
      "Epoch 901/1000\n",
      "5/5 - 0s - loss: 209.6724 - val_loss: 344.3977\n",
      "Epoch 902/1000\n",
      "5/5 - 0s - loss: 205.0153 - val_loss: 339.1029\n",
      "Epoch 903/1000\n",
      "5/5 - 0s - loss: 217.7508 - val_loss: 336.8804\n",
      "Epoch 904/1000\n",
      "5/5 - 0s - loss: 210.3230 - val_loss: 336.0476\n",
      "Epoch 905/1000\n",
      "5/5 - 0s - loss: 202.3333 - val_loss: 333.8792\n",
      "Epoch 906/1000\n",
      "5/5 - 0s - loss: 197.7968 - val_loss: 331.8941\n",
      "Epoch 907/1000\n",
      "5/5 - 0s - loss: 193.8638 - val_loss: 328.3090\n",
      "Epoch 908/1000\n",
      "5/5 - 0s - loss: 198.4854 - val_loss: 323.0724\n",
      "Epoch 909/1000\n",
      "5/5 - 0s - loss: 199.6654 - val_loss: 317.5713\n",
      "Epoch 910/1000\n",
      "5/5 - 0s - loss: 191.4333 - val_loss: 319.4500\n",
      "Epoch 911/1000\n",
      "5/5 - 0s - loss: 186.9817 - val_loss: 316.0433\n",
      "Epoch 912/1000\n",
      "5/5 - 0s - loss: 197.9898 - val_loss: 319.3231\n",
      "Epoch 913/1000\n",
      "5/5 - 0s - loss: 184.6201 - val_loss: 309.2091\n",
      "Epoch 914/1000\n",
      "5/5 - 0s - loss: 187.8586 - val_loss: 310.1116\n",
      "Epoch 915/1000\n",
      "5/5 - 0s - loss: 191.3259 - val_loss: 310.4189\n",
      "Epoch 916/1000\n",
      "5/5 - 0s - loss: 181.9589 - val_loss: 300.9490\n",
      "Epoch 917/1000\n",
      "5/5 - 0s - loss: 172.7478 - val_loss: 217.4200\n",
      "Epoch 918/1000\n",
      "5/5 - 0s - loss: 178.8292 - val_loss: 255.4659\n",
      "Epoch 919/1000\n",
      "5/5 - 0s - loss: 176.9903 - val_loss: 300.0978\n",
      "Epoch 920/1000\n",
      "5/5 - 0s - loss: 183.5206 - val_loss: 307.0366\n",
      "Epoch 921/1000\n",
      "5/5 - 0s - loss: 185.1440 - val_loss: 263.2298\n",
      "Epoch 922/1000\n",
      "5/5 - 0s - loss: 181.3331 - val_loss: 250.3484\n",
      "Epoch 923/1000\n",
      "5/5 - 0s - loss: 173.8809 - val_loss: 367.7310\n",
      "Epoch 924/1000\n",
      "5/5 - 0s - loss: 178.7755 - val_loss: 276.6222\n",
      "Epoch 925/1000\n",
      "5/5 - 0s - loss: 190.7591 - val_loss: 293.7648\n",
      "Epoch 926/1000\n",
      "5/5 - 0s - loss: 187.2568 - val_loss: 306.4396\n",
      "Epoch 927/1000\n",
      "5/5 - 0s - loss: 185.8237 - val_loss: 293.8887\n",
      "Epoch 928/1000\n",
      "5/5 - 0s - loss: 175.4393 - val_loss: 278.9443\n",
      "Epoch 929/1000\n",
      "5/5 - 0s - loss: 174.1462 - val_loss: 263.0941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 930/1000\n",
      "5/5 - 0s - loss: 170.5481 - val_loss: 264.3365\n",
      "Epoch 931/1000\n",
      "5/5 - 0s - loss: 174.3754 - val_loss: 262.7047\n",
      "Epoch 932/1000\n",
      "5/5 - 0s - loss: 184.1473 - val_loss: 238.7224\n",
      "Epoch 933/1000\n",
      "5/5 - 0s - loss: 201.3770 - val_loss: 518.2440\n",
      "Epoch 934/1000\n",
      "5/5 - 0s - loss: 224.7626 - val_loss: 429.9721\n",
      "Epoch 935/1000\n",
      "5/5 - 0s - loss: 203.7688 - val_loss: 312.9963\n",
      "Epoch 936/1000\n",
      "5/5 - 0s - loss: 212.5721 - val_loss: 255.2094\n",
      "Epoch 937/1000\n",
      "5/5 - 0s - loss: 182.8021 - val_loss: 267.7822\n",
      "Epoch 938/1000\n",
      "5/5 - 0s - loss: 199.0935 - val_loss: 264.2211\n",
      "Epoch 939/1000\n",
      "5/5 - 0s - loss: 191.4490 - val_loss: 257.2821\n",
      "Epoch 940/1000\n",
      "5/5 - 0s - loss: 182.6696 - val_loss: 241.6533\n",
      "Epoch 941/1000\n",
      "5/5 - 0s - loss: 174.8995 - val_loss: 309.5170\n",
      "Epoch 942/1000\n",
      "5/5 - 0s - loss: 181.6132 - val_loss: 252.8698\n",
      "Epoch 943/1000\n",
      "5/5 - 0s - loss: 173.8867 - val_loss: 321.4227\n",
      "Epoch 944/1000\n",
      "5/5 - 0s - loss: 183.8652 - val_loss: 263.8635\n",
      "Epoch 945/1000\n",
      "5/5 - 0s - loss: 184.1580 - val_loss: 261.9084\n",
      "Epoch 946/1000\n",
      "5/5 - 0s - loss: 189.5590 - val_loss: 279.1932\n",
      "Epoch 947/1000\n",
      "5/5 - 0s - loss: 179.4491 - val_loss: 281.3052\n",
      "Epoch 948/1000\n",
      "5/5 - 0s - loss: 195.5499 - val_loss: 281.0518\n",
      "Epoch 949/1000\n",
      "5/5 - 0s - loss: 184.4633 - val_loss: 306.6721\n",
      "Epoch 950/1000\n",
      "5/5 - 0s - loss: 187.9017 - val_loss: 315.3462\n",
      "Epoch 951/1000\n",
      "5/5 - 0s - loss: 178.1831 - val_loss: 316.5667\n",
      "Epoch 952/1000\n",
      "5/5 - 0s - loss: 182.5399 - val_loss: 311.1180\n",
      "Epoch 953/1000\n",
      "5/5 - 0s - loss: 185.5703 - val_loss: 309.1209\n",
      "Epoch 954/1000\n",
      "5/5 - 0s - loss: 188.5123 - val_loss: 292.4528\n",
      "Epoch 955/1000\n",
      "5/5 - 0s - loss: 177.2040 - val_loss: 284.4966\n",
      "Epoch 956/1000\n",
      "5/5 - 0s - loss: 178.8001 - val_loss: 295.4669\n",
      "Epoch 957/1000\n",
      "5/5 - 0s - loss: 180.2315 - val_loss: 286.9421\n",
      "Epoch 958/1000\n",
      "5/5 - 0s - loss: 178.0846 - val_loss: 258.2400\n",
      "Epoch 959/1000\n",
      "5/5 - 0s - loss: 173.8583 - val_loss: 251.9704\n",
      "Epoch 960/1000\n",
      "5/5 - 0s - loss: 167.5228 - val_loss: 285.0294\n",
      "Epoch 961/1000\n",
      "5/5 - 0s - loss: 175.0471 - val_loss: 307.3407\n",
      "Epoch 962/1000\n",
      "5/5 - 0s - loss: 181.5266 - val_loss: 312.0546\n",
      "Epoch 963/1000\n",
      "5/5 - 0s - loss: 183.0102 - val_loss: 311.6198\n",
      "Epoch 964/1000\n",
      "5/5 - 0s - loss: 182.5643 - val_loss: 309.8800\n",
      "Epoch 965/1000\n",
      "5/5 - 0s - loss: 179.2641 - val_loss: 300.5117\n",
      "Epoch 966/1000\n",
      "5/5 - 0s - loss: 177.3776 - val_loss: 295.1548\n",
      "Epoch 967/1000\n",
      "5/5 - 0s - loss: 171.4727 - val_loss: 299.0338\n",
      "Epoch 968/1000\n",
      "5/5 - 0s - loss: 185.4462 - val_loss: 298.5391\n",
      "Epoch 969/1000\n",
      "5/5 - 0s - loss: 168.8462 - val_loss: 287.0193\n",
      "Epoch 970/1000\n",
      "5/5 - 0s - loss: 175.1381 - val_loss: 287.7393\n",
      "Epoch 971/1000\n",
      "5/5 - 0s - loss: 171.8026 - val_loss: 260.1484\n",
      "Epoch 972/1000\n",
      "5/5 - 0s - loss: 176.5007 - val_loss: 243.0157\n",
      "Epoch 973/1000\n",
      "5/5 - 0s - loss: 170.8951 - val_loss: 222.3895\n",
      "Epoch 974/1000\n",
      "5/5 - 0s - loss: 178.0791 - val_loss: 231.6404\n",
      "Epoch 975/1000\n",
      "5/5 - 0s - loss: 164.7891 - val_loss: 240.3965\n",
      "Epoch 976/1000\n",
      "5/5 - 0s - loss: 165.6288 - val_loss: 237.2376\n",
      "Epoch 977/1000\n",
      "5/5 - 0s - loss: 165.8738 - val_loss: 241.0341\n",
      "Epoch 978/1000\n",
      "5/5 - 0s - loss: 168.0979 - val_loss: 232.6835\n",
      "Epoch 979/1000\n",
      "5/5 - 0s - loss: 159.8206 - val_loss: 223.7465\n",
      "Epoch 980/1000\n",
      "5/5 - 0s - loss: 166.8852 - val_loss: 232.2587\n",
      "Epoch 981/1000\n",
      "5/5 - 0s - loss: 155.3686 - val_loss: 235.4291\n",
      "Epoch 982/1000\n",
      "5/5 - 0s - loss: 158.8669 - val_loss: 249.5683\n",
      "Epoch 983/1000\n",
      "5/5 - 0s - loss: 165.0041 - val_loss: 240.7859\n",
      "Epoch 984/1000\n",
      "5/5 - 0s - loss: 163.0570 - val_loss: 237.7721\n",
      "Epoch 985/1000\n",
      "5/5 - 0s - loss: 163.9080 - val_loss: 238.1744\n",
      "Epoch 986/1000\n",
      "5/5 - 0s - loss: 161.9958 - val_loss: 231.5216\n",
      "Epoch 987/1000\n",
      "5/5 - 0s - loss: 158.4456 - val_loss: 232.0597\n",
      "Epoch 988/1000\n",
      "5/5 - 0s - loss: 167.2540 - val_loss: 231.0936\n",
      "Epoch 989/1000\n",
      "5/5 - 0s - loss: 169.6335 - val_loss: 234.4049\n",
      "Epoch 990/1000\n",
      "5/5 - 0s - loss: 169.2550 - val_loss: 244.2201\n",
      "Epoch 991/1000\n",
      "5/5 - 0s - loss: 169.4128 - val_loss: 261.0981\n",
      "Epoch 992/1000\n",
      "5/5 - 0s - loss: 166.6464 - val_loss: 248.2285\n",
      "Epoch 993/1000\n",
      "5/5 - 0s - loss: 172.7163 - val_loss: 248.2401\n",
      "Epoch 994/1000\n",
      "5/5 - 0s - loss: 166.3302 - val_loss: 236.5108\n",
      "Epoch 995/1000\n",
      "5/5 - 0s - loss: 170.1215 - val_loss: 237.5388\n",
      "Epoch 996/1000\n",
      "5/5 - 0s - loss: 169.9686 - val_loss: 277.3940\n",
      "Epoch 997/1000\n",
      "5/5 - 0s - loss: 174.6409 - val_loss: 286.1938\n",
      "Epoch 998/1000\n",
      "5/5 - 0s - loss: 169.4449 - val_loss: 278.6649\n",
      "Epoch 999/1000\n",
      "5/5 - 0s - loss: 176.4785 - val_loss: 276.2386\n",
      "Epoch 1000/1000\n",
      "5/5 - 0s - loss: 170.7800 - val_loss: 277.9518\n"
     ]
    }
   ],
   "source": [
    "history = lstm_model.fit(train_X, train_y, epochs=1000, batch_size=72, validation_data=(test_X, test_y), verbose=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Based on the num_predictions we choose, we predict on that many random time series and derive a resulting root mean square error\n",
    "\n",
    "# The resulting prediction is sufficiency rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. Estimator expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-648-b4a6bd2cc9f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0myhat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlstm_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myhat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mrmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_bridge_management\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_bridge_management\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[0;32m    254\u001b[0m     \"\"\"\n\u001b[0;32m    255\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[1;32m--> 256\u001b[1;33m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[0;32m    257\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     output_errors = np.average((y_true - y_pred) ** 2, axis=0,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_bridge_management\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_bridge_management\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_bridge_management\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    639\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n\u001b[1;32m--> 641\u001b[1;33m                              % (array.ndim, estimator_name))\n\u001b[0m\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with dim 3. Estimator expected <= 2."
     ]
    }
   ],
   "source": [
    "\n",
    "yhat = lstm_model.predict(test_X)\n",
    "    \n",
    "mse = mean_squared_error(test_y, yhat)\n",
    "rmse = math.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_bridge_management_kernel",
   "language": "python",
   "name": "tf_bridge_management"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
